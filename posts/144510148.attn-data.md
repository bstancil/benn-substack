# Attn: Data

*We worry about analysis, but maybe attention really is all you need. *

---

![](https://substackcdn.com/image/fetch/$s_!IGUZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63305b21-1035-4db5-8b3e-bf4b45001d58_1600x855.png)

A few months ago, [I said there were two ways](https://benn.substack.com/p/avg-text) to figure out how to fix a failing bar:[^1] 

I thought that option two was better, and [AI might make it better still](https://benn.substack.com/p/avg-text). But there’s actually a third option that I didn’t think of: You could *watch* people. You could sit in the corner of the bar with a notepad, and write down everything you see. The point isn’t to quantify it—that’s just manual data capture—but to actively listen, and see if you notice anything surprising. Watch what customers order; what they do; what types of people come in your door. [Do you notice patterns?](https://www.tiktok.com/@_sophiereich_/video/7275843741397650730)[^2] When your [DJ](https://www.youtube.com/@djearworm)[^3] starts their set, does it [get the people going](https://www.tiktok.com/@andrepower/video/7365984429019352350), or do they [start shopping](https://www.youtube.com/watch?v=gLnlXAIdWw0) on their phones? Though your conclusions may not be “statistically significant,” or even quantifiable, they still have force. You don't need to know how to define dancing to know when [something is a banger](https://www.youtube.com/watch?v=YghDpAEECs8).[^4] 

On one hand, this third option is terrible, because it’s a combination of the worst elements of the other two. Observations, like the behavioral datasets that you, are an indirect way to understand customers’ opinions. But unlike working with data, observation is hard to scale. At the end of a night of note-taking, there’s no way to aggregate up what you saw into precise facts and figures. It’s analysis by anecdote, math by memory, and inference by vibe. We can add up structured [likes and dislikes](https://www.instagram.com/p/C6pzEgtu2q9), but we don’t have a way to “average” [200,000 freeform comments](https://www.youtube.com/watch?v=HJeY-FXidDQ)[^5]—and we don’t have a way to average eight hours of passive observation either. The best we can do is watch, and then ask ourselves if we remember seeing anything interesting.

On the other hand, watching customers includes some of the best parts of user research and of data analysis. Like behavioral logs, observations are revealed preference; they are “true,” and not self-reported representations that [may not always be entirely honest](https://www.youtube.com/watch?v=2QiFl9Dc7D0&t=357s). Moreover, unlike behavioral logs, observations can capture things that are difficult to quantify, or things we haven’t thought to quantify.[^6] 

Perhaps most importantly, though, watching customers can reveal surprising results that *we didn’t think to ask about. *This is one of the biggest problems with traditional data analysis. The insights hidden in it like the [Isla de Muerta](https://pirates.fandom.com/wiki/Isla_de_Muerta): They can’t be found except by those who already know where they are. User research and open-ended feedback forms don’t have that problem—and neither does watching customers from the corner of a bar. If you watch for long enough, and remember what you see well enough, you’d probably see a lot of things that you never would’ve thought to look for. 

Of course, that’s a big if. You have a bar to tend; you can’t actually spend all night [terrorizing your customers with your furious note-taking](https://www.youtube.com/watch?v=i1zpv8grBiM). It’s also hard to remember everything you see, and your conclusions, though emergent, would likely be plagued by [recency](https://en.wikipedia.org/wiki/Recency_bias) and [availability](https://en.wikipedia.org/wiki/Availability_heuristic) biases.  

But what if you had an army of invisible watchmen, with a notepad long enough to perfectly record every detail they saw, and with a memory sharp enough to be able to recall all of it at once? What if you could ask that omniscient thing what *it *saw that was interesting and surprising? What if you had three tools for saving your bar—a database of numbers to analyze, a library of customer interviews, or this third thing, a thing that watches everything, remembers all of it, and finds patterns in the noise—which would you choose?[^7]

I mean, you might not always choose the third one, but it’d be a pretty nice option to have. Because it’s not data analysis, exactly, but it’s something bigger: *It’s the goal of data analysis.* Most analysis is meant to find these sorts of patterns in charts and graphs. What if we didn’t need the numbers at all, but we could just watch and remember?

# Attention is all you have

When ChatGPT first came out, [a](https://julius.ai/) [whole](https://datagpt.com/) [bunch](https://www.getdot.ai/) [of](https://www.narrative.bi/ai-data-analyst) [startups](https://talktodata.ai/) immediately tried to use it to help analysts with option one. On the surface, that made sense: Companies have enormous haystacks of data, there are (allegedly) patterns in that data, and LLMs are built on top of literally every recorded idea in human history. If something could connect the dots in our datasets, it would be ChatGPT.

So far, it hasn’t really worked. According to dbt Labs’ recent survey of data professionals, [only a third](https://roundup.getdbt.com/p/how-is-the-state-of-analytics-engineering) of them are using AI in their daily workflows, and I’d guess a much smaller fraction of them are using it to do analysis directly. As [Seth Stephens-Davidowitz said of his book](https://benn.substack.com/p/playing-for-ourselves) *Who Makes the NBA?: Data-Driven Answers to Basketball's Biggest Questions*—which he wrote in thirty days with heavy support from ChatGPT—though AI “eliminates all the parts of my job or work process that I hate [like] cleaning datasets, merging datasets,” its “current capabilities in correlating [its] extensive knowledge to generate new theories or uncover complex patterns were limited.” 

In hindsight, that also makes sense. A lot of analysis is logical reasoning. It’s asking, “Why might people not like my bar?,” and thinking through the possible causes. To do that, you need a rough theory of how bars work, and what people like, and how those things are connected.  

Large language models only *appear* to use theory and reason. Instead, what makes them powerful is that they have incredible memories. If you ask ChatGPT to write a blog post that’s full of subliminal messages that compel people to buy technology stocks, it will recall an enormous corpus of blog posts. It will find texts that it associates with subliminal messages. It will fetch everything it knows about technology stocks.[^8] And it will then smash them all together [into a post](https://chat.openai.com/share/b990cb1f-0afe-4ec0-8326-df57ff0e3c02) that represents a rough average of every related piece of content that’s ever been written.[^9] It doesn’t know what the prompt it was given *means*;[^10] it only knows how to create something that fits the prior patterns of everything it’s observed.

In some very rough sense, that’s what LLMs are—engines for finding patterns in words. But the underlying [transformer architecture](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)) behind LLMs can be applied to any sorts of sequences.[^11] ChatGPT and other LLMs take input text, break it up into small chunks, turn those chucks into complex mathematical objects, and predict, based on historical patterns, what should come next. People have already built models that do the same thing for [audio](https://suno.com/) and [video](https://pika.art/home), using essentially the same architecture.[^12] They listen to and watch everything, remember all of it, and reproduce the patterns that they see. 

If we can build models that do for audio and video what LLMs did for text, could we build the same sorts of models on behavioral data? Could AI save my bar, not via LLMs cosplaying as analysts writing SQL queries,[^13] but via transformers trained directly on sequences of customer purchases and interactions? 

# Large data models

I guess we’ll find out. Earlier this year, Motif Analytics[^14] announced that they’re building [foundation models of event sequences](https://www.motifanalytics.com/posts/foundation-models-product-analytics): 

> To model event sequences with minimal changes to the underlying data, our approach is to mimic the training of LLMs on text data but with two key modifications:
> These architectures comprise what we are calling Generalized Large Event Analytics models (✨GLEAM✨).

Motif is building a model that takes streams of product event data—which includes the event itself *and* attributes about the event, like who the user was, the device they were using, how long they’ve been a user, and so on—breaks those events into chunks, and turns those chucks into complex mathematical objects. They then use the same transformer architecture that powers LLMs to predict what events are likely to come next, based on what happened, who did it, and the context in which they did it. It’s a machine for observing everything, and finding patterns. 

Will it work? I have no idea. Training LLMs is still very hard, and requires a lot of finessing and fine-tuning to get right. Training a similar model on events is surely even harder. There’s also no internet of event logs to scrape. This whole idea could be crazy.

But I’m intrigued, because it’s one of the first efforts I’ve seen that attempts to apply [the bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) to analytical problems. GLEAM isn’t trying “to make systems that worked the way the researchers thought their own minds worked;” it’s not trying to build [knowledge or theory into AI agents](https://roundup.getdbt.com/i/142548734/third-mamba-and-jepa); it’s not trying to do analysis by making computers act like analysts. Instead, it treats AI like what it is: a blistering calculator with a breathtaking memory. It’s feeding patterns into a pattern-generation machine. And it’s saying that maybe people can get what they* want* from analysis—an understanding of the patterns in the world around us—without actually *doing* analysis, or even directly touching data. 

Which is perhaps exactly what we need. [The numbers may have been the problem all along.](https://benn.substack.com/p/disband-the-analytics-team#:~:text=Perhaps%20that%E2%80%99s%20actually%20what%E2%80%99s%20held%20us%20back%20for%20so%20long%3A%20numbers%2C%20more%20or%20less.) Data quality is really hard.[^15] [Math is even harder.](https://twitter.com/bcrypt/status/1788406218937229780) Let’s be humble, and get [some help](https://www.youtube.com/watch?v=4QIZE708gJ4).[^16] Transformers, if applied directly on top of the behaviors we want to find patterns in, could finally be what saves our bad bar—even if [they couldn’t](https://www.billboard.com/music/rb-hip-hop/drake-removes-taylor-made-freestyle-ai-tupac-snoop-1235667030/) save some people from [theirs](https://genius.com/31652831).


---


[^1]: Then, it was a hypothetical bar. It still is, but [I’m](https://benn.substack.com/p/bis-third-form#:~:text=Ten%20years%20ago%2C%20if%20you%20were%20a%20jaded%20forty%2Dsomething%2Dyear%2Dold%20tech%20executive%2C%20you%20bought%20a%20Porsche%20and%20a%20house%20in%20Jackson.%20You%20opened%20a%20bar%20in%20Oakland%2C) getting [closer](https://benn.substack.com/p/oops#footnote-1-143303690).

[^2]: I want a boy in Sig Nu, [full-pay](https://collegeinsidetrack.com/full-pay-as-a-college-strategy/), five eight, boat shoes.

[^3]: Give it up for the real [DJ Earworm](https://www.nytimes.com/2024/05/08/us/rfk-jr-brain-health-memory-loss.html).

[^4]: These [two](https://www.youtube.com/watch?v=YghDpAEECs8) reaction [videos](https://www.youtube.com/watch?v=ZuhjP8YbScE) are good examples of how option three is different from options one and two. If you wanted to figure out how people felt about the two songs, you could try to measure it with data. But using what metric? Head nods? Smiles versus aghast stares? How would you even track that? Or, if you preferred option two, you could ask peole what they thought of each song. They’d probably give somewhat political answers though, based on what they thought other people thought about them, and based on how they felt about the overall beef. But if you just watched the video and looked for informal patterns, it’s very easy to figure out [the vibe](https://www.youtube.com/clip/Ugkxgq1jmio0nfOrYIs6zm6MQIhlUF4rwyqT).

[^5]: Not yet! But people [are](https://flexor.ai/) [doing](https://docs.snowflake.com/en/user-guide/snowflake-cortex/llm-functions) [it](https://cloud.google.com/blog/products/data-analytics/genai-and-google-cloud-ml-to-get-actionable-insight)!

[^6]: I.e., the stuff in the reaction videos.

[^7]: I guess you also have a fourth option for saving a bad bar, which is to [write a song](https://twitter.com/ZeoVGM/status/1787296701490819536) that says, nuh uh, the [pub](https://itsalwayssunny.fandom.com/wiki/Paddy%27s_Pub) isn’t bad, actually. I doubt it would work, but Stranger Things [have happened](https://www.youtube.com/watch?v=HJeY-FXidDQ&t=187s).

[^8]: This isn’t exactly true. LLMs only appear to have incredible memories too. There is no database of every book that’s ever been written in ChatGPT; it can’t “remember” all of *Moby Dick*. Instead, there is a giant predictive model that’s been trained on every book that’s ever been written, and *Moby Dick—*and everything else—alters inside the weights in that model.

[^9]: Less generously, [it will crush centuries of human creativity and expression](https://twitter.com/tim_cook/status/1787864325258162239) into a [single sterile screen](https://jacobbacharach.com/2024/05/08/happiness-or-not-at-all/).

[^10]: If you need proof that ChatGPT has no theory about what words actually mean, it called the blog post that was supposed to subliminally convince people to buy technology stocks “Unleashing Future Potential: Why Investing in Technology Stocks is a Smart Move.” Though, fair, I guess it would’ve been easier to brainwash Derek Zoolander to kill the prime minister of Malaysia with a song called *Derek Zoolander, go kill the prime minister of Malaysia *than with one called *[Relax](https://www.youtube.com/watch?v=JjsjHzh815Q).*

[^11]: I think? I should caveat this by saying that I have no idea what I’m actually talking about. My career as a proper data scientist started and ended with scoring a few A/B tests [using high school statistics](https://en.wikipedia.org/wiki/Student%27s_t-test) written in raw SQL, so I’m making most of this up as I go.

[^12]: [From OpenAI:](https://openai.com/index/video-generation-models-as-world-simulators/#:~:text=The%20success%20of%20the%20LLM,for%20models%20of%20visual%20data)The success of the LLM paradigm is enabled in part by the use of tokens that elegantly unify diverse modalities of text—code, math and various natural languages. In this work, we consider how generative models of visual data can inherit such benefits. Whereas LLMs have text tokens, Sora has visual *patches*. Patches have previously been shown to be an effective representation for models of visual data.

[^13]: My brother in Christ, it is the year 2024, why are we still doing [this](https://arslanshahid-1997.medium.com/chatgpt-vs-claude-3-which-is-better-for-text-to-sql-e2eee59ea581)?

[^14]: My only advice: [Drop the “analytics.”](https://mediaoptions.com/blog/on-the-record-why-mode-analytics-acquired-mode-com/) Just, Motif. [It’s cleaner.](https://www.youtube.com/watch?v=PEgk2v6KntY)

[^15]: It’s [common](https://blog.dataiku.com/why-data-quality-matters-in-the-age-of-generative-ai) for [people](https://shelf.io/blog/garbage-in-garbage-out-ai-implementation/) to say that generative AI makes data quality even more important. Bad training data makes bad models; garbage in, garbage out; all that. That feels…backwards? Messy data is a problem for computing metrics, because one incorrect bar tab will make your revenue KPI wrong. However, if your goal is to understand patterns, you’re looking for approximations. Tools like Motif could reach the conclusion that customers who spend a lot of money tend to order wine on top of pretty messy data. In some ways, that’s the beauty of transformers. You can stuff a bunch of messy data underneath them and they don’t lose their balance. I mean, ChatGPT is trained *on* *Reddit.*

[^16]: I know it’s rap battle week, but this wasn’t bad? A little disappointing compared to the [teaser](https://www.tiktok.com/@postmalone/video/7361929441620004139) though.