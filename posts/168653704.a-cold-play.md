# A cold play

*Google engineers half an acquisition—but did they buy the wrong half?*

---

![Left Behind movie review & film summary (2014) | Roger Ebert](https://substackcdn.com/image/fetch/$s_!-IXX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81d60eff-ca35-4973-bb95-97d8cb0a04b1_1200x501.jpeg)
*[best talent](https://en.wikipedia.org/wiki/Nicolas_Cage)*

How much is chatgpt.com worth?

Not OpenAI, or the various large language models that run behind ChatGPT, or even the boxes and buttons on the website—how much is the *domain* worth? Like, if Sam Altman forgot to update his credit card on GoDaddy, lost the domain, and someone tried to sell it on eBay, how much would it go for?

I mean, it is not worth very much *to me*. I don’t own a chatbot[^1] or a large language model. If people started going to my version of chatgpt.com, they would quickly realize that it was not the ChatGPT they were looking for and leave. The most I could get out of it would be a few days of redirected traffic to my SoundCloud, and a [mildly viral LinkedIn post](https://www.linkedin.com/pulse/i-purchased-domain-googlecom-via-google-domains-sanmay-ved/). That is not worth very much.

But how much would chatgpt.com be worth to, say, Google?

Google, unlike me, owns a chatbot and a large language model. If Google secretly bought chatgpt.com, they could replace OpenAI’s GPT models with their own Gemini models. They could build a new website that looks a lot like the old website. They could keep serving a chatbot at chatgpt.com.

And if they did that, would anything happen? Would anyone even notice?[^2] Would chatgpt.com continue to be the dominant chatbot *website*, and Gemini would, almost overnight, become the dominant chatbot *model*?

I have no idea. But that at least seems plausible? Most people aren’t rigorously evaluating the quality of a chatbot’s responses, and the [people](https://www.linkedin.com/posts/emollick_when-reading-ai-benchmarks-aside-from-the-activity-7324896860186304513-SJgx/) who are [don’t agree](https://techcrunch.com/2025/02/22/did-xai-lie-about-grok-3s-benchmarks) on [how to do it](https://techcrunch.com/2024/03/07/heres-why-most-ai-benchmarks-tell-us-so-little/). Which isn’t to say the model isn’t important—of course it is; that's why chatgpt.com isn't worth very much to me. But the technical edge that OpenAI’s models arguably have over Gemini isn’t why chatgpt.com has a commanding share of today’s consumer AI market. OpenAI is winning because they built the first good chatbot product and because it became the default. As Nan Yu, who runs product at Linear, has argued, people adopt AI products that [offer great user experiences](https://thenanyu.com/ux.html), not because they’re powered by marginally better models:

> Those products won because they made powerful, highly technical tools accessible through thoughtful design. The biggest barrier to mass AI adoption is not capability or intelligence; we have those in spades. It's UX.
> The magic of something like Cursor is that there's a workflow which is heavily orchestrated to help users utilize the power that LLMs can provide. Sure — at its core, there's a series of prompts and calls to base models that generates the code... but this is marshaled through a UI that keeps users continuously flowing through the *prompt > generate > eval > test* loop.
> …
> We're still barely scratching the surface. For all of its success, tools like Cursor are still built for a highly technical audience. AI adoption won't come from more powerful models or CEO mandates — it will come from thoughtfully designed interfaces that make intelligence accessible to everyone.

Moreover, for sufficiently large companies like OpenAI, product advantages can become self-reinforcing: The more people use ChatGPT, the faster it can be refined; owning a wildly popular product helps OpenAI attract more talent; what OpenAI builds becomes an ecosystem standard; ChatGPT becomes a generic trademark, a verb. [From this blog](https://benn.substack.com/p/ai-companies-are-just-saas-companies) last year:

> [Some people might argue that] OpenAI is on track to make [11.6 billion dollars](https://finance.yahoo.com/news/openai-sees-11-6-billion-001354946.html) next year because people want to use the best model.
> Except—ChatGPT might [not be the best model](https://lmarena.ai/?leaderboard). Satya Nadella, who [might own OpenAI](https://www.bloomberg.com/opinion/articles/2024-10-21/who-owns-openai), said that leading models [aren’t all that essential anyway](https://x.com/SouthernValue95/status/1867339940159533419). And if [nobody can tell the difference](https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing) between human paintings and AI paintings, I’m skeptical that many people can tell if their book report on *The Great Gatsby* was written by GPT-4o or Gemini 1.5 Flash.
> Instead, it seems much more likely that OpenAI is going to make 11.6 billion dollars because ChatGPT is popular. It became synonymous with AI, the leading company that no CIO gets fired for buying, and the website that every high schooler has bookmarked. It’s going to make 11.6 billion dollars because it’s got the best *brand*.

While it’s easy to get distracted by benchmarks and claims about [which model is smartest](https://x.com/xai/status/1943786239376937389), horsepower alone only gets you so far. You also need a product that people both like to use and *think* to use. And OpenAI’s biggest edge today might be that when people think to use a chatbot, they think to go to chatgpt.com.

—

This—ironically; [so, so ironically](https://www.semrush.com/website/top/)—is potentially Google’s biggest problem as an AI vendor: They haven’t figured out how to get people to use their models. They own several of the world’s most popular productivity tools; they own the world’s most popular websites; they own the world’s [most popular](https://gs.statcounter.com/browser-market-share) browser and control the [most popular](https://gs.statcounter.com/os-market-share/mobile/worldwide) mobile operating system; they [arguably](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#enhanced-reasoning) have the [best](https://lmarena.ai/leaderboard) large language models. And yet, so far, it hasn't entirely added up. OpenAI dominates the consumer chatbot market, and Anthropic’s Claude is becoming the [preferred model](https://creatoreconomy.so/i/164041918/so-which-model-should-you-use) for code-writing [apps](https://www.linkedin.com/posts/lovable-dev_lovable-is-now-using-the-new-sonnet-37-ai-activity-7300808870887636993-Ei47/) and [agents](https://forum.cursor.com/t/default-option-in-the-model-selection-menu/58360). Some people assume [it’ll all eventually come together](https://x.com/buccocapital/status/1943041520556478700)—their current products, their existing distribution, their models, their [very big bank account](https://companiesmarketcap.com/alphabet-google/cash-on-hand/)—and we’ll all begin spending vast amounts of money on Google’s AI services. But how?

—

We know the story by now, or at least, we know *of* the story. A couple months ago, Windsurf, one of the more popular AI-powered coding applications, [agreed to be acquired by OpenAI](https://www.bloomberg.com/news/articles/2025-05-06/openai-reaches-agreement-to-buy-startup-windsurf-for-3-billion), which had previously [tried to acquire](https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html) Cursor, the *most* popular AI-powered coding application. Someone changed their mind, the deal between Windsurf and OpenAI fell apart, and Windsurf [sold itself to Google](https://www.reuters.com/business/google-hires-windsurf-ceo-researchers-advance-ai-ambitions-2025-07-11/) instead.[^3]

Well, sort of. Google [bought the executive team](https://www.bloomberg.com/news/articles/2025-07-11/openai-s-3-billion-deal-to-buy-ai-startup-windsurf-falls-apart) and a few dozen AI engineers for $2.4 billion, paid off investors, and left the company, the product, and a couple hundred employees behind. Windsurf’s smoking husk was then immediately bought by Cognition, yet another AI-powered coding application.

Most of the conversation about the whole drama has been understandably focused on the circus: [Who got paid?](https://x.com/jordihays/status/1944489942874456153) Who knifed whom? Will there ever be [normal acquisitions](https://www.newcomer.co/p/windsurfs-double-deal-marks-a-new) anymore? Are these sorts of bizarro acquisitions shrewd or stupid? Is Silicon Valley [broken](https://stratechery.com/2025/google-and-windsurf-stinky-deals-chestertons-fence-and-the-silicon-valley-ecosystem/)?

All fair and fun questions. But there’s another question buried in all of this too: Did Google buy the right thing?

On one hand, of course they did. The prize for building the best LLM is somewhere between hundreds of billions of dollars and complete hegemonic domination over all of humanity. So, in 2025, AI engineers are worth an [infinite amount of money](https://www.wsj.com/tech/ai/meta-ai-recruiting-mark-zuckerberg-5c231f75), and [fast-growing AI wrappers](https://cognition.ai/blog/windsurf#:~:text=%2482M%20of%20ARR%20and%20a%20fast%2Dgrowing%20business%2C%20with%20enterprise%20ARR%20doubling%20quarter%2Dover%2Dquarter) and a nice brand are worth much less. Google bought the valuable thing—the engineers—for a very big number; Cognition bought the pedestrian things—a business and a product—for a much smaller number.

On the other hand, the product is what Google needs! Google already has a lot of AI engineers, and they already have very good models.[^4] They have unrivaled channels for distribution. What they’re missing is something that convinces people to use those models, as often as possible.

And the talent that Google appears to have left behind at Windsurf—the application engineers and product designers, among others—seems to be the talent that can do exactly that. Because one thing that is undeniably true about Windsurf, which grew [to a $100 million business](https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/#:~:text=While%20Windsurf%20is%20a%20comparatively%20smaller%20company%2C%20its%20ARR%20is%20about%20%24100%20million%2C%20up%20from%20%2440%20million%20in%20ARR%20in%20February%2C%20according%20to%20a%20source.%C2%A0) in a matter of months, is that they built a good *product*. They made “thoughtfully designed interfaces that make intelligence accessible to everyone.” They solved the UX problem.

These days, it’s common for people to dismiss a lot of AI applications as wrappers around major LLMs providers. These businesses have no moat because they’re thin, cheaply addictive products; they have [terrible margins](https://x.com/jsnnsa/status/1941306461402829189) because they use a ton of foundational model compute. But if you’re Google, isn’t that exactly what you want?[^5] Aren’t products like that what your existing models need? Who is actually more valuable to Google: Some AI engineers that can make Gemini a little bit better, or the people who can make a thin, addictive product that pushes massive amounts of traffic to Gemini?[^6]

That is, after what chatgpt.com really is—an addictive wrapper around OpenAI’s LLMs. And today, is that wrapper, and all of the habits and bookmarks that come with it, not just as valuable to OpenAI as their models?[^7]


---


[^1]: And if I did, it would clearly be hosted at [benn.chat](https://benn.chat/).

[^2]: People would lose things like their chat histories and [memories](https://help.openai.com/en/articles/8590148-memory-faq), and they would probably notice that, so don’t take this question too literally. The more precise question is, “would people notice if the model answering their questions on ChatGPT was Gemini instead of GPT 4o?”

[^3]: Which, yes! Correct! [Sell!](https://benn.substack.com/p/startups-still-arent-businesses-yet?utm_source=publication-search#:~:text=On%20one%20hand,tick%20that%20bubble!)

[^4]: Obviously, models can always be better; having more talent is better than less talent; maybe Windsurf’s AI engineers are uniquely good. DeepMind certainly knows what sort of technical talent they need much more than I do.

[^5]: And bizarrely, isn’t that exactly what a coding app like Cognition *doesn’t* want?

[^6]: Are the people who were left behind at Windsurf people who can build this sort of product? I don’t know; it’s possible Google simply decided that they weren’t. But thousands of startups have tried to build AI products on top of the same handful of models, and Windsurf did it better than nearly all of them.

[^7]: Or, if you’re Google, here’s another idea, if you want a better and cheaper wrapper around Gemini: Make the Google search box bigger.People already [like Google’s AI Mode more](https://www.threads.com/@eric_seufert/post/DL9_MDpt6zZ/in-a-survey-by-oppenheimer-co-related-to-user-satisfaction-with-googles-ai-mode-) than ChatGPT! But one-line boxes are for search! Two-line boxes are for chat! Even if you can AI Mode from google.com, nobody’s gonna chat in a one-line box! So just make it a two-line box! *That’s* the thoughtfully designed interface that make Gemini accessible to everyone. Google doesn’t need a $2 billion acquisition. Google just needs some [new CSS](https://benn-dot-files.s3.us-west-2.amazonaws.com/google-homepage.png).