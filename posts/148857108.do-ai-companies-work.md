# Do AI companies work?

*The market needs to be irrational for you to stay solvent. *

---

![](https://substackcdn.com/image/fetch/$s_!IAAY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ec1c7ad-3195-4860-a7a7-a800dfeb58b2_1440x808.png)

I mean, surely something in this sequence is wrong, right?

Eighteen months ago, I said that foundational LLM vendors are potentially [the next generation of cloud providers](https://benn.substack.com/p/the-public-imagination):

> So here's an obvious prediction: AI will follow a nearly identical trajectory [as AWS, Azure, and GCP]. In ten years, a new type of cloud—a generative one, a commercial Skynet, a public imagination—will undergird nearly every piece of technology we use. 

Other people have [made similar comparisons](https://www.linkedin.com/pulse/openai-gives-you-next-aws-google-search-howie-xu/). And on the surface, the analogy seems roughly reasonable. Foundational models require tons of money to build, just like cloud services do. Both could become ubiquitous pieces of the global computing infrastructure. The market for both is easily in the tens of billions of dollars, likely in the hundreds of billions, and potentially in the trillions. 

There is, however, one enormous difference that I didn’t think about: *You can’t build a cloud vendor overnight. *Azure doesn’t have to worry about a few executives leaving and building a worldwide network of data centers in 18 months. AWS is an internet business, but it dug its competitive moat in the physical world. The same is true for a company like Coca-Cola: The secret recipe is important, but not *that *important, because a Y Combinator startup couldn’t build factories and distribution centers and relationships with millions of retailers over the course of [a three month sprint](https://www.ycombinator.com/about#:~:text=YC%20is%20a%20three%20month%20program.%20%C2%A0).

But an AI vendor could? Though OpenAI’s work requires a lot of physical computing resources, they’re leased (from Microsoft, or AWS, or GCP), not built. Given enough money, anyone could have access to the same resources. It’s not hard to imagine a small team of senior researchers leaving OpenAI, [raising a ton of money to rent some computers](https://www.reuters.com/technology/artificial-intelligence/openai-co-founder-sutskevers-new-safety-focused-ai-startup-ssi-raises-1-billion-2024-09-04/), and being a legitimate disruptive threat to OpenAI’s core business in a matter of months. 

In other words, the billions that AWS spent on building data centers is a lasting defense. The billions that OpenAI spent on building prior versions of GPT is not, because better versions of it are already [available for free on Github](https://github.com/meta-llama/llama). Stylistically, Anthropic put itself deeply in the red to build ten incrementally better models; eight are now worthless, the ninth is open source, and the tenth is the thin technical edge that is keeping Anthropic alive. Whereas cloud providers can be disrupted, it would almost have to happen slowly. Every LLM vendor is eighteen months from dead.[^3] 

What, then, is an LLM vendor’s moat? Brand? Inertia? A better set of applications built on top of their core models? An ever-growing bonfire of cash that keeps its models [a nose ahead](https://www.youtube.com/shorts/bHKPQGHSqqE) of a hundred competitors? 

I honestly don’t know. But AI companies seem to be an extreme example of the market [misclassifying software development costs as upfront investments](https://benn.substack.com/p/do-software-companies-actually-have) rather than necessary ongoing expenses. An LLM vendor that doesn’t spend tens of millions of dollars a year—and maybe billions, for the leaders—improving their models is a year or two from being out of business. 

Though that math might work for huge companies like Google and Microsoft, and for OpenAI, which has become synonymous with artificial intelligence, it’s hard to see how that works for smaller companies that aren’t already bringing in sizable amounts of revenue. Though [giant round funding rounds](https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/), often given to pedigreed founders, can help them jump to front of the race, it’s not at all obvious [how they stay there](https://sifted.eu/articles/three-cofounders-leave-h-news), because someone else will do the same thing a year later. The have to  either raise enormous amounts of money in perpetuity,[^4] or they have to start making billions of dollars a year. That’s an awfully high hurdle for survival.

In this market, timing may be everything: At some point, the hype will die down, and people won’t be able to raise these sorts of rounds. And the winners won’t be who ran the fastest or reached some finish line, but whoever was leading when the market decided the race is over. 


---


[^1]: I guess some people would say this is true until AGI solves it for us? It gets more expensive until you build a robot that does it for you, and then it gets way cheaper.

[^2]: [It’s a concept of a plan.](https://www.tiktok.com/@kamalahq/video/7413211787174137131)

[^3]: This is even more true with AI applications. Copilot was the future of software development, then [Poolside](https://poolside.ai/), then [Devin](https://www.theinformation.com/articles/six-month-old-ai-coding-startup-valued-at-2-billion-by-founders-fund), now [Cursor](https://dataphoenix.info/anysphere-the-startup-behind-cursor-raised-a-60m-series-a/).

[^4]: The market needs to be [irrational for you to stay solvent](https://www.goodreads.com/quotes/603621-markets-can-remain-irrational-longer-than-you-can-remain-solvent).