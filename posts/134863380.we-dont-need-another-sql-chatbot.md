# We don‚Äôt need another SQL chatbot

*We want one, to do the tedious parts of our job. But it might be better suited to take the fun parts.*

---

![](https://substackcdn.com/image/fetch/$s_!M2iy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf4c63f-0f38-4822-ba34-ca0b5e3fe745_3488x1958.png)
*Attack of the the Clones, 2002.*

Another week, another text-to-SQL chatbot.

Ask it a question; it‚Äôll write a query. Ask it a question, it‚Äôll send a thin prompt to ChatGPT: ‚ÄúYou are a senior data analyst. Here are some notes about a few tables and a sample query.‚Äù Ask it a question, and it‚Äôll send your entire schema, your dbt project, and your data dictionary‚Äôs API keys to Claude. It uses LangChain to validate SQL syntax; [it doesn‚Äôt use LangChain](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm#correctness_and_usefulness_can_be_at_odds#llms_are_slow_and_chaining_is_a_nonstarter) because it‚Äôs too slow; it uses LangChain to ensure industry-leading accuracy; it doesn‚Äôt use LangChain because its errors compound into [a Waluigi](https://www.lesswrong.com/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post).¬†

The bots are everywhere. They‚Äôre launching on Hacker News; they‚Äôre asking for your upvotes on Product Hunt. They‚Äôre in your Slack; they‚Äôre in your database; they‚Äôre in your Twitter DMs; they‚Äôre in Section 4, Article C of the update to your terms of surface. They‚Äôre tacked on to your favorite data tool; they‚Äôre your friend‚Äôs startup; they‚Äôre your other friend‚Äôs startup‚Äôs pivot. They‚Äôre a YC company; they‚Äôre backed by Accel; they raised $500 million from Masayoshi Son.

Never write a SQL query again; chat with your data. Never file another ticket with a data team; ask Dash, or Alan, or Newton,[^1] your friendly neighborhood analyst. It will respond with an answer; it will respond with charts, and a SQL query. It will ask for your feedback on what it told you. It will be there for you on Slack, or Teams, or over email. Its responses will be full of emojis; its responses will include cutesy jokes written by cheugy millennials.[^2]¬†

This is the future of analysis. ChatGPT‚Äôs Code Interpreter is the üö®BIGGEST AI RELEASE YET üö®, says a Twitter account that bought 200,000 followers. Data analysts are obsolete, says a Medium post. ‚ÄúAre data analysts obsolete?,‚Äù asks a user on Reddit who‚Äôs learning to become a data analyst.

No they aren‚Äôt, says a startup founder. An amateur historian on LinkedIn will say that AI gives them time to solve more important problems. Someone with a blog on a personal website will write a post about the history of technological innovation, citing Paul Graham, Tyler Cowen, and several articles that they found after googling ‚Äúthe history of technological innovation.‚Äù¬†

And some contrarian clown will go on Substack to throw a fit about these bots, to question if they work, and to suggest that they may still replace analysts after all‚Äîbut, of course, not in the way that we all expect.

# Twenty pages of context in a ten-page window

If you build a product with charts, you‚Äôre going to build a BI tool.¬†

[Nobody believes it at first.](https://benn.substack.com/p/microsoft-builds-the-bomb#footnote-4-123990165) We tell ourselves that this time is different. We‚Äôre solving a different problem, for a different audience. We can make something complementary to BI, something narrower, lighter, more focused. We tell ourselves we're more principled than the others; we have more discipline; *we* won't cave and [build](https://twitter.com/barrald/status/1610739623835369472) [pie](https://twitter.com/bobbypinero/status/1679133838113488899) [charts](https://twitter.com/dorianj/status/1610741471568891905).¬†

Maybe we're right, in theory; maybe it can, eventually, be done. But the market can stay irrational [longer than a startup can stay solvent](https://www.goodreads.com/quotes/603621-markets-can-remain-irrational-longer-than-you-can-remain-solvent). And our customers will see our charts and want more of them; they'll want reports, and alerts, and explorable dashboards that can be exported as a PDF. They'll want granular permissions, and to connect to an old version of SQL Server running on a [Dell Optiplex 3020](https://www.walmart.com/ip/Dell-Optiplex-3020-Desktop-Tower-Computer-Intel-Core-i3-8GB-RAM-500GB-HD-DVD-ROM-Windows-10-Black-Used/994517744?wmlspartner=wlpa&selectedSellerId=5787&&adid=22222222227994517744_5787_149080731017_18511067177&wl0=&wl1=g&wl2=c&wl3=665551684524&wl4=aud-430887228898:pla-1879215353022&wl5=1022762&wl6=&wl7=&wl8=&wl9=pla&wl10=113945645&wl11=online&wl12=994517744_5787&veh=sem&gclid=CjwKCAjw5MOlBhBTEiwAAJ8e1ku06SrSKQPKm4A1zuCvo0nJAIbtViM5fqcwKwbmv8XBPBCuulpk1BoCPyUQAvD_BwE&gclsrc=aw.ds) under Jeff's desk.[^3] They'll want exactly what we‚Äôre selling, plus just this one feature, and they'll pay us $100,000 if we can build it.

This is the devil that [follows all of us](https://www.youtube.com/watch?v=HkZYbOH0ujw). And *two of them* are hunting for every chatbot and AI-powered SQL writer.

The first monster is BI itself‚Äîmost query generators are destined to be BI tools in their own right. If it writes a query, people will want it to run a query; then they‚Äôll want to chart the results; and then pin them somewhere, and then drill into them by clicking on them, and then, and then, and then‚Äîand then you concede the inevitable and [admit to being BI](https://mode.com/blog/introducing-mode-as-modern-bi/).¬†

But there‚Äôs a second parallel between chatbots and BI: For both, there‚Äôs a canyon between what works well enough to get a few customers and what works well enough to win a market.¬†

An engineer can build a simple data visualization tool in a day. There are open-source libraries; there are well-documented APIs; there are best practices. But simple bar charts don‚Äôt support a venture-scale startup. Customers will want faceted bar charts, with four series, and two axes, and filters, adjusted so that weeks start on Monday, with the right date format, and branded fonts, and labels for the first day of every quarter, every *fiscal* quarter, with a particular way of handling nulls, on six million records, and a trend line, that‚Äôs dashed, with the most recent incomplete week excluded from the calculation.¬†

Similarly, getting GPT to write a SQL query on a tidy schema of six tables is relatively easy.[^4] But prompting it to answer a vague question about orders from new accounts on top of 3,500 tables, that are named using abbreviations and legacy terms, and are full of messy and duplicative columns, and four different timestamps, where there are layers of relations to join through, and test accounts to exclude, and ‚Äúnew‚Äù is defined in a nuanced way, and any calculation about orders has to account for the way the sales team used to log contracts in Salesforce, for the way that the sales team now logs contracts in Salesforce, and for the way that one sales rogue rep always logged his contracts in Salesforce? That‚Äôs a very different beast.

For bots to be successful query writers‚Äîand even harder, for them to be proper analysts that can answer questions about a business‚ÄîLLMs will likely only be a small part of the solution. There will also have to be semantic models, methods for mapping vague requests onto those semantic models, frameworks for governing access control, ways to test if it said the [same answer today as it said yesterday](https://benn.substack.com/p/all-i-want-is-to-know-whats-different), and more. Building a good text-to-SQL bot requires building systems that include all of this context in the prompt, despite it being far more information than can easily fit in the context window of an LLM.

Put differently, the LLM isn‚Äôt an application, or even close to one. It‚Äôs a fancy function inside of an application‚Äîand building the rest of that application likely requires far more work than anything done with OpenAI‚Äôs API.[^5] Which isn‚Äôt to say that it‚Äôs impossible to build a product that writes good queries from fuzzy questions (and the unavoidable pieces of BI that come with it)‚Äîit just takes a tremendous amount of work and ingenuity.[^6] 

More bluntly, LLMs and query writing are fundamentally mismatched. The former is probabilistic, creative, and *inductive*‚Äîit‚Äôs best used to generate ideas from short prompts. But analysts have to do the opposite when answering questions. They need to be precise, rigorous, and *deductive*‚Äîthey need to know all of the nuanced laws governing how data is used, and apply them to questions that don‚Äôt specify those details.¬†

But that doesn‚Äôt mean that LLMs aren‚Äôt useful for data analysis, or that all of our jobs are safe. It just means that most query bots are focused on the wrong problem.¬†

# We can be good, or we can have fun

In a very rough sense, we can plot all of the tasks we do for our jobs and in our lives along a single axis. At the bottom, there are mechanical tasks that are mostly mindless legwork‚Äîdigging holes, filing papers in filing cabinets, scheduling a meeting over email, [printing out binders full of charts](https://www.holistics.io/blog/how-amazon-measures/#:~:text=presentation%20that%20contains%20hundreds%20of%20graphs%2C%20charts%20and%20tables) for an executive team‚Äôs weekly business review. At the top, there are ‚Äústrategic‚Äù and creative projects‚Äîdesigning a building, diagnosing a patient, giving a sales pitch to a prospective customer, making decisions about how to run a company. You could also place the components of an individual task along the spectrum as well: When planning a night out, booking a reservation is lower than choosing the restaurant; when working with data, typing correct SQL syntax is lower than reasoning through a query, which is lower than coming up with an analytical technique for answering a question.¬†

There are lots of ways that people might describe each pole. The bottom is repetitive; low-skill; boring; frustrating; simple. The top is inventive; high-skill; interesting; fun; intellectual. For obvious reasons, given the choice of where we want to spend their time‚Äîeither in our careers or in a single task‚Äîmost of us would probably say the top.[^7]¬†

Computers, in a very rough sense, usually help us do that. We don‚Äôt have to dig as many holes because machines can do it for us. We don‚Äôt have to file papers in filing cabinets, or even have files at all; computers can organize millions of documents in milliseconds. We have software that can help us schedule meetings, and BI tools that will replace our three-ring binders with live dashboards that update entirely on their own.¬†

Moreover, over the last several decades, as computers have gotten "smarter," they‚Äôve typically moved up the spectrum‚Äîand let us spend more and more time at the top. They used to only be able to do [basic math](https://www.amazon.com/Sharp-EL-1750V-Two-Color-Printing-Calculator/dp/B00006IF9Q/ref=asc_df_B00006IF9Q/); then they could do [complicated math](https://www.amazon.com/Texas-Instruments-TI-83-Graphing-Calculator/dp/B00001N2QU). Then they [made charts](https://www.microsoft.com/en-us/microsoft-365/excel), and now they can make [interactive forecasts that update by the minute](https://www.nytimes.com/interactive/2020/11/03/us/elections/results-president.html). Computers replaced our [daily planners](https://en.wikipedia.org/wiki/Google_Calendar), then they [helped us](https://calendly.com/) schedule meetings, and now they [shame us](https://www.cbsnews.com/news/shopify-meeting-cost-calculator-tool/) for scheduling meetings.¬†

This pattern‚Äîcomputers automating more and more mechanical work; people doing more and more creative work‚Äîhas become our default assumption about how technology advances, *and* for what we should do with new technology. New inventions push up the boundary that divides what computers can do from what we have to do; with every new tool, we try to figure out how we can hand over our most tedious remaining errands to the machines.¬†

But this doesn‚Äôt have to continue forever. Technology could‚Äîagain, in a very rough sense‚Äîgo the other way. It could be more creative than reliable. It could subsume our lives from the top down, outperforming us in strategic tasks while struggling with the tactical ones. If this happens, the best things we could build with it might impose a choice: Do we use it to make us better at something, or do we use it to replace something we don‚Äôt want to do?

Because so far, one of the most striking things about LLMs is that they‚Äôre much better at the creative parts of analysis than they are at the mechanical parts.[^8] Ask ChatGPT to write a SQL query against an artificially simple schema; [it‚Äôs a junior analyst](https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2), at best. But ask it to come up with possible hypotheses to explain why there‚Äôs some anomaly in a metric, and it does better than I would.[^9]¬†

For example, we gave ChatGPT a dataset with a bunch of events that are exactly‚Äîand suspiciously‚Äîone hour apart. When we asked it why that might be the case, it gave more reasons than I could come up with: Coincidence; programmatically scheduled activities; a time zone issue; system maintenance; the product could be one that people use at regular intervals; and access restrictions or throttling could queue user actions to reset every hour. That‚Äôs pretty good! And when we asked it how to figure out which one it might be, it had pretty good ideas for that too. It didn‚Äôt, however, do a good job of writing the queries that would run that analysis.¬†

In other words, *it inverted the workflow between human and computer. *It was better at coming up with ideas than I was; I was better at doing the work. I was its assistant, its agent, its copilot. It was assigning instructions, and I was following them. It didn‚Äôt allow me to work on higher value work; it did the higher value work, and told me how to do the manual labor.¬†

I‚Äôm not sure that I want to say that all the query-writing chatbots should pivot into analytical reasoning bots. That‚Äôs [the job I want](https://benn.substack.com/p/insight-industrial-complex#:~:text=I%20still%20remember,wait%20a%20minute%E2%80%A6%E2%80%99%E2%80%9D), to be at the top of the creative food chain with an army of machines doing the mundane tedium below me. But the army we‚Äôre building‚Äîcreative, unpredictable, and equally prone to both novel ideas and lies‚Äîis becoming [more man than machine](https://www.youtube.com/watch?v=UNCxbM50eWQ). If we‚Äôre looking for chatbots that make us all better at working with data, without having to rebuild an entire BI tool in the process, our best option may be to let them do the job *we* wanted to do all along.


---


[^1]: These names aren‚Äôt real, but they‚Äôre close to the real ones. My point here isn‚Äôt to single anything out, so I leave it to the reader to google ‚Äúsql writing bot,‚Äù or to imagine which one is, in fact, in my Twitter DMs.

[^2]: Somehow, this style has become the standard for these sorts of things. As far as I can tell, Slack started it, with the twee Slackbot aesthetic. Now, every other brand is a clumsy and lovable klutz who enjoys using emojis, attempting humor, and phrases like ‚ÄúD‚Äôoh!‚Äù

[^3]: Jeff, of course, quit eight years ago.

[^4]: For example, [this paper](https://arxiv.org/abs/2306.00739) evaluates how well a model performs in various text-to-SQL tasks. Though they stress-test different models by using imprecise language (e.g., asking for puppies when pets are labeled as dogs), the tests appear to be run against very small schemas often with fewer than a dozen tables. And even against that benchmark, the SQL is correct only eighty percent of the time.

[^5]: There‚Äôs a longer post to write here about how LLMs fail (you know, [for](https://benn.substack.com/p/how-snowflake-fails) [the](https://benn.substack.com/p/how-analysis-dies) [brand](https://benn.substack.com/p/how-dbt-fails)). The quick version goes something like this: We use LLMs to write SQL queries; they don‚Äôt work out of the box, so we start wrapping them with better prompts, and semantic models, and rules to make sure they return consistent results. Eventually, prompt engineering is just engineering, telling the model exactly what to do and how to handle edge cases, to the point that we‚Äôre working around the LLM as much as we‚Äôre working with it.

[^6]: This is one of the reasons why we took the call‚Äîand eventually, the [acquisition offer](https://mode.com/blog/mode-founders-note-thoughtspot-acquisition/)‚Äîfrom ThoughtSpot. They‚Äôve built both the BI tool and a [lot of the infrastructure](https://www.thoughtspot.com/product/sage/how-we-built-sage-with-gpt) that can make LLMs useful for translating questions into queries. Obviously, other vendors could do that too, but it takes very real work, for which there aren‚Äôt yet any shortcuts. (So why bother, [buy ThoughtSpot](https://www.thoughtspot.com/trial)! Or [Mode](https://mode.com/lp/demo/)! Or, like, skip a step, and just Venmo me, @Benn-Stancil.*)* I‚Äôd rather use the Cash app, because the [youths](https://youtu.be/K6qGwmXZtsE?t=110) tell me it‚Äôs the cool one, and because my handle (cashtag?) is $benn. However, I signed up for the Cash app ten years ago using a debit card that‚Äôs long since expired. I need to know that debit card number to log in to the Cash app, and my bank statement forensics have only yielded 10 of its 16 digits. So my handle‚Äîand a fortune of tens of dollars‚Äîis locked away forever behind [a code I can‚Äôt quite remember](https://www.cbc.ca/radio/asithappens/as-it-happens-friday-edition-1.5875363/this-man-owns-321m-in-bitcoin-but-he-can-t-access-it-because-he-lost-his-password-1.5875366).

[^7]: This is especially true if you‚Äôre three years and two jobs out of college, have spent nine months posting ‚Äúcontent‚Äù on LinkedIn, and are interviewing to work for a startup. ‚ÄúI don‚Äôt care that much about the exact role; I just want to be working on stuff that‚Äôs really strategic, [to have the kind of impact that I know I can have](https://getyarn.io/yarn-clip/53cbe1f6-9a3a-4f7d-b143-462206546ad7), you know?‚Äù says the 26-year old white guy whose r√©sum√© describes him as being low ego.

[^8]: Analysis, by the way, isn‚Äôt creating [various pivots of a dataset](https://arxiv.org/abs/2305.15038) that plot a bunch of dimensions against a bunch of metrics, or asking a computer to find ‚Äúinteresting‚Äù correlations in a spreadsheet. At best, that‚Äôs data profiling; at worst, it‚Äôs fishing for red herrings. Analysis is asking a hard question, coming with different hypotheses, finding evidence that supports or refutes those hypotheses, and drawing conclusions from it. It is [indeed strange](https://www.oneusefulthing.org/p/it-is-starting-to-get-strange) that computers can now do the former, but it‚Äôs a very different thing than the latter.

[^9]: Yeah, yeah, low bar, I know.