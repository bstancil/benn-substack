# Tribal accelerationism

*The OpenAI circus puts us back where we started—but now we’re more polarized. And some clickbait on why Sam Altman isn’t special.*

---

![](https://substackcdn.com/image/fetch/$s_!VQTF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fec2defee-a46b-4d29-b48b-273f2bdc3f95_1600x900.png)
*[Choose your team.](https://classic.esquire.com/article/1983/3/1/philosopher-robert-nozick-vs-philosopher-john-rawls)*

One way to describe OpenAI’s boardroom civil war is as a fight between two people who wanted to go faster, and four people who wanted to be more cautious. Though tedious people can debate the exact way to label each side—[effective accelerationists](https://effectiveaccelerationism.substack.com/p/repost-effective-accelerationism) versus decels and effective altruists; [techno-optimists](https://a16z.com/the-techno-optimist-manifesto/) versus [the skeptics](https://www.currentaffairs.org/2023/10/techno-optimism-is-not-something-you-should-believe-in); capitalists versus researchers; for-profit versus non-profit; builders versus an escalating variety of derogatory slurs; “move fast and break things” versus “move fast with a stable hold on the continued existence of humanity”—the lines between the two sides are pretty clear.[^1] 

Both sides make reasonable points. Some people on the more deliberate side—including [various serious thinkers and Elon Musk](https://techcrunch.com/2023/03/28/1100-notable-signatories-just-signed-an-open-letter-asking-all-ai-labs-to-immediately-pause-for-at-least-6-months/), [leading AI researchers](https://www.theguardian.com/technology/ng-interactive/2023/nov/02/ilya-the-ai-scientist-shaping-the-world), and [multiple](https://www.nytimes.com/2023/03/31/technology/sam-altman-open-ai-chatgpt.html) [CEOs](https://twitter.com/MorningBrew/status/1726645792176546108) of OpenAI—believe that artificial general intelligence could, quite literally, destroy the world and annihilate the human race. Other people worry that advanced AI technologies may not be outright apocalyptic, but will be dangerously disruptive. Just as we [weren’t ready for a world](https://www.piratewires.com/p/jump-23d06adb4cb7) in which any idea can reach hundreds millions of people in minutes, we aren’t ready for a world in which every image could be fake and every [familiar voice could be a scam](https://twitter.com/ArmandDoma/status/1726712587747045822). 

The side that wants to go faster is motivated by an inverted set of beliefs. Some of them think that AGI won’t kill the human race, but create for it an eternal utopia where there are no problems and everyone is happy.[^2] Others believe in a weaker version of that, in which AI cures every disease, builds a real room-temperature superconductor, and finally figures out [how to board an airplane in under 45 minutes](https://www.nytimes.com/2011/11/01/business/airlines-are-trying-to-cut-boarding-times-on-planes.html).[^3] It may cause problems, they admit, but the long arc of the technological universe bends towards prosperity, or at least highly efficient real-time ad auctions. And both of those are good things.

Moreover, for most people, it’s not clear how the continued advance of AI would affect them personally. If AI is the transformative technology that many claim it could be, it represents a kind of [Rawlsian discontinuity](https://en.wikipedia.org/wiki/Original_position): It resets the rules of the giant social game we’ve all been playing—and nobody knows what the rules of the new game will be. Though lots of things can upend today’s social order, generative AI could do it in a particularly profound and unpredictable way. It could make everyone funny on Twitter; it could destroy entire professions that some people have committed their lives to; it could [make intelligence an unremarkable asset](https://twitter.com/ilyasut/status/1710462485411561808). 

I’d guess that a lot of people’s feelings about AI are driven by what they think is on the other side of that Rawlsian veil. Those who are anxious about it prefer the way things are, rather than the way things could become. Some of that may be aesthetic—they’d rather read books and weekly blog posts and snarky tweets and clever legal briefs that are created by a human—and some of it may be self-preserving—they *write* books and weekly blog posts and snarky tweets and clever legal briefs, and like the position that that skill has afforded them in today’s society. 

Conversely, people who are pushing ahead probably believe that the new rules will be written in their favor. Sure, AI might usher in an era of unprecedented prosperity and human achievement, but more importantly, it might also usher in an era of *personal* prosperity and achievement. Nobody says that [a rising tide lifts all boats](https://en.wikipedia.org/wiki/A_rising_tide_lifts_all_boats) when the higher tide requires them to exchange their big boat for a small one. People say it when they want the people in the small boats to shut up. 

At first glance, it’s not immediately obvious which team someone would choose. AGI could save the world; AGI could destroy it. Less dramatic technological advances could tilt the social order in my favor; they could invert it against me. It could make me rich; it could make me expendable.[^4]  They are all real [flips of an actual Sam Coin](https://www.businessinsider.com/sam-bankman-fried-coin-flip-destroy-world-caroline-ellison-trial-2023-10). All else equal, you’d expect some variability on which bet to make.

If there were disagreements before last week, there aren’t anymore. 

When Sam Altman got fired, Silicon Valley was nearly unanimous in its support of Altman—justifiably, perhaps, given the seemingly clownish circumstances behind his removal. Then, however, via some transitive property of online warfare, support for Altman quickly blurred into support for the unchecked pursuit of a technology that most people acknowledge could be dangerous. Now, people are not only hesitant to side with the ousting board; they were hesitant to say we should [hear the board out](https://twitter.com/EricNewcomer/status/1726347773405274357).[^5] 

Perhaps Altman and the accelerationists are right; perhaps we should be doing everything we can to build advanced AIs as fast as we can. I don’t know; as I said, reasonable people can disagree. But I think it’s important to recognize what Silicon Valley’s mass support for that movement is becoming—base tribalism.

People aren’t rushing to defend Altman and OpenAI’s mission after carefully studying the creative or destructive potential of AI, or after concluding that it’s not a seismic revolution but “just” the next megatrend, because, first, most people haven’t, and second, those who have are still pretty split on how far AI could go, and whether an all-powerful superintelligence will break good or break bad. Nor did people bring out the pitchforks when Altman was fired, and the [gloating celebrations](https://twitter.com/DataChaz/status/1726305175454040335) when he was rehired, solely because they believe OpenAI will make the [world a better place](https://www.youtube.com/watch?v=B8C5sjjhsso). Call me a cynic, but venture capitalists don’t typically rush to Twitter to protect their ability to selflessly help others. 

No, the masses sided with Altman—and now, accelerationism more generally—because Silicon Valley is our team; OpenAI is “ours;” Sam Altman is one of us. The other side is now the enemy; they are delicate and weak-kneed weenies; [we are builders](https://twitter.com/ShaanVP/status/1727412911562449129), the Chads, the undeterred pioneers for the human race. “E/acc” is a brand—a flag—not a philosophy that every reply guy researched before they add it to their Twitter handle. And AGI is no longer a technology to be respectfully feared; it [is a battle cry](https://twitter.com/DavidSacks/status/1727430371195998639). 

Now that Altman is back as CEO, it’s easy to look at last week as some Macbethian melodrama, [full of sound and fury, signifying nothing](https://www.poetryfoundation.org/poems/56964/speech-tomorrow-and-tomorrow-and-tomorrow). I don’t think that’s true. Yes, all the pieces may be back where they started, but the sound and fury was significant: It was a [Scissor event](https://slatestarcodex.com/2018/10/30/sort-by-controversial/) that snapped Silicon Valley into polarized tribes. Before last week, there were measured disagreements about AI. Now, there is dissent, there is The Way, and there is a blind march into the unknown.

# Sam Altman isn’t special

I like this [Under Armour commercial](https://www.youtube.com/watch?v=SsovD9IlT3U). It’s mostly a montage of gymnasts training in a dark and disheveled gym. They fall; they get hurt; they get up; over and over again, with nobody else watching. In the final few seconds, we see the gymnasts walking into a competition, wearing Team USA leotards. “It’s what you do in the dark,” the ad says, “that puts you in the light.”

The commercial doesn’t just describe how Olympians succeed; it also, it seems, describes Sam Altman’s success. When Altman became the internet’s main character last week, a handful of people wondered out loud why he’s so popular in Silicon Valley. Prior to taking the top job at OpenAI, Altman’s resume didn’t look like that of the typical tech icon. Though he dropped out of Stanford to found a startup, his company was a middling success at best; it was acquired for [slightly more money than it had raised](https://en.wikipedia.org/wiki/Loopt). He then became the [President of Y Combinator](https://www.ycombinator.com/blog/sam-altman-for-president), mostly, it seemed, because YC’s cofounder Paul Graham was stepping down, and because Graham liked Altman. He moved from YC to OpenAI, where he’s become one of the most prominent and powerful people in the tech industry. In an industry that reveres founders and engineers, Altman’s credentials as both are uncommonly thin.

Altman’s supporters say he’s been successful for two other reasons. The first is that he’s [an exceptionally good dealmaker](https://twitter.com/loganbartlett/status/1726612744609382711).[^6] The second—and the far more common answer—is that Altman was relentlessly helpful to those around him. As the OpenAI news broke last Friday and everyone was trying to piece together what had happened, people began posting stories about the helpful things Altman had quietly done, when nobody was looking. He [mentored young founders](https://twitter.com/adamguild/status/1725702103677772174) who others had ignored. He made [key introductions](https://twitter.com/typesfast/status/1725869138235490424). He gave people [advice and feedback](https://twitter.com/borisjabes/status/1725934950653042877). He [opened his house](https://twitter.com/gillinghammer/status/1725764624732029173) for weddings. These things, [people said](https://twitter.com/benja22083/status/1725911523061637554), were what made Altman special. His legend wasn't built on a single accomplishment, but out of thousands of small acts of kindness. We can only know Altman and his character by looking at the entire mosaic.

Is the picture true? I have no idea. Some skepticism is probably healthy. [Peer pressure](https://twitter.com/JacquesThibs/status/1727134087176204410) is a powerful thing, and there are a lot of self-serving reasons to declare yourself a loyal Altman disciple, especially if you can name-drop your relationship with him along the way. But I don't know Altman, and the support he's gotten over the last week is genuinely impressive. So let's take it at face value: Altman is who the stories say he is, and the work that Altman did in the dark is what put him in the light.

But here’s the thing—there are lots of people who do the same work. Not everyone; far from it; Altman’s willingness to help others is uncommon. But it isn’t singular. What is unique about Altman—what separates him from the other people in Silicon Valley who are also irrepressibly kind and unrelentingly helpful, who are also there when nobody is looking—is that Altman’s had his stories told. For others, their kindness stays in the dark; their mosaics remain incomplete.[^7] 

[Matt Knopp](https://www.linkedin.com/in/matthewknopp/) has one such mosaic. He’s pulled multiple all-nighters to bail me out of dumb mistakes I’ve made.[^8] He’s always been there to help, no matter how foreign—or how boring—my ask of him was. He’s spent countless hours teaching me how things work; he’s been the uncredited technical backstop to hundreds of customer calls, support tickets, and investor pitches I’ve given; he’s fixed the literal holes in my shoes. Whatever stories people can tell about Sam, I can tell about Matt. 

There are so many others. Both [Chris Davis](https://www.linkedin.com/in/christopherdavis6/) and [Asha Hill](https://www.linkedin.com/in/ashahill/) selflessly stepped into several new roles when someone else needed help, always willing to sacrifice their own comfort so that others, myself included, could succeed. If you needed help with anything—brainstorming a product design, editing a movie, making a birthday card, transforming a slide deck, finishing a hack day project at 4 a.m., despite having four others that she’s already working on—[Sam Ferguson](https://www.linkedin.com/in/novaksam/) was there. [Heather Rivers](https://www.linkedin.com/in/hrivers) bailed me out of a job that was destroying me, even though she knew it would eventually destroy her. In ten years, I’ve never heard a bad word or single complaint about [Paul Thurlow](https://www.linkedin.com/in/pthurlow/). [Bailey Douglass](https://www.linkedin.com/in/baileydouglass/) always answered the phone, no matter how messy the problem on the other end of the line was going to be.

[Alana Goyal](https://www.linkedin.com/in/alanagoyal/) responds to every email with unnerving speed. [Jon Hawkins](https://www.linkedin.com/in/jonhawkinsnyc/), [Miju Han](https://www.linkedin.com/in/miju-han/), [Denis Zgonjanin](https://www.linkedin.com/in/deniszgonjanin/), [Maura Church](https://www.linkedin.com/in/datatime/), [Drew Harry](https://www.linkedin.com/in/drewharry/), and [Perry Wang](https://www.linkedin.com/in/perrwa/) have all taken dozens of customer reference calls, answered investor diligence questions, participated in last-minute events, and provided hours of product feedback and advice, never asking for anything in return. [Leqi Long](https://www.linkedin.com/in/leqi-long-34785b2b/), [Jennifer Chu](https://www.linkedin.com/in/jenniferchu888/), and [Joel Carron](https://www.linkedin.com/in/joel-carron-1925a74a/) never forgot a coworker’s birthday, or the type of candy they liked. After buying me breakfast, [Chase Roberts](https://www.linkedin.com/in/chasecroberts/) remembered a brief comment in our conversation and sent me a book. [Monique Morales](https://www.linkedin.com/in/monique-morales-43127143/) saved me when I forgot to book a room for a party. Without me ever telling her, [Maura Ginty](https://www.linkedin.com/in/mauraginty/) figured out I wanted to spend more time in New York, and found ways to send me there. [Aashna Dhawan](https://www.linkedin.com/in/aashnadhawan/) opened her family’s home to my luggage, when I needed a temporary storage unit for two days. And [Emily Ritter](https://www.linkedin.com/in/emritter/) never stopped listening.

I know some of these people well; some are professional passersby. I have stories about some of them that are profoundly meaningful to me; some are brief moments of kindness. But each of them are tiles, just like those that cover Sam Altman’s canvas. And the only difference between their tiles and Altman’s is how much people share them. 

Shortly after getting fired, [Altman tweeted](https://twitter.com/sama/status/1725742088317534446) that the experience “has been sorta like reading your own eulogy while you’re still alive. the outpouring of love is awesome.” One takeaway, he said, was that everyone should “go tell your friends how great you think they are.”

Yes, but no. Don’t tell your friends how great they are; tell the world how great your friends are. Altman is where he is because of that. If you believe someone is underappreciated for what they’ve done, or if you have someone to be grateful for—it is Thanksgiving, after all—don’t appreciate them in the dark. Put them in the light. 


---


[^1]: There is a third team, I suppose, which sees the other two as prima donnas competing in a [demented goat rodeo](https://twitter.com/karaswisher/status/1727261357874229594).

[^2]: They post [this picture](https://hsosc.files.wordpress.com/2015/01/futuristic-city-hsosc.jpg) a lot.

[^3]: Of course, the answer here is simple: Make baggage claim faster. It seems fairly obvious that boarding a plane isn’t a Tetris problem about the order in which the rows are filled, but a psychological one about [people who don’t want to check their bags](https://www.youtube.com/watch?v=pofUsd9hEi8). If airlines could convince people to check more suitcases, and everyone boarding a plane had a purse and a backpack, I bet they could load (and unload) an entire A320 in under fifteen minutes. That would save airlines [about 30 minutes](https://www.nytimes.com/2011/11/01/business/airlines-are-trying-to-cut-boarding-times-on-planes.html#:~:text=It%20now%20takes%2030%20to%2040%20minutes%20to%20board%20about%20140%20passengers%20on%20a%20domestic%20flight)—[or $3,000](https://www.airlines.org/dataset/u-s-passenger-carrier-delay-costs/)—per flight. For Delta, which operates [4,000 flights a day](https://news.delta.com/corporate-stats-and-facts), that saves $12 million a day, and $4 billion a year. For $4 billion, surely, *surely, *you could figure out fast way to get people to tag their bags at the gate, to hand them off as they’re boarding the plane, and to quickly bring them up to the destination gate as soon as the plane lands.

[^4]: Though some people—notably Sam Altman—could become extraordinarily rich and powerful, most of our fortunes are less certain. If technology is king, people in Silicon Valley could benefit by working in that profession, via the general elevation of the industry as the new master of the universe. Or we could lose, and badly, if our jobs as people typing on a computer lose their value and prestige.

[^5]: Judgment decels.

[^6]: It’s ironic that the current It Boy in Silicon Valley—a place that has long fancied itself as being above politics—[Is Him](https://www.tiktok.com/@nfl/video/7143640716294753582) because he’s politically savvy. In the land of the willfully blind, [the man who opens his eyes is king](https://en.wiktionary.org/wiki/in_the_land_of_the_blind,_the_one-eyed_man_is_king).

[^7]: Importantly, this is how everyone advances. People’s careers are built on their reputations, and their reputations are built on the stories that circulate in the zeitgeist. And these reputations snowball, compounding on top of each other over time. Imagine, for instance, that someone is asked who they think is good in a department that they don’t work with very often. Most people would say something like, “I’m not sure, but I’ve heard that Brian* is good.” Or, a CEO gets up on stage and jokes, “We’ve got some big deals this quarter; Patrick*—where’s Patrick?—don’t get married again this month, ok?” These recommendations and jokes are often based on nothing but reputation, but they also self-reinforcing; now, more people think Brian and Patrick are good too. This is why *informal* [sponsors](https://hbr.org/2021/10/whats-the-difference-between-a-mentor-and-a-sponsor) are so important—people don’t succeed because they do great work; they succeed because people talk about their work. * Men tend to informally sponsor men. Though they may *formally *recommend women, that often matters less than the pervasive, offhand comments on which reputations are actually built. And men usually joke about and casually promote other men.

[^8]: Annually, for some reason, in [the middle of March](https://en.wikipedia.org/wiki/Ides_of_March).