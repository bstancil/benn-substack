# Who is “the community?”

*It has the potential to be one of the data industry’s biggest perks—and its highest walls.*

---

![](https://substackcdn.com/image/fetch/$s_!V2QI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc8777ee-ae85-4c4c-ba02-4ec0c4a29bcc_960x637.jpeg)

The analytics community, ironically, [didn’t listen to the odds](https://www.youtube.com/watch?v=uYX-NSZMqt0). 

Years ago, when it was first coming together, it wasn’t likely to go well. Internet communities, especially those dominated by young men, tilt toward [poisonous cesspools](https://www.amazon.com/Culture-Warlords-Journey-White-Supremacy-ebook/dp/B084FXPHM3).[^1] Analysts are generally a prickly bunch, and in the first half of the 2010s, our [anointed king](https://twitter.com/NateSilver538) was a professional “*well, ackshually”* contrarian. And the cultures of two of the data industry’s closest adjacencies—startups and software engineering—are [toxic to many of their members](https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber).

But the early pioneers in the analytics community broke the other way, drawing cultural inspiration from places like [R user groups](https://blog.revolutionanalytics.com/2017/06/r-community.html). The R crowd is well-known for striving [to be inclusive](https://qz.com/work/1661486/r-ladies-made-data-science-inclusive/), for [welcoming women](https://reshamas.github.io/why-women-are-flourishing-in-r-community-but-lagging-in-python/), and for [protecting its own members](https://www.buzzfeednews.com/article/daveyalba/datacamp-sexual-harassment-metoo-tech-startup). The data community that formed in the years that followed has built a similar reputation. Even in my experience as the apparent [modern data stack bully](https://jpmonteiro.substack.com/p/a-friday-fight-and-the-internet-of), online groups have been nothing but professionally supportive and personally welcoming.

These benefits, however, aren’t shared equally. In particular, if you look around community spaces—the conferences, the Slack channels, the meetups, the Twitter conversations, and, one assumes, the data teams inside companies—black people are woefully underrepresented. 

Over the last couple years, a handful of organizations have sponsored about a dozen community-oriented data conferences. Unlike the big pay-to-play trade shows that are dominated by hanger-sized expo halls and on-stage infomercials,[^2] these conferences aim to attract and promote community leaders. In this regard, they’re representative of both who the community is and who the community aspires to be. 

Out of a total of over 500 speakers at these conferences, less than three percent are black[^3]—a third of whom spoke about diversity.

![](https://substackcdn.com/image/fetch/$s_!ZF3_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd39f9f7-d22e-4aa5-9258-a2854536d17c_930x188.jpeg)
*Given the obvious challenges with collecting data on racial identification, these numbers are approximate.*

Moreover, these dismal numbers are, if anything, inflated: Nearly all of these conferences' hosts promote diversity in some fashion. Some of them prioritize underrepresented groups when choosing speakers. Some explicitly highlight diversity at the center of their promotional materials. And all of them have codes of conduct meant to protect people from the kind of harassment that’s [common at tech conferences](https://www.yahoo.com/now/women-gender-tech-conferences-research-155451926.html). 

Other surveys confirm the same trend. Though companies don’t publish exact figures for data teams, Harnham, a data recruiting firm, reports that [three percent of data and analytics professionals](https://www.harnham.com/2020-us-diversity-in-data-analytics-report?goal=2020_2021_US_Diversity_Report_Download#formz5XgIIbzv4gbdiIko9xYQ) are black. 

That, it seems, is where the community is. On one hand, it’s well-intentioned, bucking some of the worst tendencies of other internet groups, and a launching pad for many friendships and careers. On the other hand, those benefits are just as concentrated among privileged groups as the rest of the tech industry’s are. According to their most recent reports, black people account for [1.7 percent of Facebook’s tech workers](https://diversity.fb.com/read-report/)[^4] and [2.9 percent of Google’s](https://static.googleusercontent.com/media/diversity.google/en//annual-report/static/pdfs/google_2021_diversity_annual_report.pdf?cachebust=2e13d07#page=57)—figures nearly identical to those in the data community.[^5] 

I could, as is true in any conversation about diversity, make the case that these low numbers are a business problem. Diverse teams, I could say, [are smarter](https://hbr.org/2016/11/why-diverse-teams-are-smarter). They’re [more innovative](https://hbr.org/2013/12/how-diversity-can-drive-innovation). They make [more money](https://www.mckinsey.com/featured-insights/diversity-and-inclusion/diversity-wins-how-inclusion-matters). 

While I agree with these points, I disagree with the premise on which they depend: that diversity is about the bottom line. Drawing connections between diversity and shareholder value will always be somewhat tenuous, and, if we concede that such a connection is necessary, some people will [find easy ways to object](https://www.bloomberg.com/news/articles/2021-06-03/snowflake-ceo-says-worker-merit-should-outweigh-diversity-goals?sref=WmQJbR0T).

Instead, we should be comfortable making the argument that inclusivity and integration are important on their own merits. People shouldn’t be shut out from the opportunity to be part of a rewarding community and a lucrative career. Nor should people be comfortable in exclusionary or segregated spaces, especially when those spaces could [confer special benefits and advantages to their members](https://twitter.com/thebmbennett/status/1440807993583435776).

Beyond that, the lack of black representation in data science, machine learning, and AI is [particularly dangerous](https://venturebeat.com/2020/12/09/columbia-researchers-find-white-men-are-the-worst-at-reducing-ai-bias/). There are many well-documented stories about data science teams embedding latent racism and bigotry into their models, hurting black people’s ability [to get loans](https://www.brookings.edu/research/reducing-bias-in-ai-based-financial-services/), interfering with [their health care](https://www.nature.com/articles/d41586-019-03228-6), rejecting them [from jobs](https://www.thomsonreuters.com/en-us/posts/legal/ai-enabled-anti-black-bias/), identifying them as [carrying guns they don’t have](https://twitter.com/nicolaskb/status/1244921742486917120), and charging them with [crimes they didn’t commit](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html). 

These problems don’t just cause obvious and irreversible harm to their victims. As more and more decisions get automated,[^6] programmatic prejudices reinforce themselves, creating additional biased outcomes—in everything from who gets admitted to college to who gets reviewed for parole to the [vernacular that chatbots understand](https://datascience.columbia.edu/news/2021/making-a-commitment-to-critical-discussions-on-race-and-data-science/) to how [bus routes are designed](https://kinder.rice.edu/urbanedge/2020/08/24/transportation-racism-has-shaped-public-transit-america-inequalities)—for future models to train against. They turn systemic racism into systematic racism, encoded and executed automatically, relentlessly, at scale.

The effects of underrepresentation in the broader analytics community are harder to see, but no less damaging. Racism is durable in part because it evolves so efficiently to both code “unfavorable” traits as black, and to code “black” traits as unfavorable. Whenever society gets close to inoculating itself against a particular racist trope, a new strain emerges. 

With data, the conspiracy is already at work. The cliché that [all jobs will soon be data jobs](https://www.wired.com/insights/2013/08/road-to-the-future-paved-with-data-literacy/) elevates [quantitative reasoning](https://www.wsj.com/articles/SB10001424127887323997004578644220074391246)—a skill set that is, not so coincidentally, [seen as white and male](https://www.scientificamerican.com/article/modern-mathematics-confronts-its-white-patriarchal-past/)—above other skills. This bias is reinforced by the demographics of the data community, creating a vicious cycle that holds black people out of power and [punches out a back door](https://theundefeated.com/features/mission-impossible-african-americans-analytics/) for white men. Unless the community becomes more visibly diverse, “data literacy” could become one of racism’s most powerful professional variants—and the analytics community could, even inadvertently, be one of its most forceful accelerants. 

None of this, frankly, should be a surprise. Racial power structures are embedded in everything, and data is no different.

But, if everyone knows it, very few people in the analytics community talk about it. It’s not even brushed under the rug, like an open secret that it’s impolite to talk about. Instead, it’s a blind spot, an unacknowledged problem that’s largely ignored, save the occasional [blog post](https://towardsdatascience.com/are-there-black-people-in-ai-fb6928166d73), perfunctory diversity panel, or [statement](https://datascience.columbia.edu/news/2020/taking-action-a-message-from-dsi-director-jeannette-m-wing/) pledging to “do more.”

This shows the limits of self-perceived kindness and progressivism. The data community prides itself on being open and welcoming of new members; for many people, it is. It’s also spun out countless organizations and projects that aspire to help civic groups use public data for social good; these efforts, I believe, are genuine. Despite that, underrepresented groups still have to carry their own water. As the earlier table shows, black people are invited to conferences to talk about diversity; everyone else gets to talk about data.

This [needs to change](https://coalesce.getdbt.com/talks/beyond-the-box-stop-relying-on-your-black-co-worker-to-help-you-build-a-diverse-team/). There is no long arc toward equality without broader effort—and being “nice” isn’t enough. A culture of congeniality can be just as ruthlessly biased as a toxic one, while also being better disguising its closed doors.

Furthermore, data professionals, who have a habit of dismissing people they see as emotional or irrational, should be cognizant of how they define what’s reasonable and what isn’t. [Analysts aren’t infallible logicians](https://benn.substack.com/p/tilt-and-tilted), arriving at their position through a detached reading of The Numbers. We’re all products of our environments, and [we really, truly, can’t detach ourselves from it](https://twitter.com/drvolts/status/1433893310960070662). 

This compels people to look at some arguments—how a lot of white people view, say, defunding the police—as inherently extreme, no matter how much data is marshalled to support them. Other positions, like those that tweak but don’t upend the status quo, are seen as disciplined and impartial on their face. It’s telling that we characterize how “reasonable” a solution is by how moderate it is, rather than how effective it may be. It’s telling that people only say “let’s be reasonable” when they want to keep things the way they are. 

Analytical communities built subtle walls on top of biases like these. People [who can afford to present sober analyses in inside voices](https://twitter.com/bennstancil/status/1386759751363661830) are celebrated; people who argue forcefully for bigger changes are discounted—and in some cases, [outright fired](https://www.vox.com/recode/2020/12/4/22153786/google-timnit-gebru-ethical-ai-jeff-dean-controversy-fired).

The data industry [has the money](https://www.cnn.com/2020/09/16/investing/snowflake-ipo/index.html) to do more. It remains to be seen if it has the commitment. 


---


[^1]: Or, to keep with the early theme, [wretched hives of scum and villainy](https://www.youtube.com/watch?v=0znNiN0lYAQ).

[^2]: Welcome to our session, “How MapR™ is enabling enterprise digital transformation,” led by the chief customer officer of MapR™, sponsored by platinum partner MapR™! Join us after the session in the MapR™ Sapphire lounge for our fun happy hour event, “Pinot Noir and MapR™!”

[^3]: Notably, the distribution isn’t uniform. About six percent of the speakers at Coalesce, dbt Labs’ conference, are black. Excluding Coalesce, less than two percent of speakers are black.

[^4]: Tech workers are represented by the purple lines. [Apologize](https://www.nytimes.com/2021/09/21/technology/zuckerberg-facebook-project-amplify.html) for your busted legends, Mark.

[^5]: For comparison, gender splits are slightly better in the analytics community. At both Facebook and Google, 25 percent of tech workers are women. Harnham reports that 27 percent of analysts are women; I estimate that 30 percent of data conference speakers are women.

[^6]: Except those [personally valued by investors](https://twitter.com/shl/status/1437785001504952341).