# Posts from 2023-Q1

This file contains 13 posts from 2023-Q1.

================================================================================

# Math is overrated

*Our mental model of value needs new priors.*

---

![](https://substackcdn.com/image/fetch/$s_!fuMt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd665b705-5607-486c-8fae-bbf3247f5c5b_711x400.png)

It's a tough article to defend, but here goes nothing.

A few years ago, the *Harvard Business Review* put out a bizarre stub of research that collapsed in on itself as soon as it even began. [The piece](https://hbr.org/2018/10/prioritize-which-data-skills-your-company-needs-with-this-2x2-matrix), its opening summary told us, would identify the skills we need to stay relevant in an economy that’s increasingly dominated by "mathematically-focused jobs." The answer, revealed in [every MBA student’s favorite blunt analytical instrument](https://www.youtube.com/watch?v=XfB0g_JDIds)—a series of points [arbitrarily scattered across a two-by-two matrix](https://hbr.org/resources/images/article_assets/2018/10/W181004_LITTLEWOOD_ANEXAMPLE-1.png)—was not mathematics. Buzzy skills like data visualization, business intelligence, data science, and AI were on the frontiers of value and efficiency, but math—that juvenile banality, that undisruptive dullard, that legacy technology—was unceremoniously dumped in the quadrant labeled “Ignore.”

The internet, always looking for an [easy mark](https://www.youtube.com/watch?v=3a0kcn3NWZ0)[^1] to put on a poster, [bulleted in for the dunk](https://www.youtube.com/watch?v=GslU3xI0hQg). The piece was [destroyed](https://twitter.com/nickwan/status/1473407306884956164), [demolished](https://twitter.com/jschwabish/status/1473716236064378891), [obliterated](https://twitter.com/willcritchlow/status/1473653724060999689), *[eviscerated](https://www.salon.com/2015/08/06/jon_stewart_eviscerates_16_plus_years_of_hyperbolic_daily_show_headlines_and_it_is_literally_the_greatest_thing_you_will_ever_see_in_your_life/)*. We now trot it out [on its birthday](https://twitter.com/timmills_/status/1583732144824016898), to [humiliate it](https://twitter.com/footlocker/status/491269603612721152) for some more clicks, [over and over and over again](https://en.wikipedia.org/wiki/Kevin_McCarthy).

But what if, amid our gleeful ridicule, the post accidentally stumbled into an unexpected truth? What if math *is* overrated—and it’s exactly our infatuation with it that, ironically, motivated the creation of the diagram in the first place *and *blinds us to its inadvertent wisdom? What if our thundering dunk is [actually a charge](https://www.youtube.com/watch?v=iDRm8DOVHEU)?

# A homely mind

At some point when I was a teenager, I became a “math person.” I wasn’t any kind of savant—I took the same middle school math classes as everyone else; I was never a [mathlete](https://www.youtube.com/watch?v=EligNcjdyyI)—but I had a graphing calculator and liked looking at the statistics on the backs of baseball cards, so the branding stuck. In college, because of my [fear of writing](https://benn.substack.com/p/analytics-is-a-mess#:~:text=Looking%20back%2C%20I%E2%80%99m%20not%20sure%20if%20I%20liked%20math%20or%20if%20I%20was%20scared%20of%20writing.) and my [fear of breaking character](https://benn.substack.com/p/the-past-is-not-precious#:~:text=But%20a%20hundred%20times%2C%20and%20it%20becomes%20my%20identity.), I kept going, and majored in math.

To most of my friends and family, it made sense that I eventually found my way into a career in data. Math and data are often seen as siblings, if not outright twins. One is just the practical application of the other. Math is what you study if you [want to be a data scientist](https://towardsdatascience.com/5-best-degrees-for-getting-into-data-science-c3eb067883b1); data science is what mathematicians do [to make money](https://www.payscale.com/college-salary-report/common-jobs-for-majors/math).

But once you do the job for a while, it’s hard not to see that union as overstated, or at least outdated. Though some data roles—those that build predictive models and analyze [complex multivariate tests](https://vicki.substack.com/p/duo-the-push-and-the-bandits), for example—are often neck deep in graduate-level stats, this isn’t the norm. Instead, the 99 percent of analytical jobs deal in much simpler mathematical affairs.[^2] Yes, we have to be numerically fluent and quantitatively comfortable, but most of the math we do is calculating sums, computing ratios, and checking if averages are skewed by outliers. We [squint at p-values](https://notes.causal.engineering/archive/locally-optimal/#:~:text=I%20asked%20him%20why%20he%20hadn%E2%80%99t%20spent%20any%20energy%20on%20statistical%20problems%20at%20all%20and%20he%20had%20a%20great%20answer%3A%20%E2%80%9Cwhen%20a%20project%20we%20work%20on%20succeeds%2C%20we%20don%E2%80%99t%20need%20statistics%20to%20know%20it.%E2%80%9D%C2%A0). We [count](https://twitter.com/johncutlefish/status/1348699048249737217) [stuff](https://counting.substack.com/about). We use [stock Excel functions](https://www.vox.com/2020/5/8/21250641/kevin-hassett-cubic-model-smoothing) to draw [lines through scatter plots](https://xkcd.com/2048/). We interpret charts, lecture product managers about statistical significance, warn people that correlation doesn’t equal causation, and remind everyone that proxy metrics are the map and not the territory. 

This is all a pretty weak justification for putting math on as high of a professional pedestal as we do. Much of our mathematical work is the stuff of grade-school arithmetic, and is a bar that most college graduates easily clear. While there are exceptions, the equations we write are just algebra; our [favorite algorithm is division](https://twitter.com/mrogati/status/481927908802322433). Yes, math is useful, but our minds [don’t need to be that beautiful](https://www.youtube.com/watch?v=voqjl5yDsyk).

In other words, it’s not our ability to *do* fancy math that makes us effective, but our ability to *apply* basic math. The industry’s slow pivot away from [technical skills](https://benn.substack.com/p/analytics-is-at-a-crossroads) and [tools](https://counting.substack.com/p/data-science-has-a-tool-obsession) and towards [collaboration](https://davidsj.substack.com/p/dear-stakeholder) and [internal politics](https://wrongbutuseful.substack.com/p/elbows-of-data)[^3] is a reflection of the same dynamic: Math doesn’t separate the good analysts from those who struggle. We often operate like intelligence analysts, looking for connections in a sea of messy evidence, rather than statisticians trying to parse endless regression readouts.

This is hardly a controversial point. If most of us where asked by a junior analyst if they should invest in understanding the business, or in understanding various probability distributions and the fundamental theorem of calculus—which is high school [stats](https://apcentral.collegeboard.org/courses/ap-statistics) and [math](https://apstudents.collegeboard.org/courses/ap-calculus-ab), by the way—we wouldn’t flinch in recommending the former. 

Moreover, [excellent](https://g.co/kgs/tyudiy) [written](https://g.co/kgs/RVBx2o) [and](https://g.co/kgs/pA2GHX) [verbal](https://g.co/kgs/YrcJvU) [communication](https://g.co/kgs/z4MvYG) [skills](https://g.co/kgs/hbSUFZ) are a nearly universal requirement on analytical job postings. But we don’t require a communications degree, and don’t train people to write. These sorts of skills—presenting, persuading, and collaborating, to say nothing of having an understanding of the business domain in which most analysts work—are seen as things we can learn on the job. They’re skills that can be layered on top of a “math person.” It is only for math and its sister requirement, “technical skills,” that we want more formal qualifications—despite, I’d argue, it being easier to teach a great communicator introductory statistics than it is to teach a great mathematician how to be organizationally effective.[^4] 

In that context, the curious thing about the *HBR* article isn’t its lowly positioning of mathematics and statistics; it’s our triggered reaction to their rankings. It’s almost as if our fixation on math was never about the subject’s substance, but its signaling. 

# Shape rotators sell words

Every culture has its codes. One of Silicon Vally’s is the language of false and unnecessary quantification. We don’t change our minds; we adjust our Baysian priors. We don’t know something; we assign it a high epistemic probability. One thing isn’t way bigger than another; it’s an order of magnitude bigger.[^5] We don’t think; we create mental models. We don’t tell stories; we share [Ns of 1](https://en.wikipedia.org/wiki/N_of_1_trial). There aren’t lots of small things and a few big things; there’s a [power law](https://en.wikipedia.org/wiki/Power_law).[^6] 

Like the business jargon [it’s usually wrapped around](https://www.vulture.com/2020/02/spread-of-corporate-speak.html), these phrases only appear precise. But they describe comparisons of estimates of predictions that use assumptions—I mean, priors—that are flatly unquantifiable. By describing them in this language, however, and presenting them in [color-coded spreadsheets](https://twitter.com/NateSilver538/status/1357436842384187399) or on [two-by-two grids](https://www.google.com/search?q=gartner+magic+quadrant&sxsrf=ALiCzsb6ImRKTITeHOHlQZoH4SUhKOEpXQ:1672950041018&source=lnms&tbm=isch&sa=X&ved=2ahUKEwizu6_HoLH8AhUXEFkFHfYKD1IQ_AUoAXoECAEQAw&biw=1776&bih=1016&dpr=2), we can pretend that they represent some sort of objective science, and aren’t just [rhetoric by another name](https://benn.substack.com/p/tilt-and-tilted). 

In doing so, we math people can stifle debate against the qualitative luddites. I have numbers, you don’t, and tech folk hero [W. Edwards Deming said](https://www.goodreads.com/quotes/34849-in-god-we-trust-all-others-bring-data) that means I win. Never mind if the figures behind my slang are entirely made up; that just makes them all the more difficult to refute.

In cultures that revere math and science—not as disciplines, but as vibes—this vocabulary can be a powerful weapon. While artists are unlikely to be swayed by artificial cost-benefit calculations,[^7] among business leaders and data-driven companies, this language has standing. 

Our deference to math, and particularly its more advanced strains, isn’t about its practical business value. It’s about protecting this culture. It’s about settings the terms of our internal debates, and ensuring that those who appear to “bring data” maintain their power in the professional order.[^8] Math is a useful skill, and an even more useful sorting hat—and the more we venerate the former, the better it becomes at the latter.

# Bullets of reason

So what, though? Is this bias so bad? Is it not better to roughly quantify the unquantifiable than to discount math’s value?

Again, the *HBR* article is instructive. Rather than making a substantive, and potentially quite reasonable, claim as to why organizations should invest in data visualization expertise over mathematics training, they simply put the two on a plot. They shortcut a real argument with a smokescreen of manufactured data and feigned rigor. And like a founder trying to sneak a [scatterplot of logos by an critical investor](https://hunterwalk.com/2020/05/25/if-your-pitch-deck-has-a-competitive-2x2-im-going-to-ask-you-this-question/), they pushed their luck too far and someone called their bluff.

If we valued persuasion and storytelling as much as math, this wouldn’t happen. If we demanded that data needs to be explained in simple words as much as words need to be supported by data, we wouldn’t assume that a few lazy graphs—the [bullets of analytical argumentation](https://benn.substack.com/p/the-more-the-merrier#:~:text=Bullets%20cut%20ideas%20short.%20They%20let%20me%20glance%20at%20something%20and%20convince%20myself%20I%E2%80%99ve%20seen%20it%2C%20while%20staying%20comfortably%20on%20my%20original%20path%20through%20a%20topic.)—are sufficient. If *HBR*’s editors weren’t blinded by a mathematical bias, they wouldn’t have printed themselves on the losing end of [an immortal poster](https://twitter.com/espn/status/1607270719745843202). 

Beyond that, math can make us jerks. Shortly after college, when I was no longer just a math person but an official credentialed math major, I remember having several discussions with various family members about voting. I smugly trotted out [a few basic statistics](https://www.econlib.org/sorry-your-vote-doesnt-count/) about how your vote is very unlikely to ever affect an election. The math was sound, but missed the point: People [don’t just vote to sway an election](https://en.wikipedia.org/wiki/Paradox_of_voting#Responses). But I refused to hear these points, or even engage with them, because they weren’t quantified. I argued with math; they didn’t; Q.E.D.

In today’s society, filled with its “mathematically-focused jobs,” it’s all too easy to do the same. It’s all too easy to dismiss qualitative reasoning—and, by extension, people who don’t identify as math people[^9]—simply because they don’t speak the right dialect. But, before reflexively defending the inherent necessity of mathematical expertise, we should make sure we care about it for right reasons. To put that in terms we might better understand: Math’s value follows a power law, and even in data roles, there’s an order of magnitude more of us on the left of the distribution than in its tail.

![](https://substackcdn.com/image/fetch/$s_!KFZy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa9997dfe-ee08-419e-a14f-96074095ced7_747x441.png)


---


[^1]: Fun fact: I was in the crowd for the [original James Johnson poster](https://www.youtube.com/watch?v=lB4lTCAE5Fo).

[^2]: Math is to data jobs as algorithms are to software developers: It sounds like what we do, but in practice, we’re mostly trying to figure out why this one thing doesn’t match this other thing.

[^3]: Katie doesn’t directly refer to this as politics, but I think it’s important to recognize that that’s what it is, and that’s not a bad thing. We often use politics as a pejorative, framing internal negotiations as a kind of unhealthy horse trading. But as messy as it sometimes is, politics is how stuff gets done. By avoiding it, we aren’t taking the high ground; we’re [surrendering decisions to others](https://www.nytimes.com/2022/06/22/us/politics/jan-6-committee-republicans.html).

[^4]: You could argue that, while we don’t need advanced math, we celebrate it because foundational math is really important. Though I agree that it is, you could say the same thing about a slew of other professional skills. But would we react the same if *HBR* said that persuasive writing or basic financial acumen were things we could ignore? We might disagree with that piece, but I doubt we’d *[literally destroy](https://www.youtube.com/watch?v=fYWtbMb8Fhw)* it.

[^5]: I particularly like when this is applied to unquantifiable concepts: Superhuman is better than every other email client by at least an order of magnitude. Politicians need to know an order of magnitude more about AI. There are two orders of magnitude more free speech on Twitter now that Elon Musk owns it.

[^6]: And when we don’t use math, we’re not making stuff up; we’re [reasoning from first principles](https://commoncog.com/how-first-principles-thinking-fails/).

[^7]: This was awkwardly proven by another *HBR* article, in which [Jerry Seinfeld was asked if McKinsey](https://hbr.org/2017/01/lifes-work-jerry-seinfeld#:~:text=Could%20McKinsey%20or%20someone%20have%20helped%20you%20find%20a%20better%20model%3F) could’ve helped make *Seinfeld*. Sadly, there’s no video of [Jerry’s reaction](https://www.youtube.com/watch?v=RVTP8xZCGVw).

[^8]: Is it a coincidence that this dynamic also reinforces tech’s existing gender and racial order as well? Surely it must be.

[^9]: This can have particularly toxic effects, as people often see mathematical ability as a [fixed part of their identity](https://implicitbeliefsofintelligencetutorial.weebly.com/incremental-vs-entity-theory.html). “I’m not a math person” can easily become, “I don’t belong.”

================================================================================

# The conglomerate

*Not bundling or unbundling but a secret third thing.*

---

![](https://substackcdn.com/image/fetch/$s_!T1jS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa95b25e-c423-4922-9461-c03b58c9e621_1242x852.png)
*[If you know, you know.](http://www.freewebarcade.com/game/jezzball/)*

By most traditional measures, dbt Labs isn’t the biggest company in the data ecosystem. It doesn’t make the most money; it doesn’t have the most employees; it has [fewer followers on Twitter](https://twitter.com/dbt_labs) than the [community account](https://twitter.com/qlikdeveloper) for Qlik developers.

But, ever since [publishing their vision](https://www.getdbt.com/blog/building-a-mature-analytics-workflow/) for a better analytical workflow, dbt Labs has been the most influential. They advocated for analysts to borrow ideas from engineers; today’s data teams almost universally aspire to do so.[^1] They created a product; we swarmed it [with integrations](https://mode.com/blog/dbt-semantic-layer-integration/). They championed a [new role](https://www.getdbt.com/what-is-analytics-engineering/); in four years, other companies speed ran[^2] it through the entire [hype cycle](https://en.wikipedia.org/wiki/Gartner_hype_cycle)—from [launch](https://locallyoptimistic.com/post/analytics-engineer/) to [peak](https://jasnonaz.medium.com/analytics-engineering-everywhere-d56f363da625) to [disillusionment](https://www.datameer.com/blog/is-analytics-engineering-a-necessary-evil/) to [iteration](https://benn.substack.com/p/why-do-people-want-to-be-analytics) to a two-hundred year old toothpaste company opening an [analytics engineering position](https://jobs.colgate.com/job/Piscataway-Analytics-Engineer-NJ/970516200/) in suburban New Jersey.[^3] dbt Labs built a thriving ecosystem of users and evangelists around a Slack workspace; now every company and upstart data ideology has [its own Slack community](https://clrcrl.com/2022/05/06/mds-company-slack.html) with the same channels and fewer members. Time and time again, amid the landscape’s chaotic explosion, dbt Labs has been our philosophical pacesetter, the drum major to our [violent noise](https://www.youtube.com/watch?v=_1ZBLlsNtns). 

# Congeniality

They also set another less widely-acknowledged tone: They made neutrality popular. dbt Labs found a spot in the market where they could be everyone’s friend and nobody’s direct competitor. Seeing their commercial and community success, other companies tried to follow the same beat. They marketed themselves as grateful stewards of passionate groups of users, and chipper partners to a neighborly coalition of vendors. Save their rip-and-replace landing pages that can only be unearthed by the right Google search run by the right demographic, most data startups are polite to their competitors, and effusive about everyone else. Browse their sites, and you’ll find countless blog posts announcing exciting new partnerships, infinitely scrolling pages of integrations, and diagrams of “all the data tools you love” swirling around a single unifying nucleus. You must choose their product, they say, but the rest is up to you. We are all God’s children, and we cannot possibly choose a favorite.[^4] 

This cooperative and congenial demeanor was echoed in the industry’s embrace of modularity. This was itself a [core tenet](https://www.getdbt.com/blog/building-a-mature-analytics-workflow/#:~:text=benefit%20from%20clarification.-,Modularity,-If%20you%20build) of dbt Labs’ founding viewpoint, though it was initially proposed as a way to avoid convoluted data pipelines and repeated query logic. Over the last seven years, the principle expanded to include tools and technologies as well. The best data ecosystem, we said and now almost reflexively assume, is one that’s full of interoperable parts. Customers should be able to pick and choose from an à la carte menu of tools, with each pairing nicely with all the others. If standards emerge—if we offer a prix fixe option—they should be chosen democratically, via the dollar-denominated votes of data teams.

It’s an pleasing vision—and an unlikely one. dbt Labs’ position as Switzerland was earned, not simply chosen. They found a hole in the market that was overwhelmingly complementary with the rest of the industry, and quickly built a popular product that discouraged head-on competition. Furthermore, there’s a practical problem with too much modularity. Vendors can’t reasonably maintain a bunch of bilateral relationships with one another. Without that, the data stack, assembled from a dozen tools produced by the same number of startups, will remain [frustratingly disjointed and incongruous](https://medium.com/alexandre-beauvois/modern-data-stack-as-a-service-1-3-1a1813c38633). 

This is a steep price for customers to pay for optionality and protection from vendor lock-in. Because choice and flexibility are means to an end: The ability to choose better products. People are content to lock themselves into the Apple ecosystem because they have faith in what Apple builds.[^5] For a neutral, modular, interchangeable data stack to be similarly popular, the final product—the full stack, as a cohesive unit—has to be just as good. 

We’re not there yet, and the proof is the products. The latest wave of data companies were created to solve the problems caused by the first wave. Companies like [5x](https://5x.co/) and [Mozart](https://www.mozartdata.com/)[^6] promise to hammer down these rough edges for you by offering the entire modern data stack as a managed service (aka, the [Managed Data Stack](https://www.moderndatastack.xyz/companies/managed-data-stack)). The interest in dash meshes and data contracts are born out of related frustrations, and a desire to enforce some degree of consistency between, among other things, disconnected products and services. 

[As others have said](https://benn.substack.com/p/case-for-consolidation/comment/6537471), over time, this dynamic could forge better products at lower prices. It might look like a mess now; that’s just [democracy in action](https://youtu.be/W28w3Hv3xfI?t=289). 

But that was then. Today, time may be a luxury the industry no longer has. Buyers are getting impatient, and the data stack can remain fragmented longer than all its pieces [can stay solvent](https://quoteinvestigator.com/2011/08/09/remain-solvent/). 

# Collision 

Sooner or later, Jerome Powell comes for us all. As the tut-tutting armchair economists who fancy themselves as enlightened because they listen to the *All-In Podcast* now love to say, kids these days got addicted to a zero-interest rate environment. Paper unicorns that look promising in that climate turn questionable in “normal times,” and become outright fairy tales in [SaaS’ nuclear winter](https://www.meritechcapital.com/benchmarking/historical-trading-data/cumulative-equity-value). 

When customers stop rubber stamping contract increases of [65 percent every year](https://investors.snowflake.com/news/news-details/2022/Snowflake-Reports-Financial-Results-for-the-Third-Quarter-of-Fiscal-2023/default.aspx#:~:text=Net%20revenue%20retention%20rate%20of%20165%25), startups and huge public companies alike have to look for alternative sources of revenue. Companies that previously made efforts to space the floor, to claim neutrality, and to avoid direct competition will have to offer more products to more people, and to chase nearby markets—all while customers tighten their budgets, like the walls closing in on a [JezzBall board](https://en.wikipedia.org/wiki/JezzBall). More collisions are inevitable. 

The [common](https://metadataweekly.substack.com/p/the-future-of-the-modern-data-stack#:~:text=%F0%9F%91%89%C2%A0The%20modern%20data%20stack%20will%20start%20consolidating.) [prediction](https://benn.substack.com/p/data-and-the-almighty-dollar#:~:text=The%20second%20is,their%20ticker.) is that our Gordian Knot—the need for the modern data stack to be cohesive, and dozens of startups being [squeezed together by a narrowing market](https://www.youtube.com/watch?v=6u3QInIMVME)[^7]—gets cut by consolidation. The big fish look for acquisition targets when valuations are down. One by one, companies get assimilated by the Borg, bundled into a faceless [mothership hovering over Seattle](https://www.youtube.com/watch?v=nNOohFst9Lc&t=47s), and tacked on as a loss-leader to sell seats for a CRM or compute bills for a database. Jerome Powell, it turns out, is just the [intermezzo](https://en.wiktionary.org/wiki/intermezzo); [sooner or later](https://benn.substack.com/p/the-original-purple-people#footnote-6-58708482), Frank Slootman [comes around](https://www.youtube.com/watch?v=jiMXK9eDrMY). 

Though I believe [there are benefits](https://benn.substack.com/p/case-for-consolidation) to this type of consolidation, it’d still be a disappointing end to modern data stack. Big buyers often slowly gut their acquisitions, like [Salesforce recently did to Tableau](https://www.bloomberg.com/news/articles/2023-01-05/salesforce-crm-guts-tableau-after-spending-15-7-billion-in-2019-deal#xj4y7vzkg) and [Google did to Looker](https://community.looker.com/looker-adoption-community-1016/can-someone-confirm-looker-laying-off-us-dcl-29178). The souls of beloved businesses go away, and get replaced by new fonts and a “[A](https://mailchimp.com/) [Megacorp](https://www.looker.com/) [company](https://segment.com/)” watermark under their logo.

What if there’s another way?

# Conglomeration

In Silicon Valley, we often think of tech acquisitions as means for building a better product. We talk about how this software might integrate with that service, or how a new technology can modernize a legacy vendor. Acquisitions are about synergy, shared roadmaps, and teleprompter excitement for the next chapter of what two teams can build together.

In other industries, acquisitions are about balance sheets. They are a means for making more money. Berkshire Hathaway doesn’t own an [insurance company and a jewelry brand](https://www.berkshirehathaway.com/subs/sublinks.html) because they’re complementary; it owns them because they both make Berkshire Hathaway money. And if Berkshire Hathaway can promote them together—via, for example, an [bizarre infomercial from the world’s fifth richest man](https://www.berkshirehathaway.com/message.html)—that’s a bonus.[^8]

But there are some companies that take a middle road. They buy products that are adjacent to one another—not to use them as tuck-ins and tack-ons to a core service, but to build a balanced catalog of equals. [Over the last decade](https://en.wikipedia.org/wiki/Adobe_Inc.#History), Adobe, which started primarily as a creative design suite, bought Omniture, EchoSign, Magento, Marketo, Workfront, Frame.io, and Figma. Atlassian built itself into [a $100 billion company](https://www.smh.com.au/business/entrepreneurship/pretty-rarefied-air-atlassian-hits-us100-billion-milestone-20210917-p58sjm.html) ([for a minute](https://www.google.com/search?q=atlassian+ticker&oq=atlassian+ticker&aqs=chrome.0.69i59j69i64.2746j0j7&sourceid=chrome&ie=UTF-8)) through a [similar march of acquisitions](https://en.wikipedia.org/wiki/Atlassian#Acquisitions_and_product_announcements). 

In both cases—and unlike a company like Salesforce—neither Adobe nor Atlassian has a clear flagship product around which [everything else is primarily a funnel](https://twitter.com/_gringuinho_/status/1611484377061511183). If customers buy one product, they aren’t obligated to buy others; each is built to stand on its own. Moreover, the shared corporate umbrella provides two benefits that fully independent businesses can’t. First, it [makes the buying process convenient](https://twitter.com/josh_wills/status/1522625422449528832). If a team has Photoshop, they can buy Omniture, Magento, and Marketo without having to talk to a new vendor. Second, even if each product *can* operate independently, they don’t *have* to. Atlassian customers can provision users and manage billing from a single administrative portal. And Jira has integrations with [dozens of tools](https://www.atlassian.com/software/jira/guides/expand-jira/jira-integrations), but it fits best [with Confluence](https://www.youtube.com/watch?v=ohtDFXNAUns). Instead of having to rely on community standards and loose partnership agreements to make one product compatible with the other, Atlassian can simply make it so. 

As the data industry settles, I believe there could be—and probably should be—a couple similar conglomerates that focus on data services. By bringing various pieces of the stack together under a single roof, these businesses could sand down the rough edges between an ETL product and the observability service that’s supposed to monitor it, or a visualization tool and the data discovery platform that catalogs it. Permissions and access controls could be managed centrally and directly. Charges could be rolled up into a single unified bill. [Metadata standards](https://airbyte.com/blog/modern-data-stack-struggle-of-enterprise-adoption#:~:text=%F0%9F%93%9D%20Metadata%20in%20Enterprise%20Data%20Platforms) could be mandated, not negotiated. And if customers wanted to use a different vendor for a particular piece of the stack, no problem—it won’t be quite as seamless as staying in the family, but won’t be any worse than the experience today. *[ Update: Software conglomerates would also be good counterbalances to cloud or warehouse providers who primarily sell compute. The former is incentivized to make great tools. The latter wants to drive more compute—which won’t necessarily push companies to make the best software. Shoutout to Erik Bernhardsson [for piecing together](https://twitter.com/bernhardsson/status/1613944506545573899) this dynamic. ]*

Could it happen? Maybe—I have no idea how these sorts of holding companies actually come together. Are they facilitated through financial intermediaries, like Thoma-Bravo-subsidiary Qlik’s [acquisition](https://thenewstack.io/qlik-intends-to-acquire-talend-for-governance-integration/) of Thoma-Bravo-subsidiary Talend? Or do they emerge organically, starting with vendors forming exclusive partnerships, and the industry’s informal neutrality doctrine getting replaced by quid pro quo alliances? I don’t know. But if it’s the path that helps companies [keep their character](https://fortune.com/2023/01/05/leaked-slack-all-hands-meeting-reveals-a-strong-culture-clash-and-growing-rift-with-parent-company-salesforce/) while also building [more cohesive experiences](https://benn.substack.com/p/the-modern-data-experience) for their customers, the modern data stack might be better as the modern data conglomerate. 


---


[^1]: Or do they? Though it’s not uncommon for people to advocate for data teams to [differ from engineering teams on the edges](https://erikbern.com/2022/12/07/what-ive-been-working-on-modal.html#fn:2:~:text=Data%20as%20its%20own%20discipline), I’ve never heard an argument that working like engineers is directionally wrong. But surely there are some teams out there that outright reject this.

[^2]: [Speed ran or sped run?](https://trends.google.com/trends/explore?date=today%205-y&geo=US&q=speed%20ran,sped%20run)

[^3]: Shoutout to Colgate for being a very unexpected [217 years old](https://www.colgatepalmolive.com/en-us/who-we-are/history). Also shoutout to Colgate—a company that makes toothpaste—for [making their mission](https://www.colgate.com/en-us) (click “Mission” in the top nav bar) to be straight-up “changing the world.”

[^4]: God, of course, is low interest rates and the shoddy diligence of thirsty growth equity investors.

[^5]: [“Not I,” said the green bubble.](https://benn.substack.com/p/a-slur-on-clubhouse#:~:text=If%20losing%20half%20of%20my%20text%20messages%20to%20iMessage%E2%80%99s%20infinity%20loop%20isn%E2%80%99t%20enough%20to%20compel%20me%20to%20stop%20using%20an%20Android%2C%20an%20app%20that%E2%80%99s%20premier%20content%20is%20a%20live%20broadcast%20a16z%E2%80%99s%20content%20marketing%20standup%20won%E2%80%99t%20make%20me%20an%20iPhone%20user%20either.)

[^6]: I’m a [personal investor](https://benn.substack.com/p/disclose-your-angel-investments) in Mozart.

[^7]: Jerome! Shut down all the garbage compactors on detention level! SHUT DOWN ALL THE GARBAGE MASHERS ON THE DETENTION LEVEL!

[^8]: While we’re here, [we need to talk about this website](https://twitter.com/bennstancil/status/1613751774749380608).

================================================================================

# Do data teams have product-market fit?

*It’s us, hi, we’re the problem, it’s us.*

---

![](https://substackcdn.com/image/fetch/$s_!0md0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f7a7a28-ed5d-48e5-85f3-da4f47dba055_681x383.png)
*[really looks like](https://people.com/music/ticketmaster-cancels-taylor-swifts-eras-tour-general-ticket-sales/)*

When a startup launches a new product, the second worst thing that can happen is that nobody buys it. The worst thing that can happen is that five people do. 

Five customers could be the beginning of something big. Five customers could be a sign of much more to come. Five customers could be, in the eyes of a founding team that's hoping to validate their exciting new idea, evidence that they are. Five customers could be a wedge, a foothold, a sharp edge cutting into a huge market. Five customers rounds up to ten customers, and [ten customers is a milestone](https://www.ycombinator.com/library/9h-how-to-get-your-first-ten-customers).  

But five customers could also be a false start. Five customers could be a few eager early adopters that aren't representative of anything bigger than themselves. Five customers could be, in the eyes of a founding team that's hoping to validate their exciting new idea, confirmation bias. Five customers could be a cul-de-sac, a dead end, a commanding market share among a tiny group of idiosyncratic buyers. Five customers could be [dogecoin](https://coinmarketcap.com/currencies/dogecoin/): appealing to a passionate niche, useless to everyone else, and [ngmi](https://www.urbandictionary.com/define.php?term=ngmi).

[Five customers could be forever, or go down in flames.](https://www.youtube.com/watch?v=e-ORhEE9VVg)

Over time, reality has a way of revealing itself. The durable successes—the products with real product-market fit—[keep selling out](https://www.forbes.com/sites/forbes-personal-shopper/2023/01/16/ugg-tasman-slipper-restock/?sh=6b3d881fbf11). Five customers turns into fifty, and five hundred. Companies no longer have to fight for every sale; they [cross the chasm](https://leanb2bbook.com/blog/b2b-founders-read-crossing-the-chasm-before-startup/);[^1] [the uphill struggle flattens out](https://twitter.com/eshear/status/1155182080835194880) and [turns into a downhill run](https://twitter.com/eshear/status/1155182410608201728). 

When products don’t fit their markets, however, the climb keeps getting steeper. Initial customers show up for unique reasons, and their interests aren’t representative of what other people want. The further the company gets from that group, the more it struggles to sell.

The problem is that it takes time to tell which path a company is on. Did the early excitement around the iPhone foreshadow a global revolution, or was it [brand loyalists getting overhyped about a product](https://www.marketwatch.com/story/apple-should-pull-the-plug-on-the-iphone) that "will be passé within 3 months?" Were conference calls the next huge innovation in social media, or was Clubhouse just the perfect product for grandstanding VCs and crypto grifters in the middle of global pandemic? Is an exclusive and minimalist email client with dozens of snappy keyboard shortcuts the future of productive digital communication, or is Superhuman just a status symbol for startup CEOs? 

In the heat of the moment, at the beginning of what feels like the vertical leg of the exponential growth curve, these aren’t easy questions to answer—but [it is difficult](https://www.goodreads.com/quotes/21810-it-is-difficult-to-get-a-man-to-understand-something) to get a man to take the pessimistic view when his stock options depend on him not taking it. So we often choose to believe that our initial idea was a good one; that five customers is just the beginning; that we can build and iterate and educate our way up and over the mountaintop; that, if demand is slowing or sales take more selling, [the market just needs a bit more annealing](https://a16z.com/2023/01/11/market-annealing/). 

In some cases, the company is right. Their relentless effort works, and they pound the product and the market into one another. But in other cases, the initial pop of interest was actually the peak, and [the company dies with their hammer in their hand](https://www.youtube.com/watch?v=bqxjHzff-Qo).

# Sold, not bought

Over the last several months, the data punditry has shifted from talking [about the tools](https://counting.substack.com/p/data-science-has-a-tool-obsession) to talking [about the work](https://pedram.substack.com/i/93416609/on-talking-about-the-work)—and specifically, how [we work with teams outside of our own](https://twitter.com/BM_DataDowntime/status/1613942755730018304). This is important, we say, because we don’t yet have the influence within our companies that we know we could.

Sure—this is a useful discussion, and a version of a [podcast that I’d listen to](https://twitter.com/bennstancil/status/1421225199157002245). But here’s the thing: *These aren’t new conversations. *We’ve been hammering on this problem for years. [Katie Bauer’s recent post](https://wrongbutuseful.substack.com/p/elbows-of-data) about data teams being left on the sidelines is excellent—and depressingly evergreen. Two years ago, Erik Bernhardsson [wrote a story](https://erikbern.com/2021/07/07/the-data-team-a-short-story.html) about navigating the same problems of being misunderstood, left out, and asked to do the wrong work. The frustrations resonated then as much as now: “[It’s so realistic](https://twitter.com/fulhack/status/1413534531060211718);” “[very relatable](https://twitter.com/chuckcode/status/1413353327887192064);” “[this is so spot on](https://twitter.com/ito/status/1413346937739251712);” “[OMG - its my life!](https://twitter.com/KirstyKitto/status/1413422224627748872)”

Evidence of data teams’ persistent struggle is everywhere. [This advice](https://mode.com/blog/how-to-ask-an-analyst-a-question/) from 2015 to business stakeholders on how to work with analysts could’ve been written today—and in fact was, [by David Jayatillake](https://davidsj.substack.com/p/dear-stakeholder), just two weeks ago. For as long as we've had analytics and BI teams, we've tried to create [good processes](https://chartio.com/blog/3-steps-to-prioritizing-data-requests/) for people to ask them questions. We’ve [shared intake forms](https://www.caitlinhudon.com/posts/2020/09/16/data-intake-form). We’ve [built products](https://www.secoda.co/data-ticketing). And yet, most data teams still can’t convince their business partners to regularly use them, and our most common ticket management system [is still Slack DMs](https://twitter.com/imightbemary/status/1614663474113806338). We’ve put self-serve interfaces between us and everyone else, and declared it [disaster](https://www.reddit.com/r/BusinessIntelligence/comments/9zjhm2/how_much_of_a_disaster_has_selfservice_bi_been_in/)—no, [critical](https://www.businesswire.com/news/home/20220112005334/en/New-Report-Finds-Self-Service-Analytics-Are-Critical-to-Empowering-Frontline-Workers-with-Data-Driven-Decisions-and-Autonomy)—no, [a lie](https://www.montecarlodata.com/blog-is-self-service-datas-biggest-lie/). And we’ve [punted on efforts](https://hex.tech/blog/data-team-roi/) to measure our value to the point that it’s [become an inside joke](https://twitter.com/pdrmnvd/status/1610090122162364416). 

In this context, imagine that the data community is the company, and the product that company makes are data teams that operate in the manner that’s popular today—embedded in a business, designed to help people make better decisions. Our business partners who choose to work with us are our customers.[^2] 

If we had product-market fit—if stakeholders were enthusiastic buyers of the services we offer—would we still be kept out of the influential rooms we want to be in? Would we have to fight to be heard? Would we have to constantly remind people why our work is valuable?

No. Products that have product-market fit [are bought, not sold](https://a16z.com/2017/02/18/12-things-about-product-market-fit-2/#:~:text=%234%20%E2%80%9CYou%20can,Buck%E2%80%99s.%E2%80%9D%20Marc%20Andreessen). And as people’s responses to posts like those from Katie and Erik show, most data teams still have to do an awful lot of selling. 

# Shepard tones

There are, of course, data teams that don’t have these problems. We have our [famous idols](https://twitter.com/sarahcat21/status/1590054662551764992), and there are surely scores of other teams who’ve been successful outside of the limelight. 

These companies, though, might be our first five customers: the peculiar businesses for whom the current model of a data team works. They might [have data that is particularly valuable](https://benn.substack.com/i/83946516/its-not-a-data-lake-its-a-peat-bog). They might have executive teams who bought the hype, and now [have blind faith](https://twitter.com/seanjtaylor/status/1433636587699539996) that data teams are essential. They might be companies that hired a uniquely talented set of analysts who can make good on promises that most of us can’t.

However, none of these cases are necessarily representative of the market writ large. If we’re only useful to companies with especially useful data, we’re like Superhuman: good for a small and specialized audience; overpriced and unnecessary for everyone else.[^3] If we need people to be true believers, we’re like the Apple its skeptics imagined: fueled by brand loyalty and not product utility. And if we need our users to be extremely talented, we’re like Clubhouse: great only for people with the right resumes.[^4]

In these cases, user education and a few more features won’t fit the product into the market.  The mismatch is more fundamental than that. Incremental iterations may seem like progress, but the motion is mirage, a [Shepard tone](https://www.youtube.com/watch?v=LVWTQcZbLgY) that never reaches where it feels like it’s going. 

Though I’m not convinced that data teams are *that* far from finding their way, I think it’s worth assuming, if just for a moment, that they are. What if we’re not [prophets in the wilderness](https://davidsj.substack.com/p/dear-stakeholder#:~:text=prophet%20in%20the%20wilderness), but salespeople selling a lemon? What if the problem isn’t that market doesn’t understand what we’re offering—it’s that they do, and they don’t want it?

# One good idea and four bad ones

The first thing we should do is talk to some product and marketing managers. They’re paid to figure this stuff out, and they can certainly outline a better plan than we can. 

But I was a product manager for a minute (it didn’t go well), ran a marketing team once (it went worse), don’t have the creative courage [to end a blog post so abruptly](https://clrcrl.com/2022/05/06/mds-company-slack.html) (respect), and am a white guy ([I’m not qualified, but I got this](https://www.linkedin.com/pulse/men-apply-job-when-meet-only-60-qualifications-women-100-mei-ibrahim/)), so here are four ideas fired off from the hip.

### Pay attention to what’s working

[In a comment](https://benn.substack.com/p/the-conglomerate/comment/11966114) to last week’s post, Kendall Willets pointed out the big X [I’ve been standing on but never saw](https://www.youtube.com/watch?v=dvywOjh_hdY): different types of data work are treated differently. When marketers want to optimize their ad spend, there’s a ton of pull for our services. We can pout about that—”[I want a ](https://www.youtube.com/watch?v=Z9obgyYB1IU)*[strategic](https://www.youtube.com/watch?v=Z9obgyYB1IU)*[ oompa loompa!](https://www.youtube.com/watch?v=Z9obgyYB1IU)”—or we can ask why that’s the product of ours that people want to buy. 

My suspicion is that it’s because it matches an actual customer demand that we’re uniquely suited to provide. As much as we may hate it, people need data pulls. They don’t need junior strategic advisors armed with spreadsheets and an attitude. If we want to be in the [room where it happens](https://www.youtube.com/watch?v=qrkwgEUXyTU), we shouldn’t spend our time trying to sell an unnecessary service to a reluctant buyer; we should spend it figuring out what we can do that would make it necessary for us to be there. 

### Pay attention to what’s broken

In asking myself if data teams have product market-fit, I kept getting hung up on how we handle work requests. This is a simple task and a solved problem. Huge engineering teams do it for far more complicated projects than we work on. Support teams do it for [hundreds of thousands](https://www.uber.com/blog/cota/) of daily tickets. Why have five-person data teams still not figured it out?

I don’t know.[^5] But I suspect there’s something interesting about our relationship with our customers in this answer. Just as actual vendors can learn a lot from churned customers and lost opportunities, we can learn a lot from our unexpected failures. 

### Don’t assume, ask

The corollary to both of these points is that we have to talk to our customers. We have to research them; understand them; put ourselves in their shoes and figure out why they do what they do. When they push us aside, we shouldn’t assume that we’re offering something valuable—strategic advice! Metrics and alignment! Experimentation and the scientific method!—and our job is to sell it; we should instead ask them why they don’t want it. 

The answers may surprise us. Our advice might be bad. [Metrics might not be that useful.](https://commoncog.com/goodharts-law-not-useful/) We might create more disruption and doubt than we do agreement and alignment. If there’s a case to be made for [hiring a data PM](https://twitter.com/imightbemary/status/1614663891501580292), this is it—to do [discovery](https://www.gong.io/blog/what-is-a-discovery-call/), and figure out what people actually want from a data team.  

### Read the history books

Finally, [my least favorite idea](https://twitter.com/bennstancil/status/1598518024490962952): We should do our historical research. Though our technology is new, our job titles are new, and many of us are, in the scheme of things, new, the organizational problems we’re trying to solve are old. We can choose to solve them again, or we try to learn from our ancestors, and not repeat their mistakes.  

Do I know what those mistakes are? [Of course not.](https://medium.com/@laurengreerbalik/6-reality-based-predictions-for-data-in-2023-bdcf006e6026#:~:text=The%20entire%20%E2%80%98Modern%20Data%20Stack%E2%80%99%20world%20is%20slowly%20just%20re%2Dlearning%20concepts%20that%20are%20well%2Ddefined%20among%20larger%2C%20established%20companies%20with%20years%20to%20decades%20of%20data%20management%20cultures.) But I’m sure that prior generations of data teams, BI developers, and IT professionals have tried to sell their services to hesitant customers. And they probably have stories to share. 

# That sinking feeling

When writing these blog posts or putting together presentations, I usually start with a bunch of mushy waypoints through a loosely formed idea. These aren't bullets of Takeaways,[^6] but the stories I want to tell, articles I want to reference, [petty grievances I want to air](https://benn.substack.com/p/do-data-driven-companies-win#:~:text=Imagine%2C%20if%20you,of%20its%20success.)—and sometimes, substantive points I want to make. In a post's or presentation's early stages, I'm usually shuffling around paragraphs or slides to see if there’s a coherent way to fit them together. 

[It doesn’t always take](https://www.youtube.com/watch?v=PehdC24cyCU). The story doesn't fit; the slides refuse to give up the fight; [I read it over and over and still can’t stand it](https://benn.substack.com/p/the-more-the-merrier#:~:text=Once%20the%20studs%20are%20set%2C%20the%20rest%20is%20polish.%20In%20this%20final%20stage%2C%20the%20best%20advice%20I%E2%80%99ve%20heard%20is%20from%20Jia%20Tolentino%20(via%2C%20again%2C%20Angela)%3A%20%E2%80%9CRead%20it%20over%20and%20over%20again%20until%20you%20can%20stand%20to%20read%20it.%E2%80%9D).[^7] A sinking feeling of disappointment sets in, and you know what you have to do: concede defeat, [kill your darlings](https://roundup.getdbt.com/i/42061643/kill-your-darlings), and start over. 

For the better part of a decade, we’ve been trying to manifest a narrative about how data teams are critical pillars in modern companies. We sell our ideas to our employers, get frustrated with them when they don’t buy it, and blame ourselves for not having the influence we feel like we should. 

I’m not sure that’s the right reaction. The problem might not be our sales pitch, but what we’ve been taught to sell. We may be extrapolating too much from our first few customers, and are trying to force their story onto a broader market that never wanted it. In which case—let’s [shake it off](https://www.youtube.com/watch?v=nfWlot6h_JM), and [reinvent ourselves](https://en.wikipedia.org/wiki/Folklore_(Taylor_Swift_album)).


---


[^1]: At the risk of turning this blog into a [snarky design critique site](https://benn.substack.com/p/the-conglomerate#footnote-8-96491513), what on earth is going on with the signup box [at the end of this post](https://leanb2bbook.com/blog/b2b-founders-read-crossing-the-chasm-before-startup/)? Why is it tilted by one degree? *One *degree?!?* *It’s subtle enough that you can’t quite tell what’s going on, other than you’re slowly getting dizzy. It’s the online equivalent of being in a stopped train, looking out of the window at another stopped train, seeing *something* move, not being able to tell if it was you or them, and then feeling nauseous for the next ten minutes. Except someone did this on purpose.

[^2]: Just what we need, yet another definition of [data as a product](https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean) to be added to the lexicon.

[^3]: As it’s now trendy to say, when interest rates were low and money was cheap, it was easy to lose sight of what cost more than it was worth.

[^4]: Importantly, product-market fit also requires the product to be accessible. People may want to buy a self-driving car, but if it costs fifty million dollars, it doesn’t work in the market it needs to be sold to. Similarly, a surgery that cures cancer would clearly be in high demand, but it doesn’t have product market-fit if it’s so complicated that it can only be performed by a few doctors.

[^5]: Though I have theories. Perhaps it's because data team work is often seen as "just pulling a number," so creating a ticket seems like more overhead than it’s worth. Perhaps it's because these asks are often offhand curiosities that come up in meetings and not formal requests. Perhaps it's because a lot of our work comes from [questions we ask ourselves](https://wraptext.equals.app/the-curious-analyst/#:~:text=Building%20a%20practice.), and we’re the lazy ones who don’t stamp our timesheets. Perhaps it's because we do a lousy job of showing the value of having a paper trail, so nobody creates one (but shoutout to Caitlin Hudon [for breaking this cycle](https://twitter.com/beeonaposy/status/1616112218411597825)).

[^6]: I’m [allergic to bullets](https://benn.substack.com/p/the-more-the-merrier#:~:text=Bullets%20cut%20ideas%20short.%20They%20let%20me%20glance%20at%20something%20and%20convince%20myself%20I%E2%80%99ve%20seen%20it%2C%20while%20staying%20comfortably%20on%20my%20original%20path%20through%20a%20topic.) (and, if we’re honest about evidence, [allergic](https://benn.substack.com/p/the-internet-2022) [to](https://benn.substack.com/p/the-worst-spreadsheet) [takeaways](https://benn.substack.com/p/open-the-window) [too](https://benn.substack.com/p/coffee-cake)).

[^7]: My five (for real, not a joke) rules for giving an effective presentation: 1. Think in prose. 2. Go fast. 3. Spend most of your time on transitions. 4. Rhyme off the beat. 5. Don’t listen to other people’s rules for giving effective presentations.

================================================================================

# The rapture and the reckoning

*I'm a believer—AI will change everything about data too.*

---

![the end is nigh | The End is Nigh sandwich board near the en… | Flickr](https://substackcdn.com/image/fetch/$s_!NAFf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b4b0b56-4c54-4017-86dc-b034c8799142_1024x687.jpeg)
*The mess-AI-ah is coming.*

Give me a Bible and a bullhorn; the end is near. 

All the work we’ve put in to building the modern data stack is on the cusp of being undone. Hard-won theologies will be proven wrong; [the day of judgment](https://www.biblegateway.com/passage/?search=Revelation+18%3A10&version=KJV) will come for our mighty Babylon. That great city will be thrown down; it will be cast into the sea, and dozens of promising SaaS tools [shall be found no more at all](https://www.biblegateway.com/passage/?search=Revelation+18%3A21&version=KJV).

The [prophets](https://www.wsj.com/articles/how-artificial-intelligence-will-change-everything-1488856320) were right. AI will change everything.

Admittedly, I didn’t believe them at first. Yes, large language models like ChatGPT are impressive, and image generation software like [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion) is breathtaking, but I never saw how this technology would meaningfully change the data industry. Most early converts would just point to ChatGPT, make a comment about how it can pass the bar exam, and handwave past how, exactly, this would change the day-to-day job of a data team. 

So far, its real applications have been either trivial or underwhelming. AI might help us identify defects in our data or anomalies in our metrics. Neat, I guess, but hardly transformational. It might [make us more creative analysts](https://twitter.com/bennstancil/status/1598522785453772800). Again, an improvement in degree, not in kind. 

What about [replacing analysts with a chatbot](https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/)? *That* would be a revolution—but we’re not anywhere close to it being possible. On the surface, early efforts like these to generate [SQL with ChatGPT](https://towardsdatascience.com/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2) have been extraordinary. With shockingly little input and tuning, it can turn English questions into working queries. Though it’s only right about half the time—which isn’t close to good enough[^1]—that also means, when asked to perform a task that a tiny fraction of adults could do, it’s *right half the time.*

But these impressive demos are just that: Impressive demos. Though they aren’t exactly scripted, they’re run in tidy sandboxes that don’t resemble anything close to real data environments. The chatbot, for example, was built against a database [with three tables](https://www.patterns.app/blog/2023/01/18/crunchbot-sql-analyst-gpt/) and 32 columns. Everything was simply and sensibly named, mostly using words that can be looked up in a dictionary. The test questions were basic, unambiguous, and could be answered by an experienced analyst in a handful of lines of SQL.[^2]

The distance between this and companies’ actual data ecosystems is staggering. [In a webinar earlier this week](https://atlan.com/great-data-debate), Tristan Handy, the CEO of dbt Labs’, said that a meaningful percentage of their customers are using dbt to create more than 5,000 tables. These tables are often named with unintuitive and idiosyncratic idioms and abbreviations, and are littered with ambiguous words, like accounts and transactions, that mean different things in different contexts.[^3] There are no simple questions—answering “How many new European accounts did we add last week?” requires defining an account, what new means, where Europe is, when a week starts, [in what time zone it should be calculated in](https://twitter.com/teej_m/status/1616920472322727939), and if “add” means net or gross. And there aren’t often simple answers—the average query in Mode is 75 lines and 2,700 characters long. 

If ChatGPT is already unacceptably bad in [impossibly agreeable environments](https://twitter.com/sethrosen/status/1252291581320757249), it would be abysmal in the real world. To borrow again from Tristan in the same webinar, the early attempts to use AI to write SQL queries (to answer questions or to generate dbt models) are akin to our efforts to build self-driving cars. Practically overnight, both went from it being the stuff of science fiction to appearing tantalizing possible. But the [progress bar is a mirage](https://www.reddit.com/r/ProgrammerHumor/comments/s60to6/i_made_a_fake_progress_bar_to_shut_up_clients/). The edge cases—the construction sites, the unexpected traffic patterns, the school zones; the messy schemas, the bespoke metric definitions, the complex questions—are far, *far* harder than highways and dummy databases we got excited about. And I would guess that this is particularly true for using large language models to write company-specific queries. It’s hard enough to build a self-driving car that can navigate complicated neighborhoods; it’s quite another if every single one of those neighborhoods has its own traffic laws, follows different traditions, and has never bothered to write any of it down.[^4]

The inevitable revolution in data, it seems,  would arrive at the same time as our [autonomous cars](https://www.youtube.com/watch?v=Vrxyr1CjiSM):[^5] [Tomorrow](https://phys.org/news/2014-09-tesla-chief-self-driving-cars-corner.html). [Always](https://www.cnn.com/2019/02/20/tech/musk-self-driving-car-prediction/index.html) [tomorrow](https://www.dailymail.co.uk/sciencetech/article-11159627/Elon-Musk-claims-Teslas-fully-autonomous-self-driving-cars-available-end-2022.html).

# Where we're going, we don't need roads 

But maybe our problem is easier. Contemplating the problem of self-driving cars, Balaji Srinivasan—who may well be a chatbot himself, trained exclusively on backwater crypto subreddits, the University of Austin’s “[curriculum](https://www.uaustin.org/undergraduate-curriculum),” and *[Future](https://future.com/)*, Andreessen Horowitz’s techno-optimism content marketing program[^6]—proposed a solution: [Rebuild the roads](https://twitter.com/balajis/status/1578723247067389953).

Balaji’s tweet was ratioed into oblivion.[^7] Putting aside the fact we already have these roads—they're called train tracks—at our current pace of improving [two miles](https://www.google.com/maps/dir/37.773019,-122.4187079/37.804132,-122.42523/@37.7885145,-122.4394498,14z/data=!3m1!4b1!4m2!4m1!3e2) of road every [six years](https://www.sfmta.com/projects/van-ness-improvement-project), we’d be able to replace all [four million miles of roads](https://www.fhwa.dot.gov/policyinformation/pubs/hf/pl11028/chapter1.cfm) in the United States by the year 12,002,023.[^8]

Still, Balaji’s tweet highlights a useful trick. To solve a problem, we can solve it outright—or we can change the problem. Rather than asking self-driving cars to navigate hopelessly complex terrain, we could bulldoze the terrain into something more manageable. 

The same principle applies when we ask an AI to analyze today’s sprawling and labyrinthine data structures. We could demand it figure them out, or we could refactor them into something more consistent. And unlike our roads, these models are just code—they could be rebuilt, not in [meggannums](https://www.wikidata.org/wiki/Q20764), but in days and weeks. 

# Back to the future

Two decades ago, the data industry’s holy wars weren’t about meshes or contracts, but [warehouse schema design](https://andyhogg.files.wordpress.com/2012/11/kimball-vs-inmon.pdf). Should tables be wide or narrow? Should multiple tables [contain redundant information](https://www.geeksforgeeks.org/denormalization-in-databases/) to make queries faster by avoiding joins? How should [data marts](https://www.ibm.com/topics/data-mart) be used? These questions mattered because databases were much slower and more expensive back then. But an organized warehouse was a faster warehouse, so IT teams that rigorously chose and stuck to a consistent set of governing principles could squeeze out better performance. The only way to cook efficiently in a small kitchen is [by putting everything in its place](https://en.wikipedia.org/wiki/Mise_en_place); the only way to work with an old database is to be disciplined about how you structure your tables.

As warehouses have gotten faster, we’ve backed away from these principles. Part of that is intentional—ideas that were canon fifteen years ago [are now outdated](https://www.fivetran.com/blog/star-schema-vs-obt). Part of it is also probably necessary—the average Fivetran customer, for example, is extracting data from about 25 different services;[^9] it’s very difficult to apply a single design pattern across such a diverse range of sources. But most of our slow abandonment of old design principles feels like intellectual drift. Without yesterday’s performance constraints, we can lazily relax our standards. And more importantly, the accessibility of the modern data stack and tools like dbt make it possible for any [illiterate clown](https://twitter.com/bennstancil/status/1598518024490962952) to cosplay as a DBA. 

The results are predictably chaotic. Like most other [Kids These Days](https://www.tiktok.com/@lenovo/video/7136281311337123118),[^10] I don’t design our databases based on the actual teaching of Ralph Kimball or Bill Inman, but [in accordance with what I think their wishes might well have been](https://youtu.be/Wk61MeDmk2M?t=82). Fact and dimension tables aren’t oriented around tight star schemas; they’re instead just a naming convention for [separating tables of events from tables of objects](https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355#:~:text=There%20are%20entire%20books%20written,customers%2C%20products%2C%20candidates%2C%20buildings%2C%20employees.). Most schemas aren’t intelligently designed; they’re emergent, the result of an evolving web of new models that are continually added to the dbt DAG. There is no law governing how the database should be organized; there’s convention and a bunch of halfway-educated best guesses. 

Amid this chaos, there have been some calls to [define schema design standards](https://www.getdbt.com/coalesce-2020/kimball-in-the-context-of-the-modern-data-warehouse-whats-worth-keeping-and-whats-not/) for the modern data stack. Of course, we shouldn’t try to go back to the same patterns we used a decade ago; we need new ones, for the people, data, and technology we have today. 

But why stop there? As messy as the current world is for us, it’s kryptonite for an AI. What if instead of building new patterns for people, we built them for our AI gods?

A few years ago, [Narrator](https://www.narratordata.com/), a product inspired by tools inside of WeWork, proposed a design pattern that they called the [activity schema](https://www.activityschema.com/). If nothing else, I give it points for audacity: The entire blueprint is one giant event table. It’s as if you took a star schema, joined every dimension table onto its corresponding fact table, and then unioned all of those fact tables together into one bottomless list of events.

Assuming this approach doesn’t have structural limitations (i.e., there aren’t questions that it can’t answer that other schemas could), its biggest problem might be usability. For analysts who are accustomed to thinking about relational models, working with [a single event stream and a bunch of self-joins](https://github.com/ActivitySchema/ActivitySchema/blob/main/2.0.md#multiple-activities) feels pretty unnatural. 

For ChatGPT, however, this could be trivially easy—far easier than stepping through a convoluted series of joins. Moreover, because the activity schema is heavily standardized, an LLM doesn’t need to be deeply aware of the individual idioms within each company that wants to use it. Train a general model with a bit more detail about activity schemas, prompt your version of it with the basic documentation of the events contained in your stream—in other words, put the car on the traffic-free interstate and tell it the traffic laws—and see how far *that'll* go.[^11]   

# Judgment day

To be clear, Narrator’s activity schema is meant to be illustrative, not prescriptive. I haven’t used it in meaningful ways, and I have no idea how ChatGPT would actually interact with it. The point, though, is that it seems unlikely that the schema design patterns that we created for people are optimized for LLMs. As the [skeptics of the chatbot analyst correctly pointed out](https://news.ycombinator.com/item?id=34521149), it’s the relational nuances that confuse AI models. But we could flip that. If AI-powered analytical tools have enough potential—which, seeing what ChatGPT can do, it seems like they do—would it not make sense to favor schema design patterns that enable the big-brained computers more than they enable us feeble-brained apes?

If something like this works, it’s a bomb that blows up half of the data industry. For data consumption, it would be like replacing [AOL channels](https://www.google.com/imgres?imgurl=https://newconsumer.com/wp-content/uploads/2021/02/aol-channels.jpg&imgrefurl=https://newconsumer.com/2021/02/clubhouse-mobile-audio-chat/&tbnid=jmZODA0oB8DLgM&vet=1&docid=YCdeJqhkVMjDrM&w=1400&h=879&source=sh/x/im) with search. Instead of leafing through a sitemap of existing reports, people could ask for what they need directly. Analysts would either become less relevant, or would finally be freed up to work on [more interesting things](https://benn.substack.com/p/why-do-people-want-to-be-analytics#footnote-anchor-3-62062026:~:text=A%20lot%20of%20analysts,on%20some%20real%20analysis.%E2%80%9D).[^12] 

Analytics engineering would be recast as well. Today, analytics engineers have to translate [complicated technical schemas](https://docs.google.com/presentation/d/1wSWI7SbY4NMtyRLWdg2Z4LW3-SRCF8K7McN0VzLjh3w/edit#slide=id.g1ba00f96b0c_2_0) into semantically useful ones that have to make sense to the people who use them. That’s an architectural job, it’s a creative job, and [it’s hard](https://twitter.com/tejasmanohar/status/1414670898880200712). Schema models designed for LLMs, by contrast, would probably come with a spec. Because the model wouldn’t need to be semantically expressive—LLMs find patterns, not meaning—that spec would likely also be relatively simple and consistent. Our transformation layers wouldn’t be inventive kitchens, figuring how to design bespoke dishes for individual customers. They’d instead become factories, stamping out the same standardized and machine-readable perforations that everyone else does. 

This would also make our data more reliable. Not only is something like the activity schema easier to produce than a complex logical mesh of tables and metrics; it would also be much easier to monitor and debug. Observability tools wouldn’t need to be anything more than an QA tester on an event stream assembly line. 

The implications of this would be profound. For decades, we’ve thought about building data tools and processes for people. They’ve been our best analysts, our best query writers, and our best decision makers. 

But I’m not so convinced that’s true anymore—and the only thing that’s keeping us on top is we’ve rigged the game in our favor. If that changes, if we design our worlds for AIs, [if we give our power and strength unto the beast](https://www.biblegateway.com/passage/?search=Revelation+17%3A13&version=KJV), we might be able to go much  further than we can today. A new heaven and a new earth will come, and the [first heaven and the first earth will pass away](https://www.biblegateway.com/passage/?search=Revelation+21%3A1&version=KJV). 


---


[^1]: Nobody’s going to use a tool that is randomly and confidently incorrect half the time, or even ten percent of the time. No CEO will send a financial statement to the board that misstates one in ten metrics wrong; no operations team will manage their inventory based on order volume reports that have a ten percent chance of being wrong. [Spectacularly bombing a mathematical riddle](https://twitter.com/Carnage4Life/status/1602802693034373120) is one thing; invisibly issuing a bad SEC filing is quite another.

[^2]: None of this is meant to be critical of either blog post, neither of which claim to be anything more than experiments.

[^3]: Are accounts…customers? People who signed up for a product? Shared workspaces for collections of users? The [Salesforce account object](https://help.salesforce.com/s/articleView?id=sf.accounts.htm&type=5)? The [Stripe account object](https://stripe.com/docs/api/accounts)? And transactions—are they customer orders? Credit card payments? Web events? The [Salesforce transaction object](https://help.salesforce.com/s/articleView?id=sf.om_order_transaction_objects.htm&language=en_US&r=https%3A%2F%2Fwww.google.com%2F&type=5)? The [Stripe transaction object](https://stripe.com/docs/api/issuing/transactions/object)?

[^4]: Some people drive on the right side of the road, some on the left, and lunatics [drive down the middle](https://mode.com/blog/should-sql-queries-use-trailing-or-leading-commas/#:~:text=nearly%2014%25%20of%20query%20authors%20in%20a%20disturbing%20middle%2C%20as%20tragic%20wafflers%2C%20acquiescent%20centrists%2C%20or%20intentional%20vandals%2C%20more%20anarchist%20than%20analyst.).

[^5]: [And our free beer.](https://happyneon.com/products/free-beer-tomorrow-neon-sign)

[^6]: I mean, [read this](https://balajis.com/elondrop/) and tell me it’s not at least *possible.*

[^7]: Balaji’s 9.1 quote-tweet-to-retweet ratio was higher* *than the 7.9 Matt Yglesias put up when *[well ackshually](https://twitter.com/mattyglesias/status/1529234787579355136)*’ed the Uvalde shooting, but far lower than the 51.3 [masterpiece](https://twitter.com/natesilver538/status/1478925497786675206) that Nate Silver dropped when he compared Covid school closures to the invasion of Iraq.

[^8]: True longtermism isn’t worried about our great-grandchildren, but about the world 400,000 generations hence, when the only surviving life is a few mountain lichens, a handful of [horseshoe crabs](https://en.wikipedia.org/wiki/Horseshoe_crab), and [Peter Thiel’s immortal husk](https://www.ft.com/content/681fa287-f9ff-47f3-9f44-c0736ee0ab53).

[^9]: In 2022, Fivetran said they were syncing data from [100,000 connectors](https://www.fivetran.com/press/fivetran-extends-market-leading-position-more-than-doubles-revenue-in-2021) for [4,000 customers](https://www.fivetran.com/blog/data-integration-gartner-mq).

[^10]: Ok, somehow Lenovo Tiktok [isn’t](https://www.tiktok.com/@lenovo/video/7193018093197724970) [bad](https://www.tiktok.com/@lenovo/video/7187496621737872682).

[^11]: Are there already two decades of history behind this idea? [Probably.](https://www.linkedin.com/feed/update/urn:li:activity:7024373260607713280/) But what is a data Substack if not a place to rebrand [old ideas](https://en.wikipedia.org/wiki/OLAP_cube) with [new names](https://benn.substack.com/p/metrics-layer)?

[^12]: Yes, there are already tools like Thoughtspot that sorta do this. The difference is that these tools either require a semantic model to work, or are tripped up by the same problems that confound today’s ChatGPT bots. The point here is to back up a step: Can we structure our data such that these tools work on complex questions without predefined semantic configurations?

================================================================================

# The insight industrial complex

*Most people just want to know what's going on.*

---

![Eisenhower's Military-Industry Complex Warning, 50 Years Later : NPR](https://substackcdn.com/image/fetch/$s_!AGUE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcf10c810-6f7e-4209-832c-f97b053930ac_972x729.jpeg)
*[I like Ike’s catchy phrases.](https://www.npr.org/2011/01/17/132942244/ikes-warning-of-military-expansion-50-years-later)*

At some point over the last decade, [every company became a platform](https://www.nytimes.com/2021/09/15/books/review/jonathan-knee-platform-delusion.html), leeching all meaning out of the word:

> Peloton, which sells indoor exercise bikes, calls itself an “interactive fitness platform.” Casper, which sells mattresses, is a “platform built for better sleep.” Beyond Meat, which sells faux-burgers that taste like beef, pork and poultry, insists that these are actually “three core plant-based product platforms.”

Companies are stale and corporate. Tools are lifeless antiques. Services are valued at [low revenue multiples](https://www.corumgroup.com/Not-All-Revenue-Is-Created-Equal--Revenue-Composition-Affects-Valuation-Part-I-of-II#:~:text=a%20commodity%20business.-,Services,-%3A%C2%A0The%20performance%20of). But platforms—platforms are dynamic and modern. They have viral flywheels, and network effects, and economies of scale. They don’t sell to customers; they champion their communities. Since 2020, 1,926 companies have [been accepted to Y Combinator](https://www.ycombinator.com/companies). Thirty-four percent, or 655 startups, [market themselves as a platform](https://www.ycombinator.com/companies?query=platform). 

We data vendors, of course, would never give in to such melodrama.[^1] Of YC’s 702 [data companies](https://www.ycombinator.com/companies?query=data), only thirty percent—a sober, disciplined figure, far less than 34 percent—[claim to be a platform](https://www.ycombinator.com/companies?query=data%20platform). 

Fortunately, styling ourselves as platforms is a mostly victimless crime; it might make some smug little Substackers roll their eyes, but [forty percent of YC’s top companies](https://www.ycombinator.com/companies?query=platform&top_company=true) are platforms, so it also might make you successful.[^2] Unfortunately, oversaturating the definition of a platform isn’t the worst act of rhetorical strip mining that we routinely engage in. And our other grammatical grift—bludgeoning the word “insight” to death—has more meaningful costs.

# A platform for insight

As data teams, we’ve painted ourselves into a corner. On one hand, no data team wants to be a [help desk](https://www.winwithdata.io/p/the-analyst-isnt-your-bitch) or dashboard factory, resolving Jira requests for data pulls or cranking out [ghosted dashboards](https://twitter.com/DataGwen/status/1575098830001156097). On the other hand, as much as we might resent it, this is [some of the most important work we do](https://twitter.com/_abhisivasailam/status/1616540986225889280). Optimistically, we’re victims of our boring successes; cynically, our egos are bigger than our abilities. 

Data vendors—analyst advocates, community champions, etc, etc—have found a solution: We should build some dashboards, yes, but our higher calling is to find *insights*. 

MicroStrategy, a BI tool (and “[platform](https://www.evernote.com/l/ADqRtSIOZxdMNpQsPd1LAvmyfJaZr0vnMso) built for disruption”), promises to “bring actionable data [insights](https://www.evernote.com/l/ADoRTC5Pg1tBy4SW-BVCeWyTBLsvocMMsIs) to everyone.” PowerBI, a BI tool (and “analytics [platform](https://www.evernote.com/l/ADrow297SDlPMZAZheRTxxQdE99MMTe24SM)”) will “quickly find meaningful [insights](https://www.evernote.com/l/ADrqrRJXCChI7K8h3HtND0Ajxpzx63ZFz-0).” Looker, a BI tool (and “data analytics [platform](https://www.evernote.com/l/ADq4QhqHA7BH4qnmIKCbjmckfiB0A0VDLng)”), and can unify and empower your teams with “integrated [insights](https://www.evernote.com/l/ADqDoW3YJvFEfp95rTjuKvszAIUthE5M5gc).” Sigma, a BI tool (and “cloud analytics [platform](https://www.evernote.com/l/ADqLQG5Q2TBDgZdjF1NVqlYiPl5UMGoI52Y)”), tells us we “need [insights](https://www.evernote.com/l/ADr4_JYZxsxN9ZQnbJdjb3Mvuj-IrRv0CjA) for the enterprise.” ThoughtSpot, a BI tool (and “developer-friendly [platform](https://www.evernote.com/l/ADreITZHCZVEW6S0ZPq17HmYvlU-3BcbBLI)”) can “get [insights](https://www.evernote.com/l/ADq157Ly__hBma3I6vtBW0xjYkoACDToyvc) faster from your cloud data.” BusinessObjects, a BI tool (and “single, scalable [platform](https://www.evernote.com/l/ADolTv2LrEJFkLexBzGjEYwcxHSzSaiP7lw)”) provides “access to real-time [insights](https://www.evernote.com/l/ADqVqdwlouBJ0a6VLmJF9C1xEivMkEaG04w).” Sisense, a BI tool (and “leading cloud analytics [platform](https://www.evernote.com/l/ADoP1rCWRCNCdavXF05R0QeMLln4f0bvAJQ)”), will “uncover powerful [insights](https://www.evernote.com/l/ADpTzDkMI-RJZZT8BGvjnIzrAKXHRzPWVvQ).” Qlik, a BI tool (and the “only cloud [platform](https://www.evernote.com/l/ADrEbt4AHhhEg4oItLfUVpPD7VG8jw5930c) built for Active Intelligence”), modernizes analytics “for deeper [insights](https://www.evernote.com/l/ADrvNLN7dC1CEbovb1GWMN-HtMe6-ne7g-8) and action.” Mode, a BI tool (and “single [platform](https://www.evernote.com/l/ADqTZo14onxLR5oGv6FT7qmHZYGZfn6gnYY)” for data teams) will “clear the path from data to [insights](https://www.evernote.com/l/ADp6p5zYF4pHdLLzimi3jaifG3eURnv4qQg).” Hex, a hosted notebook (and “magical, modern [platform](https://www.evernote.com/l/ADoWxXERr9JJ4Lvhm0x36wivTvKY_v7sndQ)”), is for “generating [insight](https://www.evernote.com/l/ADpKukOMnuRIrKD7dquzmNKkDgqGXYrVczQ).” Snowflake, a data warehouse (and “[platform](https://www.evernote.com/l/ADrVQz-S5wdCO7dUQa4oUdlhpk67hRgoQKk) that powers the data cloud”) unlocks “previously unimaginable [insights](https://www.evernote.com/l/ADpa5f1MN6lEUbF4M1TN2X6eUdvRbU9lQok).” Teradata, a data warehouse (and “flexible data and analytics [platform](https://www.evernote.com/l/ADogXjHyJmlK6YKpzCLZ8x9XYG8zyM6v2D8)”), is used to “gain new [insights](https://www.evernote.com/l/ADoj7BV0xLVLpLSBfgG4BxEsi9ZEWUes6rA).” Databricks, a data warehouse (and “simple [platform](https://www.evernote.com/l/ADqQAMpk9klAFLsoKJMy1IQhw8Lsdyfn0Wg) to handle all your data, analytics and AI use cases”) helps people “derive new [insights](https://www.evernote.com/l/ADrNymA2akdE3bWn3pa4LkfTGDWfwaHSX8s).” And that’s just on our homepages.[^3] 

What are these ubiquitous insights? We’re never really told,[^4] which is part of the point. Insights are grandiose enough to sound valuable, and amorphous enough to avoid actually saying what that value is. It promises buyers the world without promising anything at all. It confirms to us that our job isn’t to build dashboards without telling us what we should do instead.

Left to figure this out on our own, it’s easy to romanticize “finding insights” into eureka moments and dramatic presentations. Hollywood shows us what these look like: They’re the late-night discoveries that stop us in our tracks, and [rescue the firm](https://youtu.be/QAWtcYOVbWw?t=193).[^5] They’re the whiteboards that [upend an industry](https://youtu.be/Tzin1DgexlE?t=87). They’re the needles that are found in [haystacks of financial data](https://www.youtube.com/watch?v=-OzBI2r0Xb8) and pieced together into a trading position that returns [489 percent](https://en.wikipedia.org/wiki/Michael_Burry#Investment_career:~:text=.%5B6%5D%20Scion%20Capital%20ultimately%20recorded%20returns%20of%20489.34%25%20(net%20of%20fees%20and%20expenses)%20between%20its%20November%201%2C%202000%20inception%20and%20June%202008). They’re the cracked codes that [save the world](https://www.youtube.com/watch?v=kVybZ6YWwHA). 

Though our work is less cinematic—we send bulleted summaries on Slack; we don’t give [presentations in the Oval Office](https://www.youtube.com/watch?v=-XbYQ59vfN4)—it’s hard not to picture ourselves somewhere in these characters.[^6] We’re [storytellers](https://roundup.getdbt.com/p/stories-of-and-about-data#:~:text=Telling%20stories%20using%20data%20is%20when%20I%20personally%20feel%20at%20the%20top%20of%20my%20game%20as%20a%20data%20practitioner.), yes, but we don’t want to be just reporters; we want to be investigative journalists, more detective than narrator. We want to find the clues that others don’t see; to crack cases; to gather everyone around and tell them that things [aren’t what they seem](https://www.youtube.com/watch?v=N4o4XIaeb8E). I still remember an old tag line from [Periscope Data’s website](https://web.archive.org/web/20170210192210/https://www.periscopedata.com/about)[^7] because of how well it resonated with how I saw myself as an analyst: “We love our customers, overpriced avocado toast, and that moment when a blip in the data makes you say, ‘wait a minute…’”

It’s not an outright fiction—these blips happen, and we all have our moments of theatrical glory. But they’re exaggerated, stretched, “inspired by” a true story. In reality, data teams can provide insights—they just don’t look like [the photoshopped versions in our ads](https://www.youtube.com/watch?v=F9K5IS-inHs). 

# An insight by any other name

Gong, a sales call recording service (and “reality [platform](https://www.evernote.com/l/ADoVQkl9nwtLR59BY-JOrat7H0-r2F6HJJY)”), says that it can deliver sales teams “the [insights](https://www.evernote.com/l/ADpQFLLDHjFDbJ0wHZCYUzqSmXB2gqQNAj8) they need to close more deals.” Chorus, another sales recording service (“and conversation intelligence [platform](https://www.evernote.com/l/ADphKIYtOGVB3KHWuRzRbQk0NGMieu9e8bk)”), markets the same kind of “actionable deal [insights](https://www.evernote.com/l/ADpTsRexYbNFyLyGKPHb2pLoMew-WgN6r78).” Both products claim to use AI to mine your customer calls for patterns that can identify which deals are at risk, figure out the types of pitches that resonate, and provide automatic coaching tips to sales reps. 

Sounds great—but it’s not, apparently, why a lot of customers buy these products. I’ve heard from people at both companies that the most useful thing both products do is transcribe sales calls. Sales managers can use those transcriptions to quickly catch up on a deal, or to run simple searches to see how often different competitors get mentioned on calls. The fancy insights—deals that engage a VP in the negotiation stage are forty percent more likely to close! The highest performing reps talk twenty percent less than the lowest performing ones!—are neat, at best. But the real insights, the ones that people are paying for and are consistently valuable, are simple descriptions of fact. They tell sales teams what’s happening, and leave it to the sales teams to figure out what to do about it. 

I’ve heard analogous stories about other “smart” products and services. [Silicon Valley regularly cranks out healthcare startups](https://www.forbes.com/sites/robtoews/2020/08/26/ai-will-revolutionize-healthcare-the-transformation-has-already-begun/?sh=3d5367f4722f) that promise to use data about people’s vitals, the medicines they take, and their genetic history to preemptively diagnose problems and prescribe interventions. A couple doctors I know think this is fantasy, but think an app that accurately tracks when people take their medicine and makes that information available to healthcare providers would be almost revolutionary. Similarly, I have a number of friends who bought nutrition and fitness apps for the insights that the products would supposedly uncover about what they should eat, when they should exercise, and what time they should go to bed. In the end, they liked the products, not for the [pseudo-scientific calculations](https://www.whoop.com/experience/strain/) that they were sold, but because the apps had simple monitors that tracked how many hours they slept every night.

The insight (ha) from these stories is that experts—be it sales leaders, doctors, or anyone who’s trying to figure out why they feel tired in the morning—aren’t looking for complicated and fancy analyses; they usually just want to know what’s happening. The value a data team provides is making that information available. We rarely need to figure anything else out, or obscure these basic facts behind a [Daily Readiness Score](https://www.fitbit.com/global/us/technology/daily-readiness-score). More often than not, this isn’t insight; it’s distortion.

The same applies to internal applications of data. Just as doctors want to know when their patients took their medicine more than they want to know the composite reading on the Mental, Cardiovascular, Dietary, Respiratory, Emotional And Medicinal Yardstick ([MCDREAMY](https://en.wikipedia.org/wiki/Derek_Shepherd)™ by ThriveHealth.ai, YC W24), customer success teams often just want to know what their customers are doing more than they want to see an aggregate health score.

# To each according to his effort

All of this raises a rather obvious final question: Why do we build the health scores? Why do we do the complicated work and in-depth analysis when the easier thing—just some basic reporting—is also the more valuable thing?

My guess is that it’s the result of two illusions that amplify each other. The first is an extension of the [locksmith paradox](https://danariely.com/locksmiths/). In principle, people should be willing to pay a locksmith who picks their lock in a minute more than one who picks it in an hour—the former is a strictly better service. However, people will actually pay the latter more, because, the hypothesis goes, people pay for effort and fairness as much as utility. 

The same applies to the work of data teams. For people who are buying some form of insight, whether that’s a sales team evaluating Gong or an executive wanting to understand their business, complicated work seems more valuable than simple work. Whereas people might pay tens of thousands of dollars for a [Revenue Intelligence Platform](https://www.linkedin.com/company/gong-io/), a simple transcription bot feels like it should be free. Internal data teams are encouraged to do the same thing through social “payments.” Analysis and ostensibly incisive insights are celebrated; building dashboards and reporting is seen as us doing the bare minimum. 

Data teams, however, aren’t like locksmiths in one important way: Basic reporting isn’t actually easy. For many SaaS businesses, accurately and consistently calculating revenue is often harder than far more advanced looking analysis. In many cases, reporting is tedious, fragile, and often under a very precise microscope; analysis is fun, freewheeling, and rarely picked apart by the people who consume it.[^8] 

Put together, these two things trap us in a bad equilibrium, in which data teams aren’t rewarded for the hard work of simply sharing what’s happening. The solution, I suspect, is similar to what’s required to fix any sort of market failure—government intervention to subsidize what’s undervalued. In this case, the authority is an executive team, and the subsidy is praise and promotions. And until we celebrate and reward the “simple” work of creating basic reports and of working with experts around the business, data teams and data vendors will keep chasing the false idol of insight. 


---


[^1]: [He](https://benn.substack.com/p/coffee-cake) [doth](https://benn.substack.com/p/the-rapture-and-the-reckoning) [protest](https://benn.substack.com/p/open-the-window) [too](https://benn.substack.com/p/how-analysis-dies) [much](https://benn.substack.com/p/the-internet-2022), [methinks](https://benn.substack.com/p/runaway-train).

[^2]: It’s sound analysis like this that gives me the confidence to be a smug little Substacker.

[^3]: Literally—all of these quotes are from vendors’ homepages. Tableau, a data tool (and “world’s leading analytics [platform](https://www.evernote.com/l/ADpdWxSxejJJxIyfMwGvOvtzyQvWG0K8wsg)”), didn’t make the list because you have to click on the *Why Tableau* tab to learn that it will “discover and share [insights](https://www.evernote.com/l/ADrKJGxv4ipDHKmz3ZZFbM5kiYfvgRtaUtQ) that can change businesses and the world.”

[^4]: Part of the problem here is that there’s a general assumption that data teams [can’t really talk about their work](https://pedram.substack.com/i/93416609/on-talking-about-the-work). And in practice, that’s true—there aren’t many blogs out there that talk about the specific problems data teams are trying to solve. But maybe there could be? Every data vendor has dozens of case studies on their websites that do exactly this. If someone rewrote all of these case studies so that they highlighted the business problem the company had rather than the tool they used to solve it, we’d very much be talking about the work.

[^5]: The employees, [not so much](https://www.youtube.com/watch?v=6D7KVozqRvk). The partner is dead, the firm lives; the partner is dead, the firm lives; [the partner is dead, the firm lives](https://abovethelaw.com/2018/04/lawyers-apparently-perform-this-weird-ritual-during-cravath-partner-funerals/).

[^6]: Normal people picture themselves [hitting the game-winning home run](https://www.youtube.com/watch?v=AQQQTBkovQg) on a literal field of dreams; we picture ourselves [showing up a bunch of crusty scouts](https://www.youtube.com/watch?v=3MjxoaynCmk) in a septic basement in Oakland.

[^7]: Prior to being bought by Sisense, Periscope Data, a BI tool (and “complete data analysis [platform](https://www.evernote.com/l/ADrdM5HhsY5E2Lz5Bd8jmsSrNmBobBtKYJI)”), went from “SQL queries to actionable [insights](https://www.evernote.com/l/ADoXlpa8fclFKpTdp_Ed1eegysq2fG1Cc2U)” in seconds.

[^8]: For example, if you build a dataset of customers and how much they pay you every month, people will comb through it looking for surprises or inconsistencies. If you put together some analysis based on the same data, people might prod at your conclusions, but they’ll rarely pick through the source data.

================================================================================

# The case for being biased

*Why telling the truth might be the second-most valuable thing data teams can do.*

---

![Rolling Deep ITM QQQ Vertical Spread - Options Trades by Damocles](https://substackcdn.com/image/fetch/$s_!UeZn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F49567450-85b6-4633-ac3a-aaea25e5652b_1200x675.jpeg)
*[manipulate the dice](https://www.youtube.com/watch?v=7oM7-Jsa168)*

While we're on the subject of the [all-time greats](https://www.youtube.com/watch?v=MOPjtuzoSyA), I’ve got two candidates for the best interview of all time. 

The first contender is an engineer that we interviewed at Mode in 2015. He was at our office for the onsite, and we were prodding our way around his resume, asking canned questions about his prior jobs. In the middle of deadpanning through an otherwise unremarkable answer, he trailed off, his eyes drifted into the middle distance, and, as if [sabotaged by some microscopic rebel](https://youtu.be/zhCB4GR5Iis?t=31), his brain sputtered, stalled, and powered down. We all froze in the silence. After a few seconds, he lurched back to life, and said, as flatly as before, "Oh, sorry. I just got really excited about the internet of things." 

We tried to resume the conversation, but none of our hearts were still in it—his stolen by the possibilities of wifi-enabled thermostats, and ours unsettled by the visitation we'd just witnessed. Later, when the interview panel got together to make a decision, we learned that he'd apologized in another conversation for “doing too many drugs prior to the interview.” Networked hardware is a hell of drug, I guess.

The second candidate for the greatest interview ever—and my personal favorite—had applied to be a data analyst at Microsoft. We were always hiring for this role, so the phone screens were standardized and formulaic. We typically opened the call with a few simple math questions to judge how comfortable people were with thinking through and explaining quantitative concepts. This interview started just as hundreds had before: "If you rolled a standard six-sided die and got paid based on what you rolled—for example, roll a three, get three dollars—how many dollars would you expect to make from one role?"

"Six," he said.

"Six? How did you get six?"

"I'm the kind of guy who rolls sixes." 

Never in my life will I say something so incredible. The stunning certainty; the breathtaking audacity; the complete disregard [for the assignment](https://www.youtube.com/watch?v=vb1w_1PuWGE). He was Banksy, [humiliating us](https://www.smithsonianmag.com/smart-news/watch-14-million-bansky-painting-shred-itself-soon-it-sold-180970486/) and everything that we thought was valuable; he was James Harden, [leaving us twisted and broken](https://www.youtube.com/watch?v=17NXRpGbjlg) on the floor;  he was our nemesis, a criminal mastermind [flawlessly orchestrating](https://www.youtube.com/watch?v=wZ3OIYdDifw) our every helpless move. In one cavalier wave, he dismissed lifetimes of careful study about uncertainty as a cowardly distraction, a brash and bullying alpha to our pocket-protected beta. 

He was also, of course, completely wrong.[^1] No amount of confidence will make him more likely to roll a six. No amount of genius will unwind the impossibly complicated physics of a tumbling die. [God may not play dice](https://en.wiktionary.org/wiki/God_does_not_play_dice_with_the_universe), but for us mere mortals, probabilities are the best we can do. As analysts, and as candidates interviewing to be analysts, that’s our job—measure the odds, do the math, devise a strategy, and hope the dice land the right way. 

Or is it? In my recent descent into [data](https://benn.substack.com/p/data-teams-product-market-fit) [team](https://benn.substack.com/p/insight-industrial-complex) [existentialism](https://benn.substack.com/p/day-of-reckoning), I’ve started to wonder if he was actually onto something, and it was me who was misunderstanding our assignment. 

# What’s the truth for?

If all the various flavors of data philosophies were different sects in a religion, the search for understanding and truth—for the real probabilities in our corporate craps game—would be our shared savior. No matter [the denomination of the data team](https://stkbailey.substack.com/p/two-party-system)—reporting specialists, internal consultants, builders of data products, a help desk, insight seekers, [coin-operated mercenaries](https://benn.substack.com/p/datas-invisible-hand)—we all agree that our jobs are built on objectivity and honest observation. Our very name, data science, suggests that we’re on some noble quest for worldly knowledge and apolitical enlightenment. Even when we [criticize that term](https://www.getdbt.com/coalesce-2021/down-with-data-science/), our objections [are to our unscientific methods](https://docs.google.com/presentation/d/10daljbuI0wVs9CGvL-cvJ2E1lY8OA58LfWfVZnhPDNI/view#slide=id.gcfcbc60c03_1_69). On our goals, we’re unequivocal: We’re here to figure out [what’s true](https://www.winwithdata.io/p/analytics-is-not-about-data-its-about) and tell people about it, [unbowed by bludgeonings](https://www.poetryfoundation.org/poems/51642/invictus) of organizational politics and [executive pressure](https://twitter.com/pdrmnvd/status/1623192508867170307).

But, crass as it may sound, truth is just a means to an end—to make a company successful. We aren’t paid to be curious researchers who are trying to understand a confusing world; we are, just like every other employee, corporate instruments for making money. Our desire to find the truth is a retrofitted projection, built on the assumption that data begats discoveries, that discoveries begat knowledge and understanding, and that knowledge and understanding begats business success. 

Put differently, the fundamental argument underneath most data teams is this: Given the skills we have, we can contribute to our employer’s success by figuring out what is true. Though that seems obviously right, it answers the wrong question. The question shouldn’t be if this is a useful role for a data team; the question should be, is it the *most useful* role for a data team?

# Trust the process

In 2013, the [perennially mediocre](https://en.wikipedia.org/wiki/History_of_the_Philadelphia_76ers#2006%E2%80%932012:_The_Andre_Iguodala_era) Philadelphia 76ers hired Sam Hinkie as their new general manager. Almost immediately, he put in place a now infamous plan: Rather than staying stuck in the middle of standings, he’d intentionally tanked the team by [trading away its top players](https://www.espn.com/blog/truehoop/post/_/id/69285/sixers-tank-machine-strikes-again) for draft picks. They’d then finish at the bottom of the league and get more top picks, which they could use to draft a handful of future superstars. Eventually, they’d collect enough young talent to not only be a contender, but to be great. 

In its early days, the plan was predictably controversial. For Hinkie, this wasn’t just a PR problem; it was an existential one. Doubt from players and team executives could undermine the entire effort. Players and coaches, for example, might get frustrated during the team’s dark years and demand trades. Hinkie’s job, then, wasn’t just to devise the strategy and to execute on it; he also had to sell it. And sell it he did: “[Trust the process](https://bleacherreport.com/articles/2729018-the-definitive-history-of-trust-the-process)”—the shorthand for the plan—became a [catchphrase](https://www.youtube.com/watch?v=0LYM6C9rPwI), a [brand](https://phillysportsshirts.com/products/process-logo-shirt), a *[lifestyle](https://everydaypower.com/trust-the-process/)*.[^2] 

During this critical moment, after players had been traded away and The Process was in motion but [before people were convinced it’d work](https://www.youtube.com/watch?v=agKDPntMv-E), what should the 76ers' data team do?[^3]

Should they be reporting the facts to Hinkie and the rest of the organization, and be bold truth tellers about what is and isn’t working? Or should they be selling the strategy, and doing everything they can to make people believe in it? Should data be for explaining nuance, or should it be propaganda, used selectively to keep people committed to the now irreversible plan?

This dilemma highlights the key difference between business decisions and scientific ones, and between what analysts and actual scientists do. For the chemist in a pharmaceutical lab or the physicist in a wind tunnel, natural truths matter. Will the chemical compound eradicate the disease, or [poison the patient](https://twitter.com/sarahcpr/status/1253474772702429189)? Will the plane fly, or not? The answers to these questions, like the outcome of a roll of a die, aren’t affected by the resolve of the doctor, or the confidence of the pilot. Physics and biology will cure the sick, not courage. The laws of aerodynamics will keep a plane in the air, not faith.

The success of business decisions and strategies, by contrast, depend heavily on what happens *after* a decision is made. To stick the landing, you’ve got to commit to the jump. Execution and organizational alignment often matter [as much as the decision itself](https://benn.substack.com/p/the-best-decision-is-one#:~:text=Instead%2C%20outcomes%20depend%20on%20both%20what%20we%20choose%20and%20what%20we%20do%20after%20we%20choose%20it.%C2%A0). 

Data can be a powerful weapon in this operational struggle. Data is deeply persuasive, especially among today’s quantitatively conceited corporate class.[^4] When woven through tight narratives, it can paint clear pictures of where a company wants to go, how it will get there, and why the chosen path is the right one. It can keep people from walking at different cadences, or from questioning if they’re going the right direction at all. Data can even tap into baser instincts. Few things will make us as [manically obsessive](https://www.platformer.news/p/elon-musk-fires-a-top-twitter-engineer) about something as much as regularly measuring it. 

In this light, it seems at least possible that the 76ers’ data team—and by extension, every data team—would be more valuable as periodic propagandists than they would be as truth seekers. As [the cliche goes](https://quotefancy.com/quote/66103/Confucius-The-man-who-thinks-he-can-and-the-man-who-thinks-he-can-t-are-both-right), the man who thinks he can and the man who thinks he can't are both right. The same principle surely apply to organizations as well. While waffling and second guessing can undermine even the best strategies, flawed plans can be overcome by a commitment to make them work.[^5] 

Admittedly, this doesn’t *feel* right. But I think that reaction is mostly emotional, and my objections to data teams leaning into biases rather than away from them don’t really hold up.

## It’s immoral

Using data in this way sounds perverted if not outright profane, improper if not outright immoral. But is it immoral for a CEO to give a rousing speech to rally a company? Is it immoral for a marketing team to cherry pick numbers to sell a product? Is it immoral for startup founders to aggressively promote their company in a pitch deck to a venture capitalist? At best, we’d say no, this is what they should be doing; at worst, we’d say the answer is complicated. In all these cases, we’d recognize that there are times to put our thumbs on the analytical scales, and to be selective about the truths we tell.[^6] 

Data teams don’t operate on a higher moral plane than these other functions. We’re here to promote the same outcomes as everyone else. If we can support those goals—by presenting, say, a compelling but biased analysis—why should we be exempt from doing so? 

## People would see through it

If we stop being objective all the time, data could lose its persuasive power. Practically speaking, though, it probably wouldn’t. People aren't all that critical of data or analysis, especially when they aren’t motivated to doubt it. What’s more, it may not matter if people knew some bit of analysis was more partisan than balanced. People are affected by facts and narratives, [even when they’re told](https://www.newyorker.com/magazine/2017/02/27/why-facts-dont-change-our-minds) they’re completely made up and they’ve been explicitly misled. 

Professional wrestling is the ultimate proof of our willingness to surrender to things we know aren’t real. Wrestling is cartoonishly fake. It panders to our most ridiculous indulgences. But it gives its fans a chance to elope to an imaginary world that seems more fun than the one they’re in, and they happily go along for the ride. 

In what’s probably the only parallel between business intelligence and the WWE, data can provide a similar escape. A few compelling numbers give us permission to see the world as we want to see it. Even if we know they’re not entirely honest, they tell us that it’s ok to believe. 

## Somebody has to be the referee

Certainly, sometimes companies need nonpartisan researchers and unbiased scorekeepers—I’m not arguing that we should give up this duty entirely. But I think our insistence to *always* play that role is mostly self-serving. It’s cooler to be a bold contrarian than a patsy for the party line. It’s easier to lightly question every decision, so that you can stay silent if it goes well, and be able to say “I told you so” if it goes wrong. And there’s power and comfort (and a sense of smug superiority[^7]) in working above the political fray. The more we can convince ourselves and other people that we’re here to be fact checkers and not pundits, the more unimpeachable our influence—but the less useful our impact.

# I believe that we will win

In her most recent post for the Analytics Engineering Roundup, [Anna Filippova asked a question](https://roundup.getdbt.com/p/build-a-resilient-dag): “What business scenarios require information delivered within *minutes*?” 

I found myself wincing at her answer. She said, for dbt Labs, they need minute-by-minute data on product launches and the deals that are closing at the end of the quarter. Why, I thought, would they possibly need this? What decisions do they need to make that would justify the work it must take to cut a sales dashboard’s latency down from three hours to thirty seconds?

But Anna, like the analyst we interviewed ten years ago, is working on an entirely different plane than I am. The point of the dashboard isn’t to make decisions. It’s to keep the mission at the front of everyone’s mind. It’s to make sure everyone sees the impact of the work they’re doing. It’s to rally a company around a sales team pushing through their final sprint. It’s to use data, not to tell detached truths, but to connect with people emotionally, to make them trust the process, and [to help them believe](https://www.youtube.com/watch?v=7bz6UMwCquM), despite all the odds stacked against startups, that theirs can go out and hit a hard six. 


---


[^1]: Wrong, I should say, in the way that [Van Gogh’s stars](https://en.wikipedia.org/wiki/The_Starry_Night) are wrong, or [Turner’s trains](https://en.wikipedia.org/wiki/Rain,_Steam_and_Speed_%E2%80%93_The_Great_Western_Railway) are wrong.

[^2]: The plan mostly worked. They were indeed terrible for a few years, and finished with one of the worst records in the NBA for four straight seasons. And then got way better. In 2021, they had the best record in the Eastern Conference.

[^3]: Hinkie was also famously analytical, and the 76ers [actually had a data team](https://www.inquirer.com/philly/sports/sixers/philadelphia-76ers-analytics-stats-trust-the-process-sam-hinkie-20171115.html) at the time. So I I ask this question hypothetically, but also, if anyone knows what that team did, I’d love to hear.

[^4]: My general theory is that most people want to be able to say that they make decisions based on data and sound reasoning. Many don’t—they start with their preferred outcome and [work backwards from there](https://benn.substack.com/p/tilt-and-tilted)—nor do they care that they don’t. But appearances are important, which is why quantitative arguments are so persuasive. We feel [safer when we’re armed with one](https://benn.substack.com/p/does-data-make-us-cowards).

[^5]: [Sounds like a cult](https://www.soundslikeacult.com/), you may say. And, yeah, fair, but cults…work? ([Counterpoint.](https://twitter.com/dril/status/831805955402776576)) I’m not going say that I’m pro-cult, but cults have been able to accomplish—if you use “accomplish” in a very loose sense—a lot of unbelievable things (literally; it is hard to believe what cults make people do). I’d guess that most successful startups—and maybe bigger companies, though that seems less obvious—are successful in part because employees develop a cult-like devotion to their product, mission, founders, or culture.

[^6]: Importantly, this is different from outright lying. You can be persuasive without being dishonest.

[^7]: As the youngest child, I live for this. Nothing gives us more self-righteous satisfaction than sniping from the sidelines, all while pretending to be a neutral bystander.

================================================================================

# Customer capture

*The perilous promise of a big market.*

---

![](https://substackcdn.com/image/fetch/$s_!zols!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5746f7fe-464b-45cf-a749-ed6736b89593_2186x1406.png)
*[The cops have kidnapped the liquor store customer.](https://www.youtube.com/watch?v=DrRy06k2keA)*

Every era has its intellectual institutions. Ancient Greece had Socratic dialogues. The Enlightenment had scientific academies. American revolutionaries had *The Federalist Papers*. And Silicon Valley has brash blog posts: self-published on personal websites and Medium and Substack; full of [superficially relevant](https://arxiv.org/abs/2209.08026) arXiv citations, [appropriated references](https://benn.substack.com/p/customer-capture#:~:text=Ancient%20Greece%20had%20Socratic%20dialogues.%20The%20Enlightenment%20had%20scientific%20academies.) to ancient philosophers and European scientists, and an air of cool detachment; and written, often, in an effort to coin some unnecessary new phrase, like “[the fatal pinch](http://www.paulgraham.com/pinch.html)” or “[wordcel](https://roonscape.substack.com/p/a-song-of-shapes-and-words)” or “[data OS](https://benn.substack.com/p/the-data-os),” meant as something between a joke, a real contribution to the discourse, bait for some Hacker News upvotes, and desperate attempt to put a memorable scratch on Etch-a-Sketch of the internet, and [not be forgotten](https://www.youtube.com/watch?v=QEmAlohId0E).[^1]

This is a contribution to that tradition, and the term I’d like to submit for consideration is “customer capture.” Share and like and subscribe.

# Split personality

Audience capture was introduced into the lexicon by [Gurwinder Bhogal](https://gurwinder.substack.com/p/the-perils-of-audience-capture), or [Eric Weinstein](https://twitter.com/EricRWeinstein/status/1347924271679430658?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1347924271679430658%7Ctwgr%5E373e60fd277d65858b3b9f6f4cac1caac5c7f557%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Ftheportal.wiki%2Fwiki%2FAudience_Capture), or maybe [Alan Parisse](https://parisse.com/risky-business-how-audience-capture-can-sabotage-your-presentation/). The phrase describes how influencers’ are, over time, transformed by their audience. When people post on social media, extreme stunts and outlandish opinions generate more engagement than mundane content, which encourages people to push the envelope further. Over many cycles of posting and refining, people evolve towards their online caricatures until, eventually, the person loses track of what’s a persona and what’s real. The person, as the phrase goes, becomes captive to their audience, unable to define who they are anymore, and fully becomes the character their audience wants them to be. 

Is it real? I dunno—like any good Silicon Valley Think Piece, it’s compelling and has lots of links to Wikipedia pages about cognitive biases, so, sure. But either way, I’d argue that companies are vulnerable to a similar phenomenon.

Save a few [instant successes](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/), most startups grow unsteadily. Their launch attracts a burst of users, and [many leave as quickly as they arrived](https://andrewchen.com/after-the-techcrunch-bump-life-in-the-trough-of-sorrow/). But some people—those who see beyond the horizon of the initial release, and can imagine what might come next—stick around. They like the product, they say, but they love the vision. 

The startup, coached on the canon of Silicon Valley—[the four steps to the epiphany](https://en.wikipedia.org/wiki/Steve_Blank#Key_customer_development_concepts); [the only thing that matters](https://pmarchive.com/guide_to_startups_part4.html); [do things that don’t scale](http://paulgraham.com/ds.html)—humbly listens to their customers. They take the feedback; they tweak their marketing; they twist their product to lean towards the promising prospects and use cases. The roadmap curves away from the one laid out at the company’s founding. 

As both common sense and every startup incubator will tell you, these adjustments are not only prudent, but necessary. [Companies can’t bend buyers to their will](https://pmarchive.com/guide_to_startups_part4.html#:~:text=Andy%20puts%20it%20this%20way%3A); no matter how brilliant an idea, the market [can stay stubborn](https://quoteinvestigator.com/2011/08/09/remain-solvent/) longer than a startup can stay solvent.

In this sense, a startup *wants* to be captured by its customers. Unlike influencers—i.e., people—a company doesn’t need to have an external identity beyond its audience. Who cares if Instagram originally identified as a [Dartmouth Sigma Nu who can’t believe you’ve never been to the Kentucky Derby](https://www.theatlantic.com/technology/archive/2014/07/instagram-used-to-be-called-brbn/373815/)? It’s now a photo-sharing app, and nobody, least of all Instagram, is upset by that.[^2] 

The problem, however, is that customer capture is rarely so clean. Early products are just sketches and scaffolding; the full building exists only as an artistic rendering. Customers, then, are left to imagine the details on their own. And for complex products, like B2B SaaS tools, each customer’s extrapolation is a bit different. One might be excited for a product’s collaborative potential; another might be imagining it as a power tool for specialized teams; a third plans on customizing it to integrate with other services. 

But customers rarely articulate these ideas completely, because they aren’t asked, because they don’t fully see it themselves, or because they assume that’s what’s getting built. Instead, each customer’s vision trickles in through individual feature requests—requests that, to the company, seem complementary to one another. They’re all just a step or two off the roadmap; they all point in the same general direction; they differ by only a few degrees. There’s no harm in indulging each request, either by building it now or by telling the customer we’re building it later. Moreover, customer feedback is important; optionality is valuable; strong revenue retention is critical for raising the next round. In time, we’ll get to what they’re asking for.

In reality, the company doesn’t get to those features; it gets drawn and quartered. The longer diverging visions are entertained, the further they pull apart. Customers, sensing the tension, lose patience; the company, now larger and under more pressure to grow, starts throwing bones at the riskiest renewals. While each decision might make sense on its own—a small feature to save a customer seems like a fair trade[^3]—together, they compound into incoherence. The product and its positioning become a labyrinth, a maze without a floor plan, full of [doors that don’t open and staircases that lead into the ceiling](https://en.wikipedia.org/wiki/Winchester_Mystery_House). 

Eventually, the customers fully capture the company, trapping it not in a single identity, but in many. The company loses sight of what it’s doing and who it’s selling to, and has the capacity for one and only one strategy: appeasement. 

# Give a customer a cookie

Though this disease is endemic in Silicon Valley, data startups are one of the most vulnerable populations. 

The geography of the modern data stack isn’t so much fragmented as it’s [shattered](https://mattturck.com/data2021/). We don’t agree on the categories; we don’t agree on the borders between those disputed categories; we don’t agree on where tools sit among the disputed borders of the disrupted categories. Where does data transformation end and BI begin? Are data quality and data observability the same thing? Is reverse ETL real? And how do all of these products interact with our [mahjong board](https://en.wikipedia.org/wiki/Mahjong_solitaire) of [job titles](https://twitter.com/ElenaRunsNYC/status/1483651998335614978?)?

Every customer will answer these questions differently, which creates an environment incredibly vulnerable to customer capture. The crowded landscape forces companies to wedge themselves into tiny slivers of open space in the market. These initial positions are typically too small to support a venture-backed business, so companies look for adjacencies to expand into. Customers all pull in different directions, based on how they’ve built their teams and technology stacks. Almost overnight, a narrow tool that was too small to fund can become too big to build. 

Transform, which launched as a [metric store](https://techcrunch.com/2021/06/17/transform-metrics/), potentially illustrates this problem.[^4] Metric stores [were probably too narrow to stand on their own](https://twitter.com/frasergeorgew/status/1468986410464002053); they needed to be attached to some other category to be viable. But which one? Semantic layers have historically been part of BI tools; [that’s one option](https://blog.transform.co/product-news/introducing-boards/). Transform could do more transformation, and compete directly with dbt. Metrics are also key entries in [data dictionaries](https://blog.transform.co/product-focus/metrics-catalog/), in [observability tools](https://docs.bigeye.com/docs/metrics), and in [augmented analytics platforms](https://docs.sisudata.com/docs/metric-library/using-metric-library); Transform could expand in all of those directions as well. 

With so many avenues for expansion—which often looks like promising optionality but is actually deadly variability—you could imagine five teams buying Transform, and all of them anticipating a different roadmap. A midmarket retailer might be moving off of Looker, and is shopping for a LookML replacement. A Fortune 500 media company might want a fast way to define and share simple charts with content partners. An AI startup is adding alerting around infrastructure performance KPIs. A Series B SaaS vendor is trying to create a catalog of metrics for their executive team. A fintech provider needs to centralize their metric logic into a versioned semantic layer prior to their upcoming IPO.

When a startup is looking for traction and product-market fit, it’s enormously difficult to turn away any of these customers, especially when its five-year roadmap would solve many of these problems. But these requests are just the [first of many cookies](https://en.wikipedia.org/wiki/If_You_Give_a_Mouse_a_Cookie), given to five mice, all of whom will have ten more requests that come next. By selling to all five customers, Transform wouldn’t be wiggling along their planned roadmap, but tacitly committing to a dramatic—and almost surely unsustainable—fanout across half of the data ecosystem.[^5] 

# Saved souls

In his piece, Gurwinder proposes a defense to audience capture: A strong sense of identity. If you know who you want to be, and have the discipline to stay true to it, you’re less likely to chase the identity that’s projected on you by others.

The same is true of customer capture. Companies with a firm identity—a narrow roadmap, tight market positioning, a clear and well-defined buyer—can resist the tangential feature requests and divergent use cases that tug startups in different directions. Importantly, however, this identity doesn’t need to be fixed—the founding identity may miss the mark—but it can’t be fragmented.

The obvious way to develop this is discipline. Say no to customers; say no to optionality; [try to make the plan work](https://benn.substack.com/p/the-case-for-being-biased), and if it doesn’t, explicitly change it.[^6] 

This also means saying no to investors. During the fundraising carnival after the pandemic, a bold vision and a big [TAM](https://en.wikipedia.org/wiki/Total_addressable_market) was enough to extract a FOMO round from venture capitalists. That pitch, and the VC money it earned, made aggressively expanding into new categories seem both possible and necessary. But in most cases, it’s better to keep a humble soul than to scatter a sold one across a half-dozen horcruxes.

The other way to maintain an identity is for a company to care about what they’re doing. In Silicon Valley, hundreds of startups exist to be successful and to solve a problem, in that order. They’re trophies, status symbols, learning experiences, lottery tickets, lifelong dreams, and, somewhere down the list, a means for making a particular product. These startups, [which shoehorn feigned passions around market opportunities](https://www.washingtonpost.com/business/2019/10/22/iraq-war-protests-inspired-facebook-zuckerburg-says-lawmaker-who-was-there-says-thats-false/), are ripe for capture, because their missions never mattered anyway. It’s easy for a customer to cleave a company from its identity when that identity was manufactured for the customer in the first place. Consequently, I don’t think it’s [ill-advised at all](https://twitter.com/seanjtaylor/status/1549630638663208960) to fall in love with a project idea. To the contrary, there are few better ways to do it. 

Ultimately, the companies that refine their core identity are richly rewarded, and not only in the market that they serve. The bigger a product gets, the more immune it becomes to customer capture; its mass makes it immovable. Companies that reach this point can experiment with expansion, which is often necessary once a company's revenue passes fifty to a hundred million dollars, with little risk of dislodging their core product.[^7] In a world of captives, the free company is king.


---


[^1]: A troubling thought: The writers of past eras were presumably motivated by the same basic impulses, which suggests that at least some of what we think of today as revolutionary thought was, at the time, the badly-researched ramblings of a triggered blogger.

[^2]: Nor is the Dartmouth Sigma Nu who wants to make sick Reel of his [porta potty run at the Preakness](https://www.youtube.com/watch?v=IIcyFSYhvV4).

[^3]: iN tHiS eCoNoMy, this dynamic is even more pronounced. When financial markets—i.e., venture capitalists and public market investors—reward efficiency over growth, a dollar retained is worth more than a dollar added (or, put differently, a dollar of churn looks worse than a missed dollar of new business).

[^4]: Potentially! Hypothetically! This is speculation about what could’ve plausibly happened to Transform, given the dynamic of customer capture. I have no idea if it actually happened or not. It’s just a convenient example, and, because Transform was [recently acquired](https://blog.transform.co/all/transform-and-dbt-labs-better-together/) by dbt Labs, one that’s safely less relevant to Transform today.

[^5]: Again, this is a hypothetical! I have no idea if Transform’s customers wanted these things, or if Transform sold any of them. (If nothing else, “a fintech company is about to IPO” should be a dead giveaway that this is [all](https://finance.yahoo.com/quote/COIN) [a](https://finance.yahoo.com/quote/HOOD) [fantasy](https://finance.yahoo.com/quote/AFRM).)

[^6]: As a bit of tactical advice, startups should also be mindful of timelines. If you compare prospects’ requests with where you want to be in five years, it’s easy to convince yourself that everyone is a worthwhile customer. But customer patience is not infinite, product roadmaps are path-dependent, and most startups build a fraction of what they say they will in their founding pitches. By promising customers the features in your stars, even taking them to the moon will seem disappointing.

[^7]: Dropbox, for instance, had such a polished core experience that the company could swallow [HelloSign](https://www.cnbc.com/2019/01/28/dropbox-buys-electronic-signature-start-up-hellosign-for-230-million.html) and launch [Paper](https://en.wikipedia.org/wiki/Dropbox_Paper) without so much as budging most people’s perceptions of what Dropbox was.

================================================================================

# Terror in the Skynet

*The futile effort to outwit our emotions, and the looming effort to engineer them. *

---

![A plane](https://substackcdn.com/image/fetch/$s_!DRss!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2bcd0e0b-8d51-4a49-b416-de06aff2d079_790x496.jpeg)

> *You will stay calm in the face of an emergency. Lucky numbers 10 15 16 29 31*

The four of us—me, my parents, and one of my best friends—were on our way to Venice. My brother was studying abroad there, and we were going to visit him over spring break of my college freshman year. Since all of our hotel rooms could sleep four, my parents offered to bring my friend, who was a few generations removed from being Sicilian, loved pizza, *Goodfellas *and [Spaghetti Westerns](https://en.wikipedia.org/wiki/Spaghetti_Western), and had always wanted to visit Italy. He was excited for the trip, until we got to the airport.

I wasn’t a seasoned traveler, but had been on a handful of airplanes before. I liked them—the acceleration at takeoff, sudden and ceaseless, without the usual hitches in a transmission’s gearing; the unfamiliar upward pressure rising under your seat; the tilt as the plane rolls through its ascent; the undoing of your mental geography, when, in a time before Google Maps, you see for the first time that that *that* local landmark is actually *there*. My friend, however, had never flown before. The thrills I was looking forward to were unknown to him; all he could think was our plane breaking down, blowing up, and falling out of the sky. At the airport, as we walked to get lunch at the food court, I tried to convince him that we’d all be fine.

His fortune cookie disagreed.

Sure, the chances of a plane crash are [one in a million](https://www.hitc.com/en-gb/2022/10/26/what-are-the-chances-of-a-plane-crashing-in-2022/)—but what are the chances that he’d get that fortune, in this moment, right when I was telling him that no emergency was coming? He thought about going home. I shrugged it off. Even if the [Panda Express](https://www.cltairport.com/shop-dine-and-relax/view/#477) prophecy was true, I was already a captive to a different emotion. Shortly before the trip, a year-long will-we-or-won’t-we dance with a crush took what I thought was a fatal turn. Flying anxiety was no match for my teen angst: Take us down, I thought. Crash the plane; [splash me into the deep blue sea.](https://www.youtube.com/watch?v=2GHyLhbdzN0) 

Needless to say, we didn’t crash. Rather than having a birthday party at the bottom of the ocean, I spent most of the trip sulking, pumping myself full of Bright Eyes and James Blunt, and telling everyone, "I'm fine," in the most unconvincing tone possible.

Over the [next two decades](https://twitter.com/bennstancil/status/1556803126275047425), the story turned upside down. My friend, now [one of the best sports broadcasters](https://www.nytimes.com/2022/08/16/sports/baseball/sny-mets-diaz.html) on TV,[^1] flies every few days, routinely "commuting" between New York and Mississippi. I went the other way. Far from staying calm in the face of an emergency, I built an emergency out of the calm. Several years after our trip to Venice, on an otherwise uneventful flight from Salt Lake City to Cincinnati,[^2] something broke loose inside of me. In those three hours, my sense of wonder was replaced by fear, wholesale. Flying became emotionally backbreaking. I began dreading air travel; I started getting nervous about stormy forecasts days before takeoff; I said flight numbers out loud to see if they sounded like future Wikipedia articles.[^3] I even started to avoid flying altogether—a retreat that, in my fear’s ultimate conquest, drove one of the last nails in the coffin of my eventual relationship with the girl I was sulking over in Venice.[^4] 

> *Does anyone know where the love of God goesWhen the waves turn the minutes to hours?*
> *Gordon Lightfoot, *[The Wreck of the Edmund Fitzgerald](https://www.youtube.com/watch?v=9vST6hVRj2A)

As is common for most anxious flyers, it’s the turbulence that gets me. On a smooth flight, I can find an uneasy peace. But add a few bumps—the kind that don’t even get the seatbelt light on, and are inevitable in anything moving at six hundred miles per hour—and I clam up, I can’t focus, and I begin counting down the long minutes until we land. If the turbulence gets worse than that, to say nothing of the shaking that leads to the heart-stopping announcement that flight attendants will need to discontinue their service for a few minutes, I’m overcome, unable to eat or drink, unable to think, frozen in place, my body and mind short-circuited by some primal electricity, as though pinned down and paralyzed by an invisible shock collar. 

And so, during most trips, I sit sentry at my window and stitch together a five-hour panorama of clouds and countryside. I stare at the steady ground below, and use it to remind myself the wings are still upright and that physics still work.[^5] I classify different types of turbulence—the long sways, the gravelly rumbles, the sudden thudding drops, the hard lurches off and back onto a centerline. I monitor for changes in pressure or speed, listen for new engine pitches or hisses in the ventilation, and try to detect hidden connotations in announcements that we've reached ten thousand feet, that Southwest is now offering an exciting new credit card, or that the right engine fell off and we’re pitching straight into Lake Superior.[^6] 

Over the years, I’ve collected my preferred set of coping mechanisms. Some are taken from various self-help sites on the internet: (try to) breathe slowly; (try to) count to ten; (try to) relax your shoulders; (try to) plant your feet. Some are chemical: Take sleeping aids; get drunk; take anti-anxiety meds; take someone else’s prescription muscle relaxants. Some are distractions: Search for baseball fields on the ground below; look out the window at other planes, and remind myself that we’re moving just as gracefully as they are. And some are on the spectrum between weird and pathological: Rock back and forth in my seat like [Leo Mazzone](http://www.espn.com/espn/eticket/story?page=mazzone&redirected=true), blending the plane’s motion with my own, camouflaging the former in the latter; start the stopwatch on my phone and, without looking at it, try to stop it after exactly one minute, over and over and over again.[^7] 

Most of all, I try to convince myself that all of this is ridiculous. I know the math and history—the odds of a crash are infinitesimal; the odds of turbulence tossing a plane out of the sky are even lower. I know that we’ll be ok; that we’ll land safely and were always going to land safely; that planes [fly through much worse](https://www.businessinsider.com/hurricane-irma-delta-jet-made-escape-from-storm-2017-9) ([by choice](https://www.vice.com/en/article/vbzp9x/hurricane-irma-category-5), even); that the pursuit of smooth air is about comfort and not safety; that my distress is no more sensible than that of a cat in the car, afraid of something it doesn’t understand. 

No matter. Despite putting [more](https://benn.substack.com/p/twitter-profile-pictures) [faith](https://benn.substack.com/p/scoring-data-predictions) [in](https://benn.substack.com/p/moneyballing-the-world-cup) [data](https://benn.substack.com/p/how-to-play-wordle) [than](https://benn.substack.com/p/how-to-feel-about-a-tie) [most](https://benn.substack.com/p/a-season-without-bats),[^8] actuarial tables are a useless antidote. I can’t bend my feelings around facts; I can’t forge them between a hammer of reason and the anvil of reality. I am at their mercy, captive to them just as they’re captive to every jolt and shiver. My emotions can’t be outwitted, only sterilized—among all of my in-flight therapies, the only reliable one is tranquilizing myself with a self-prescribed dose of borrowed pills.

> *“If one engine fails, how far do you think the other one will take us?”“All the way to the scene of the crash.”*
> *[Ron White](https://www.youtube.com/watch?v=FH-LmkLFJg0)*

When ChatGPT launched out a few months ago,[^9] my first thought was that [we aren’t smart enough](https://benn.substack.com/p/how-analysis-dies) to handle what was coming next. Because ChatGPT and other LLM-based AIs can make [wrong-but-seemingly-feasible](https://twitter.com/saranormous/status/1600491163915812864) claims about anything, the “marketplace of ideas”—tenuous as that concept already is—would soon be inundated with millions of counterfeit debate club arguments that have no [foundational legitimacy](https://benn.substack.com/i/89635026/foundational-legitimacy). We’d lose track of what’s true, and slowly get lost in [Sydney’s sauce](https://www.theverge.com/2023/2/23/23609942/microsoft-bing-sydney-chatbot-history-ai).

I’ve since changed my mind. As fact finding tools, AI chatbots [have tripped so publicly and so loudly](https://www.npr.org/2023/02/09/1155650909/google-chatbot--error-bard-shares) that I suspect we’ll be overly skeptical of what they tell us, just as we were taught to “never trust what you find on the internet” in the early days of the World Wide Web. 

However, [like Ben Thompson pointed out](https://stratechery.com/2023/from-bing-to-sydney-search-as-distraction-sentient-ai/), chatbots are quickly proving to be astonishingly capable around another domain: Our emotions. *That’s* what makes today’s chatbots feel [so much more eerie](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html) than every version that came before. Those were stilted and sterile, like an uncomfortably formal support agent who’s required to read from an unnatural script. But even in these early days, ChatGPT and its siblings are fluid and anthropomorphic; they can, as Thompson says, “make the human it is interacting with feel something.” They are, for lack of a better term, emotionally manipulative.[^10] 

What’s more, they seem to do this on their own, in response to users’ prompts and not their own programming. Imagine if they were tuned to tug in this direction, to incite anger, engender fear, promote happiness, or incept jealousy. Imagine if the bots didn’t follow us into our emotional pits, but instead pulled us there.

Though they aren’t marketed as such, AI applications are already being built to do exactly this. For example, consider [Tome](https://beta.tome.app/), a generative storytelling app that’s [on a mission](https://medium.com/lightspeed-venture-partners/storytelling-at-the-cost-of-zero-673755c1bf77) to “help anyone tell a compelling story.” Though they claim that this is to enable society to “act on its best ideas,” this justification is self-contradictory. It admits that ideas are chosen not by their substance, but by the stories that argue on their behalf. While good ideas may make better stories, Tome can also make bad ideas look plenty polished too. 

In other words, the entire point of Tome, and [dozens of other apps like it](https://twitter.com/mattturck/status/1628817222880591876), is emotional capture.[^11] And if we can’t resist generic [SPCA commercials](https://www.youtube.com/watch?v=IO9d2PpP7tQ) and [hokey political ads](https://www.youtube.com/watch?v=cfjQujYrfEk), do we really have any hope against the future bots that can take this a step further, and triangulate around our exact aspirations and insecurities? What if every email is generated to make us, individually, feel a very precise way? Every social media site is overrun by bots praising and trolling your posts? Every text message is edited by an assistant that’s dialed, like a [host in Westworld](https://howard-chai.medium.com/all-120-attributes-of-westworlds-host-attribute-matrix-6f5ced9167a6), to be funny, [flirty](https://www.samflirts.date/), or [spiritual](https://www.robotspiritguide.com/)? If this is where we arrive, it’s hard to see who’s controlling who—are we in charge of the AI, or is the AI in charge of us?[^12] 

Maybe I’m underestimating our collective resistance to such emotional manipulation. But I have no faith in my own ability to face it. As flight after labored flight has shown me, I can’t immunize myself to what I feel. I can’t tell myself that [hallucinations](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)) are coincidences that mean nothing, like an ominously timed fortune cookie. I can’t resist the machine pushing my buttons by reminding myself it’s just a machine programmed to push my buttons. The artificiality of AI won’t matter any more than data and physics matter to me on a flight plowing through choppy air—bump me with the [right magic words](https://www.youtube.com/watch?v=IbSfJLF_0-8), and I’ll be triggered, overwhelmed, [my brain on a loop](https://youtu.be/a9UFyNy-rw4?t=12), trying to count to ten.

Not you, perhaps. But that may not matter. All of us are on the same societal plane. If enough of us get blinded by some kind of engineered outrage, we could all be headed to the scene of the same crash. 


---


[^1]: In another echo from the past, he’s one of the best because he draws [inspiration from the movies](https://twitter.com/JohnDeMarsico/status/1608499378313912320) he watched growing up.

[^2]: A shower thought about planes: It’s weird that they go all over the world, but only touch tiny parts of it. Like, if a plane was nearsighted, it’d travel everywhere, but all it’d ever see is runways and open sky.

[^3]: Alaska 82? Nothing to worry about. Delta 321? Iffy. United 990? Lifetime movie.

[^4]: To be clear, this was surely fine and necessary, even if the proximate cause was a bit senseless.

[^5]: It was [always about the view](https://benn.substack.com/p/open-the-window) but never just about the view.

[^6]: Superior, they said, never gives up her deadWhen the gales of November come early.

[^7]: Artifacts of my fear are scattered across my phone. There are short stories about airplanes vanishing into the breach, the name I gave to the interval of a flight’s climb when it roils through low, dense clouds, and all you can see out of the window is a gray haze cut by blinking navigation lights, like a silent fire alarm flashing in a smoke-filled room. There’s an outline for a novel about new pills that let you sleepwalk through hours and days and years of life, living them but not experiencing them. There are notes about movies that capture planes in extreme slow motion, documenting how violently their engines tear through the air. And there are long lists of numbers—[turned into bizarre analyses](https://app.mode.com/modeanalytics/reports/1291a42f9475)—bouncing between 40 and 80, recording my guesses of how long a minute actually is.

[^8]: [Ostensibly. ](https://benn.substack.com/p/math-is-overrated)

[^9]: It’s with great self-loathing that I have to admit that all of this was a lead-in to talk about AI. Or, it’s with great pride that I can say I figured out a way to write about airplanes and stuff while pretending to talk about AI.

[^10]: I think it’s telling that, thus far, AI’s most captivating application has been simple text generation. Tools like Shazam or image recognition software are in some ways more technologically inexplicable, but they feel computational and encyclopedic. Conversation, by contrast, is expressive, affecting, *human*.

[^11]: To be fair to Tome, their version of this is mostly benign; it seems that they primarily help people write better [fundraising pitch decks](https://tome.app/tomecommunity/templates-clbuesgor01rs92390wb6z58f). Which, if nothing else, [answers this question](https://benn.substack.com/p/how-analysis-dies#:~:text=Do%20you%20still%20invest%3F%C2%A0).

[^12]: I don’t mean that the AI is sentient. It’s more akin to an addictive drug, which can control people without being alive, or self-aware, or anything more than an inert pile of powder.

================================================================================

# What happened to the data warehouse?

*It's a sandwich, a floppy disk, and an iPhone. *

---

![the iphone launch](https://substackcdn.com/image/fetch/$s_!dE93!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fadde7e64-cb4c-47a6-b845-d66119c75cb1_1280x720.jpeg)
*What could have been.*

Here's a [manic idea](https://benn.substack.com/p/the-internet-2022#footnote-anchor-2-85372487:~:text=Could%20dbt%20and%20S3%20be%20the%20next%20cloud%20data%20warehouse%3F)—let’s run dbt directly on top of S3. 

Admittedly, it stresses me out to suggest that, for two reasons. First, I don’t entirely understand what I’m proposing. There’s an outline that makes sense—dbt can now [compile queries](https://docs.getdbt.com/docs/use-dbt-semantic-layer/dbt-semantic-layer#product-architecture), so why not compile them into something that could be run by a generic Lambda function or an EC2 machine against a bunch of Parquet files in S3?—but I have no idea what technical issues, both big and small, would have to be worked through to make this possible. [Computers are above my pay grade. ](https://www.evernote.com/shard/s58/client/snv?noteGuid=fefd12d0-7824-4255-b27e-e6dc8e1ea203&noteKey=78ad63094298178f&sn=https%3A%2F%2Fwww.evernote.com%2Fshard%2Fs58%2Fsh%2Ffefd12d0-7824-4255-b27e-e6dc8e1ea203%2F78ad63094298178f&title=Screenshot%2B11%252F23%252F22%252C%2B10%253A56%2BAM)

Second, in the last couple years, the data industry has mostly settled on how to design the lower levels of a data stack. After flirting with a bunch of NoSQL and Hadoop architectures—one of the premier data conferences in 2014, called *[Hadoop World](https://www.oreilly.com/content/top-keynotes-at-strata-conference-and-strata-hadoop-world-2014/)*, had tracks like “Hadoop and Beyond” and “Hardcore Data Science”—we agreed on an orderly peace.[^1] Every data stack needs an ETL tool that spiders its way into various data sources and ingests them into a centralized location; it needs that location, typically a warehouse that both stores the data and provides a means for running queries (or [fancier operations](https://www.databricks.com/product/machine-learning)) on top of it it; and the stack needs a transformation tool—i.e., dbt—where teams can define business logic that regularly tell the warehouse how to turn its messy raw data into something fit for human consumption. Each of these three territories is well understood and well defined. The borders between them are clear and uncontested. [It feels good](https://www.buzzfeed.com/connorrdunlap/perfect-fits-that-will-make-you-say-oh-my-god-thats).

The top layer—how we cooked with our data, once the other tools [put it all in its place](https://en.wikipedia.org/wiki/Mise_en_place)—is the only problem left to solve. BI, analytics, AI tools, data apps, data observability systems, data discovery platforms, data catalogs, and a half dozen other categories desperately trying not to be BI[^2] still live in the wilderness, at war, on the other side of the wall. Once we civilize those [barbarian hordes](https://benn.substack.com/p/business-in-the-back-party-in-the-front#:~:text=Instead%2C%20the%20front,is%20coming.), we can all [move on from talking about the tools to “doing the work.”](https://benn.substack.com/p/day-of-reckoning)[^3] 

The alarming truth, I’m realizing, is that the three layers underneath our disorganized outer boundary aren’t actually so stable after all. Specifically, the data warehouse—the anchor, the main beam, the hub around which even ETL and transformation tools spin—has already started to break apart. And an idea like replacing the whole thing with dbt and some CSVs in Azure isn’t actually a deranged dive into some unhinged chaos; it may well be exactly where we’re headed.

# Take us to your warehouse

Suppose [the aliens](https://www.nytimes.com/article/ufo-spy-balloons-china.html) are real,[^4] but weird. They manage to sneak one of their ships through our now-robust balloon popping defenses. Fortunately for us, given how eagerly we shot down their first envoys, they come in peace—they’re pedantic linguists, on a mission to inventory the galaxy into a tidy dictionary that explains how words are commonly understood. “Give us a series of yes or no questions,” they tell us, “that will conclusively tell us if the data community agrees that something is a data warehouse. And we don’t want a textbook definition; we want to know what people think of when someone says warehouse.’”[^5] 

If we can give this to them, our sins will be forgiven, and they’ll go on their merry way. But if we can’t, they’ll annihilate the planet, because our indecision and frustrating inexactitude is [a blemish on their perfectly arranged universe](https://www.tiktok.com/@tired_actor/video/7003006051024981254?lang=en).

As someone who’s helped [build a product that connects to data warehouses](https://mode.com/), who regularly uses warehouses (and has [plenty of pedantic opinions](https://mode.com/blog/should-sql-queries-use-trailing-or-leading-commas/) of my own about that), and writes a blog [about](https://benn.substack.com/p/the-end-of-big-data) [warehouse](https://benn.substack.com/p/how-snowflake-fails) [vendors](https://benn.substack.com/p/the-original-purple-people), I should probably be able to give our fussy foreigners an answer. But I can’t. I have no clue how to tell them what a warehouse is. I can name a bunch of examples—Redshift is one; so is Snowflake; Excel is not—but they’re not based on a clean set of rules. It’s classification by feel, by vibe, by Supreme Court Justice Potter Stewart's famous ruling on what defines porn: "[I'll know it when I see it.](https://en.wikipedia.org/wiki/I_know_it_when_I_see_it)"

To define a data warehouse is to define a sandwich: Every attempt has weird and unacceptable exceptions. A sandwich is meat between bread? A PB&J isn’t a sandwich and a hot dog is. A sandwich must have [two separate pieces of bread](https://www.foxnews.com/story/massachusetts-judge-settles-dispute-by-ruling-burrito-is-not-a-sandwich#:~:text=The%20difference%2C%20the%20judge%20ruled%2C%20comes%20down%20to%20two%20slices%20of%20bread%20versus%20one%20tortilla.)? Most [cheesesteaks](https://www.youtube.com/watch?v=SCMi9YGyRQU) aren’t sandwiches and tiramisu is. A sandwich is food surrounded by leavened bread? Ice cream sandwiches aren’t sandwiches and soup in a bread bowl is. By *two* pieces of leavened bread? Fine, put on of those [little caps](https://images.app.goo.gl/C4xyybFMVjogoxH16) on the bowl.

Do this for data warehouses, and we tie ourselves in the same impossible knots. Warehouses are where data is physically stored? Consider Snowflake, which can query from [external data sources](https://docs.snowflake.com/en/user-guide/tables-external-intro) like S3 and Google Cloud Storage. If I used this feature, I’d still refer to Snowflake as my warehouse; by creating external tables, the warehouse wouldn’t magically transfer itself from Snowflake to S3. 

Are they compute engines? If this were true, it’d force us to conclude that a Python notebook, running Pandas on top of Parquet files, is a warehouse, which definitely doesn’t seem right. 

“Sources of truth?" This one is almost laughable, given that most warehouses today are aggregators of data from other places, like software applications and third-party SaaS apps. In this way, warehouses are the map to other sources’ territories. 

Perhaps a data warehouse is all of these things—they are, [as Oracle says](https://www.oracle.com/database/what-is-a-data-warehouse/), the storage, the compute engine, and the database management system that knows how the whole thing is organized and accessed. But that’d imply that some stacks, like one that uses Presto’s query engine on top of files in Azure, have warehouses that are split across different vendors. That’s uncomfortable—but not nearly as uncomfortable as this definition also implying that Excel, which stores data, processes it, and provides interfaces for accessing it, is a warehouse. Outside of the inevitable Hacker News food fights about whether [Excel ](https://news.ycombinator.com/item?id=1430383)*[ackshually](https://news.ycombinator.com/item?id=1430383)*[ is or isn't a database](https://news.ycombinator.com/item?id=1430383), most analysts would agree—nay, *plead*—that Excel is neither a database nor a warehouse.[^6] 

To make matters even more complicated, our definitions of warehouses are path dependent. [Amazon Athena](https://aws.amazon.com/athena/), a standalone query engine that has never stored data itself, is nearly identical to a Snowflake deployment that only queries external tables. But because Athena has always just been the engine, and because Snowflake usually stores data, we’d be more inclined to call the latter a warehouse than the former, even if both are used in the same way. In other words, if [you start with a ship](https://en.wikipedia.org/wiki/Ship_of_Theseus), you can strip it down to just a few planks and still call it a ship. But if you created the same object by nailing a few planks together, it’s just a [shoddy raft](https://www.youtube.com/watch?v=alpbLYmny4M). 

# The skeuomorphic database

Another definition—the most reasonable one, probably—could be: Who cares? There are no aliens. Why do we need a definition for a warehouse at all?

Mostly, we don’t. Just as 24-hour cable news networks have to fill late-night airtime with [squawking clowns](https://www.foxnews.com/shows/gutfeld), so too do weekly Substacks. The problem is made up, my manufactured outrage against [Xbox’s power saving mode](https://gamerant.com/fox-news-unhappy-xbox-power-saving-mode/),[^7] for the likes and subscribes and MyPillow advertising dollars.

But, the absence of a definition is, at least for us squawking clowns, an intellectually startling realization. It suggests that the data stacks don’t have to have a traditional warehouse at their center, because today’s warehouse is a [skeuomorph](https://en.wikipedia.org/wiki/Skeuomorph). It’s an aesthetic echo of a bygone era, and its actual architecture—[streaming](https://materialize.com/), [serverless](https://aws.amazon.com/rds/aurora/serverless/), [storageless](https://www.dremio.com/platform/sonar/)—can be wildly different from what might’ve assumed was required.

Another such wild architecture? dbt on S3. 

The rough idea is simple enough. When queries get run through dbt’s SQL proxy (this is the thing that intercepts queries with Jinja and metric references in them, and renders them into pure SQL), it doesn’t hand the query off to an database; it instead compiles the query again into something that can be executed against files in S3. A dbt Server processes the job, by reading data out of S3 and writing the results back out as a new file.[^8] 

Josh Wills’ [DuckDB client for dbt](https://github.com/jwills/dbt-duckdb) shows what this could look like, and Jacob Matson’s [modern data stack in a box](https://duckdb.org/2022/10/12/modern-data-stack-in-a-box.html) shows how it could be used. As Jacob says, removing the traditional database and running the entire thing on bare compute services could save money and depend only on open-source software. Though his example is more of an experimental prototype than enterprise product, its general pitch could be similar to that of DuckDB itself—huge and complex data platforms [are overpowered](https://motherduck.com/blog/big-data-is-dead/) for most of what we need them to do.  

It could also be just the beginning. What if the [dbt sources](https://docs.getdbt.com/docs/build/sources) didn’t have to point to tables in a database, but could reference any data source, from files in S3 to Google Sheets? What if Transform’s models inside of dbt could be defined across those sources? What if the semantic layer—be it dbt, LookML, Malloy, or any other potentially independent semantic configuration—isn’t just an encoding of join keys and metric formulas on top of a database, but is an [organizational ERD](https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model) that describes how entities are related across data sources and apps? What if we modeled our business rather than just our data?

These ideas aren’t exactly novel either; [the Modern Data Company](https://themoderndatacompany.com/) is building something similar with their [DataOS](https://themoderndatacompany.com/dataos/)(®), and I might be describing a data mesh in cheaper language.[^9] But whatever you call it, it seems likely that the next decade’s data warehouses—even if they’re still called that—will be as unrecognizable to us as [floppy disks are to teenagers](https://www.cnet.com/culture/surprise-kids-dont-know-what-the-save-icon-stands-for/). 

# An iPod, a phone, and an internet communicator

The thing is, I don’t think it had to be this way.

In his famous launch announcement of the iPhone, Steve Jobs had a choice. He could’ve decided that the device’s combination of features—[an iPod, a phone, and an internet communicator](https://youtu.be/wGoM_wVrwng?t=82)—transcended the traditional telephone. “This is not a phone,” he could have said, “it’s a personal communication platform.” 

Instead, he went the other direction. “Today,” [he actually said](https://youtu.be/wGoM_wVrwng?t=177), “Apple is going to reinvent the phone.” Implied in his announcement: A phone isn’t something that just makes calls and sends texts anymore, but does dozens of things, all at once. 

It’s always struck me as a little odd that ambitious warehouse vendors took the opposite approach with their flagship products. Snowflake, for instance, has largely moved away from calling itself a [database](https://www.google.com/search?q=site%3Asnowflake.com+-inurl%3Adocs.snowflake.com+database&rlz=1C5GCEM_enUS1043US1043&sxsrf=AJOqlzULhrKqIh6Z1S5J7e9j6RqOjbvGfw%3A1677826398518&ei=XpkBZPKQH9rj5NoP26iVsAs&ved=0ahUKEwjyt-mzlr_9AhXaMVkFHVtUBbYQ4dUDCBA&uact=5&oq=site%3Asnowflake.com+-inurl%3Adocs.snowflake.com+database&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAVCuC1izNmDON2gFcAB4AIABVYgBpwSSAQIxMZgBAKABAcABAQ&sclient=gws-wiz-serp) in favor of the [data cloud](https://www.google.com/search?q=site%3Asnowflake.com+-inurl%3Adocs.snowflake.com+%22data+cloud%22&rlz=1C5GCEM_enUS1043US1043&sxsrf=AJOqlzUIgJ_5p8CKdRpstOvPVm0WzAjTUA%3A1677826390451&ei=VpkBZJSVG96g5NoPmJKbuAM&ved=0ahUKEwiUmP2vlr_9AhVeEFkFHRjJBjcQ4dUDCBA&uact=5&oq=site%3Asnowflake.com+-inurl%3Adocs.snowflake.com+%22data+cloud%22&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQA0oECEEYAVDoClj6JGDzJ2gCcAB4AIABVogB6ASSAQIxMpgBAKABAcABAQ&sclient=gws-wiz-serp). I get the reasoning; the platform does a lot more than your everyday database. But for Snowflake, I think that’s a missed opportunity. Rather than rebranding themselves, they could’ve rebranded the data warehouse. They could’ve said, as Steve Jobs did, that they reinvented the database. They aren’t a warehouse with lots of extra features; they’re just a warehouse—and for anyone else to be one, they have to have those same features. The only thing better than being a category creator is being the pacesetter in a category that everyone already buys from. (Counterpoint: They’ve got [1.938 billion reasons](https://investors.snowflake.com/news/news-details/2023/Snowflake-Reports-Financial-Results-for-the-Fourth-Quarter-and-Full-Year-of-Fiscal-2023/) to keep doing it their way). 


---


[^1]: It’s not the modern data stack; it’s *[Pax data](https://en.wikipedia.org/wiki/Pax_Europaea). *(*Datum*? *Datum*? *Dor*? [Grammar is above my pay grade too](https://www.online-latin-dictionary.com/latin-english-dictionary.php?parola=data)).

[^2]: [“I’m not bi! i’m not bi!!”, i continue to insist as i slowly shrink and transform into bi.](https://www.linkedin.com/posts/benn-stancil_im-not-that-old-categoryim-not-that-old-activity-7036419804676673537-BXc1)

[^3]: To be clear, once this happens, I’ll be moving on to talk about [Pitbull](https://twitter.com/bennstancil/status/1379534830740893703).

[^4]: My theory on aliens: They *were* out there, and *will be* out there, but they aren’t out there now. There are roughly [one trillion planets](https://earthsky.org/space/how-and-when-did-the-first-planets-form-in-our-universe/) (what) in the Milky Way, some of which surely could produce intelligent life. But the Milky Way is also 13 billion years old, so the odds of that our window of galactic availability overlaps with that of some other species—that we are both in between the time we’ve developed technology that can communicate with the cosmos and the time we kill ourselves with it—isn’t that high. Or, as Wikipedia’s entry on the [Drake equation](https://en.wikipedia.org/wiki/Drake_equation#:~:text=we%20are%20probably%20alone%20in%20this%20galaxy%2C%20and%20possibly%20in%20the%20observable%20universe.) put it, under one set of (disputed) assumptions, “we are probably alone in this galaxy, and possibly in the observable universe.” Anyway, back to the important stuff: The future of data warehousing over the next 24 months.

[^5]: In their dictionary, Frankenstein is the monster, because the aliens are Good.

[^6]: Troublingly, most blog posts I found about [why](https://www.safe.com/blog/2021/01/excel-not-database/) [Excel](https://www.easasoftware.com/spreadsheets/is-excel-a-database) [isn’t](https://www.solving-finance.com/post/excel-is-not-a-database) [a](http://valentina-db.com/docs/dokuwiki/v8/doku.php?id=valentina:products:adk:v4rev:howto:databases_from_zero:what_is_in_a_database_and_why_excel_isnt_a_database) [database](https://channelmix.com/blog/excel-is-not-a-database/) don’t answer that question at all, and just explain why Excel *shouldn’t be* a database. But is it one? Seems like it could well be.

[^7]: In fairness to myself—and honestly, probably Fox News—[I at least proofread these things.](https://twitter.com/pmarca/status/1630623768094867457)

[^8]: *I think* this is the same thing as saying dbt could be a [data lakehouse](https://www.databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html), which is, as best I can tell, a query engine that runs on top of files in cloud storage tools like S3. But I don’t really know, because data lakehouses are rarely described in plain language. This has always seemed a little suspicious to me. [Good ideas don’t need to be lied about to gain public acceptance](https://blog.danieldavies.com/2004_05_23_d-squareddigest_archive.html); good technology doesn’t need to be exaggerated or obfuscated and dressed up in [dizzying corporate doublespeak](https://www.vulture.com/2020/02/spread-of-corporate-speak.html) to prove its value. Or maybe this sort of language—”no matter the workload, leverage all your data assets instantly with our new high-concurrency data lakehouse that treats data as code”—is how bank CIOs communicate. If you have to ask someone to explain it, [you can’t afford it](https://www.youtube.com/watch?v=i0CW39q0TrY).

[^9]: Ibid.

================================================================================

# For immediate release: Doubling down on our data investments

*We have no problem selling data. But would we buy it?*

---

![](https://substackcdn.com/image/fetch/$s_!cKec!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62a4c3ee-a90d-438a-b661-13b07fe33437_1600x1066.png)
*Look at these very real people getting very real value out of very real data. *

Suppose, [this](https://benn.substack.com/p/do-data-driven-companies-win#:~:text=Imagine%2C%20if%20you%20can%2C%20that%20you%27re%20a%20venture%20capitalist.) [time](https://benn.substack.com/p/how-analysis-dies#:~:text=Imagine%2C%20once%20more%2C%20that%20you%E2%80%99re%20a%20venture%20capitalist.), that you're a day trader. But you’re not one of those Twitch stream [carnival clowns](https://twitter.com/WallStreetSilv/status/1577236794860371970) who scribbles [conspiratorial lines](https://images.app.goo.gl/mAMzhkYKhgAyzqwr8) on top of [candlestick charts](https://images.app.goo.gl/U2h8HnSeMrrNAYBh9); you’re not a [get-rich-quick sucker](https://www.gocomics.com/foxtrot/1999/07/17) who was conned by a Clubhouse scam; and you definitely didn’t spend high school playing Xbox Live, college playing video poker, and your twenties in a basement reading r/WallStreetBets and [fueling your destiny](https://en.wikipedia.org/wiki/Bang_(beverage)) with Bang energy drinks and crypto pump and dumps. 

No, you look for long-term value. You trade public equities and bonds; you only buy bitcoin as a hedge; you have just one Ape; you knew SPACs were a fraud from the beginning. You do your research, and buy long. You're the blue-collar Buffett; the Oracle of the everyman; the proletariat prophet. 

Sitting at your trading terminal on January 14, 2022, you see a [big announcement](https://www.jpmorganchase.com/news-stories/tech-investment-could-disrupt-banking) from JPMorgan Chase. Over the next year, the bank—the biggest in the United States—is committing to spending $12 billion on new technology and data investments. In 2023, they’ll add another $3.5 billion, pushing their annual technology budget over $15 billion. The announcement is littered with promises that could’ve been plagiarized from whitepapers about digital transformations and the modern data stack: “There are two kinds of corporations emerging from today’s technology revolution: the disrupted and the disruptor;” JPMorgan will use “machine learning to personalize the digital experience of its research platform” and an “AI-powered assistant to adapt to the clients' behavior over time and make insightful recommendations;” they’ll “push the limits in tech applications” to reinvent JPMorgan for this “once-in-a-generation transformation.”

Put more succinctly, the JPMorgan leadership team saw the hype that’s come out of Silicon Valley's data industry for the last decade, and they’re in—hook, line, and sinker.

Immediately after the announcement, JPMorgan’s stock [got wrecked](https://www.ft.com/content/e543adf0-8c62-4a2c-b2d9-01fdb2f595cc). It fell 6.2 percent that day, compared to a 0.6 percent drop for the Dow Jones, a 1.2 percent drop for Citi, and a 1.7 percent decline for Bank of America.[^1] So here's the uncomfortable question, for those of us who aren’t yet day traders but are instead representatives of that data industry, often selling the exact vision that JPMorgan is so enthusiastically buying: After reading that press release, are you long or short on JPMorgan’s stock? Though nearly unimaginable in scale, JPMorgan’s investment is the sort of support that data teams dream of. It’s the kind of initiative that data vendors want to galvanize. It’s the digital transformation that we say is necessary for every modern company’s survival. Here’s our chance to put [our actual money](https://en.wikipedia.org/wiki/Skin_in_the_Game_(book)) behind what our marketing mouths are saying—and at a 6 percent discount, to boot. Do we do it?

Given that the majority of this blog’s audience is people who work in or around data, anything short of landslide in favor of buying feels like something between a low-key crisis and “our careers are a fraud.” And yet, my vote is to sell—and not just JPMorgan. I suspect I’d have the same reaction to almost any company that put out a similar announcement. 

What do we make of this? The answer, I want to believe, is more complicated than “data is a waste of money.”[^2] So let’s do what everyone who’s performatively lost faith in Silicon Valley does: Pretend to go to Miami.

# Take the talents from South Beach

Instead of trading stocks, now imagine that you bet on sports.[^3]

Suppose that the Miami Heat—considered [one of the best run organizations in the NBA](https://www.reddit.com/r/nba/comments/ye7n8i/espns_nba_management_power_rankings_1_heat_2/)—pull a JPMorgan, and announce that they’re going all in on advanced analytics. They say they’re going to do more to quantitatively assess talent and look for low-cost diamonds in [D-I](https://en.wikipedia.org/wiki/NCAA_Division_I) and [D-League](https://en.wikipedia.org/wiki/NBA_G_League)[^4] rough. They’ll do real-time in-game analysis to optimize substitutions, lineups, and defensive schemes. They’ll track player’s health metrics (and not just [their age](https://www.sbnation.com/nba/2012/3/25/2902424/tim-duncan-old-did-not-play-box-score-spurs)) to manage midseason workloads and reduce injuries. They’ll hire a team of quants to find more creative ways to structure their salary cap.[^5] 

After this announcement, would you bet on the Heat winning or losing more games over the next several years? Would you be a buyer of Heat shares—as measured by how good of a basketball team they are—or a seller?

This time, I’d be bullish.[^6] My instinct is that this investment—this “digital transformation”—would pay dividends, in the way that JPMorgan's wouldn’t. Obviously, my bets may well be wrong,[^7] but the reaction is curious. Why do I believe in one, but not the other? 

The answer, I think, is that the Heat’s problems are clear. They need to find better players, design better lineups, and keep their roster healthy. Data and analysis can play a direct role in all of these things. Though the Heat may not be able to figure out how to do it, they at least know what they need to figure out. If nothing else, they have a hypothesis. 

JPMorgan, by contrast, has only hope—hope that the hype is real; hope that there’s [actually value](https://benn.substack.com/p/day-of-reckoning) in the data they have; and hope that, once they lay a new foundation, they can do something useful with it. Their investment is, as the cliche goes, a $12 billion solution in search of a problem, inspired, it seems, by [fear and FOMO](https://www.jpmorganchase.com/news-stories/tech-investment-could-disrupt-banking#:~:text=Silicon%20Valley%20may%20dominate%20the%20headlines%2C%20but%20it%20isn%E2%80%99t%20the%20only%20player%20in%20the%20emerging%20technology%20game.%20Being%20large%20and%20well%20established%20can%20be%20a%20burden%20for%20many%20companies%2C%20especially%20in%20industries%20swarming%20with%20nimble%20tech%20startups.). Their path ahead is indirect and [paved with faith](https://twitter.com/seanjtaylor/status/1433636587699539996), like building a bridge over a river, with hopes that there’s something worthwhile on the other side. According to [one critic](https://www.ft.com/content/e543adf0-8c62-4a2c-b2d9-01fdb2f595cc#:~:text=Even%20Jamie%20Dimon%2C%20one%20of%20the%20best%20bankers%20of%20his%20generation%2C%20doesn%E2%80%99t%20get%20a%20free%20pass%20to%20increase%20investment%20spending%20by%20half%20over%20three%20years%20without%20giving%20more%20granularity%20about%20expected%20benefits), “even Jamie Dimon, one of the best bankers of his generation, doesn’t get a free pass to increase investment spending by half over three years without giving more granularity about expected benefits.”

In other words, open-ended data initiatives suffer from, as [Gwen Windflower put it in her new blog](https://www.gwenwindflower.com/blog/1), an intention deficit. My skepticism about JPMorgan isn’t exactly about data; it’s about direction. If there was a better plan and a clearer roadmap—if there was intention rather than [a competitive arms race](https://www.jpmorganchase.com/news-stories/tech-investment-could-disrupt-banking#:~:text=Silicon%20Valley%20may%20dominate%20the%20headlines%2C%20but%20it%20isn%E2%80%99t%20the%20only%20player%20in%20the%20emerging%20technology%20game.%20Being%20large%20and%20well%20established%20can%20be%20a%20burden%20for%20many%20companies%2C%20especially%20in%20industries%20swarming%20with%20nimble%20tech%20startups.)—I might be a buyer.[^8] 

# Forward to the future

Even if that’s true, it raises another unnerving question: How many JPMorgans are out there? Both my and the market’s reaction to JPMorgan’s announcement isn’t just because of a disappointing press release; it’s because we’ve [seen this movie before](https://sloanreview.mit.edu/article/why-so-many-data-science-projects-fail-to-deliver/). Data projects are famously hit or miss. Surely there are a bunch of companies that have stacked up a lot of losses. 

At this point, I’m probably supposed to say that data teams and data vendors need to get back to the essentials; that we need to do a better job of defining our objectives and what success looks like; that we need to think about bUsInEsS vAlUe. If we don’t, this part should go, the bubble will burst, and we’ll pay for our thoughtless profligacy.

But I’m not so sure. We don’t have to back out of a problem the same way we came in. If this grand experiment in big data and all of its spinoffs bear fruit, I don’t think it’ll come from a return to the basics. It’ll come from the thrash, from the failed attempts, and the busted billions of companies like JPMorgan. Though most roads to uncertain destinations are bridges to nowhere, someone will find something [transformative](https://benn.substack.com/p/the-rapture-and-the-reckoning) and [unimaginable](https://twitter.com/bennstancil/status/1631790710381748225) on the other side of the river. Ultimately, that will be the legacy of the modern data stack: the data industry’s creative phase. It’ll be the period when we write a bunch of bad drafts, and probably have to throw out most of them, but ultimately find something novel and profound in it. 

In that, I think JPMorgan’s short sellers are right, but not predictive. Yes, the value of digital data transformations have probably been overpromised and oversold. Yes, we’ve created a bunch of unnecessary tools. Yes, there’s a bubble, and it may be bursting [in this very moment](https://www.wsj.com/livecoverage/stock-market-news-today-03-10-2023/card/svb-stock-price-slides-another-29-premarket-gdGa9ANN0vNESUUorGqm?mod=hp_lead_pos1). But our inventions are real, even if the money that created them was artificial.


---


[^1]: I understand that investors value JPMorgan’s shares based on how much of a profit they think that JPMorgan will turn. Spending a bunch of money is the opposite of making money, so almost anything that costs $12 billion dollars—be it IT investments, a [chat app](https://www.investors.com/news/technology/salesforce-stock-crm-acquires-slack-stock/), or a [design tool](https://www.wsj.com/livecoverage/stock-market-news-today-09-15-2022/card/adobe-shares-drop-after-figma-acquisition-announcement-b4ZSOBPnK38CY2AcXcxy)—is unlikely to thrill Wall Street. Still, investors aren’t *that* short-sighted; their reaction is likely because of the price tag and because of what’s being bought.

[^2]: Or, it’s not, that is the whole answer, and I’m [#opentowork](https://www.linkedin.com/in/benn-stancil/).

[^3]: [FanDuel](https://en.wikipedia.org/wiki/FanDuel), the Robinhood for men who still play fantasy football.

[^4]: Apparently, this is now called the G League because Gatorade sponsors it. Which I guess means we can look forward to BMW sponsoring F1 and changing it [M1](https://en.wikipedia.org/wiki/BMW_M), and Apple sponsoring NFL and calling the championship game the iBowl.

[^5]: Sometimes the quants figure out how to restructure contracts so that you can [make sure Patrick Mahomes has people to pass to](https://twitter.com/JamesPalmerTV/status/1371475923321581568); sometimes they put all your money into mortgage-backed securities and [trigger a bank run](https://twitter.com/jamiequint/status/1633956163565002752).

[^6]: In theory, there could be data on what “the market” thinks too, just as there is on the JPMorgan announcement. Vegas has [over-under lines for team win totals](https://www.nbcsports.com/boston/celtics/odds-2022-23-nba-regular-season-win-totals)—lines that would likely shift if a team signaled that they were committing to being more analytical. I couldn’t find an exact example like this, but if you know of one like it, I’d love to know what happened.

[^7]: [Though my track record speaks for itself.](https://benn.substack.com/p/internal-tools-make-lousy-startups#:~:text=I%20started%20my,Giddy%20up.)

[^8]: Plans: Necessary but [not sufficient](https://www.cnbc.com/2021/11/02/zillow-shares-plunge-after-announcing-it-will-close-home-buying-business.html).

================================================================================

# Too innovative to fail

*Subprime comes to Silicon Valley.*

---

![A Guide To Sand Hill Road | Built In San Francisco](https://substackcdn.com/image/fetch/$s_!-qrP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73626b15-8978-4af2-9499-aac71657402e_1200x630.jpeg)
*[The cradle of innovation.](https://en.wikipedia.org/wiki/Sand_Hill_Road)*

There are, generally speaking, two arguments in favor of the actions that federal regulators took to contain the fallout after Silicon Valley Bank failed last week.[^1] 

The first is that a [bailout](https://www.youtube.com/watch?v=D4h7tKVuJao) was necessary to prevent a much wider crisis. In the time after SVB’s collapse and before its depositors were fully backstopped by the FDIC, we were [teetering towards a full-blown financial panic](https://www.washingtonpost.com/us-policy/2023/03/14/72-hour-scramble-save-united-states-banking-crisis/). If the run on SVB proved “successful”—in that the people at the front of the outgoing wire queue got their money back and the people at the back of the line got blown up—there could be a lot more runs. 

Though we’ll never know if this would’ve happened,[^2] regulators evidently deemed it both plausible enough and plausibly catastrophic enough to intervene. Notably, in this telling, it doesn’t matter who the players in this crisis were, or who’s fault the fire was. Everything was about to burn down—call the fire department now, and investigate for arson later. Questions about how we punish bad actors, avoid moral hazard, prevent future crises, or ethically justify the bailout—save the general principle that widespread suffering is bad and we should try to avoid that—are all secondary.[^3] [Promote the general welfare](https://www.archives.gov/founding-docs/constitution-transcript#:~:text=We%20the%20People,States%20of%20America.); promote [maximum employment](https://www.federalreserve.gov/monetarypolicy/monetary-policy-what-are-its-goals-how-does-it-work.htm); bail us out.

The second argument in favor of the rescue is more specific to Silicon Valley. Thousands of startups banked at SVB; when the bank failed, these companies could no longer access their money. If their deposits were locked up for days or weeks—or if they outright evaporated along with SVB’s equity—these companies couldn’t continue operating. They’d have to furlough employees, fire people, or shut down entirely. It would be, as YC CEO Garry Tan put it, an [extinction level event](https://twitter.com/garrytan/status/1634260576431136768) for startups.

Though Tan and others making this argument often cited the number of people who’d lose their jobs because of this—with estimates ranging as high as [120,000](https://twitter.com/garrytan/status/1634630941334470656)—the argument clearly hangs on more than economic impact of those job losses alone. In January of this year, [3.8 million](https://fred.stlouisfed.org/series/JTUQUL) people quit their jobs, and another [2.3 million](https://fred.stlouisfed.org/series/JTULDL) were let go. Tens of thousands of additional layoffs is, quite literally, a rounding error. Moreover, [professional and business services’ layoffs and firings](https://fred.stlouisfed.org/series/JTU540099LDL) increased by more than 120,000 in January alone, from 417,000 in December of 2022 to 580,000 in January. If anything, the VC class has *[cheered](https://twitter.com/altcap/status/1635635438265438209)* that uptick in layoffs, including [another 10,000](https://www.nytimes.com/2023/03/14/technology/meta-facebook-layoffs.html) announced by Meta just this week, as a necessary and prudent correction.[^4]

The acute danger of this crisis, then, wasn’t that some people would be fired, though that would indeed be bad for those people; it was who would be fired. As Tan suggests [in an interview with CNBC](https://twitter.com/CNBCOvertime/status/1634307044613189635), tech startups are our future—our future employers, our future engines of growth, our future competitive advantage, and the future ramparts of our national defense. And it’s our duty to protect our future.

It’s an evocative argument, akin to saying “our children are our future.” And who can argue against protecting the children?

But Tan’s appeal has one clear but unsaid implication—that Silicon Valley deserves special treatment. That we, as tech startups, are a special class of employer. That we matter more to the country and to the “general welfare” than other companies. That we, like our children, deserve extraordinary protection.[^5]

Admitting this openly, however, presents a pretty serious complication for Silicon Valley. If tech startups (whatever that actually means) were deemed special, and were given, say, [access to exclusive services](https://davidsj.substack.com/p/a-storm-in-a-value-store), the typical social contract for that sort of recognition, as is the case for banks that are [officially designated too big to fail](https://en.wikipedia.org/wiki/Systemically_important_financial_institution), is regulation that prevents abusing those services—regulation that most of Silicon Valley’s boosters would say is anathema to innovation. Tech startups and the financial entities that fund them wouldn’t just be kneecapped by additional scrutiny; they, in fact, need to be *less* regulated to thrive. Companies like Uber and Airbnb needed to operate in legal gray areas; VCs need to be able to deploy capital quickly, and in [huge concentrated piles around immature but promising innovations](https://twitter.com/mattturck/status/1628817222880591876), to speedrun technologies through what would otherwise be a slow and ineffective evolution. 

Maybe! These things may all be true! Startups may be too uniquely important to allow them to die en masse; for an armchair economist like me, it certainly *seems* like the tech industry is—or at least, has historically been—a strategic asset for the United States (and I guess, if we want to be weepy about it, for humanity). And Silicon Valley may not be Silicon Valley if there’s more regulatory oversight. Nor is this necessarily a logically inconsistent position! It’s possible for Silicon Valley to get a regulatory pass *and* a government backstop if things go wrong. 

But that’s almost certainly a *politically* untenable position, which likely explains why it’s only been quietly promoted over the last week. At some point, though, we’re going to have to confront this tension more directly. We might be able to avoid it through this crisis, because it can remain sufficiently hidden behind the arguable necessity of bailing out SVB anyway. But the next crisis—say, a widespread collapse of [new VC funds](https://techcrunch.com/2022/07/19/so-many-new-venture-funds/) or a [crash in venture debt](https://pitchbook.com/news/articles/venture-debt-financing-blackstone-KKR) that threatens thousands of startups at once—may be more localized. And in that case, “we’re too innovative to fail” may be the best case a desperate tech industry has. 

In this way, SVB’s collapse really could be Silicon Valley’s Lehman moment, not because it leads to some immediate catastrophe, but because it catalyzes a dramatic regulatory shift. Like Lehman, SVB demonstrated how seemingly narrow bets—on mortgage-backed derivatives in the former case, on private tech startups in the latter one—can get leveraged into a national crisis. Though SVB has been rightly blamed for mismanaging their balance sheet, that mismanagement was made possible by the [mismanaged bets of venture capitalists](https://www.netinterest.co/p/the-demise-of-silicon-valley-bank#:~:text=Driven%20by%20the%20boom%20in%20venture%20capital%20funding%2C%20many%20of%20Silicon%20Valley%E2%80%99s%20customers%20became%20flush%20with%20cash%20over%202020%20and%202021.%20Between%20the%20end%20of%202019%20and%20the%20first%20quarter%20of%202022%2C%20the%20bank%E2%80%99s%20deposit%20balances%20more%20than%20tripled%20to%20%24198%20billion) (who, for their part, would say that mismanagement was made possible by the [mismanaged policies of the federal government](https://twitter.com/DavidSacks/status/1635753517892915200)). In the end, though, it likely won’t matter that much who’s right; there’s political hay to be made by reacting to the crash that happened and not the one that, hopefully, [didn’t](https://twitter.com/patio11/status/1634923819654848514).

Like Lehman, SVB also deeply wounds an already teetering mythology about the industry it serves. Before 2008, Wall Street was the prestigious destination for elite college graduates; when I was in college, it was, if not a noble career, a defensible one. Following the financial crisis, tech took over the top cultural spot: it paid well, [partied hard](https://benn.substack.com/p/delirium#:~:text=In%202012%2C%20I,was%20a%20bacchanal.), and, unlike finance, “[made the world a better place](https://benn.substack.com/p/free-fall#:~:text=We%20were%20there%2C%20we%20say%2C%20to%20%E2%80%9Chave%20an%20impact%2C%E2%80%9D%20the%20cliche%20that%E2%80%99s%20replaced%20its%20now%2Dparodied%20predecessor%2C%20%E2%80%9Cmake%20the%20world%20a%20better%20place.%E2%80%9D).” But after years of [high](https://en.wikipedia.org/wiki/WeWork)-[profile](https://en.wikipedia.org/wiki/Elizabeth_Holmes) [scandals](https://en.wikipedia.org/wiki/FTX), the image of the heroic founder—[the misfit, the rebel, the dreamer who’s pushing the human race forward](https://www.youtube.com/watch?v=5sMBhDv4sik)—has been replaced by one of a con artist or copycat opportunist. And venture capitalists, rather than emeritus entrepreneurs, are seen as unsophisticated [podcast bros](https://www.nytimes.com/2023/03/06/style/dating-men-with-podcasts.html)[^6] who play [swarm ball](https://www.playsportstv.com/soccer/articles/1668/avoid-the-swarm-in-youth-soccer) with billions of dollars. Just as the exact cause of the crash may not matter, neither will the correctness of these characterizations, so long as they have political appeal. 

I don’t know. Maybe there’s a regulatory reckoning; maybe not. But on the question of if there *should* be one, I can’t shake the feeling that SVB, also like Lehman, was wrapped up in a subprime crisis of its own. And unlike Lehman, which was the huge cloud of deadly carbon monoxide that killed half the miners, SVB could just be the canary.

The arc of Lehman's implosion is well known: Banks aggressively made loads to unreliable borrowers, packaged those loans up into “diverse” derivatives, and sold them back and forth to one another. But all the loans were correlated, the derivatives were neither safe nor diversified, and eventually, all at once, the whole thing went nuclear.

Squint, and Silicon Valley's financial scaffolding has a lot of similar contours. Nearly every aspect of starting and running a company has been streamlined, automated, or offloaded to a SaaS startup that promises to do it for you. You can file [incorporation paperwork](https://stripe.com/atlas), [manage your books](https://www.zeni.ai/) (including, apropos of nothing, spreading your deposits across different nine banks to increase your[ FDIC insurance limit](https://www.brex.com/support/how-do-brex-cash-accounts-protect-my-funds#:~:text=Brex%20Cash%20accounts%20have%20a%20FDIC%2Dinsured%20offering%20that%20stacks%20customer%20deposits%20across%20nine%20banks%20(each%20in%20%24250%2C000%20increments)%20for%20%242.25M%20of%20FDIC%2Dinsured%20coverage.) nine times over), and [run your entire back office](https://gusto.com/) in a few clicks. Though these could be very good things individually—just like making some creative loans might be good for helping make financial services more accessible!—in the aggregate, they encourage a lot of risky behavior. Specifically, they make it easy to start a lot of startups that are bad ideas.[^7] They make it easy to start startups that are good ideas too, but good ideas usually take a lot longer to IPO than bad ideas do to blow up.

This could all be fine, if these companies never made it out of dorm rooms and garages. But many do, and with brand name backers: YC, for example, invested in more than 500 companies in 2022, up 1,000 percent from their storied years when they were incubating companies like Airbnb, Stripe, and Dropbox. VCs, for whom no KPI matters as much as who else you have a term sheet from, keep following on; Silicon Valley’s collective terror of down rounds keeps ratcheting companies’ valuations higher. And the whole thing, like the subprime mortgage market, gets layered in “derivatives”—startups selling to each other, funds investing in founders who [invest back into funds as LPs](https://www.theinformation.com/articles/ftxs-bankman-fried-invested-more-than-500-million-in-sequoia-and-other-vcs)—that hide how concentrated everyone’s exposure is around a bunch of risky assets. 

This music, obviously, can stop. And when it does—as it did in 2000, and 2008, and seems to be now—maybe companies die, capitalism works as intended, and we all move on. But today’s [widening](https://www.nytimes.com/2023/03/15/business/credit-suisse-shares-saudi.html) [crisis](https://www.nytimes.com/live/2023/03/16/business/banking-crisis-stocks-market-news) at least demonstrates that what happens in Silicon Valley’s financial institutions doesn’t stay in them.[^8] If we want to keep the tech ecosystem’s innovation engine going—if it really is too innovative to fail—we also need to make sure its financial engine doesn't become too risky to exist. 

# Fair ways to fail

There was actually a third reason that people said that the SVB bailout was necessary: People and companies losing their deposits wasn’t *fair*. Startups who banked at SVB didn’t do anything wrong, unethical, or even (we all thought) risky; all they did was open a checking account. It wasn’t their fault; they were victims of mismanagement and an economic shock; they deserve to be made whole. 

Ok, yes, on one hand, these points seem obviously true.[^9] On the other hand, I think it’s worth at least briefly reflecting on why they seem so obviously true in this case, and not in others.

To state the obvious, unfair things happen to people all the time. Notably, tens of thousands of people have been laid off by large tech companies. They didn’t do anything wrong, unethical, or even risky—many of them took jobs at stable (we all thought) giants like Google, Facebook, and Salesforce. All they wanted was a job. They then lost it; it wasn’t their fault; they were victims of mismanagement or the same economic shock. 

This is generally seen as natural and normal. Yes, people are *supposed* to get fired for poor performance, but sometimes, bad things happen to their employer. 

However, companies going under because of SVB’s implosion is perverse. Startups are *supposed* to be fail because they build bad products or spend too much on ads or [commit fraud](https://en.wikipedia.org/wiki/FTX), but not because bad things happen to their bank. And when that happens, we, apparently, have a moral obligation to correct it.

It’s striking how parallel the two situations are, and how differently so many people in tech respond to them. Is the argument about fairness just [self-serving](https://www.ft.com/content/7bc11176-293c-4a89-bb3e-686a6d4d9623) rhetoric? Is it because there’s a clear way to reverse SVB's collapse but not layoffs? Is it because layoffs are fairly common occurrences, and we stop seeing things that happen all the time as unfair?[^10] 

I don’t know. Think about it though. If you’re convinced that this was the series of unfortunate events that demands extralegal actions to correct—to make *fair*—why, among all the unfair tragedies that befall so many people, is this one special?


---


[^1]: This story has been [told](https://www.bloomberg.com/opinion/articles/2023-03-10/startup-bank-had-a-startup-bank-run#xj4y7vzkg) and [retold](https://www.netinterest.co/p/the-demise-of-silicon-valley-bank) dozens of times by now, and I—a data blogger and [accidental CTO](https://www.linkedin.com/posts/benn-stancil_some-personal-news-after-nine-years-of-being-activity-7037501139327614977-VlD6/) who didn’t know what [AFS](https://www.investopedia.com/terms/a/available-for-sale-security.asp) or [HTM](https://www.investopedia.com/terms/h/held-to-maturity-security.asp) meant until last week—won’t be able to summarize it nearly as well as they already have.

[^2]: The banks that people were worried about [got hammered](https://www.wsj.com/articles/bank-stocks-are-taking-their-worst-beating-since-the-covid-scare-d835a0cc) by financial markets on Monday, which some people might say is proof that more runs were imminent. But [it’s also possible](https://twitter.com/JustinWolfers/status/1635341353847775232) that they got hammered *because of* Sunday’s announcement, not despite it. Don’t bail out SVB, and regional banks are overvalued, because they might blow up next. Bail out SVB, and regional banks are overvalued, because they’re about to lose their regulatory hall pass.

[^3]: You could argue, [as some have](https://slate.com/technology/2023/03/silicon-valley-bank-rescue-venture-capital-calacanis-sacks-ackman-tantrum.html), that the mess was made worse by Very Online venture capitalists who, in their zeal to get the fire department to come, ran around lighting more fires. The VCs would say they were simply [pointing out fires](https://twitter.com/DavidSacks/status/1635443171995058177) that were already lit. Unfortunately, if the world really was on brink, it doesn’t really matter who’s right. Either way, the most important thing is that the firefighters show up.

[^4]: Of course, it’s possible that the different reactions are lazy hypocrisy and self-interested reasoning, and “the workers” are a rhetorical volleyball to be thought of or ignored, depending on how their interests align with that of my portfolio. It is, [after all](https://www.goodreads.com/quotes/21810-it-is-difficult-to-get-a-man-to-understand-something), difficult to get a man to argue on Twitter for something, when his carried interest depends on not arguing for it.

[^5]: Some may say, no, we just want the same fair and equal treatment that any industry would get in this situation. To which I’d ask, do you think Tan has a point? Most people—including me!—would struggle to see his argument as a complete non sequitur.

[^6]: [According to Forbes](https://www.forbes.com/midas/), four of the top 51 VCs in the world are women. Three of the top 51 are named Peter.

[^7]: There’s also very little personal risk in starting a company. If it goes well, you win big. If it doesn’t, you lost someone else’s money, made a lot of connections with important people, and will probably have an *easier* time getting your next job or raising money for your next startup. [As I said before](https://benn.substack.com/p/customer-capture#:~:text=In%20Silicon%20Valley%2C%20hundreds%20of%20startups%20exist%20to%20be%20successful%20and%20to%20solve%20a%20problem%2C%20in%20that%20order.%20They%E2%80%99re%20trophies%2C%20status%20symbols%2C%20learning%20experiences%2C%20lottery%20tickets%2C%20lifelong%20dreams%2C%20and%2C%20somewhere%20down%20the%20list%2C%20a%20means%20for%20making%20a%20particular%20product.), this dynamic means that “hundreds of startups exist to be successful and to solve a problem, in that order. They’re trophies, status symbols, learning experiences, lottery tickets, lifelong dreams, and, somewhere down the list, a means for making a particular product.”

[^8]: To reiterate, the point here isn’t if Silicon Valley caused the SVB to collapse or not. The point is that SVB was a bank that almost exclusively served the Silicon Valley ecosystem, and its collapse is having effects that go well beyond that ecosystem.

[^9]: Or not! Some people disagree! They say that startups put too much money in a single bank, didn’t vet that bank well enough, and ignored basic practices of financial governance. Which, to me, warps the concept of fairness beyond recognition. Just because someone could’ve conceivably avoided some bad thing doesn’t mean that bad thing is fair.

[^10]: I would reflexively say that someone getting shot by a stray bullet was treated more unfairly by the universe than someone who died of cancer, but I’m not sure that makes any sense.

================================================================================

# The public imagination

*OpenAI shouldn't be an app store. It should be a hardware store.*

---

![](https://substackcdn.com/image/fetch/$s_!iscQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2a52cca-3508-4863-a685-23b80e13334f_1600x899.png)

[“ChatGPT is having an iPhone moment.”](https://venturebeat.com/ai/why-this-chatgpt-moment-harks-back-to-the-original-iphone/)​​

When ChatGPT came out late last year, people immediately [began](https://www.youtube.com/watch?v=tA9SMpuXR5A) [comparing](https://www.axios.com/2023/01/24/chatgpt-openai-iphone-boom) its launch to [that of the iPhone](https://www.youtube.com/watch?v=wGoM_wVrwng). It’s a tempting analogy. AI could be the biggest technological breakthrough since the mobile revolution. Both launches immediately captivated the public’s attention. And just as the NBA is constantly looking for the [next Michael Jordan](https://www.theringer.com/nba/2020/5/4/21246021/next-michael-jordan-last-dance-kobe-bryant-lebron-james), the tech industry is always hunting for its [next Steve Jobs](https://www.cnbc.com/2015/09/23/worlds-youngest-female-billionaire-next-steve-jobs.html). 

Just yesterday, OpenAI, the maker of ChatGPT, took another apparent step towards the iPhone: They launched [an app store](https://twitter.com/DrJimFan/status/1638959417692680192). ChatGPT now supports [plugins](https://openai.com/blog/chatgpt-plugins), which are apps that run directly inside of the chatbot and allow it to interact with other services on the internet, like OpenTable and Instacart. With these apps, people can use ChatGPT to make reservations, order ingredients for a given recipe, or do a handful of other similar tasks. 

It’s a bold step—but it feels like either a mistake or misdirection. Because public AI providers like OpenAI aren’t destined to become the next iPhone, but the next—and maybe, much bigger—AWS. 

# The internet’s hardware store

Cloud computing wasn’t one revolution, but two. 

The first was architectural. Prior to “the cloud,” most software was bought off shelves, installed on computers, and run entirely on customers’ own hardware. It was Microsoft Word for Windows 95: Sold at [CompUSA](https://en.wikipedia.org/wiki/CompUSA), in a box, on a CD. Cloud software, by contrast, is delivered over the internet. Rather than installing an entire program on your computer, it runs elsewhere, and users interact with it remotely. Though you sometimes still have to install software too—like the Dropbox widget on your computer or an app on your phone—the majority of the service runs in some data center somewhere. Instead of Word, it’s Google Docs: Accessible on a website, no download required. 

Revolutionary as this concept is, it’s not actually all that transformative on its own. Because, in addition to developing the applications they wanted to sell, cloud software vendors also had to* run* them. They had to buy servers. They had to hire people who knew how to manage those servers. They had to run software on those servers that ran the software that they sold to customers. They had to keep the servers up, 24/7. They had to figure out contingency plans for when [a server fried itself](https://www.youtube.com/watch?v=0a2lv4IwZFY), or the power went out, or someone accidentally ran a command that caused those servers to [stop announcing their DNS prefix routes through BGP](https://blog.cloudflare.com/october-2021-facebook-outage/). For many companies, these messy realities made the theoretical promise of cloud software impractical and expensive. 

But in these problems, Amazon saw an opportunity, and an [incomprehensibly large pile of money](https://twitter.com/Humphreytalks/status/1233184797507256320). Amazon—and later Google, Microsoft, and a few others, who are collectively now known as [cloud providers](https://www.zdnet.com/article/the-top-cloud-providers-of-2021-aws-microsoft-azure-google-cloud-hybrid-saas/)—began offering ways for companies to lease servers. The cloud providers would make the upfront investment to buy a bunch of computers, and would do the work to make sure they were always up and running. Companies could then rent them, by the minute, for a fee.

To make the offer more appealing, cloud providers started selling utility services as well. In addition to renting hardware, people could also lease a [file storage system](https://aws.amazon.com/s3/), a [database](https://aws.amazon.com/rds/), a [tool that runs simple programs on demand](https://aws.amazon.com/lambda/), and [hundreds of other similar products](https://aws.amazon.com/products). All of these services were designed to be a kind of middleware that sits somewhere between [bare metal](https://en.wikipedia.org/wiki/Bare-metal_server) and the sort of software that most people use every day. The utilities are building materials, and cloud providers are the internet's hardware stores—they sell pre-cut lumber and boxes of nails and sandpaper of dozens of different grains, but don’t offer birdhouses or lawn furniture or two-story houses. They [leave it to other people](https://erikbern.com/2021/11/30/storm-in-the-stratosphere-how-the-cloud-will-be-reshuffled.html) to build, market, and sell the thousands of finished products that their raw materials can create. 

It has been, in what's still probably an understatement, a staggering success. The combination of cloud architectures and the affordability and convenience of AWS and its utility services launched a revolution. Tens of thousands of companies were created on the platform. Hundreds of thousands of new products got launched. Millions of engineers experimented with cloud technologies and stretched the limits of what they could do. And roughly a trillion dollars ended up in the bank accounts of the major cloud providers.[^1]

Yes, there are skeptics and holdouts—some companies don’t like the idea of running sensitive applications on another company’s hardware; for very big companies, the fees that cloud providers charge can [end up costing more than buying their own servers](https://a16z.com/2021/05/27/cost-of-cloud-paradox-market-cap-cloud-lifecycle-scale-growth-repatriation-optimization/). But these exceptions are uncommon. For many companies, their AWS (or GCP or Azure) bill is an unavoidable tax for doing business on the internet, a universal line item on our income statements, the toll to drive on the information superhighway. 

For end users, cloud providers are the internet’s invisible backbone. Nearly all of us rely on them, daily, and in countless ways. Their reach is often only appreciated when they go down, and [take half the internet with them](https://techcrunch.com/2021/12/07/amazon-web-services-went-down-and-took-a-bunch-of-the-internet-with-it/).[^2] They are, true to their name, an ever-present cloud over modern society. 

# The generative cloud

So here's an obvious prediction: AI will follow a nearly identical trajectory. In ten years, a new type of cloud—a generative one, a commercial Skynet, a public imagination[^3]—will undergird nearly every piece of technology we use. 

In the same way that cloud architectures predated the cloud providers, deep learning and neural networks have been around far longer than AI applications like ChatGPT. However, for most companies, these technologies are too impractical to use widely. They have to be developed by expensive experts, they’re hard to integrate into software applications and business processes, and they don’t deliver clear enough benefits over more basic techniques—like [division](https://twitter.com/mrogati/status/481927908802322433)—to justify the cost. For years, the [AI-powered organization](https://hbr.org/2019/07/building-the-ai-powered-organization) has been coming; we just have to [figure out how to use AI first](https://hbr.org/2020/06/the-dumb-reason-your-ai-project-will-fail).

But a million companies’ problem is one company’s opportunity (and another [very large pile of money](https://www.reuters.com/business/chatgpt-owner-openai-projects-1-billion-revenue-by-2024-sources-2022-12-15/)). For better and for worse, OpenAI—and specifically, its APIs—will finally [take AI mainstream](https://benn.substack.com/p/scoring-data-predictions#:~:text=In%202021%2C%20AI%20will%20go%20mainstream%3B%20no%2C%20in%202022.). Rather than training their own models, companies can now use generalized large language models offered by OpenAI.[^4] The [explosion](https://www.intercom.com/blog/announcing-intercoms-new-ai-chatbot/) [of](https://www.wsj.com/articles/instacart-joins-chatgpt-frenzy-adding-chatbot-to-grocery-shopping-app-bc8a2d3c) [GPT](https://techcrunch.com/2023/02/27/snapchat-launches-an-ai-chatbot-powered-by-openais-gpt-technology/) [integrations](https://www.reuters.com/technology/fintech-startup-stripe-integrating-openais-new-gpt-4-ai-2023-03-15/)—all developed in a few months—speaks to how broadly useful universal LLMs are, and to how easy they are to build on. 

Just as cloud providers built out hundreds of utilities that are all underpinned by core services like EC2, I'd expect OpenAI to do the same thing on top of GPT and other foundational models. They already offer a [chatbot](https://chat.openai.com/chat), a [speech-to-text service](https://openai.com/research/whisper), and a [text-to-image service](https://openai.com/product/dall-e-2). Surely, more utilities like these are coming: Text-to-video, video-to-text, text-to-audio, text-to-code, image-to-text, code-to-documentation, detection services to figure out if something was created or altered by an LLM, music generation, software generation, pipes between these services, and dozens more.  

These products won’t be end-user applications, but developer tools. If you want to build on top of them, it's a simple API call. Ask the ChatGPT API a question, and it’ll talk back to you. Send an image to it, and it’ll describe what it sees. Pass it a codebase and a desired change, and it’ll send you a new codebase with the requested feature. And give all of these models [temperature parameters](https://ai.stackexchange.com/questions/32477/what-is-the-temperature-in-the-gpt-models), content moderation settings, or other simple tuning dials. We’ll manage them with Terraform, and, if history is any guide, spend a lot less time on model development and a lot more time trying to figure out how to configure OpenAI’s [API Gateway](https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html) and [IAM services](https://aws.amazon.com/iam/).[^5]

If this happens, public AI providers like OpenAI would become another backbone for the internet. Nearly every piece of technology will rely on their models. Outlook will need them to summarize our emails. Github will use them to automate code reviews. DoorDash will need them to help guide you through your order. Delta will depend on them for booking flights. Facebook [might not be able to open doors](https://www.businessinsider.com/facebook-employees-no-access-conference-rooms-because-of-outage-2021-10) without them. But, as is the case for cloud providers, this critical infrastructure will be invisible to most people. Customers won’t know or care which products use GPT, just as they don’t care which ones use [DynamoDB](https://aws.amazon.com/dynamodb/) or [Spanner](https://cloud.google.com/spanner) or [Azure Functions](https://azure.microsoft.com/en-us/products/functions/). They’ll just come to expect that the products they buy to do the things at AI can do.

The race, then, is to be a dominant AI provider, since—again, as is true for the cloud—dominance is self-reinforcing. The bigger a provider becomes, the deeper its moat gets through an entrenched ecosystem, better models, and, likely, lower prices. And because training and running LLMs is [very expensive](https://www.cnbc.com/2023/03/13/chatgpt-and-generative-ai-are-booming-but-at-a-very-expensive-price.html) (like building data centers is expensive), once a few AI providers separate themselves from the rest of the market, nobody else can catch up. 

The final equilibrium is the same as it for the cloud providers: A few companies win the market, and the rest of us come to accept their bills as the cost of doing business.

Of course, there will also be skeptics. Some companies will resist using public AI providers because of concerns about security or privacy. Other companies will get big enough that it’ll be cheaper for them to develop their own models than it is to rent one from OpenAI or Google. And there will probably be “multi-cloud” approaches, where companies let their customers choose which LLM they prefer. 

We’ll also have to grapple with one very messy issue that cloud computing can ignore: AI is opinionated. Though today’s cloud providers have tremendous power, it’s almost entirely economic. [Adam Selipsky](https://www.linkedin.com/in/adamselipsky/) and [Thomas Kurian](https://www.linkedin.com/in/thomas-kurian-469b6219/) can extract rents, but EC2 and Google Compute Engine can’t outright manipulate us

Public AI providers can do both. If [nudging Facebook users towards more positive or negative content](https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds) can change their emotions, imagine the effect of public AI providers turning up the temperature on their core models. That single parameter could control how polite or rude we are to each other in billions of emails and text messages. Other parameters could turn every company’s support staff into [agents](https://www.youtube.com/watch?v=RqlQYBcsq54) [of](https://www.youtube.com/watch?v=WlKr-yg-y5I) [chaos](https://www.youtube.com/watch?v=cfNzZre-sIU), or [embed political bias](https://www.nytimes.com/2023/03/22/business/media/ai-chatbots-right-wing-conservative.html) in every generated piece of text.

It’s a terrifying amount of power—far bigger than Elon Musk [controlling our Twitter feeds](https://www.theverge.com/2023/2/13/23598514/twitter-algorithm-elon-musk-tweets), far more direct than TikTok [putting its thumb on its algorithmic scales](https://techcrunch.com/2022/08/16/oracle-now-monitoring-tiktoks-algorithms-and-moderation-system-for-manipulation-by-chinas-government/), and far more precise than Russia’s [disinformation campaigns](https://en.wikipedia.org/wiki/Active_measures). And I have no idea what to do about it.[^6]

# …or not

With all that said, ChatGPT’s plugins feel like a step in a different direction. On one hand, everyone got [very excited about them](https://news.ycombinator.com/item?id=35277677), so maybe they’re a great idea. Plus, in the last twenty years, there are only two tech products that have been more successful than AWS—the [iPhone](https://www.globaldata.com/data-insights/technology--media-and-telecom/annual-sales-of-apples-iphone/) and [Google search](https://www.statista.com/statistics/266249/advertising-revenue-of-google/)—and OpenAI seems to be chasing both of them.

On the other hand, it strikes me as a risky bet for OpenAI. Plugins—and ChatGPT itself, for that matter—position OpenAI’s products as apps that people should log into and use directly. ChatGPT’s [staggering user numbers](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app) have already become its public benchmark. The deafening buzz around everything OpenAI does—every new release is a [revolution](https://openai.com/product/gpt-4); every blog post is a [revelation](https://openai.com/blog/planning-for-agi-and-beyond)—could become an addiction. [Google going DEFCON 1](https://www.nytimes.com/2023/01/20/technology/google-chatgpt-artificial-intelligence.html) over ChatGPT could further bait OpenAI into more fights for user attention.[^7]

People’s attention, however, is a scarce and competitive commodity. In order for that business to get anywhere near the scale of Google or Apple, OpenAI needs to become the [front page of the internet](https://images.app.goo.gl/7HbzsYiFjipeqvBG6) for billions of people. Though that’s not impossible, there are a lot of big companies vying for the same screen time.[^8] 

The more lucrative opportunity for OpenAI, it seems, is to sit behind the apps that are fighting for our attention. In that scenario, whoever wins, so does OpenAI.[^9] Moreover, if AI can replace service jobs, public AI providers could be [much bigger businesses than the cloud providers](https://twitter.com/saranormous/status/1638958539623534597). For OpenAI to be truly ubiquitous and to truly “[benefit all of humanity](https://openai.com/about#:~:text=smarter%20than%20humans%E2%80%94-,benefits%20all%20of%20humanity.,-null%20links),” ignoring how many people use it *directly* may be the most important thing they can do. The real war isn’t for users, but for the public imagination.


---


[^1]: Over the last ten years, AWS has collected about [$290 billion](https://fourweekmba.com/aws-revenues/) in revenue. AWS has consistently represented [about a third](https://techcrunch.com/2023/02/06/even-as-cloud-infrastructure-market-growth-slows-microsoft-continues-to-gain-on-amazon/) of the cloud provider market, implying that the cumulative spend on cloud services over the last decade is about $1 trillion.

[^2]: Speaking of things that are [too important to fail](https://benn.substack.com/p/too-innovative-to-fail), what would happen if Amazon went bankrupt and had to shut down AWS? Or if they just decided this wasn’t worth it anymore, and turned it off? If the banking system is too big to fail, the same is almost certainly true for the public cloud—not least of all because the banking system would probably fail without it.

[^3]: I’m sure we’ll end up calling this something dull, like the AI cloud, or the generative cloud, or the public mind, or the public brain. But my vote is for the public imagination, because it captures the expansive potential of AI and the dystopian possibility that it actually [replaces human imagination](https://twitter.com/bennstancil/status/1631035615738224645).

[^4]: Yes, this conflates things a bit. A lot of existing AI models are things like bespoke fraud detection tools, which LLMs can’t (yet) replace. However, in ten years, I’d expect AI to be in far more places than it is today, powering a much wider range of applications than AI does today. And most of that infrastructure will be backed by companies like OpenAI.

[^5]: As a longer aside, a new role recently emerged in the AI froth: [LLMOps](https://manifold.markets/MattCWilson/7-the-concept-of-llmops-will-emerge). Some people say that this is just a buzzy new name for DevOps. I disagree, at least in the short term. One of the weirdest properties of LLMs is that they can’t actually be directly engineered the way software can. I tend to think of any computer program as having both a user interface and a hood that an engineer can pop to precisely control that interface. If you want an LLM to respond in certain ways, for example, can’t you program it to do that? The answer, it seems, is not really. The only way to get it to take the actions you want it to take is to talk to it. In this way, it is kind of human—there are no dials that will reliably control exactly what it does. If we want to do something, we have to persuade it to.That means that [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) isn’t some hacky way for non-engineers to control an LLM; it’s the *only* way to control an LLM. Given that, LLMOps—which involves [developing new techniques](https://en.wikipedia.org/wiki/Chain-of-thought_prompting) for getting LLMs to respond in reliable ways—seems both necessary and very different from today’s DevOps roles. Over time, however, I’d expect OpenAI to provide utilities to make different methods of prompt engineering easier (e.g., rather than having to chain prompts together manually, OpenAI offers a service that does it for you). If that happens, LLMOps would probably start to look a lot more like a specialized subfield of DevOps, instead of some bizarro engineering role that’s responsible for finding new conversational tricks to socially engineer a computer.

[^6]: Fortunately, our tech-savvy lawmakers are *[on it](https://www.tiktok.com/@gbp97/video/7213775012883434795)*.

[^7]: Or, maybe OpenAI is baiting Google to defend search and not GCP. Either way, it’s curious to me that Google responded so aggressively to ChatGPT and Amazon didn’t.

[^8]: Although, those of us in the United States may have [a lot more free time soon](https://www.cnbc.com/video/2023/03/24/tiktok-hearing-was-an-unmitigated-disaster-for-social-media-app-says-stanfords-jacob-helberg.html), particularly in bed between midnight and 3 a.m.

[^9]: Though it’s possible to be both AWS and the iPhone, that’s a very tall order. As [Steve Yegge suggested](https://gist.github.com/chitchcock/1281611) in his [famous memo](https://www.washingtonpost.com/blogs/blogpost/post/google-engineer-steve-yegge-has-his-jerry-maguire-moment/2011/10/13/gIQATU1hkL_blog.html) about Google and Amazon, you can be a great platform or a great prodcut. Even companies as promising as OpenAI can get [captured and pulled apart by their customers](https://benn.substack.com/p/customer-capture).

================================================================================

# Large language labor markets

*Everything is about to get very weird.*

---

![](https://substackcdn.com/image/fetch/$s_!y4cG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3aad979e-751a-4929-90ff-4382786bf74f_799x533.png)
*Source: The future United States Department of Artificial Labor.*

Whoops.

Four hours before I published [last week's post](https://benn.substack.com/p/the-public-imagination)—which argued that, because LLMs are so expensive to develop, OpenAI shouldn’t be an iPhone but should instead be AWS—[Databricks announced](https://twitter.com/databricks/status/1639239800145465344) that they had created a chatbot that could be built cheaply and in under 30 minutes.[^1] Their bot wasn’t as good as the one OpenAI had that was backed by GPT-3—which isn’t as good as one using GPT-4—but it was still, compared to what most people thought chatbots was capable of in the middle of last year, a huge leap forward.[^2]

People had questions. Does this change everything? Does that mean that LLMs are becoming commodities? Will every company train their own? Is OpenAI’s strategy of launching an app store—and using an ecosystem ([or regulation](https://twitter.com/jonst0kes/status/1636425454931329035)) as its moat, rather than a technology—the right strategy? Will open source models ultimately win out? 

I have no idea—clearly, this blog is a lousy source of the latest news on AI.[^3] However, it did raise one interesting question for me about where all of this is headed: Are we going to have labor markets for LLMs?

# Low-skilled AI

Historically, economists have divided the labor market into two groups: Low-skilled workers and high-skilled workers. As the name suggests, low-skilled workers are people who hold jobs that don’t typically require advanced degrees or special training, like service workers, taxi drivers, construction workers, and so on. High-skilled labor, by contrast, are lawyers, doctors, engineers, electricians, or any other profession that takes a long time to develop the ability to do. 

Though the terminology [is problematic](https://www.vox.com/22871812/eric-adams-aoc-low-skill-workers), the concepts provide a useful sketch of how labor markets work. Jobs that require what are perceived as more generic skills get paid low wages, whereas those that require a lot of expertise can usually command higher wages. And jobs that require extreme specialization—say, a heart surgeon over a primary care physician—are paid an even greater premium. Very roughly, the more a person invests in acquiring skills, the more expensive their labor is. 

The introduction of Dolly suggests that LLMs and other generative AI models are also “skilled,”[^4] and could be divided along the same crude lines that economists use to divide the labor force. Dolly is low-skill. You might not trust it to send an important email to your boss, but you’d probably be fine with it making a restaurant reservation for you. GPT-4 is high-skill—it might actually be good enough for that email to your boss. And companies will surely develop specialized models that extend GPT-4 (or GPT-5, or GPT-[6S Plus](https://en.wikipedia.org/wiki/IPhone_6S)) with specific training data, and are particularly good at creative writing, or molecular chemistry, or negotiating for higher salaries. 

These high-skill models are likely to be more expensive to employ than their less-skilled counterparts. They would cost more to train because they’d have to be tuned, tested, and refined against a new set of complex tasks. They would also cost more to run. In order to perform advanced tasks, LLMs would probably require longer prompts, which are much more computationally expensive.

You could imagine a world where we call Comcast, and talk to a cheap, low-skill LLM that [can’t figure out how to cancel our subscription](https://www.theguardian.com/technology/shortcuts/2014/jul/17/comcast-customer-services-call-ryan-block). By contrast, USAA, which markets itself as [having industry-leading customer service](https://www.cdxe.de/en/blog/how-usaa-delivers-an-excellent-customer-and-digital-experience), would be running on more refined models. If their frontline AI can’t solve our problem, we’d get escalated to another model that’s specifically designed to help us file an insurance claim or apply for a home loan. The quality of these services becomes yet another way companies try to differentiate themselves, or upsell premium packages.[^5]

This dynamic could appear everywhere. There could be expensive AI therapists that keep years of dialogue in their conversational memory, and there could be cheap ones that start from scratch every session. There could be good AP U.S. History tutors (and test-takers), and bad ones that hallucinate facts about American history.[^6] There could be AI lawyers that specialize in obscure corporate tax law—for the right price. People with money may be able to train models on lookalike groups of patients and get personalized medical care, while people without it may have to rely on ChatWebMD. 

The same could be true in the corporate world as well. Companies don’t pay a premium for McKinsey because of the quality of their consultants, but because McKinsey promises to train a dedicated model for all of their clients. Google builds a better writing assistant than anyone else because it’s trained on [private data](https://www.linkedin.com/feed/update/urn:li:activity:7047532319661809664/) inside of Google Docs, which only Google has access to.[^7] HBO stops investing in the best writers, and starts investing in creative LLMs. Nike’s ads are developed by a team of experts and a fork of Midjourney that’s tuned to create [inspiring and emotionally arresting imagery](https://www.youtube.com/watch?v=-8yOG3qYk08); Pepsi storyboards [their ads](https://www.youtube.com/watch?v=uwvAgDCOdU4) with [Microsoft Tay](https://en.wikipedia.org/wiki/Tay_(chatbot)).

True, it’s possible that the floor for these models, including the cheap ones, is so high that the differences don’t actually matter. ChatGPT might already be a [halfway decent lawyer](https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html); in a year, even the lowest-cost LLMs might be a regular [Elle Woods](https://www.youtube.com/watch?v=GSu7BGbyJqc). Prices may also fall so much that the best and worst models are all trivially cheap.

Still, it’s also possible the *ceiling* for some of these tools is so high that there’s still a huge gap between what’s cheap and what’s expensive—it’s just that the expensive ones are capable of things we can barely fathom today. Or, even if the differences between models are small, the advantages they provide, like being able to ship code faster, could compound quickly. Employing a marginally better AI “workforce” might not make a discernible difference in how a company operates from day to day, but those benefits could accrue into huge gaps over time. 

# Moving history

Databricks’ Dolly was released [under a headline](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) that said it was “democratizing the magic of ChatGPT.” It’s another parallel to the iPhone: Generative AI tools could be egalitarian, and afford [no privilege to the rich](https://benn.substack.com/p/rich-man-and-his-iphone#:~:text=Of%20all%20of%20the%20iPhone%E2%80%99s%20accomplishments%2C%20one%20of%20the%20most%20remarkable%20is%20that%20it%20put%20the%20same%20exact%20piece%20of%20technology%20into%20the%20pockets%20of%20people%20in%20every%20strata%20of%20society.). The reality, however, seems much more complicated—and much weirder. Legal LLMs could drift towards being intentionally obtuse so that you have to pay them to interpret one another, and can’t replace your lawyer with your low-skilled personal assistant chatbot. A [cabal of overbearing parents](https://en.wikipedia.org/wiki/Varsity_Blues_scandal) is going to bribe the College Board for all of its test data so that they can create a test-taking and essay-writing bot for their kids. Someone will propose that LLMs pay income tax, and someone will become the first AI labor economist. 

Whatever happens, it feels like one thing is pretty clear: We’re barreling towards a very strange future. Even if we don’t go to war with Skynet, or if Bard doesn’t [harvest us to be batteries](https://www.youtube.com/watch?v=IojqOMWTgv8) for Google’s data centers, it feels like a lot of the assumptions we make today about how society works, including the basic underpinnings of how jobs work, [are about to get upended.](https://marginalrevolution.com/marginalrevolution/2023/03/existential-risk-and-the-turn-in-human-history.html) 

Here’s to hoping that [it doesn’t happen faster than we can handle](https://www.piratewires.com/p/openai-slowing-walking-gpt)—unless, of course, at the pace we’re going, it already happened four hours ago.


---


[^1]: This wasn’t even my worst timed blog post of the month. Three weeks ago, SVB collapsed [28 minutes](https://www.bloomberg.com/news/articles/2023-03-10/silicon-valley-bank-collapses-enters-fdic-receivership#xj4y7vzkg) before I made some elaborate analogy about [JPMorgan transforming banking](https://benn.substack.com/p/for-immediate-release).

[^2]: I’m speculating a bit here. Dolly’s creators said that it demonstrated a “surprising degree of the instruction following capabilities exhibited by ChatGPT,” which I read as acknowledging that it’s not as capable as GPT-3.

[^3]: The big brained computer is once again reminding me to [do the reading](https://twitter.com/bennstancil/status/1598518024490962952) before writing one of these things.

[^4]: We even benchmark that skill in the same (somewhat dubious) way that we benchmark it in people: with [standardized tests](https://openai.com/research/gpt-4).

[^5]: “Our starter plan includes a maximum of 10 user licenses, all of our essential features, and our 24/7 chatbot support. Our enterprise plan includes unlimited seats, SAML-based single sign-on, and a chatbot trained on your own usage data, updated once a quarter.”

[^6]: For example, it might claim that the Civil War was fought over “[states’ rights](https://www.jacksonville.com/story/news/nation-world/2017/08/22/how-civil-war-taught-school-depends-where-you-live/15766977007/).”

[^7]: Is this legal? Probably not. Are they doing it? I’m sure they’ve thought about it. Could it hallucinate something from someone else’s document into your own? If they haven’t done it, I’m guessing that’s why not.