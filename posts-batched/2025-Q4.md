# Posts from 2025-Q4

This file contains 10 posts from 2025-Q4.

================================================================================

# Something in the orange

*A last exit.*

---

![](https://substackcdn.com/image/fetch/$s_!ge7K!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F704db9ce-209b-4bb3-8c30-ad6d7b42c7b2_2846x1336.png)

I think about the interstate sometimes. Between San Francisco and New York, between New York and Los Angeles, between Los Angeles and Philadelphia and New Orleans and every other city in the United States, there is an uninterrupted artery of pavement. Pick any two points on a map, and they are not only connected by a single, spidering blacktop; but you can also draw a line from one to the other without ever encountering an obstacle, a stop light, or even an intersection. Somehow, despite millions of people crisscrossing the country every day, there is always a path to go from where you are to where you are going in [one long, continuous sprint](https://www.instagram.com/p/CEuAgaZJav-/).

There is an metaphor here, if you want to make one. Startups, despite having a name that suggests a beginning—which seems to also imply the existence of an end, or at least, an evolution—are often one long, continuous sprint. [Go fast, forever](https://benn.substack.com/p/live-like-youre-dying#:~:text=take%2C%20it%E2%80%99s%20that%3A-,Go%20fast%2C%20forever,-.%20Maintain%20perpetual%20urgency). Those who find themselves on that highway, they know the feelings that it shares with those of a road trip: There is a destination—an IPO, an acquisition, [the promise of peace in two weeks](https://benn.substack.com/p/live-like-youre-dying#:~:text=So%20another%20friend%20and%20I%20had%20a%20different%20joke%3A%20%22It%27ll%20get%20better%20in%20two%20weeks.%22)—but it always seems to stretch just beyond the curve of the horizon. Are we there yet? We are [perpetually halfway there](https://en.wikipedia.org/wiki/Zeno%27s_paradoxes#Dichotomy_paradox); it is still [day 1](https://aws.amazon.com/executive-insights/content/how-amazon-defines-and-operationalizes-a-day-1-culture/); we are only [two percent done](https://www.crn.com/news/ai/2024/thoughtspot-s-new-ceo-ai-is-the-new-bi). There are mileage markers, like [fundraising rounds and big hires](https://benn.substack.com/p/live-like-youre-dying#:~:text=Between%20my%20friend%20and%20I%2C%20it%20became%20a%20meme%3A), that tease our progress. There are pockets of debilitating traffic that wear us down; there are near-miss accidents that nearly kill us; there are stretches of [open road and a whole lot of speed](https://www.youtube.com/watch?v=2-S-PaMWhwI); and there are, most of all, [hours of absolutely nothing](https://www.instagram.com/p/CFEDbbQpD9U), and the grind of an empty, exhausting drive.

But there is something more subtle about roadtrips, and about startups: Their stories don’t translate. So much is lost in the telling. The misery of inching through clouds of tar and construction dust does not sound, in the grand scheme of things, all that miserable. The [barreling mountain wind](https://www.instagram.com/p/CE9vcrrp24W) loses its divinity, when you put it into words. The Colorado sunset does not fit on an iPhone.

But if you were there, in the car, you would understand. You would’ve also wondered if we were going to die in that slug of traffic. You would’ve seen that canvas of a thousand shades of orange, stretching into the cosmos. And you would’ve also felt how the road bends time—how the last thirty minutes before the hotel feels like three hundred; how quickly [a sun rises](https://www.instagram.com/p/CEvFzwBp3lM/) and how [slowly it sets](https://www.instagram.com/p/CFFafLcJB4J/?img_index=1); and how, amid the hypnotic hum of the engine, the hours detach themselves, and you become a [loose photon](https://bigthink.com/hard-science/photon-experience-light-speed/), blasting down a timeline all your own.

So it is with startups. From the outside, the hard parts look easy, because, in the grand scheme of things, [they are](https://benn.substack.com/p/ambition-fun-and-not#:~:text=Here%20is%20a%20conversation%20you%20might%20imagine%20a%2030%2Dyear%2Dold%20having%20with%20Jensen%20Huang%2C%20the%20founder%20of%20Nvidia%20and%20tenth%2Drichest%20person%20on%20earth%3A). The successes look mundane, because there are always other companies that are growing bigger, moving faster, and raising more. The time inside a startup passes the same as the time outside of it, because we are all bound to the same ticking clock. And yet, if you were there, inside of that furious, fitful machine, you would understand. You would know that none of that is true.

I towed a trailer from New York to Austin this week. There was a public service announcement on the highway: “Slow down, you’re in Texas already.”

A good offer, when you’re tired. You’ve been going fast for what feels like forever; the highway goes on forevermore. You can only drive for so long. Eventually, you need something more stable. Eventually, you need to find more solid footing. Eventually, you are excited for a simple [melon party](https://content.severance.wiki/melon_bar) with a few good friends.

It is all a metaphor, of course.

You’ve probably seen [the rumors](https://www.theinformation.com/articles/data-startup-fivetran-talks-buy-dbt-labs-multibillion-dollar-deal) by now. I don’t know if they’re true, and even if they are, deals can always fall apart. The final signature that made [Mode’s sale to ThoughtSpot](https://www.thoughtspot.com/press-releases/thoughtspot-acquires-mode-analytics-for-200m) official came exactly 37 minutes before the press release was published. Startups are more resilient than we often assume, but mergers and acquisitions—those are frail things.

Still, perhaps that will be the conclusion to this story, to this *whole* story: dbt Labs—the startup that defined a minor technological epoch; the one that hammered [its particular will](https://docs.getdbt.com/community/resources/viewpoint) into the professional world; the company around which hundreds more revolved—will end up owned by Fivetran, its long-time sibling.

If it happens, two things are inevitable. First, there will be corporate blog posts about continuity and carrying on. People will be excited to announce that they are joining forces, deepening partnerships, and going further, [together](https://www.npr.org/sections/goatsandsoda/2016/07/30/487925796/it-takes-a-village-to-determine-the-origins-of-an-african-proverb). This is not a new direction, [someone might say](https://mode.com/blog/mode-founders-note-thoughtspot-acquisition#:~:text=Today%2C%20we%20start%20that%20journey%20together%E2%80%94not%20in%20a%20new%20direction%2C%20but%20towards%20a%20bolder%20destination.); this is just a bolder destination.

And second, those posts won’t matter. Fair or not, the tech world will close its book on dbt Labs: $400 million raised, [5,700 customers](https://www.getdbt.com/about-us), somewhere north of $100 million in revenue, and $5 billion exit to a sensible partner.

By all reasonable standards, a huge success, for many people. But nothing is particularly reasonable here, [especially now](https://benn.substack.com/p/enough#:~:text=Which%20one%3F%20I,the%20last%20week.). And Silicon Valley’s scoreboard doesn’t care about absolutes; it cares about derivatives: “We don’t value people by where they are. [We value them](https://benn.substack.com/p/ambition-then-and-now?utm_source=publication-search#:~:text=We%20don%E2%80%99t%20value%20people%20by%20where%20they%20are.%20We%20value%20them%20in%20the%20same%20way%20we%20value%20our%20companies%E2%80%94by%20how%20fast%20they%E2%80%99re%20rising.) in the same way we value our companies—by how fast they’re rising.”

Five years ago, the market valued dbt Labs at [only slightly less](https://www.prnewswire.com/news-releases/dbt-labs-raises-222m-in-series-d-funding-at-4-2b-valuation-led-by-altimeter-with-participation-from-databricks-and-snowflake-301489733.html)—or, potentially, [slightly more](https://www.forbes.com/sites/kenrickcai/2022/02/24/dbt-labs-series-d-4-billion-less-than-planned/)—than $5 billion. Snowflake, a close dbt partner, was worth over $100 billion. Venture capitalists said that both companies sat at the center of a [trillion-dollar opportunity](https://benn.substack.com/p/entity-layer?utm_source=publication-search#:~:text=When%20Martin%20Casado%2C%20a%20partner%20at%20Andresseen%20Horowitz%2C%20was%20asked%20why%20he%20thought%20the%20data%20industry%20was%20a%20trillion%20dollar%20market%20and%20what%20bets%20he%E2%80%99d%20make%20%5Bupdated%20link%5D%20about%20where%20it%E2%80%99s%20going%2C%20this%20was%20his%20response.), and [dozens of huge companies](https://benn.substack.com/p/how-snowflake-fails?utm_source=publication-search#:~:text=%22A%20fuckton%2C%22%20he%20said.%20%E2%80%9CGo%20build%20a%20%24100%20million%20business.%20It%E2%80%99s%20all%20possible%20for%20everyone%20in%20this%20room.%E2%80%9D%20The%20audience%20applauded.) were left to be built. There was [something in that orange](https://www.getdbt.com/brand-guidelines)—the sort of promise that [happens once every few lifetimes](https://www.youtube.com/watch?v=iMMUAd66vxo).

Now, the modern data stack is a punchline. The trillion-dollar data market has already been replaced by an AI market that’s [five times as big](https://unctad.org/news/ai-market-projected-hit-48-trillion-2033-emerging-dominant-frontier-technology). Billion-dollar companies [are everywhere](https://www.forbes.com/lists/ai50/), and [the decacorn is the new unicorn](https://x.com/JenniferHli/status/1965657822387200376). Five billion dollars? Ho-hum.

And so, there will be critics. There will be autopsies. There will be [detached cynicism](https://benn.substack.com/p/how-dbt-fails) and views from nowhere. There will be references to [the line about dying a hero](https://www.youtube.com/watch?v=8WfRcnF4iZI&t=94s), or living long enough to [become the villain](https://en.wikipedia.org/wiki/Zach_Bryan#Personal_life)—about dbt Labs drifting away from its core; about the commercialization of a community; about the [perils of venture capital](https://dhh.dk/2013/the-perils-of-mixing-open-source-and-money.html); about consolidation; about the end of an era, or an idea, or an ecosystem.

But there is another, quieter version of the *Batman* quote: *If you live for long enough, nobody is left to give your eulogy*. The people who started the trip with you [get bored](https://benn.substack.com/p/its-time-to-build#:~:text=So%2C%20it%E2%80%99s%20time,the%20dark.) or tired or unhappy, and the only records left are feeble photographs and fading memories, and stories that never sound like they felt. And you begin to wonder, [if nobody else remembers it](https://www.youtube.com/watch?v=hBoDr5g25tk), did it happen? Did it count?

But I was there, for a bit. Many of us were—on the road, in the caravan, some of you were in the car. And though we may now be old and wise—or old and bitter—we were [not always](https://benn.substack.com/p/delirium) that way.

Do you remember it then? Do you remember when [the road felt full of promise](https://www.youtube.com/watch?v=QeYSqZPzwr8)? Do you remember how it was before they built what they built?

When I was in school, technology had no particular appeal to me. I ended up here—in Silicon Valley, in data, at Mode—by chance. But once I found myself in San Francisco, I stayed for much longer than I ever meant to. And when my trip with Mode ended, I told its good people why I had stayed:

> At the end of *Charlotte’s Web*, Charlotte the spider says to Wilbur the pig, “You have been my friend. That in itself is a tremendous thing. I wove my webs for you because I liked you.”
> I probably should say that I worked at Mode to accelerate human reasoning, or to make the world a better place, or whatever. And in some loose sense, I guess that’s true—I wanted to make something that mattered, to get rich and famous, and all of that.
> But in reality, I worked at Mode for a more basic reason. I started it with Derek and Josh because I liked them. And I wove my webs here because I liked all of you. For ten years, through disastrous days and calm ones; through good quarters and bad; through layoffs and acquisitions; through highs and lows and the everyday drudgery of corporate administrivia and company building, all of you have been my friends. And no matter what is next, that in itself has been a tremendous thing.

And so it’s been, with my time in this industry, and with many of the people at dbt Labs. No matter what happens next, you have also been my friends. I do not know if that is enough of a narrative for you, but it is enough of a narrative for me.

Next week, I’ll go from Austin to Las Vegas. dbt Labs is hosting their annual conference, and [we have things to share](https://coalesce.getdbt.com/event/21662b38-2c17-4c10-9dd7-964fd652ab44/agenda?session=84fb8dd8-d727-439e-aa4c-195053d12ed2&shareLink=true).

Though I drove here, I will fly there. I made it as far as I could, but could not make it all the way to Las Vegas. It was further than I was able to drive. Like most people, I need a shortcut to the end.

Off the planes, we’ll no doubt whisper about dbt Labs’ future. Is this where their trip ends? There is so much more highway left ahead of them. From Fishtown to Las Vegas—could they make it to LA? Up to Seattle? All the way back to [New York](https://www.nyse.com/ipo-center/filings)?

Maybe; I don’t know. But who are we to judge life on the road when we came here in the air?

There is a Lowe’s distribution center a hundred miles east of Dallas, just off of I-30. Giant letters are [woven](https://maps.app.goo.gl/HMr522ZHQsA8mJY47) into the fence that sits between the facility and the highway: “Who is counting on you to come home safely today?”

When you’re on the highway, it is easy to chase what is in front of us, and forget what—and who—is waiting behind us. It is easy to get absorbed in our ambitions and ourselves, and to forget that [someone wants us home](https://www.youtube.com/watch?v=KUwjNBjqR-c). Adventure, for a while. But eventually, a quieter home. A mountain house; a view of the late fragments of sunset light. A small boat and a big lake. A room for movies; a fire place; an ice maker; a nice set of speakers; a few kids running around.

It is an easy exit to miss, on the madness of this highway. But as deserved as it is worthy, if you found it. You can pack a lot of glory into a car, but you cannot fit the good stuff.

================================================================================

# In the air

*Now what?*

---

![Airplane Sunset Images – Browse 462,831 Stock Photos, Vectors, and Video |  Adobe Stock](https://substackcdn.com/image/fetch/$s_!oJZg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4182be3c-1015-4d6c-992f-cc58d505addc_586x360.jpeg)

This year, there were no venture capitalists.

Often, at tech conferences, there are. They typically drift around as an odd sort of anti-matter, existing among everyone else, but in a different dimension. They are neither practitioners nor prospects, neither speakers nor sponsors. They don’t teach technical workshops, and they definitely don’t *attend* technical workshops.[^1] For most of us, conferences are a place to sell or be sold to, to learn “best practices,” to mischievously order the Macallan 12 at sponsored happy hours, and to gossip. But VCs are there for other reasons, as rogue agents with agendas all their own—to evaluate and to “[diligence](https://www.ft.com/content/8c239cf6-e8e4-11de-a756-00144feab49a),” to [flatter](https://benn.substack.com/p/fear-and-self-loathing-in-silicon?utm_source=publication-search#:~:text=After%20the%20last%20pitch%2C%20the%20founders%20and%20investors%20all%20milled%20about%20during%20a%20closing%20happy%20hour.%20A%20robot%20mixed%20cocktails.%20The%20founders%20repeated%20their%20pitches.%20The%20investors%20did%20their%20best%20to%20also%20impress%20the%20founders%2C%20but%20you%20can%20only%20be%20so%20impressive%20with%20a%20backpack%20on.) and to politic, and to astroturf a brand as “one of us.”

People complain about this sometimes. If you are a startup, you can’t relax around a VC—is this conversation a pitch? Could they do our next round? Are they thinking about doing our competitor’s next round?—and you definitely can’t sell to a VC. Too many venture capitalists, people whisper, are bad for the vibes.

But they’re also important representatives of a different vibe: Potential. VCs are moths to a flame: They swarm towards the action; the energy; the chaos; the delirium. They are drawn to the transitional epochs, the moments when the world reinvents itself—when it has let go of one trapeze but not found the next, suspended in the air, with nothing certain to hold on to. They are there, in the beginning.

For years, [Coalesce](https://coalesce.getdbt.com/), dbt Labs’ annual conference and the [closest thing to a center](https://benn.substack.com/p/all-in-one-place) that Silicon Valley’s data ecosystem has, has been that sort of flame. Its hosts were the ringleaders of a booming new circus, and its attendees were starting companies, challenging boundaries, and inventing things. They were, in a niche and indirect way, changing the world.[^2] People talked about the future a lot at Coalesce, and every conversation had an unspoken preamble: That we were the ones creating it. Imagine a world of [consistent metrics](https://benn.substack.com/p/metrics-layer); imagine a world where we can do [math on text](https://benn.substack.com/p/avg-text); imagine a world where we all [share a single corporate brain](https://benn.substack.com/p/entity-layer); imagine a world [without bugs](https://benn.substack.com/p/data-contracts). We were a major prong that was [pushing on the edge](https://matt.might.net/articles/phd-school-in-pictures/) of what was possible, and VCs [wanted](https://benn.substack.com/p/entity-layer#:~:text=When%20Martin%20Casado%2C%20a%20partner%20at%20Andresseen%20Horowitz%2C%20was%20asked%20why%20he%20thought%20the%20data%20industry%20was%20a%20trillion%20dollar%20market%20and%20what%20bets%20he%E2%80%99d%20make%20%5Bupdated%20link%5D%20about%20where%20it%E2%80%99s%20going%2C%20this%20was%20his%20response) a [piece](https://benn.substack.com/p/how-snowflake-fails#:~:text=%22A%20fuckton%2C%22%20he%20said.%20%E2%80%9CGo%20build%20a%20%24100%20million%20business.%20It%E2%80%99s%20all%20possible%20for%20everyone%20in%20this%20room.%E2%80%9D%20The%20audience%20applauded) of the heat.

But [the weather in Las Vegas](https://www.wunderground.com/history/daily/us/nv/north-las-vegas/KVGT/date/2025-10-15) was cooler [this year](https://www.getdbt.com/blog/coalesce-2025-rewriting-the-future). The [usual](https://www.wunderground.com/history/daily/us/nv/north-las-vegas/KVGT/date/2024-10-8) scorching [temperatures](https://www.wunderground.com/history/daily/us/nv/north-las-vegas/KVGT/date/2022-6-15) from [data](https://www.getdbt.com/blog/coalesce-2024-highlights) conferences [past](https://www.snowflake.com/en/news/press-releases/snowflake-to-bring-together-the-world-of-data-collaboration-at-snowflake-summit-2022-live-in-las-vegas/) were gone. There were more pronunciations [about ends](https://x.com/mattturck/status/1977787882946388144) than beginnings.

Eulogies feel too blunt—there are still things to do and to talk about, like the unappreciated lessons behind dbt Labs’ success, or what might happen after this week’s merger, or how everything could contort itself again. But these questions have become more insular. They are a community’s local curiosities. They are interesting to us, now, but they are, apparently, no longer interesting to venture capitalists.

[Las Vegas, so nice we did it twice.](https://www.linkedin.com/in/jeremytcohen/)

Or thrice. Or a half dozen times, if you’ve been involved in this industry for the last few years. And when you come to Vegas enough, you begin retracing your steps. You remember standing at this bar; pacing that promenade; sitting on the floor in that corner. You notice when they update the carpet in the vendor hall. You’re pretty sure that’s the same bar where they had the happy hour last year. That’s the table where Wes hit a hard eight. That’s the back hallway in the airport where you negotiated the last terms of the deal; that’s the Starbucks that you went to celebrate [signing the last Docusign](https://benn.substack.com/p/something-in-the-orange#:~:text=The%20final%20signature%20that%20made%20Mode%E2%80%99s%20sale%20to%20ThoughtSpot%20official%20came%20exactly%2037%20minutes%20before%20the%20press%20release%20was%20published.).

People say that living in college towns can feel like living life on repeat. The same is true of conferences here. New people show up; mainstays leave; *deja vu*; ghosts haunt you in the hallways. Is he here this year? I didn’t expect her to be back. Did we meet last year? Did we meet *at this bar?* It all becomes static—constant motion with no movement.

But that is the point, right? After all, why do we work for startups? Why do we start companies? Why are we drawn to [rocket ships](https://thevcfactory.com/if-youre-offered-a-seat-on-a-rocket-ship-dont-ask-what-seat-sheryl-sandberg/)?

The romantic answer is that we do it for the ride. It is to [go fast](https://www.youtube.com/watch?v=_qJGsSuFRIg). To go cruising, to entertain ourselves; [to speed so fast, we feel we were drunk](https://www.youtube.com/watch?v=pLfH9HSUyf4). It’s to live in the center of the universe, where the plasma is still hot, and where there is more potential than permanence.

The other answer is we want to ride the rocket ship to a particular destination—[to find work and get promoted; to buy a bigger house and live in the suburbs](https://www.youtube.com/watch?v=pLfH9HSUyf4). To buy business class tickets, to escape the turbulence, and to reach a smooth cruising altitude. In other words, permanence is the point: Make a thing, sell a thing, and disappear into the mountains. Or, less dramatically, get a job as a Senior Vice President of Enterprise Data Platforms, E-Commerce Cloud.

That’s the catch-22 of Silicon Valley, and of the thrill of potential: You can only keep it so long as you don’t realize it. With a few rare exceptions, you can be comfortably rich or you can be culturally relevant. You can work on critical global plumbing, or you can be inventing new toys. You can matter to the frenetic zeitgeist of Hacker News, or you can grow up.

On the south end of the Las Vegas strip, [very rich men](https://www.google.com/finance/beta/quote/ORCL:NYSE?window=MAX) in [blue shirts and plaid blazers](https://www.oracle.com/ai-world/) were giving keynotes about [how Oracle Applications are](https://www.oracle.com/ai-world/#:~:text=The%20AI%20revolution,speed%20your%20success.) “transforming workflows and business processes to speed your success.” I spotted a couple of their attendees who had wandered north near us, walking through the casino floor with branded backpacks and blaring lanyards. They were out of place, talking in corporate acronyms I didn’t understand, and, by all appearances, having a rather good time.

That is the question now, I suppose. Oracle is among the most successful companies in the world, and the people in its orbit are among the tech industry’s most quietly important operators. If all goes well—historically well—in our world, we can become them. Coalesce is potential, realizing itself. They are potential, fully realized.

Is that what we want? Is that who we want to be? Is that the ambition?

The collective effort of a generous community has granted us a great privilege: We can stay here forever. This industry will exist[^3] longer than we will; our career ladders extend higher than most of us can climb.[^4] We have [more data, more problems](https://www.linkedin.com/in/drewbanin/), and more to do. We can get away with hosting conferences that are more [high-wire demos](https://www.linkedin.com/in/eliasdefaria/) than scripted “fireside chats” from high-paying customers. We can keep building the invisible infrastructure of modern society, and log off when the sun sets and it’s time to go home.

But if we want to live in the spotlight—on the wild edge of possibility, with the frontiersmen—that is no longer here. That is elsewhere, at different companies, in different conference halls, with different people. We are the settlers now; the townspeople; the ones with the family and kids. We can [write the case studies](https://www.linkedin.com/in/tristanhandy) about history, but not the dispatches from the front. Those, we will be told about, after they happen.

When I boarded my flight out of Vegas last night, the man sitting by the window had already taken residence in his seat. He was wearing AirPods, Lululemon joggers, and Nike Flyknits. [His window shade was closed.](https://benn.substack.com/p/open-the-window) Throughout our taxi, our takeoff directly over the Las Vegas strip, our tear across the American West and into a Pennsylvania sunrise, and our slip into the dawn over Manhattan, his window shade remained closed.

I spent the entire flight mad, bitter about the adventure on the other side of the shade that I was missing. He spent the entire flight sleeping peacefully.

There is one other thing: When I first found dbt, I was a pessimist. We had built our own transformation tool called [easybake](https://benn-dot-files.s3.us-west-2.amazonaws.com/webapp.dimension_query_runs.yml), and liked my version better than theirs. I thought their ref functions were overly complicated; [I didn’t have the emotional octave](https://benn.substack.com/p/delirium?utm_source=publication-search#:~:text=That%20vibe%2C%20if,full%20emotional%20range.) for their community Slack.

As I was slowly proved wrong, we all found our roles over the years—the quiet builders, the cheerleaders, the genuine enthusiasts, the opportunistic bandwagoners. The organizers and the leaders. The optimists; the critics, the skeptics, the haters.

Once you see these personas and see who occupies each character, you could not help but notice something else this week: In the end, it was the optimists who were on stage. It is not those who wondered about [how it might fail](https://benn.substack.com/p/how-dbt-fails), but those who believed [the crazy stunts might just work](https://www.linkedin.com/in/gracegoheen/). They are the ones who survive, because when everyone [stands up to do the wave](https://www.linkedin.com/in/bolaji/), you can only scowl at it for so long. 

[No matter](https://benn.substack.com/p/the-past-is-not-precious). It is never too late. All life is is whatever’s ahead, and [we are supposed to sing or to dance](https://www.goodreads.com/quotes/8587787-we-thought-of-life-by-analogy-with-a-journey-a) while the [music is being played](https://www.youtube.com/watch?v=AQS3JGqx46U), be it in this neighborhood that once was, or in the next neighborhood that is just becoming.

![](https://substackcdn.com/image/fetch/$s_!3c1I!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F418bf07d-7dec-46a0-989c-6d21e97f1e83_2048x1152.png)


---


[^1]: Yes, I understand that *you *attend the technical workshops. *You* still read ArXiv; you aren’t like the other VCs; you are an operator—no, a builder—at heart. I’m talking about everyone else.

[^2]: Did git change the world?Ten percent of you are probably insulted by the question. *Of course* git changed the world. You have always thought this; you have evangelized this; you are mad that nobody else appreciates this. git made collaborative software development possible. It made large-scale open source projects possible, and the world is run on large scale open-source projects. It is the printing press of the computing age. To imagine a world without git is to imagine a world where every building is built by one person.Another forty percent of you are probably thinking, “huh, ok, maybe git *did* change the world.” You’ve always thought of git as a useful nuisance, a series of incantations that, when recited correctly, do the same thing as uploading a file to Dropbox, and when recited incorrectly, require you to throw away your work, throw away your computer, throw away your career, move to Montana, become a ranch hand, eat only the potatoes you grow and the cattle you raise, and to only think about upstream conflicts when you stare, through squinted eyes across a sun-scorched creek bed, at two fighting coyotes.And fifty percent of you are probably asking, what is git? (For those of you who are asking this, it is a very rigorous and pedantic way to track changes in text files. But rather than just telling you when things change, it instead creates branching tributaries of divergent timelines, which [inevitably intersect in paradoxical ways](https://en.wikipedia.org/wiki/Temporal_paradox), and [eventually implode](https://www.youtube.com/watch?v=L3pk_TBkihU).)In any case, there is certainly a case to be made for the first argument. If nothing else, git completely changed the economic structure of software development. It makes updating software less brittle and more reliable, and it makes it easier for engineers to work together. Engineers are more productive, and the software we all use is better, because of git. Many hands make light work, and git made it possible to build software with many hands.It is conceivable that you could make a similar argument about dbt, which has changed how data teams work together. If data is important—which, [you know](https://benn.substack.com/p/disband-the-analytics-team)—then perhaps all of this did change the world.

[^3]: I  mean, there is a half-written draft in my notes somewhere called “How data fails.” But I have a pretty bad track record [on this stuff](https://benn.substack.com/p/how-fivetran-fails).

[^4]: I guess the robots could replace us, but, [not yet](https://docs.google.com/presentation/d/1ZDBCg2NgnGHDj7pu0NjUrPFnmnbNlj9zhruqgXHj_FA/edit?slide=id.g38ca6e15d53_0_256#slide=id.g38ca6e15d53_0_256).

================================================================================

# An very obvious deal

*Shopping for the Data Stack Value Realization methodology.*

---

![](https://substackcdn.com/image/fetch/$s_!ApMH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2268c2a7-b67d-4c03-92ac-78a653d54738_2048x1094.png)
*[Isn’t it obvious?](https://www.youtube.com/watch?v=hmLnKnNh2ns)*

I sometimes wonder if it’s all Slack’s fault.

In 2012, before Slack existed, I worked for a [would-be Slack competitor](https://www.youtube.com/watch?v=wXKSp4_yKWM). We sold software in the way that was [trendy](https://en.wikipedia.org/wiki/Software_as_a_service) at the time: People bought licenses to use it. [Pay us $15](https://www.businessinsider.com/microsoft-slashes-prices-on-yammer-2012-11#:~:text=It%20used%20to%20cost%20five%20times%20that%E2%80%94%2415%20per%20user%20a%20month.), and one person can use it for a month. Pay us $30, and two people can. Pay us $15,000, and a thousand people can.[^1] And just as a landlord doesn’t care how much time someone spends in their apartment every month, we didn’t care what people did with our software, or if they even logged into it all.[^2] In both cases, customers buy timed access. What they did with that access was irrelevant.

When Slack launched, they charged their customers in the same way. According to their [first pricing page](https://web.archive.org/web/20140713151221/https://slack.com/pricing), “adding or removing team members during the term of a subscription will cause a one-time pro-rated credit or charge on your account.” But then, Slack blew up. The product—and [this chart](https://share.google/images/UGPzVP5U3wZLNv4wF)—was suddenly everywhere. And Slack, with their “be kind” brand and CrayolaCore aesthetic, decided that [this old pricing model was capital-w Wrong](https://web.archive.org/web/20150824215548/https://slack.com/pricing):

> Most enterprise software pricing is designed to charge you per user regardless of how many people on your team are actively using the software. If you buy 1,000 seats but only use 100, you still get charged for 1,000. We don’t think that’s fair. And it’s also hard to predict how many seats you’ll need in advance.
> At Slack, you only get billed for what you use. So you don’t pay for the users that aren’t using Slack. And if someone you’ve already paid for becomes inactive, we’ll even add a pro-rated credit to your account for the unused time. Fair’s fair.

It was a savvy maneuver, for Slack. People were quickly becoming addicted to their product, and it’s unlikely that many of their customers were buying 1,000 licenses and only using 100. Instead, they probably had the opposite problem: More people wanted to use Slack than companies’ IT departments were willing to initially pay for. By charging for only the licenses that people used, Slack could tell those IT departments that they didn’t need to worry about overspending on Slack, because they *couldn’t* overspend on Slack. If nobody liked it, then they would stop logging into it and nobody would get charged for anything. And if lots of people liked it and used it all the time, wasn’t that worth a few dollars a month?

It was an ethos that ate the internet. Silicon Valley is an industry of trends, and Slack was our generation’s trendsetter. Shortly after they launched their “[Fair Billing Policy](https://slack.com/help/articles/218915077-Slacks-Fair-Billing-Policy),” other startups launched their own imitations. At Mode, our customers, many of whom had recently bought Slack, started to ask for the same thing. “Why should I get billed for something if I didn’t want to use it that month?” people said, for the first time. “That’s not how this should work,” they said of how it always worked.

Software pricing is like that though. When you’re selling virtual ephemera on the internet, there is no obvious way to buy it, and there are no physical or economic laws for how it should work. Instead, it’s almost entirely driven by norms and market expectations:

These trends were especially apparent in data products. People [used to buy databases](https://www.teradata.com/blogs/teradata-jumps-ahead-flexible-licensing-choices-change-everything#:~:text=Teradata%20has%20moved%20from%20the%20high%20up%2Dfront%20cost%20of%20perpetual%20licenses%20to%20the%20lower%20up%2Dfront%20and%20more%20predictable%20subscription%2Dbased%20licenses) via perpetual licenses that they paid for once and could use forever. Then, Amazon launched Redshift, which was offered as [a monthly lease](https://aws.amazon.com/about-aws/whats-new/2012/11/28/announcing-amazon-redshift/) of a dedicated database. Snowflake shortened the term of the lease—instead of renting a database for a month at time, [you leased it by the minute](https://docs.snowflake.com/en/user-guide/warehouses-considerations#:~:text=However%2C%20the%20value,is%2C%2060%20seconds).).[^3] BigQuery then [began charging by query](https://cloud.google.com/bigquery/pricing?hl=en#analysis_pricing_models), billing customers for every byte they asked BigQuery to process.

At first glance, these steps seem like a refinement of the former model. Each progression adds [smaller intervals](https://en.wikipedia.org/wiki/Riemann_sum) under the demand curve. Pay for exactly what you use—it is pure; efficient; the markets, [clearing](https://en.wikipedia.org/wiki/Market_clearing).

Which, maybe; I don’t know; [sir, this is a Substack](https://www.youtube.com/watch?v=ONn7lNA89wU), not an NBER paper. But if you spend some time selling all this virtual ephemera on the internet, you’ll probably discover at least one thing: Regardless of the economic theory of each pricing model, there is a *psychological* discontinuity between model three and model four. In the first three models, it is hard to reason about *how much* some software service should cost. What is the right price for a license to use Slack? What is a Google Docs subscription worth? How do I put a price on Spotify? These are esoteric, almost philosophical questions. What is the value of corporate communication? Of an infinite library of documents? Of listening to Gracie Abrams[^4] on a loop for a month?[^5]

We don’t know, so we price software via dead reckoning: What’s fair today is what was fair yesterday. Outlook cost [$12.50 a month](https://www.zdnet.com/article/microsoft-office-365-more-new-packages-and-prices-coming-in-november/#:~:text=Office%20365%20Small%20Business%20Premium%20will%20cost%20%2412.50%20per%20month%2C%20or%20%24150%20per%20user%2C%20per%20year.), so Yammer cost $15 a month, so Slack cost [$12.50 a month](https://web.archive.org/web/20140713151221/https://slack.com/pricing).[^6]

But in the fourth model, this breaks down. When you’re selling a single unit of consumption, *people seem much less willing to accept an arbitrary price.* And they start asking one question in particular: “How much does this thing I’m buying cost *you*?”

Consider: A customer could say to Slack, “It costs you a few cents to add another person to your user database and to store the thousand messages that they send every month. Why are you charging me $12.50 for that?” Historically, people don’t ask that though—or at least, don’t complain about it too much—because that’s not how the world works. Arbitrary monthly licensing fees might not be an economically precise pricing model, but, when everyone is used to paying them, it’s a psychologically durable one. But if Slack started charging per message sent, people would start talking about the egregious markup. “It costs Slack a fraction of a penny to send a message, and they’re charging a full penny for it!” There would be righteous online riots about price gouging.

There is nuance here though. If Slack charged incremental fees for storing files, there would be probably be protests, but tamer ones. Because, again, we’re used to that. Storage is a thing we long thought of a scarce resource; we’ve still [pay more for computers](https://www.apple.com/mac/compare/) with more memory; conceptually, storage feels like a fair expense.

We saw all of these dynamics at Mode. When we charged a monthly licensing fee, our first price was $250 for technical users. People were upset by that—not because of the titanic markup we charged on top of a website that cost pennies to provide to an additional user, but because $250 a month for SaaS software was abnormally high. We eventually changed our prices to about $25 for all users. Then, when we added a fee of a few cents to run an additional query—running a query was our equivalent of sending a message on Slack, and also cost us a fraction of a penny—people were outraged by our brazen margins. But later, when we added computational middleware—“an in-memory compute engine”—that made running queries a plausibly expensive operation for us to perform, people still objected, but most customers were ultimately ok with it.

And that’s the lesson, I’d argue. If you can sell subscriptions to your software, you won’t get asked about margins, but you only have so much flexibility about what you can charge. And if you sell consumption, you better charge for something that [sounds expensive](https://www.youtube.com/watch?v=1mY5FNRh0h4&t=32s). Storing stuff works. Doing a bunch of hard math works. Generating an AI image works. But rendering a website, or calling an API, or managing a database of files and messages—well, “we don’t think that’s fair.”

This is why dbt Labs has always been a fascinating company to me ([and why it will be good for that HBS case](https://benn.substack.com/p/how-dbt-fails#:~:text=In%20the%20data%20industry%2C%20no%20company%20is%20more%20likely%20to%20end%20up%20in%20an%20HBS%20classroom%20than%20dbt%20Labs.)). Because, stylistically, here is the position that it’s always been in:

It’s a very unique set of rocks and hard places: A popular product, without no obvious way to sell it. And for years, [I assumed the way out](https://benn.substack.com/p/how-dbt-succeeds) was for dbt Labs to attach itself—via acquisition or a series of white-labeled OEM deals—to the databases that had more direct ways to make money from people using dbt:

> Databricks solves the riddle of dbt Labs’ business model. Databricks can offer dbt as a free, unmetered service. It wouldn’t care if you use the open-source version or dbt Cloud, nor would it worry about how many seat licenses you buy. This frees up dbt Labs to focus on what it does best—driving adoption of dbt’s core services.

It’s an obvious solution: if you can’t monetize your own service, find someone who can, and get a shared bank account.

Of course, when it happened, people also said that combining [dbt with Fivetran](https://www.getdbt.com/blog/dbt-labs-and-fivetran-merge-announcement) was obvious. It was peanut butter and jelly. It was [one-third](https://www.getdbt.com/) and [two-thirds](https://www.fivetran.com/) of a [three-letter acronym](https://en.wikipedia.org/wiki/Extract,_transform,_load). It just made sense.

Spiritually, absolutely; both companies are from the same generation; of the same religion; they went to the same high school. Logistically, as a merger to make a one-stop shop for data services—the Atlassian for Open Data Infrastructure, the Adobe for data people, the [Bean Counter Cloud](https://www.adobe.com/creativecloud.html)—I can see that too. Financially, as a way to combine two IPO-ish scale balance sheets into one; makes sense. Defensively, as a means for creating a business big enough to stand its ground against empire-building companies like Databricks and Snowflake; sure, why not?

But, as a solution to the pricing problem—the core dbt problem—that story seems harder to tell. Fivetran can’t make money off of the queries that dbt generates, nor can dbt transform their popularity into more volume for Fivetran. The two businesses are loosely synergistic: They indirectly help one another by, because Fivetran brings more raw data to dbt and dbt makes Fivetran’s raw data more useful, but that was true when they were independent.

Which doesn’t mean the deal *doesn’t* make sense—those other benefits are there, and it gives both companies one less potential competitor in a [compacting industry](https://benn.substack.com/p/category-collapse). Still, it’s not quite 1+1=3, and M&A bankers [love 1+1=3](https://www.bloomberg.com/news/newsletters/2024-05-17/exxon-mobil-s-formula-for-m-a-success-1-1-3).

There are a couple obvious options though. One is for the combined company to use its weight and position as the data department store [to become the bully in the industry](https://ethanding.substack.com/p/fivetran-and-dbt-gear-up-for-war):

> fivetran and dbt, the two largest players outside the data warehouses, are merging to flip the script: move value capture back into business logic. what is business logic? it’s the finite set of if/else statements that define your business. sql pipelines are endless conditionals that say “if customer did x, then calculate y, and route to z.” those transformations, rules, definitions of what revenue means and who counts as an active user and how to segment customers - that’s your actual business encoded in code. …
> [Snowflake and Databricks convinced everyone] that compute should capture all value, that business logic should be free. … by merging, [Fivetran and dbt Labs are] trying to have more firepower to make compute cheap and commoditized, and move value capture back where it belongs: business logic.

I guess it could work? But, this doesn’t solve the psychological issue: What, exactly, does dbt charge *for*? You can’t bill for lines of business logic written. I suppose you could charge for a giant platform license—but that is the way we sold software decades ago. The trend is towards charging for consumption, and databases *feel* like they have more right to charge for that than SaaS applications that use databases.[^7]

A second option is for dbt and Fivetran to [fill in the hole in diagram](https://www.getdbt.com/blog/dbt-labs-and-fivetran-merge-announcement#:~:text=Here%E2%80%99s%20what%20it%20looks%20like%20when%20both%20products%20come%20together%3A), and become a database. Which, also, could work too? But that’s a big risk. Snowflake and Databricks aren’t huge companies because they figured out that there is money in building a giant enterprise database; everyone has know that for decades. They’re huge because they actually pulled off the very difficult thing of building a giant enterprise database. There is a big difference between a clever idea and a *hard* idea, and building a database is very much a hard idea.

Still, perhaps there is a third option—stolen, in true Silicon Valley fashion, from our latest trendsetter.

Here is one way to think about how Cursor works:

The analogy is obvious. Cursor is to Anthropic as dbt is to a database. dbt is the interface; the database “does the work.” dbt has people’s attention; the database gets the money.[^8] And—most notably—[most of the queries that people run are small](https://motherduck.com/blog/big-data-is-dead/), and don’t require giant databases to execute.

So, you know. Put a database underneath dbt Fusion. But a small one; one that’s not about *competing* with Databricks and Snowflake, but about saving customers’ money by choosing more efficient ways to run queries. It’s about doing what’s more efficient. It’s about Fair Pricing.

If only there was a company that was about [Small Data](https://www.smalldatasf.com/).[^9]


---


[^1]: Well, no, that’s not quite right. Most SaaS software vendors offer discounts if you buy in bulk, so if you paid us $15,000 a month, you’d probably get something like 1,500 licenses. And if you paid us enough—say, $100,000 a month—we’d probably give you an unlimited number of licenses.

[^2]: That’s not quite right either. We also cared a lot about how much people used a product, but it wasn’t because we charged for usage; it was because unused licenses were unlikely to get renewed. If we sold 1,000 licenses and only 100 people used it, most customers (though not all! You’d be surprised!) would notice that, and wouldn’t buy 1,000 licenses again next month or year. And the [entire economic apparatus](https://benn.substack.com/p/do-software-companies-actually-have?utm_source=publication-search#:~:text=The%20conventional%20view,significant%20operating%20leverage.) of a SaaS business depends on customers buying *more* services every year, not less.

[^3]: Strictly speaking, Snowflake doesn’t charge for consumption. They charge for the amount of time you keep the database active; what you do while it’s active doesn’t matter. It’s similar to Slack in this regard—they refined the terms of the subscription, but didn’t charge for actual activity.

[^4]: [Has everyone always known this????](https://en.wikipedia.org/wiki/Gracie_Abrams#:~:text=The%20daughter%20of%20the%20director%20J.%20J.%20Abrams)

[^5]: [Duuuu](https://www.youtube.com/watch?v=BX3bN5YeiQs)…[dun](https://www.spotify.com/us/wrapped/).

[^6]: How philosophical is SaaS pricing? [Slack’s guide to understanding the value of Slack](https://slack.com/resources/slack-for-admins/unlocking-value-with-slack) includes the following phrases:“What is value…?”“...a value-centric partnership…”“...we have a dedicated Value Realization team…”“...the Slack Value Realization methodology…”“Build a value map”“...value stories…”“...value strategy…”“Start your journey toward becoming a value expert”And, in a telling coincidence, after all of that, uh, rigorous study, Slack found that the correct price of their revolutionary new communication platform was…exactly the same as as what their older competitors charged.

[^7]: Making compute a faceless commodity doesn’t really solve this either. All that does is drive the margins out of the database; it’s not clear that it pushes those margins back into the software that’s on top. “We own more of the pie by shrinking everyone else’s slices of pie” is great for customers, but not so great for anyone with pie.

[^8]: Cursor charged their customers and then paid Anthropic to execute their requests, whereas dbt connects to customers’ databases, who then bill customers directly for dbt’s usage of the database. The result is the same though; the money ends up with Anthropic and the database, not with Cursor or dbt Labs.

[^9]: An [idea](https://a16z.com/announcement/investing-in-motherduck/) and an [analogy](https://a16z.com/announcement/investing-in-cursor/) that [is](https://a16z.com/announcement/fivetran/), also, [obvious](https://a16z.com/announcement/investing-in-fishtown-analytics-the-makers-of-dbt/).

================================================================================

# A strange delight

*We are more machine now than man, and it's better if we remember that.*

---

![Minority Report' Review: 2002 Movie](https://substackcdn.com/image/fetch/$s_!tLIR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91854e86-ad60-4dc6-a6e0-e3b20aae47b0_1296x730.jpeg)

Have you ever seen *Minority Report*? Do you remember [this scene](https://www.youtube.com/watch?v=33Raqx9sFbo), where Tom Cruise uses a pair of gloves to flip through a bunch of videos on a giant screen? When you first saw it, did you think that it looked cool? Did you want to use a computer like that? Did you ever think, I don’t care what I’m trying to do—he’s solving murders before the victims are dead; I’m mostly responding to emails long after they matter—but I bet it’d be pretty fun to do it with controllers attached to my hands?

Have you ever driven a sports car? Have you ever borrowed [your uncle’s BMW](https://www.youtube.com/watch?v=s2jbR0uF7zY), taken a turn faster than you would in your Toyota, and been startled by how precisely it angles through the bend? By how firm it feels on the road? By how easily it finds its pace? Have you ever thought, I don’t have anything practical to do with this car, but if it were mine, I’d look for an excuse to drive it?

Have you ever shot a gun? Even if they aren’t your thing—and [they aren’t mine](https://www.tiktok.com/@tonystatovci/video/7253231136703483182?lang=en)—did their appeal start to make sense? Was there something stupefying in its weight and heavy trigger, and then, all at once, its sound, its recoil, and its explosive hammer? Did you find something electric in it? Not in any practical problem that it might solve or in its alleged everyday utility, but in its awful, intoxicating power?

Most software is not like that. We might say it’s magical; we might describe it as delightful; but, come on. We usually say that because we have something to sell—the product itself, or our taste in it. The only emotion that software typically evokes is slow-simmering frustration; the best software often—aspirationally!—evokes nothing at all. One of Fivetran’s core product principles is to [set it and forget it](https://fivetran.com/docs/core-concepts/product-principles). Google Chrome was built to [get out of your way](https://googleblog.blogspot.com/2008/09/fresh-take-on-browser.html#:~:text=It%20gets%20out%20of%20your%20way%20and%20gets%20you%20where%20you%20want%20to%20go.). Those are often our highest ideals: To be efficient, to “just work,” to “help us get back to the things we really care about.”

But, occasionally, we stumble across something different.

It was not a car, or a gun, or a personal IMAX mind-melded to the FBI’s Eye of Sauron, but I still remember the first time that I wrote a script that scraped stuff from the internet.[^1] I wanted some numbers from YouTube, they were available in a chart under each video, and I didn’t want to write them all down by hand. So, I wrote a short program to collect them for me. Eventually, my cryptic incantation somehow worked, and the terminal ticked through a series of confirmations:[^2] “*Getting videos…* *Found 57 videos*. *Retrieving video 1…* *Done. Retrieving video 2… Done. …*”

It was, of course, an unremarkable piece of technology. A [popular website](https://www.amazon.com/) could retrieve an obscure object from a distant warehouse and physically deliver it to your door in under 24 hours; all I was asking a computer to do was copy a few dozen numbers from the internet and paste them into a file. Still, that is what made it striking. Amazon’s operations are impossible to comprehend; my script was practically mechanical. You could see its individual pieces; you could see its incessant digital hands and its relentless energy; you could see the impossible infallibility of its math.

And, there was the rote work that I did, and then, the work that *it* did. Yes, that work was dumb, but when we use a computer to do something important, it’s too easy to get distracted by the destination. How fast can I create this document? How efficiently can I file these expenses? How well does it do this Job To Be Done? Can the car haul enough groceries? Does the automated drone have tactical practicality? When there is a [worldwide network of abstract magic](https://x.com/localbateman/status/1969280614055755938) behind a computer, we [forget to be amazed by it](https://www.youtube.com/watch?v=me4BZBsHwZs).

But, up close, there is something mesmerizing about watching [a machine do its simple work](https://ciechanow.ski/mechanical-watch/).

Here’s a question, [while](https://benn.substack.com/p/an-very-obvious-deal) [we’re](https://benn.substack.com/p/in-the-air) [here](https://benn.substack.com/p/something-in-the-orange): What if dbt had launched itself with a UI?

For years, dbt’s only interface was the command line. You told it what to do, and, like my old Python scripts, it would slowly print out its progress. That was it—there was no webpage for running dbt; there wasn’t even a way to interact with it using buttons or a mouse. And when it was put on the internet, dbt’s first UI was, for the most part, still [a command line and some logs](https://www.getdbt.com/blog/introducing-dbt-cloud).

But suppose there had been more. Suppose the first version of dbt had included everything that was there, *plus *an interface for dragging and dropping models together [on a visual canvas](https://www.getdbt.com/blog/dbt-canvas-is-ga). And suppose that nothing else had been different: dbt Core was developed at the same pace, with the same functionality. Would it have been more successful? *Less* successful?

One answer is that it would’ve been better, because [more is always better](https://en.wikipedia.org/wiki/Preference_(economics)#:~:text=Non%2Dsatiation%20refers,diminishing%20marginal%20utility.). Another answer is that it would’ve been worse, because dbt’s limited interface taught data analysts technical skills. For many analysts, dbt was a gateway: Learn dbt; learn how to stumble around the command line; learn foundational engineering tools like git; learn how to write a bit of code, how to write your own scripts, and, eventually, how to do a lot more with a computer than you otherwise could. A UI would’ve shortcut that, and given training wheels to a profession that needed to learn how to ride a bike.

But a third answer is that it would’ve been worse because *the command line tool was a big part of dbt’s appeal*. It was a gateway, though not for practical skills; it was a gateway to the same oddly evocative experience[^3] that I stumbled into when I was trying to scrape YouTube. It was thousands of people’s first glimpse into the guts of their computer, and its arithmetic power. After a lifetime of pointing and clicking, it was the first time we fully commanded a computer with a keyboard and all ten of our fingers. After waiting for websites to load behind a bunch of spinners, we saw how quickly a computer could respond when you removed ads, pictures, and a quarter-million lines of javascript.[^4] It was our first version of Tom Cruise’s gloves, and our first computational sports car. And it was our first time directly holding a gun, [with the safety off](https://www.reddit.com/r/dataengineering/comments/1cjn8am/i_deleted_data_for_the_prod_table_instead_of).

It was not perfect, of course. Analog tools can be frustrating, and we all had our protective checklists.[^5] But there was something mesmerizing in it too.

[For reasons](https://coalesce.getdbt.com/event/21662b38-2c17-4c10-9dd7-964fd652ab44/agenda?session=84fb8dd8-d727-439e-aa4c-195053d12ed2&shareLink=true), I’ve spent a lot of time in two products over the last couple months: [Snowsight](https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour), Snowflake’s built-in query and visualization tool; and terminal-based coding apps like [Claude Code](https://www.anthropic.com/engineering/claude-code-best-practices) and [Codex](https://developers.openai.com/codex/cli).

If you use these tools, you will notice two things. First, the terminal apps are extraordinarily basic. Their interfaces are text, displayed in bulleted lists and a monospaced font. The text is usually white; occasionally, it’s off-white. Sometimes, the text is in a box. You navigate the app with arrow keys. You cannot use a mouse. Anthropic’s and OpenAI’s frontier models—the most advanced programs that humans have ever created—sit behind these apps, but the apps themselves could be rendered by a [dot matrix printer](https://www.youtube.com/shorts/V-WAnJAezXI).

The [Snowsight UI](https://www.youtube.com/watch?v=jGLsIVunNVQ) could not be more different. There are tabs and dynamic panels; there are buttons and hover states and user preferences. There are loading states; empty states; overflow states. There is a left-side navigation menu that animates as it slides open, and animates again as the menu’s contents unfurl. And there is AI too: When you click into the query editor, a blue [sparkle](https://www.nngroup.com/articles/ai-sparkles-icon-problem/) pulses twice; click on that button, and a chat dialogue appears—a chat dialogue that, roughly speaking, contains almost the entirety of Claude Code’s UI.

But the second thing you will notice—or at least, the second thing that I noticed—is, when bouncing between Claude Code and Snowflake, you prefer Claude Code. That could be a basic point about clutter and product bloat, though that seems like a lazy criticism: Snowflake’s editor, by most reasonable measures, a well-composed piece of software. It is also the child of two startups that were hallmarks of [technical taste](https://streamlit.io/) and [modern software design](https://x.com/numeracyco).

Still, it is Claude Code—the [Brother WP-80](https://www.youtube.com/watch?v=eRLy4VqKGiM)—that feels modern. Most reviews of Claude Code say that’s because of what it *does,* and that it’s good despite its raw interface. “Ironically, its simplicity contributes significantly to its charm,” [said one post](https://rafaelquintanilha.com/is-claude-code-worth-the-hype-or-just-expensive-vibe-coding/); “A terminal interface for chat-based code editing? Sounds like a step backward. But Anthropic did a decent job with it,” [said another](https://www.builder.io/blog/claude-code). Maybe that’s true; maybe for proper engineers, terminal interfaces are outdated anachronisms, an unnecessarily uncomfortable Jeep Wrangler in a world with Waymos and Teslas.

I’m not so sure though. Because, for all the comforts that come with [driving a sofa down the highway](https://cars.usnews.com/cars-trucks/lexus/ls/photos-interior?img_name=2023-lexus-ls-7-custom), luxury is rarely an emotional experience. We are not moved by detachment. Tools like Claude Code puts you as close to the technology as it can. Though it only exists on a screen, it is an unexpectedly physical product. Its aesthetic suggests that you’re plugged directly into the mainframe; its snappiness implies that there’s no intermediation. It’s just you and the machine, and the uncanny sense of dexterity that comes with learning how to use it.

Touch grass, they say. Good advice, I suppose, in an [increasingly artificial world](https://openai.com/sora/). But as computers and the internet become ever more unavoidable, I hope that those of us who build them don’t anesthetize them too much. The internet does not need more whiz-bang whirligigs or beautifully efficient minimalism. We can also go the other way, and build stuff that reminds us that computers are physical things too. Because real delight—and productivity, if we must—comes from feeling the machine that we live our lives on, rather than forgetting to see that it exists.


---


[^1]: By “stuff,” I of course mean “[the number of likes](https://mode.com/blog/data-driven-look-at-vmas) Miley Cyrus’ and Lana Del Ray’s music videos got on YouTube.”

[^2]: Evidently, the terminal did not actually do this, because [my barbaric PHP scraper](https://github.com/mode/blog/blob/master/2013-08-28%20VMAs/YoutubeScrapper.php) didn’t print anything at all. But my later scripts—like, uh, the [price_of_weed_scraper.py](https://github.com/mode/blog/blob/master/2013-10-03%20MMap/price_of_weed_scraper.py)—were much more professional.

[^3]: Or, a [Strange Delight](https://www.strangedelight.nyc/).

[^4]: Rendering the homepage of the *New York Times *requires 11,000 kilobytes of javascript, which is about 11 million characters, or, [at 40 characters per line](https://benn.substack.com/p/the-industrialization-of-it?utm_source=publication-search#footnote-2-160968590), 275,000 lines.

[^5]: Like our git cheatsheets, which usually started by suggesting reasonable things—remember to pull! Write descriptive commit messages!—and ended with `git reset --hard HEAD`, a link to [this page](https://docs.github.com/en/account-and-profile/how-tos/account-management/deleting-your-personal-account), and an instruction on how to [launch your computer into the sun](https://benn.substack.com/p/in-the-air#footnote-2-176451954).

================================================================================

# All you can do is play the game

*I don’t know what’s coming next.*

---

![](https://substackcdn.com/image/fetch/$s_!bMcE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe66e55c5-1844-4ad0-8f18-86a4893f1b53_1024x460.png)

When someone says “I don’t know,” what does it mean? [There are levels to it](https://www.youtube.com/watch?v=tvTRZJ-4EyI&t=62s):

Anyway, this is a blog that’s ostensibly about tech, and to be a blog in Good Standing in Silicon Valley—or a podcast, or a Twitter talking head, or a useful guest on a conference panel—we’re supposed to talk about the future. That’s the preferred direction of our discourse: Forward. Looking ahead. What’s newly dead? What’s coming; what’s next? What will be [the new new thing](https://www.amazon.com/New-Thing-Silicon-Valley-Story/dp/0393347818)? What [big change is happening in the world](https://www.linkedin.com/pulse/greatest-sales-deck-ive-ever-seen-andy-raskin/)?

This is also a blog that’s ostensibly about data, so here are some things that could happen in the data industry:

Though these stories aren’t exactly mutually exclusive, they aren’t quite compatible either. It doesn’t make sense to build specialized chatbots if we feed everything into Claude; it doesn’t make sense to give analysts a blinged-out IDE if nobody hires analysts to answer questions anymore.

So which one wins? I don’t know, and man, it’s a full Gregory Olinovich.

Because if there is a single story that explains how AI changes the world, it is that it happens by accident. ChatGPT—the [most valuable](https://www.reuters.com/business/openai-lays-groundwork-juggernaut-ipo-up-1-trillion-valuation-2025-10-29/) AI product in the world, and the one that is [turning the entire internet into a chatbot](https://openai.com/index/introducing-chatgpt-atlas/)—was a last minute project hacked together by a [group of volunteers](https://www.youtube.com/watch?v=ixY2PvQJ0To&t=964s) at a research lab. Nobody thought too hard about use cases or ideal customers; nobody asked how big Gartner predicted the market for chatbots would be; there was no two-by-two matrix of competitors. To the extent that there was a grand plan for ChatGPT, it was to launch it, and then [shut it down](https://www.youtube.com/watch?v=ixY2PvQJ0To&t=1004s).

Almost certainly, whatever changes happen in the data world over the next five years will also happen because of similar accidents. People have already tried to build that entire list of products in the previous section, with varying degrees of success. But will the [next model release](https://www.testingcatalog.com/gemini-3-spotted-again-as-google-readies-its-release/) suddenly make one of them work? Will the next startup that tries to make an analytical chatbot [make an interface for it that people unexpectedly love](https://benn.substack.com/p/a-strange-delight)? Will someone hack together an automated business analyst with just the right incantations in their prompts, and it starts to work? As soon as one of these dominos fall, an army of new startups with rush towards that timeline, like [moths towards a flame](https://www.youtube.com/watch?v=jJN9mBRX3uo&t=228s).

If the swarms of agents work, suddenly dozens of companies will try to build ways to make it cheaper to run thousands of queries all at once. If semantic ontologies and context engineering make chatbots useful, the context layer will become [the next powder keg](https://benn.substack.com/p/powder-keg?utm_source=publication-search#:~:text=The%20biggest%20looming%20battle%2C%20however%2C%20will%20be%20over%20a%20different%20territory%3A%20The%20brain%E2%80%94or%20operating%20system%E2%80%94of%20the%20data%20stack.%C2%A0) in IT software. If someone finds answers in messy buckets of text and video files, a hundred data pipeline companies will chase that heat. Or, more generally, the entire analytical world—and probably, every other software vertical—depends on which random breakthrough happens first.

So what do you do, when the winners are chosen by lottery?

There is a lesson I learn every Thursday night, and forget by Saturday morning: To figure out what a blog post is about, you have to write it first. You might think that it goes the other way—an idea starts in your head, it becomes an outline on a piece of paper, and then a blog post on the internet—but that’s never how it works. Epiphanies come from typing, not thinking.

Analogously, in a way—Cursor was founded by [recent college graduates](https://www.wearefounders.uk/cursor-founders-the-mit-team-behind-the-400-million-ai-code-editor-revolution/). They were not hardened engineers who’d [Seen Things](https://www.youtube.com/watch?v=NoAzpa1x7jU&t=108s); they were not part of some corporate [mafia](https://en.wikipedia.org/wiki/PayPal_Mafia). They probably didn’t have a detailed corporate business plan about wedges, growth strategies, marketing channels, or their [second step](https://benn.substack.com/p/trading-places#:~:text=For%20other%20startups,in%20the%20sand.). Instead, they were a few engineers who primarily differentiated themselves among the millions of other engineers who had the same idea—“what if someone put a chatbot inside of VSCode?”—by being the ones who built it. Though Cursor no doubt did some clever things, the most important thing was that they did it at all.

[Generational riches](https://www.wsj.com/tech/ai/the-ai-coding-startup-favored-by-tech-ceos-is-now-worth-29-3-billion-14c72c02), it turns out, also starts with typing, not thinking.

There’s a scene in *Margin Call* where Jeremy Irons, who’s playing the hardened CEO of titanic bank on the cusp of collapsing in the acute hours of 2008 financial crisis, [contemplates his mortality](https://www.youtube.com/watch?v=fij_ixfjiZE&t=297s):

> Do you know why I’m in this chair? I’m here for one reason, and one reason alone: I’m here to guess what the music might do one week, one month, one year from now. That’s it. Nothing more. And standing here tonight, I’m afraid that I don’t. hear. a. thing. Just...silence.

If you work in tech for long enough, you, like Jeremy Irons, will begin to hear the music. You learn the realities of life in the trenches. You see the mistakes that everyone repeats. You talk to customers in whatever market you specialize in; you will hear of their troubles. You begin to see the patterns; you pick up on the chorus and common refrains; [you](https://benn.substack.com/p/everything-is-still-bi) hear [the](https://benn.substack.com/p/no-really-everything-becomes-bi) way [it](https://benn.substack.com/i/171672882/everything-becomes-bi) all [rhymes](https://benn.substack.com/i/174032155/msnbc-becomes-bi). You develop an intuition, and that intuition becomes your edge. The kids might work harder, but if you can hear the music, you can work smarter.

Unfortunately, there is no music right now. The fog of AI—the wild randomness of today’s technological developments and of which products catch a viral updraft and which don’t—have silenced it. No IDC report on market sizing matters; no engineering fundamentals will save you when engineering becomes [industrialized](https://benn.substack.com/p/the-industrialization-of-it); no SaaS playbook works when nobody can say for sure that [SaaS will even be around](https://benn.substack.com/p/saas-20) in ten years. Perhaps, no *experience* even matters. There is no such thing as a long term plan. There is just step one, and how you respond when the market tilts under your feet, and some new technical change punches you in the face.

An odd fact about the internet is that we’re all a few clicks or keystrokes from incomprehensible power and wealth. Right now, if you log into Robinhood and click on a few buttons in the right order, you could retire next week. Type a few thousand of the right characters into a code editor, and you’ll end up pulling the technical strings that control the world. Sure, the odds of that happening are small, but it is still strange—we are all one fifteen minute fugue state from owning an island.

What are those characters though? Obviously, nobody knows. But now, more than ever, it seems like the only way to find them—no matter who you are, whether that’s a grizzled veteran or at college student—it is to start typing.


---


[^1]: Lol, no, it can’t do that; this isn’t AGI.

[^2]: By which I mean, it refuses to answer your questions until you tell it why you’re asking them.

[^3]: I have no idea if either of these tools are good, but one of them lists a bunch of trending Kalshi bets underneath its chatbot that promises “faster insights and smarter decisions,” so, you know.

[^4]: This is presumably what Thinking Machines is trying to do; [according to ](https://www.theinformation.com/briefings/muratis-thinking-machines-lab-talks-raise-money-50-billion-valuation?rc=wxwupy)*[The Information](https://www.theinformation.com/briefings/muratis-thinking-machines-lab-talks-raise-money-50-billion-valuation?rc=wxwupy)*, “the company aims to produce models customized to key performance indicators, specific business metrics that companies track, typically related to revenue or profit growth.” And they should know how to do this, because Thinking Machines clearly figured out the [best make tons of money](https://www.theinformation.com/briefings/muratis-thinking-machines-lab-talks-raise-money-50-billion-valuation?rc=wxwupy) is to promise to build a robot that tells you how to make tons of money.

================================================================================

# Producer theory

*Platforms are overrated. *

---

![](https://substackcdn.com/image/fetch/$s_!rM2l!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa92043c0-2a72-41f9-9034-45267f8108b3_1600x1128.png)
*Bill Watterson doesn’t care about your aggregation theory.*

You know you’ve thought about it:

It’s all a bit weirder than that, though, because the “standards” are circular. Notion ingests conversations from Slack; Slack ingests documents from Notion; both use [OpenAI](https://www.salesforce.com/en-us/wp-content/uploads/sites/4/documents/legal/misc/salesforce-infrastructure-and-subprocessors.pdf) or [Anthropic](https://www.notion.so/notion/Notion-s-List-of-Subprocessors-268fa5bcfa0f46b6bc29436b21676734) to provide their AI features, which themselves both offer native connectors to ingest [conversations](https://chatgpt.com/features/connectors/) from Slack and [documents](https://www.claude.com/connectors) from Notion. The [Jasper AI platform](https://www.jasper.ai/platform) learns how to write ads for you by learning from those same documents, and then [makes that context available to other products](https://www.jasper.ai/mcp), like bots that write copy in, again, those documents. [Lots](https://www.poggio.io/platform) of [startups](https://briefhq.ai/) aggregate and integrate context together, and then make it available via MCP, to be consumed by another product that will aggregate and integrate it again. It’s platforms, [all the way down](https://www.youtube.com/watch?v=LWx6csgGkg4).

You could have a couple theories about all of this, I suppose. One is that integrating all of this data together is extremely valuable, and that the rush to do it—according to *The Information*, [every major enterprise software company](https://www.theinformation.com/articles/snowflake-sierra-every-enterprise-software-firm-selling-ai-agents) is building an “enterprise search” agent—is a very sensible war for a very strategic space. Google became the [fourth biggest company](https://companiesmarketcap.com/) in the world by being the front door for the internet; of course everyone wants to be the [front door for work](https://newsroom.workday.com/2025-09-16-Workday-Signs-Definitive-Agreement-to-Acquire-Sana#:~:text=Workday%20the%20new-,front%20door%20for%20work,-%2C%20delivering%20a%20proactive). And this messiness is just an intermediate state, until someone wins or [we all run out of money](https://www.wsj.com/finance/stocks/nvidia-earnings-ai-stock-market-af933127?mod=hp_lead_pos3).

A second theory, however, is that platforms aren’t as valuable as we think they are. For a decade now, Silicon Valley has come to accept, nearly as a matter of law, that the [aggregators are the internet’s biggest winners](https://stratechery.com/2015/aggregation-theory/). But aggregation theory[^5] assumes that production flows cleanly from left to right: From producers, to distributors, to consumers, with the potential for gatekeepers along the way. “Context”—especially if MCP succeeds in making it easy for one tool to talk to another—is not like that. Slack aggregates what Notion knows; Notion aggregates what Slack knows; ChatGPT aggregates what everyone knows, and everyone uses ChatGPT to aggregate everything. Producers are consumers, consumers become producers, and everyone is a distributor. There aren’t people orderly walking into one big front door; there are agents crisscrossing through hundreds of side doors.

In that telling, the right analogy for context isn’t content, but knowledge. Because what is context, anyway? It could be a pileup of Google Docs and emails, but it’s also things that are *derived *from that information—the preferences of how someone manages their meetings, and the unspoken style guide that’s implied from a thousand marketing emails, and the loosely combined summaries of what employees are saying in engagement surveys.

If you squint at these context ecosystems, they are a bunch of tools that are trying to learn from each other. The most valuable nodes aren’t the tools that aggregate the most information and offer it up for easy consumption, but the ones that push the most new intelligence back to the group—either by being a unique source of raw information, or by learning clever new things from other people’s information.

Arguably, that’s what a lot of these tools are already doing—some are [collecting](https://www.granola.ai/), and some aggregating and enriching, or aggregating and compressing.[^6] But in our obsession with becoming platforms, we might be surprised by how valuable it is to stay “just” a producer.


---


[^1]: [Even OpenAI is worried about it!](https://www.theinformation.com/briefings/openai-ceo-googles-ai-breakthrough-cause-headwinds-openai?rc=wxwupy)

[^2]: You put these logos on your website, and it’s a little bit unclear if they’re integrations or customers. This may or may not be intentional.

[^3]: “The company [has to be](https://www.youtube.com/watch?v=LQc8NDKcnpM) at least three times bigger than [this](https://www.cnbc.com/2025/11/18/anthropic-ai-azure-microsoft-nvidia.html)!” (“And he’s…[absolutely right](https://www.reuters.com/business/openai-lays-groundwork-juggernaut-ipo-up-1-trillion-valuation-2025-10-29/)?”)

[^4]: There are variants to this story, of course. Some companies start as natural [aggregators](https://hightouch.com/) of [data](https://www.snowflake.com/en/news/press-releases/snowflake-intelligence-brings-agentic-AI-to-the-enterprise/#:~:text=Snowflake%20Intelligence%20unifies%20all%20enterprise%20data%20sources%20from%20structured%20tables%20and%20unstructured%20documents%20to%20data%20from%20third%2Dparty%20apps%20like%20Salesforce%20Data%20360%20via%20Zero%20Copy.), and [softly pivot](https://www.forbes.com/sites/kenrickcai/2021/09/15/glean-startup-emerges-from-stealth-enterprise-search-assistant/) into becoming [context layers](https://atlan.com/) for AI. Some companies already host valuable information, like documents or conversations, and begin [incorporating other sources](https://slack.com/features/enterprise-search) into their [products’ search](https://www.notion.com/product/enterprise-search). Some companies are [really big](https://newsroom.workday.com/2025-09-16-Workday-Signs-Definitive-Agreement-to-Acquire-Sana), and buy some [connectors](https://www.salesforce.com/news/press-releases/2025/11/18/salesforce-completes-acquisition-of-informatica/) and a [search engine](https://www.salesforce.com/news/stories/salesforce-signs-definitive-agreement-to-acquire-doti/).

[^5]: I can’t succinctly explain aggregation theory because I’ve never quite understood aggregation theory, but to do the best I can: Before the internet, distribution was expensive, so consumers had limited choice, so suppliers, who controlled or owned distribution channels, had a lot of market power. After the internet, distribution was cheap, so consumers had tons of choice, so aggregators—companies like Google that sat between consumers and suppliers, and could control or influence what they chose—had all the power.

[^6]: Which could be a disaster, I should say. Every tool reads from the same primary sources, they all “learn” from each other, their confusion compounds, and the enterprise agentic workforce is a [blurry JPEG](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web) of two Google Docs.

================================================================================

# 9-9-6-0

*When all you build is character.*

---

![](https://substackcdn.com/image/fetch/$s_!iLS0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e4cf4cd-ebeb-4162-8610-bf8da02ca3d9_2070x838.png)

“The future is already here,” [the](https://www.instagram.com/p/DCUl-6BPYAD/?hl=en) [lede](https://x.com/visualizevalue/status/1930957883555885334) [goes](https://practicalfounders.com/articles/the-future-is-already-here-but-its-not-evenly-distributed-william-gibson/), “it’s just not evenly distributed.”

Similarly: The AI bubble will burst—it’s just that the disappointment won’t be evenly distributed.

First, I suppose—*is* AI a bubble? [Some people are worried.](https://www.reuters.com/business/big-short-investor-burry-launches-newsletter-after-closing-hedge-fund-2025-11-24/)[^1] Ben Thompson says yes, [obviously](https://stratechery.com/2025/the-benefits-of-bubbles/): “How else to describe a single company—OpenAI—making $1.4 trillion worth of deals (and counting!) with an extremely impressive but commensurately tiny $13 billion of reported revenue?” Others are [more optimistic](https://www.goldmansachs.com/pdfs/insights/goldman-sachs-research/ai-in-a-bubble/report.pdf): “While [Byron Deeter, a partner at Bessemer Venture Partners,] acknowledges that valuations are high today, he sees them as largely justified by AI firms’ underlying fundamentals and revenue potential.”

Goldman Sachs [ran the numbers](https://finance.yahoo.com/news/goldman-says-stock-market-already-205637567.html): AI companies are *probably* overvalued. According to some “simple arithmetic,” the valuation of AI-related companies is “approaching the upper limits of plausible economy-wide benefits.” They estimate that the discounted present value of all future AI revenue to be between $5 to $19 trillion, and that the “value of companies directly involved in or adjacent to the AI boom has risen by over $19 trillion.” So: The stock market might be priced exactly as it should be. Or it could be overvalued by $14 trillion.

Either way, though—these are aggregate numbers; this is how much money every future AI company might make, compared to how much every existing AI company is worth. Even if the market is in balance, there are surely individual imbalances. [Sequoia’s Brian Halligan:](https://www.wsj.com/articles/sequoias-brian-halligan-theres-more-sizzle-than-steak-about-gen-ai-startups-7c18a118) “There’s more sizzle than steak about some gen-AI startups.” [Or](https://www.ft.com/content/23e54a28-6f63-4533-ab96-3756d9c88bad): “OpenAI needs to raise at least $207 billion by 2030 so that it can continue to lose money, HSBC estimates.” [Or](https://www.nytimes.com/2025/11/28/world/ai-valuations-markets-technology-hongkong-fire.html): “Even if the technology comes through, not everybody can win here. It’s a crowded field. There will be winners and losers.” That is the nature of a gold rush, though, even when there is a lot of gold in the ground. Some people get rich, and some people just get dirty.

No matter, says Marc Andreessen; [this gold will save the world](https://a16z.com/ai-will-save-the-world/). And the people digging for it are heroes:

> Today, growing legions of engineers – many of whom are young and may have had grandparents or even great-grandparents involved in the creation of the ideas behind AI – are working to make AI a reality, against a wall of fear-mongering and doomerism that is attempting to paint them as reckless villains. I do not believe they are reckless or villains. They are heroes, every one. My firm and I are thrilled to back as many of them as we can, and we will stand alongside them and their work 100%.

I do not know if the tech employees are heroes, but they are [working hard](https://ramp.com/velocity/san-francisco-tech-workers-996-schedule). Some, [monstrously so](https://x.com/dakshgup/status/1855150225402552676):

> recently i started telling candidates right in the first interview that greptile offers no work-life-balance, typical workdays start at 9am and end at 11pm, often later, and we work saturdays, sometimes also sundays. i emphasize the environment is high stress, and there is no tolerance for poor work.[^2]

This is the new vibe in Silicon Valley: Grinding, loudly. [Hard tech](https://www.nytimes.com/2025/08/04/technology/ai-silicon-valley-hard-tech.html), and [extremely hard core](https://www.nytimes.com/2022/11/16/technology/elon-musk-twitter-employee-deadline.html). Because that’s what’s needed to meet the “[deranged pace](https://x.com/signulll/status/1993798022510334223)” of this historical moment. [Venture capitalist Harry Stebbings](https://www.linkedin.com/posts/harrystebbings_founder-funding-business-activity-7334473729579606016-56Od/): “7 days a week is the required velocity to win right now.” [Cognition’s Scott Wu](https://x.com/ScottWu46/status/1952776198947520659): “We truly believe the level of intensity this moment demands from us is unprecedented.” From others—this isn’t mere capitalism; [this is a crucible](https://sfstandard.com/2025/09/16/san-francisco-became-ultimate-996-city/): “‘This work culture is not unprecedented when you consider the stringent work cultures of the Manhattan Project and NASA’s missions,” said [Cyril Gorlla, cofounder and CEO of an AI startup]. ‘We’re solving problems of a similar if not more important magnitude.’”

So far, so good, at least for the capitalists: [According to CNBC](https://www.cnbc.com/2025/08/10/ai-artificial-intelligence-billionaires-wealth.html), there are now 498 private AI companies worth more than $1 billion. A hundred of them are less than three years old. There are 1,300 startups worth more than $100 million. And these companies have created dozens of new billionaires.

In recent years, this has become the math that punches Silicon Valley’s clock: [996](https://www.nytimes.com/2025/09/28/business/996-hustle-culture-tech.html)—work from 9 am to 9 pm, six days a week. Seventy-two hours a week; 3,600 hours a year; 10,000 hours in three years. But if that adds up to a billion-dollar payday? Or even a [pedestrian](https://benn.substack.com/p/enough#:~:text=The%20week%20before,daily%20beat%20report.) few million? Just hang on. “‘I tell employees that this is temporary, that this is the beginning of an exponential curve,’ [said Gorlla](https://sfstandard.com/2025/09/16/san-francisco-became-ultimate-996-city/). ‘They believe that this is going to grow 10x, 50x, maybe even 100x.’” Another founder told Jasmine Sun their plan—[get in, get rich, get out:](https://jasmi.news/p/bait)

> I asked a founder I know if he thinks that AI is a bubble. “Yes, and it’s just a question of timelines,” he said. Six months is median, a year for the naive. Most AI startups are all tweets and no product—optimizing only for the next demo video. The frontier labs will survive but it’ll be carnage for the rest. And then what will his founder friends do? I ask. He shrugs. “Everyone’s just trying to get their money and get out.”

A few years of hard work, funded by borrowed money. And what’s just a few years?

[There is a point during every party](https://www.youtube.com/watch?v=S7jo5Cr6WUA), when the alcohol takes hold and the music swallows you whole, that you lose yourself in the fever. The moment, indomitable. The walls, impenetrable. But how quickly a night can turn. [How quickly a tune can change.](https://www.youtube.com/watch?v=yjiVUnNJ4Ko)

Back in my day, it was [banking and consulting](https://gregmankiw.blogspot.com/2007/06/harvard-class-of-2007.html): “Among men who are entering the workforce next year, 58 percent are taking jobs in the finance and consulting industries. Among Harvard women in the workforce, only 43 percent are going into finance and consulting.” In 2011, in her canonical investigation of this phenomenon, Yale senior Marina Keegan interviewed her classmates to figure out why so many of them took jobs they didn’t seem to really want. Their answer? [This is temporary:](https://yaledailynews.com/blog/2011/09/30/even-artichokes-have-doubts/)

> Annie Shi ’12 has similar justifications for her job at J.P. Morgan next year. When asked what she might be most interested in doing with her life, she mentioned a fantasy of opening a restaurant that supports local artists and sustainable food. Eventually, she’s “aiming for something that does more good than just enriching [her]self.” She just doesn’t think she’s ready for anything like that quite yet. …
> “I’m practical,” she says. “I’m not going to work at a non-profit for my entire life; I know that’s not possible. I’m realistic about the things that I need for a lifestyle that I’ve become accustomed to.” Though she admits she’s at least partially worried of ending up at the bank “longer than [she] sees [her]self there now,” at present she sees it as a “hugely stimulating and educational” way to spend the next few years.

A few years of hard work, as an investment into the rest of your life. And what’s just a few years?

In a tragic twist that many of you probably know: Nine months after publishing her story, and five days after she graduated, Marina Keegan died in a car crash.

But there’s another twist, that you may not know. Here’s a second quote from Keegan’s article, from a different classmate who was almost seduced by a pitch from McKinsey: “There’s definitely a compulsion element to it. You feel like so many people are doing it and talking about it all the time like it’s interesting, so you start to wonder if maybe it really is.” That classmate was Tatiana Schlossberg.

You can live your life on borrowed money, but there is [no such thing as borrowed time](https://www.newyorker.com/culture/the-weekend-essay/a-battle-with-my-blood). 

What happens if—when?—the AI bubble bursts? We’re frequently told the stakes. In the United States, “AI is the only source of investment right now,” [some economists say](https://www.wsj.com/tech/ai/how-the-u-s-economy-became-hooked-on-ai-spending-4b6bc7ff); without it—without huge companies like Amazon and Alphabet spending billions to build huge factories for their huge computers—it’s “plausible that the economy would already be in a recession.”[^3] [Other economists](https://www.nytimes.com/2025/11/22/business/the-ai-boom-economy.html): “This A.I. gold rush is generating all the excitement and papering over a drift in the rest of the economy.”

In San Francisco, there would be smaller, quieter consequences. Companies will pivot themselves in circles; evaporate; sell themselves for parts. There will be thousands of employees, grinding for the 10x, 50x, maybe even 100x payday, collecting nothing. There will be abandoned options, vested through years of hard work, unexercised and returned. Sometimes, 996 adds up to generational wealth. Sometimes, it adds up to zero.

That is at least one big difference between a party and a bubble: A hangover comes with memories.[^4] The night out was the point; the morning after is a delayed invoice. An eye for an eye.

But a collapsed company is a price paid for nothing. It is the entire transaction. It is a hangover, for a party that never happens. It is a discarded lottery ticket, scratched for 72 hours a week, for years. Sometimes, there is just borrowed money, and lost time.

When you join a startup, they don’t tell you about this part. They tell you about the potential. They paint their vivid visions[^5] in pitch decks. They sell the better world they’re building to their employees. They give you worksheets: Your equity, if we sell at our last valuation; if we IPO; [if we become Salesforce](https://benn.substack.com/p/the-whole-scheme?utm_source=publication-search#:~:text=And%20startups%20hire,than%20%245%20million.).

Somewhere at the bottom, they put the disclaimers. Startups are inherently risky. Your options may have no financial value. “You should consult with your own tax advisor concerning the tax risks associated with accepting an option to purchase the Company’s common stock.” Everyone knows this, of course.

But, zero? We aren’t conditioned to understand that, not really. Hard work feels like it must have some reward; [unpleasant experiences](https://www.reddit.com/r/calvinandhobbes/comments/10qqymf/whats_this_disgusting_slimy_blob/) must be building *something*. We grow up with a sense of cosmic balance: Our parents are watching; our teachers are watching; God is watching; [Santa is watching](https://share.google/images/Jw0jiOGgzsqqtboVK). Surely, the same saviors must exist here. Even if the market turns, an acquirer will save you. Your boss will take care of you. Your investors will help you out. Everyone knows they may not win the lottery. But all the work—to build a resume, to get a job, to help create a company—surely, it must be worth something? It’s hard to imagine otherwise, because nobody paints a vivid vision of *that* future.

Or at least, startups don’t—[but they’re out there:](https://www.youtube.com/watch?v=znUsjNI34_4)

> Fred sits alone at his desk in the darkThere’s an awkward young shadow that waits in the hallHe’s cleared all his things and he’s put them in boxesThings that remind him, life has been good.25 years, he’s worked at the paperA man’s here to take him downstairs“And I’m sorry, Mr. Jones, it’s time.”
> There was no party, there were no songs‘Cause today’s just a day like the day that he startedNo one is left here that knows his first nameAnd life barrels on like a runaway trainWhere the passengers changeThey don’t change anythingYou get off; someone else can get on“And I’m sorry, Mr. Jones, it’s time.”…He’s forgotten but not yet gone.

Of course, these aren’t real tragedies. Writing off your options after working a good job in a comfortable chair—even for 12 hours a day—is not a terminal diagnosis; it is not even bad. Most of us will, at worst, be passing extras in someone else’s tragedy; we are unlikely to be its main character. This week, of all weeks, we should be grateful for that, and for the good twists in many of our stories.[^6] So many of us have won so many lotteries already.[^7]

And it must also be said: Silicon Valley produces plenty of circular slop. Legions of startups exist *because* they are lottery tickets, and legions more exist to sell stuff to them. Is it a tragedy that they are gone? A comedy? A blessing?

Still. That is too crude. Wherever you work, do you know good people, working hard? Have you invested in people, and asked to take their time in exchange for your lent money? Do you know people putting in honest hours for a fraction of the benefits of their boss? Do you know people who are giving their time—so much of it, time that cannot be returned—to the office? Would you be sad for them—*mad* for them—if it does not turn out?

More calculus [that we all have to do](https://www.reddit.com/r/calvinandhobbes/comments/a2dcv0/calvins_choice/):

![](https://substackcdn.com/image/fetch/$s_!ojQR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc08c5e5b-ea78-49be-a691-79e4475bb2df_1080x342.png)

We imagine ourselves as Calvin: Do we do what makes us happy now? Do we invest in our future? Do we eat the [marshmallow](https://en.wikipedia.org/wiki/Stanford_marshmallow_experiment) today, or wait for more later? Do we make memories with our friends?

But we forget: The punchline of the strip doesn’t work without Hobbes. Calvin’s memories—our memories—only matter when Hobbes is there. And, of course, the corollary: Hobbes’ memories require *us*.

If you work here, in technology, you know an entire Rolodex of people, doing their homework, for the long term. You might want the best for some of them; some of them might be your friends. For many of them, it won’t work out. “Not everybody can win here. It’s a crowded field. There will be winners and losers.” 

That part—their disappointment; yours; somebody’s—is inevitable. Though it can’t be stopped, and their time cannot returned, that doesn’t mean nothing can be done. Because in the very long term, as Calvin says, the memories matter than the success.

But their memories require us. So, before it is too late: Be Hobbes. Pay attention. Watch your friends work; see what they are sacrificing. Call them; email them; wish them a happy birthday, even if you cannot tell them directly. See, and show them that you see.

Because when a bubble bursts, and people’s work gets erased and their hours wasted, all that remains is what other people witnessed. And it is on each of us remember what they hope we do not forget.


---


[^1]: Typically, investment firms make money by charging a small management fee, and by taking a larger cut of their investments’ earnings. And typically, these fees are about 2 percent and 20 percent. So, if you gave ([a hypothetical](https://benn.substack.com/i/149158309/is-this-real)) [benn.ventures](https://benn.ventures/) $100 to invest, I’d take $2 as a management fee, and invest the remaining $98 in various startups. If those investments return $100 on top of the invested capital, I’d give you your initial $98 dollars back, plus $80 of the returns, and I’d keep the other $20. The point of this structure is to guarantee that I make a little bit of money for my efforts—the 2 percent fee—while still incentivizing me to make as much money as possible with the investments.But if you’re a celebrity investor, this might not be an optimal model. First, a lot more people might want your investing opinions than are able to give you money. Only charging your investors a management fee is leaving money on the table. Second, if people are paying attention to those opinions, they can become somewhat self-fulfilling. (When Warren Buffet says he likes a stock, the stock goes up.) And third, if you’re a celebrity investor, you probably want to be a celebrity, and [want attention](https://benn.substack.com/p/everyone-is-crazy-now#:~:text=People%20get%20addicted,New%20Yorker%3A) as much as money.A better model, then, might be to publish your opinions, charge people to read them, and then charge a much smaller management fee. You could make more guaranteed money, pump your positions, offer more compelling terms to prospective investors, and get even more attention, all at once.Anyway, earlier this year, celebrity investor Michael Burry[ managed a $155 million fund](https://www.cnbc.com/2025/11/13/michael-burry-of-big-short-fame-deregisters-scion-asset-management.html), which would bring in about $3 million in management fees. He closed that fund, and now puts all of his investment advice on Substack, behind a paywall that costs $40 a month. He has about 100,000 subscribers. If ten percent of them pay, he’ll make $400,000 a month, or about $5 million a year. That’s better! And here we are, talking about him!

[^2]: Regarding the horrific casing, [sic].

[^3]: This Black Friday, [I hope I can trust all of you to do what’s right for our country](https://www.reddit.com/r/calvinandhobbes/comments/18m50ym/remember_to_be_a_responsible_consumer/).

[^4]: I mean, [usually](https://youtu.be/tcdUhdOlz9M?si=BZChePHu-nxqIf_Y&t=47).

[^5]: [™](https://www.amazon.com/Vivid-Vision-Remarkable-Aligning-Business/dp/161961877X)

[^6]: For example, after working at J.P. Morgan for three years, [Annie Shi ‘12](https://www.instagram.com/annie.h.shi) opened a [very good](https://www.nytimes.com/2017/06/06/dining/king-restaurant-review-soho.html) restaurant.

[^7]: I think about reincarnation sometimes. If you were a disembodied soul, and didn’t know which organism you’d be placed into, how would you feel about your current draw? First, you would have to be born as a person, and not a termite or a fern or slaughterhouse chicken (though you were *not* born a house cat, which seems pretty solid). Second, you’d have to be born in an equally privileged and broadly painless historical era (i.e., not the Stone Age or in a time before anesthesiology). Third, you’d have to be born into greater relative social wealth, or granted more physical or mental gifts. For most people here, those aren’t good odds! You could be reincarnated thousands of times, and this is still probably the best shot you’ve got!

================================================================================

# Will there ever be a worse time to start a startup?

*Today's frontier is tomorrow's tech debt.*

---

![](https://substackcdn.com/image/fetch/$s_!q0SW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F587ee33f-b72b-4294-bcb4-278ce19f404d_1536x1024.png)
*[If only he had waited a bit longer.](https://www.youtube.com/watch?v=xcSwBHs1uD4)*

Deflation is an odd phenomenon. The problems associated with inflation are fairly intuitive—when prices go up, people can’t buy as much of the stuff they want or need. But deflation? People like lower prices! It’s a [whole](https://www.aboutamazon.com/news/retail/amazon-pricing) [thing](https://insights.citeline.com/RS000506/WALMART-CHANGING-ITS-ALWAYS-THE-LOW-PRICE-ALWAYS-AD-SLOGAN/)! If inflation is bad, shouldn’t its opposite be *good*?

Most economists say, emphatically, no. Deflation is not only bad; it’s often considered *[worse](https://www.theatlantic.com/international/2025/12/china-deflation-american-inflation-market-interference/685078/)* than [inflation](https://www.aei.org/research-products/report/inflation-is-better-than-deflation/).[^1]

Because, when prices are falling and people expect things to get cheaper, they save their money instead of spending it. Moreover, borrowing—which fuels a lot of economic activity—is especially disincentivized, because if you borrow [$400,000](https://fred.stlouisfed.org/series/MSPUS) to buy a house, the $400,000 principal you owe back to the bank will be more valuable than the $400,000 you borrowed.[^2] Finally, to make up for the money they’re losing from falling prices, companies need to reduce wages or lower employees’ salaries. Though that’s technically possible, [workers tend](https://www.federalreserve.gov/pubs/feds/1999/199931/199931pap.pdf) to “resist pay cuts for many reasons, most obviously because cuts lead to a lower standard of living, but also because they may be perceived as unfair or demeaning.” This makes cutting wages practically infeasible, so firms have to save money in other ways—by building less stuff, by reducing employee benefits, or by laying people off. The whole thing can [spiral](https://www.bbvaresearch.com/wp-content/uploads/2015/02/Global_Economic_Outlook_1Q15-Cap4.pdf): People save more, borrow less, and spend less; firms invest less and fire people; this reduces economic activity further; as their finances tighten, people save more, borrow less, and spend less; down and down and down.

And the more severe the deflation, the more it compounds. If you think cars will cost 1 percent less in a year, you may still buy one today. But if they keep getting 10 percent cheaper every month, well. [Imagine the car you could buy if you just wait a year.](https://www.youtube.com/watch?v=EbTn8hjdfEI)

Anyway. It would be very strange to say that right now is a bad time to start a company. Startups are growing [faster than ever](https://a16z.com/revenue-benchmarks-ai-apps/), money is coming [out of venture capitalists’ ears](https://kpmg.com/xx/en/media/press-releases/2025/10/global-vc-investment-rises-in-q3-25.html), and everyone you know is a [billionaire](https://benn.substack.com/p/enough#:~:text=The%20week%20before,daily%20beat%20report.). The conventional wisdom is that now is a *great* time to start a company. [There has never been a better time to start a startup](https://insights.teamignite.ventures/p/why-theres-never-been-a-better-time). [There’s never been a more amazing time to go create something totally new](https://x.com/Overlap_Tech/status/1954234482132652143):

> You have access to tools that can let you do what used to take teams of hundreds.

This was particularly evident last week, when Anthropic released [Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5). As other [people](https://every.to/chain-of-thought/opus-4-5-collapsed-six-months-of-development-work-into-one-week) have [said](https://www.reddit.com/r/ClaudeAI/comments/1p5zk99/opus_45_is_insane/), Opus 4.5 was alarmingly good: “You can build astonishingly complex apps without looking at a single line of code.” Or, as I said in an earlier post:

> The comfortable physics that I thought governed Silicon Valley—that stuff takes time to build; that products need to be designed before they can be created; that computers cannot assume intent or interpolate their way through incomplete ideas—broke, utterly. It all worked too well, too fast. I was staggered, drunk on the Kool-Aid and high on the [pills](https://knowyourmeme.com/memes/pilled), unwell and [off-brand](https://benn.substack.com/p/welcome-to-bennventures). I knew that anyone can now build [vibe-coded toys](https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html); I did not know that people with a basic familiarity with code could go much, much further. … In 2013, it took us eight people, nine months, and hundreds of thousands of dollars to build something we could sell, and that was seen as reasonably efficient. Today, that feels possible to do with one person in two days.

Ah, no, wait. That quote isn’t about Opus 4.5; it’s [from February](https://benn.substack.com/p/the-end-of-yc), and is about Cursor and Anthropic’s Sonnet 3.5, a model that’s so outdated that *it has already been [deprecated](https://platform.claude.com/docs/en/about-claude/model-deprecations#2025-08-13-claude-sonnet-3-5-models)*.

But that’s the pattern now, isn’t it? A new model comes out; we declare the game changed. And we wonder how we got anything done with the trash we used to have:

> [Claude 3.5 Sonnet](https://silatus.com/blog/claude-3-5-sonnet-anthropic-s-game-changing-ai-model-revolutionizing-enterprise-solutions) isn’t just an incremental update—it’s a quantum leap forward.

> There was this moment—I think it was around when [Sonnet 3.7](https://every.to/podcast/transcript-how-to-use-claude-code-like-the-people-who-built-it#:~:text=there%20was%20this%20moment%E2%80%94I%20think%20it%20was%20around%20when%20Sonnet%203.7%20came%20out%E2%80%94where%20I%20used%20it%20and%20I%20was%20like%2C%20holy%20shit%2C%20this%20is%20a%20completely%20new%20paradigm.) came out—where I used it and I was like, holy shit, this is a completely new paradigm.

> Holy shit. I’ve used ChatGPT every day for 3 years. Just spent 2 hours on [Gemini 3](https://x.com/Benioff/status/1992726929204760661). I’m not going back. The leap is insane.

> [Opus 4.5](https://every.to/podcast/anthropic-s-newest-model-blew-this-founder-s-mind-and-made-him-uncomfortable-273eac07-071c-4638-b6fe-a7a72541dd5d) has left him feeling wonderstruck, excited.

In a sense, none of this is new; technology is always getting better. “You’re the oldest you’ve ever been and the youngest you’ll ever be” is both profound and trivial; so is “technology is the best it’s ever been, and the worst time it’ll ever be.” If all you think about is the tools that are available to you, then today is always a better time to start a company than yesterday, and today will always be worse than tomorrow. The cost of doing something with a computer goes one direction: Down.

But what if those costs are falling quickly? What if doing things gets [10 percent cheaper every month](https://theaidigest.org/time-horizons)?[^3] Imagine what you could build if you just wait a year.

For example, I’ve been playing around with various AI coding tools to build a couple personal products or experimental ideas. Every couple months, when some new AI thing comes out—first Replit; then Cursor; then Lovable; then Cursor, with Gemini 2.5 Pro; then Claude Code; then Antigravity; then, last week, Claude Code and Opus 4.5—the same story repeats itself:

Part of the reason this seems to happen is because each successive model is, in effect, writing for a different—and potentially incompatible—audience. The early versions of Cursor finished the code that I started. Then, it was more of a coworker, pair programming alongside me. Now, [why even look at an IDE anymore](https://www.linkedin.com/feed/update/urn:li:activity:7402358181747728384?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7402358181747728384%2C7402378988272181248%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7402358181747728384%2C7402380978448662528%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287402378988272181248%2Curn%3Ali%3Aactivity%3A7402358181747728384%29&dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287402380978448662528%2Curn%3Ali%3Aactivity%3A7402358181747728384%29)? Let them generate whatever code they want. [As long as it works, we should be happy.](https://x.com/headinthebox/status/1918030539958972507)

Earlier this year, [I guessed that](https://benn.substack.com/p/copy-copy-revolution#:~:text=Perhaps%20we%20should%20let%20the%20machine%20write%20for%20itself%20and%20its%20abilities.%20Let%20it%20be%20redudant.%20Let%20it%20ignore%20the%20frameworks%3B%20let%20it%20create%20explosively%20large%20codebases.%20Let%20it%20write%201%2C000%20distinct%20pipelines%20in%201%2C000%20distinct%20languages.%20Let%20it%20be%20offensively%20unaesthetic.%20Let%20it%20be%20radically%20simple.) AI models would eventually drift towards writing code that was optimized for their computer comprehension over human comprehension:

> Perhaps we should let the machine write for itself and its abilities. Let it be redundant. Let it ignore the frameworks; let it create explosively large codebases. Let it write 1,000 distinct pipelines in 1,000 distinct languages. Let it be offensively unaesthetic. Let it be radically simple.

But that theory has a corollary that I hadn’t considered: The machines aren’t static. Across vendors and release versions, models could develop their own habits. Just as Sonnet 3.5 might be better off unencumbered by us and our feeble reasoning, Opus 4.5 could be better off unencumbered by Sonnet 3.5. And if that’s true, it seems naive to assume that some future AI won’t want to undo the mess Opus 4.5 made. There is no fixed definition of tech debt—it is simply code that the current engineers would prefer to be written differently.

Of course, a side project is not a startup, and [benn.chat](https://benn.chat/) is not a capital-P Product. But still—to rephrase the original question, if now is a great time to start a company, was *2023 *a great time to do it? Well, yes, obviously—that is where all the billionaires came from. But if you started a company in 2023 and it *didn’t* take off—if you’re not a billionaire but are instead [still pushing the boulder uphill](https://mixpanel.com/blog/what-14-startup-investors-and-advisors-taught-us-about-chasing-and-finding-product-market-fit/#:~:text=According%20to%20Raymond,and%20can%20handle.%E2%80%9D)—would you do things differently if you were starting the company again today? *Do you wish you were starting it today?*

After all, [you can rename your company](https://x.com/wallstengine/status/1996929414324682819) to keep up with the latest fads, but it’s not so easy to rebuild it. 


---


[^1]: Though [not every economist](https://www.cato.org/commentary/whos-afraid-little-deflation) agrees with this, because [if you put two economists in a room, you’ll get three opinions](https://freedomlab.com/posts/does-the-future-belong-to-keynes-and-mazzucato#:~:text=Put%20two%20economists%20in%20a%20room%20and%20you%E2%80%99ll%20get%20three%20opinions%2C%20the%20old%20economic%20saying%20goes.).

[^2]: Banks could, in theory, charge negative interest rates, where they loan out $400,000 and ask for only $390,000 back. Central banks [have experimented with this](https://www.ecb.europa.eu/press/pr/date/2014/html/pr140605_3.en.html), but it doesn’t really work for private lenders because they can just hold cash. Why would a bank lend someone $400,000 so that they can—[probably!](https://fred.stlouisfed.org/series/DRALACBN)—get paid $390,000 later, when they could instead put $400,000 worth of cash in a vault that will—definitely! Or, [probably?](https://benn.substack.com/p/data-is-for-dashboards#:~:text=The%20county%20I,Fargo%20in%201997.)—be there in a year?

[^3]: “The length of coding tasks frontier systems can complete is growing exponentially—doubling every 7 months,” which, very roughly, implies that they can complete 10 percent more every month.

[^4]: Sure, they’re great at writing code, but, are they good, I am contractually obligated to ask you, at analyzing data?! Maybe! I don’t know![ Let’s all find out together!](https://www.getdbt.com/resources/webinars/analytics-data-engineer-bench)

[^5]: At the risk of falling into the exact trap this post is trying to highlight: Opus 4.5 *is* unsettlingly good. When [I said this in April](https://benn.substack.com/p/the-industrialization-of-it), I felt like I be losing myself a bit in artistic hyperbole:The dominant conglomerates of the future won’t be the companies that build software with humanoid agents, but those that figure out how to run the computing machine at a massive scale. They will figure out how to put coding agents on a perpetual loop, in a factory that doesn’t have to sleep or take vacations. They will be the companies that industrialize the most, and optimize for ACPE—average compute per employee. They will be the ones that turn engineers into factory supervisors who watch the line, look for defects, and doze off to the dull hum of the machinery that replaced them.Now, frankly, I’m not sure it goes far enough.

================================================================================

# The vibes and the noise

*The post-empirical generation.*

---

![US gymnast Chiles loses floor bronze to Romania's Barbosu after CAS ruling](https://substackcdn.com/image/fetch/$s_!CWW2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbfaa27c7-2c9a-4028-a451-607068b3fadd_1024x683.jpeg)

**A programming note:*** Have you ever thought, “These blog posts are alright, but I wish that they were longer and louder? Well. This post was adapted from a recent talk, so if you’re sick of mere metaphorical yelling and would prefer actual yelling, there is a video of that [on YouTube](https://www.youtube.com/watch?v=D7zcwFSu4HU). Like and subscribe.*

Here is what happened to Jordan Chiles:

At the beginning of Section I of the *Code of Points*, the document declares its purpose: “To provide an objective means of evaluating gymnastics exercises.” Section II defines the rights of the gymnast in this evaluation; the very first right—article 2.1.1a—is the right to have performances judged correctly and fairly.

Which demands the obvious question: Despite the 400 pages of rigor and quantified rules, was this competition judged correctly? Was it objective? For all three women involved, does anything about this result seem fair?

And how did all of this even happen?

# The quantification of everything

You could answer that question in two ways. The proximate cause of last year’s mess was another, [similar mess in 2004](https://www.nytimes.com/2004/08/22/sports/summer-2004-games-gymnastics-all-around-judges-suspended-for-error-but-hamm-will.html), in which a scoring error—also about an incorrectly assessed deduction—cost Yang Tae Young, a South Korean gymnast, the gold medal in men’s Olympic all-around. FIG [overhauled the scoring system](https://www.nytimes.com/2008/08/06/sports/olympics/06scoring.html) after that, replacing the traditional “perfect ten” framework with the new, more mathematical *Code of Points*.

But the *Code of Points* could also be explained as part of a larger narrative: The quantification of everything. Because, in the late 2000s and early 2010s, [numbers became our inexorable future](https://www.nytimes.com/2012/02/12/sunday-review/big-datas-impact-in-the-world.html):

> “It’s a revolution,” says Gary King, director of Harvard’s Institute for Quantitative Social Science. “We’re really just getting under way. But the march of quantification, made possible by enormous new sources of data, will sweep through academia, business and government. There is no area that is going to be untouched.”

Hedge fund managers no longer bet on their intuition, but [on their models](https://www.nytimes.com/2005/06/05/magazine/the-quantitative-databased-riskmassaging-road-to-riches.html). Sports teams [did the same](https://en.wikipedia.org/wiki/Moneyball:_The_Art_of_Winning_an_Unfair_Game). Political pundits were out; [Nate Silver was in](https://hbr.org/2012/11/how-nate-silver-won-the-2012-p). He launched [FiveThirtyEight as an entire media division](https://www.espn.com/espn/story/_/id/9499752/nate-silver-joins-espn-multifaceted-role), to bring their “data-driven approach into new areas.” We quantified [companies](https://www.nytimes.com/2011/04/24/business/24unboxed.html), [elections](https://sloanreview.mit.edu/article/big-data-and-the-u-s-presidential-campaign/), and [ourselves](https://www.wired.com/2009/06/lbnp-knowthyself/). And, gymnastics.

As a sub-trend: We also wrote blog posts about everything that we could graph: [Our sleep](https://web.archive.org/web/20140905235023/https://jawbone.com/blog/napa-earthquake-effect-on-sleep/); our [commutes](https://mode.com/blog/daylight-savings-commute); our [mortality](https://web.archive.org/web/20170331211359/https://deadspin.com/feel-old-with-our-how-many-pro-athletes-are-younger-th-1565829499). Writing in the *New York Times*, [Seth Stephens-Davidowitz](https://benn.substack.com/p/playing-for-ourselves#:~:text=Earlier%20this%20week,who%20excels%20there.) looked at the numbers [behind our musical preferences](https://www.nytimes.com/2018/02/10/opinion/sunday/favorite-songs.html). He found that our tastes are overwhelmingly defined by what was popular when we were teenagers. More recently, the *Washington Post*’s “Department of Data” [extended the idea](https://www.washingtonpost.com/business/2024/05/24/when-america-was-great-according-data/), and found that the same pattern holds for nearly everything: Fashion, movies, television, sporting events, food—all of it, we said, was better in our adolescence.

Of course, there is no “best fashion.” There are only fads, and the generational indoctrination that makes us believe that our fad was the best one. With things like clothes, no matter how militantly we believe that we looked cool and that the Kids These Days look dumb, it is easy to see how fickle fashion can be. It is easy to see that, as our styles fade into obsolescence, the next generation is not wrong; we are just growing old.

But other trends can be harder to recognize as trends. For example: What makes a good employee? What are the right ways to think, and make decisions? What is the best way to answer an ambiguous question like which of these products, or baseball players, or gymnastics routines, is best?

If you came of *professional *age in the 2000s and 2010s, your answer—per the same trend that created Stephens-Davidowitz’s research—is to be data-driven. But is that answer right—is it the “best method”?—or do we simply believe that is, because that was the corporate philosophy that we were indoctrinated into? Was the quantification of social science—and business, and culture, and sport—a revolution, or was it just a fad too?

# The new revolutionaries

When this all started, 15 years ago, there was clout in data work. It was urgent; it was prestigious; it was strategic; it was, dare we say it, *cool*:

> Sterrett saw analytics as “pre-eminently the profession of business advice” and the analyst as a person who “is thoroughly conversant with the principles” underlying a successful company and who “has accumulated a large fund of information in…business policy.”

And:

> Stettler believed that the prestige of the data profession would grow to match and surpass that of the older, more recognized professions of law and medicine, and that data scientists would outnumber physicians and lawyers.

But cool never lasts. Because those two quotes aren’t actually about analytics and data science; they are about accounting, from [1904](https://www.journalofaccountancy.com/issues/2005/oct/100yearsofthejournal) and [1968](https://www.nysscpa.org/news/publications/the-cpa-journal/article-detail?ArticleID=11611). And accountants, critical as they are, are rarely in charge these days. They are fact-checkers, not decision-makers. They are the part of the corporate machine that someone else drives.

For analytics, [the path seems similar](https://benn.substack.com/i/137070616/die-a-hero-or-live-long-enough-to-become-an-accountant). A generation grew up reading *The Signal and the Noise* and *Thinking Fast and Slow*, and bludgeoned the prior generation to death with models and [quantitative rhetoric](https://benn.substack.com/i/41161485/the-reverence-for-quantitative-rhetoric) and complex codes of points. In God we trusted; [all others must bring data](https://www.ibm.com/think/insights/in-god-we-trust-all-others-must-bring-data).

No longer. Anu Atluru is right: [Taste is eating Silicon Valley](https://www.workingtheorys.com/p/taste-is-eating-silicon-valley). Craft, not data, is the new buzzword. Linear CEO Karri Saarinen, whose company has built one [most copied brands](https://web.archive.org/web/20250415171457/https://www.linears.art/) of the 2020s, [recommended that startups](https://x.com/karrisaarinen/status/1845201572533256432) “ban use of data as a decision making tool.” “Don’t make decisions based on data or experiments,” [he told Figma](https://www.figma.com/blog/karri-saarinens-10-rules-for-crafting-products-that-stand-out/); “to design with craft, you must develop and trust your intuition.” The former dean of Harvard Business School—whose associated publication, the *Harvard Business Review*, has published hundreds of articles on the [urgency of becoming data-driven](https://hbr.org/search?search_type=search-all&term=data-driven)—[said earlier this year](https://www.theatlantic.com/technology/archive/2025/06/good-taste-ai/683101/) that “good taste is more important than ever.” Nobody wants to be a [data nerd](https://x.com/newrelic/status/646824479696420864) anymore; we all want to be a [tastemaker](https://x.com/claudeai/status/1974193032531517950).[^4]

Anecdotally, this seems especially true inside of AI companies, which are quickly becoming corporate trendsetters. The enthusiasm that SaaS startups had for analytics, experimentation, and rigorous quantitative thinking has been almost wholly replaced by a demand for people with taste and “agency.” One popular AI company—employing hundreds, used by millions, making hundreds of millions—has *one* person dedicated to data work. They have formal evals to measure how their product is performing, they said, but decisions are ultimately made based on how new features *feel*.

None of this is to say that data is going away. But it is falling out of fashion.[^5] It is fading into the background. In data we trusted; now, God is in the vibes.

# Quantity has a quality all its own

But that story is incomplete. Even if vibe-driven decision-making is ascendant, how do we figure out those vibes? Business people need to know what’s happening with their businesses. Politicians need to know what voters think. Judges need to score a gymnastics routine. If not with numbers, then what?

On the second page of the *Code of Points*, there is an ad. It is for the [Fujitsu 3D Sensing and AI Judging Support System](https://www.rdworldonline.com/ai-assisted-gymnastics-judging-system/):

> The Judging Support System (JSS) employs a multi-step process to analyze gymnastic performances. It begins by capturing 3D data of the athletes’ movements without the use of physical markers. AI-powered pose estimation algorithms then identify and track the position of the gymnasts’ joints throughout their routines. …
> To understand the details of gymnastic routines, the AI powering the JSS learned from a database of 8,000 routines. … The system can discern differences between elements, transitions, and pauses, as well as its understanding of the specific criteria for deductions based on deviations from the ideal execution. …
> In addition to providing near real-time feedback to judges—identifying elements, calculating scores, and flagging deductions—JSS can be used by gymnasts and coaches to analyze performances and refine skills.

If AI is good at anything, it is good at interpreting the vibes. It is good at aggregating massive amounts of text—and increasingly, of video and audio—into its approximate average. Give it your support tickets and customer communications, and [ask it questions about what it read](https://hightouch.com/blog/hightouch-agents-ai-for-marketers). Don’t classify and categorize images; [just ask an AI model what it thinks it sees](https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_query#:~:text=the%20image%20file.-,SQL,what%20is%20this%20image%20about%3F%27%2C%20files%20%3D%3E%20content),-as%20output%20FROM). Don’t argue about steps on landings and timestamps when protests are filed; just have a robot watch the routine, compare it to thousands of others, and have it spit out how it deviated from the ideal execution. Ask it for the vibes.

The old generation might protest—this is not objective! This is not rigorous! There is nuance and bias in these questions, and “vibes” is just another word for hocus pocus punditry!

Maybe—though we would say that; it’s our whole bit. But regardless of our arguments’ merits, do we really think it’s going to keep winning? When a CEO asks us how a new product is doing, which answer will they prefer?

Is the second answer right? *It almost doesn’t matter.* As, uh, [Stalin](https://en.wikipedia.org/wiki/Heartbreaking:_The_Worst_Person_You_Know_Just_Made_a_Great_Point) once [said](https://www.goodreads.com/quotes/795954-quantity-has-a-quality-all-its-own), “quantity has a quality all its own.”[^6] If you make something accessible and compelling enough—Wikipedia over Encarta; news on social media over news in the paper; ChatGPT over manual searches; immediate answers describing the vibes over legalistic answers about numerical minutiae—that’s where people will turn.

And then, it becomes self-reinforcing. The more that people use Wikipedia, the better it gets. Similarly, the more CEOs ask about their customers’ vibes, the more effort we’ll go to to understand them. When numbers were in demand, we built a giant, sprawling network of suppliers to collect, store, transform, and aggregate them. If the new bosses demand vibes, [we’ll find the suppliers](https://benn.substack.com/p/producer-theory) and build them a vibe stack.

# Vibe native

Ask data people what teams need to do to prepare for the next era of analytics, and they will tell you about the importance of building semantic ontologies for AI agents. They will talk about context engineering, and metadata management, and the supreme importance of data quality. They will talk about the layers of technologies that need to get created to make sure that AI agents compute metrics consistently and accurately. They will talk about the various things that companies need to invest in tomorrow, so that data teams can make good on the promises that they made yesterday. All we need, they might say, is to finally build a better code of points.

It is so much work to do all of this, and it takes [a lot of faith](https://x.com/seanjtaylor/status/1433636587699539996) to believe in it. Why should the next generation will have that faith? They were raised on taste, [aura farming](https://www.nytimes.com/2025/07/10/style/aura-farming-indonesia-boat-kid.html), and ChatGPT’s instant answers. Their politicians—Trump, Mamdani—won on instinct and [aesthetic](https://www.nytimes.com/2025/11/09/opinion/zohran-mamdani-aesthetic-new-york.html). Their heroes on Twitter are the [menswear guy](https://x.com/dieworkwear?lang=en), not Nate Silver. Their startups were more founder-mode than data-driven; their success came from their [agency](https://www.wsj.com/opinion/ai-is-a-boon-to-high-agency-people-entrepreneur-replit-cb495999) and not their analytical reasoning. They are [vibe native](https://www.washingtonpost.com/style/trends/2025/12/12/aesthetic-gen-z-meaning).

For those of us who are still trying to build a data-driven world, that may be the only context that matters: We can keep trying to bring data, but in vibes they trust. 


---


[^1]: Their website has several menus, the first of which is called “General Information.” The first item on that menu is “Bank Details,” which contains, without explanation, [all the information necessary](https://www.tas-cas.org/en/general-information/bank-details.html) to wire them money. Which, uh.

[^2]: Four! One Mississippi two Mississippi three Mississippi four Mississippi! About that long!

[^3]: Included in the lawsuit: Arguments about the Court of Arbitration for Sport sending important emails to the wrong address, very detailed discussions about video timestamps, and a debate about what it might mean that a video file was called “v3.”

[^4]: [As one commenter put it](https://x.com/ParkerOrtolani/status/1974308919401963839), “OpenAI might be winning with virality, but Anthropic could plant a flag squarely on the cultural edge and in a race this fast, taste can be power.”

[^5]: *Moneyball *didn’t end scouting in professional sports, but it made scouts subordinate to the statisticians.

[^6]: Or maybe it was a [U.S. defense contractor](https://www.quora.com/Who-said-Quantity-has-a-quality-all-its-own)?

================================================================================

# Pure heroin

*A different kind of buzz.*

---

![](https://substackcdn.com/image/fetch/$s_!Vk_D!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feb10751d-b6f3-4d4b-a266-f0bd4c9134af_892x713.png)
*[Lorde, in Brooklyn.](https://www.brooklynvegan.com/lorde-began-barclays-center-run-night-1-pics-video-setlist/)*

If you asked me why this blog exists, I couldn’t tell you. Though it [often](https://benn.substack.com/p/the-industrialization-of-it) [repeats](https://benn.substack.com/i/161617363/the-industrialization-of-it) [itself](https://benn.substack.com/i/164203877/the-industrialization-of-it), it is not here to make any particular point or achieve any particular ends. There was no central reason why it began, and there won’t be one for why it ends. It has no serious purpose; it is only here [to sing or to dance](https://www.goodreads.com/quotes/8587787-we-thought-of-life-by-analogy-with-a-journey-a) while the [music](https://www.youtube.com/watch?v=LsgNG-L6aw4) is being played.

That is: It’s entertainment, more or less. The world is full of interesting things, even in this erratic corner, and they are more interesting—and entertaining—to look at together. And so we are here: We hang out; we go home; I hope you had fun.

Still, there are lapses. Attention is a hell of a drug, and as you do something like this, you develop a loose intuition about the sorts of things that attract it. And sometimes, [you give in to temptation](https://x.com/bennstancil/status/1864817985770127430).

That is the [existential corruption of the internet](https://paulkrugman.substack.com/p/the-general-theory-of-enshittification), both for the people who use it and the companies that make it. Start honorably; get addicted; [step out](https://www.youtube.com/watch?v=rp4UwPZfRis). Substack, for example, [initially promised](https://on.substack.com/p/a-better-future-for-news) that “publishers will own their data, which we will never attempt to sell or distribute, and we won’t place ads next to any of our own or our customers’ products;” last week, they [began piloting native ads](https://substack.com/home/post/p-181141812) and forcing [mobile readers to download their apps](https://x.com/GergelyOrosz/status/1999241496005066755). And, partly in service of those goals, they show me dashboards of engagement metrics and [give badges](https://on.substack.com/p/badge) to their most popular writers; I get hooked and chase those, too.

It’s [Goodhart’s law](https://en.wikipedia.org/wiki/Goodhart%27s_law) for social media: When a good becomes a metric, it ceases to be good.

But, this is old news. We know that this is how social media works. [We’ve talked about this before:](https://benn.substack.com/p/the-scorpion-box)

> In direct and indirect ways—by liking stuff, by abandoning old apps and using new ones—we told social media companies what information we preferred, and the system responded. It wasn’t manipulative or misaligned, exactly; it was simply giving us more of what we ordered.
> The industry refined itself with devastating precision. The algorithms got more discerning. The products got easier to use, and asked less of us. The experiences became emotionally seductive. The medium transformed from text to pictures to videos to short-form phone-optimized swipeable autoplaying videos. We responded by using more and more and more of it.
> And now, we have TikTok: The sharp edge of the evolutionary tree; the final product of a trillion-dollar lab experiment; the culmination of a million A/B tests. There was no enlightenment; there was a [hedonistic experience machine](https://en.wikipedia.org/wiki/Experience_machine).

We know that this type of internet—one dialed to optimize engagement—can tear us apart in thousands of ways. It can make us [miserable](https://www.wsj.com/tech/personal-tech/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739); it can make us [dull](https://www.honest-broker.com/p/the-world-was-flat-now-its-flattened); it can make us [self-obsessed](https://lab.cccb.org/en/the-i-in-the-internet/); it can make us [murderers](https://x.com/bennstancil/status/1967701694458044870). It can destroy a [generation](https://www.theatlantic.com/magazine/archive/2017/09/has-the-smartphone-destroyed-a-generation/534198/). It can destroy a [democracy](https://www.usnews.com/opinion/articles/2025-01-14/how-social-media-is-polluting-our-public-spaces-and-devastating-democracy). Everyone from the [U.S. surgeon general](https://www.hhs.gov/sites/default/files/sg-youth-mental-health-social-media-advisory.pdf) to [Heineken](https://www.youtube.com/watch?v=UK8gP_12KVU) is worried about it.

But what do you do? Social media is too big to [regulate](https://www.politico.com/news/2024/12/25/mark-zuckerberg-meta-congress-bill-00195958), too integrated to remove, and we are too addicted to want to do either.

Anyway. What does OpenAI do? Roughly speaking, they build two things:

Sure sure, this is all very reductive and imprecise—the chatbot sits on top of the models; the models use data from the chatbot to improve; OpenAI makes other products, like [web browsers](https://chatgpt.com/atlas) and [computer chips](https://www.nytimes.com/2025/10/13/technology/openai-broadcom-chips-deal.html) and [data centers](https://openai.com/index/announcing-the-stargate-project) and [creative corporate financial solutions](https://www.nytimes.com/interactive/2025/10/31/technology/openai-fundraising-deals.html). But, as far as core services go, these are two big ones.[^1]

Of course, you could label them differently. You could call one “research” and the other “applications.” Or, more stylistically, “[safe and beneficial AGI](https://openai.com/charter/)” and “commercial products.” Or, even more stylistically, a “mission” and “money”—according to [some reports](https://www.saastr.com/openai-crosses-12-billion-arr-the-3-year-sprint-that-redefined-whats-possible-in-scaling-software/), about 80 percent of OpenAI’s revenue comes from ChatGPT subscriptions.

And for OpenAI, there are some [natural tensions between the two](https://www.theinformation.com/articles/openais-organizational-problems-hurt-chatgpt):

> Even as ChatGPT attracted more users this year, improvements to the underlying AI model’s intelligence—and the in-depth research or calculations it could suddenly handle—didn’t seem to matter to most people using the chatbot, several employees said. …
> The company’s research team had spent months working on reasoning models that spent more time computing answers to complex questions about math, science and other topics than ChatGPT’s previous models. … Most of the questions users asked ChatGPT, though, didn’t take advantage of those types of improvements. …
> Much of the time, ChatGPT users are “probably asking about pretty simple things, like movie ratings, where you wouldn’t need a model to think for half an hour.”

If you are trying to replace Google with an omniscient chatbot, you first worry about how smart the chatbot is. When people ask, “how long does it take to caramelize onions?,” it can’t blithely tell them “[five to ten minutes](https://gizmodo.com/googles-algorithm-is-lying-to-you-about-onions-and-blam-1793057789),” and it definitely can’t get confused and give them reviews of *Glass Onion: A Knives Out Mystery*. They will stop using your chatbot. But once your models are smart enough to solve that problem—once they can not only tell people how to caramelize onions, but can also give them an [entire menu for their dates](https://www.youtube.com/watch?v=To04SSylvVY)—more intelligent models might not make it more popular. It’s cool—and maybe good for humanity?—if your chatbot can solve the [world’s hardest brain teasers](https://x.com/alexwei_/status/1946477742855532918). But people use it, and pay you $20 a month for it, because they [like the UI](https://x.com/raizamrtn/status/1994493418354139335) and [remember the URL](https://stratechery.com/2025/google-nvidia-and-openai/#:~:text=changing%20the%20habits%20of%20800%20million%2B%20people%20who%20use%20ChatGPT%20every%20week%2C%20however%2C%20is%20a%20battle%20that%20can%20only%20be%20fought%20individual%20by%20individual.%20This%20is%20ChatGPT%E2%80%99s%20true%20difference%20from%20Nvidia%20in%20their%20fight%20against%20Google.).

When everything is booming, these two ambitions—superintelligent models and delightful chatbots, or research teams and product teams, or benevolent AGI and financial prosperity—can peacefully coexist. You can do everything. You can [spend $6.7 billion](https://www.theinformation.com/articles/openais-first-half-results-4-3-billion-sales-2-5-billion-cash-burn) on research and development, and [another $6.5 billion](https://www.nytimes.com/2025/05/21/technology/openai-jony-ive-deal.html) on famous product designers. You can have a mission and a business. And, as we’ve talked about before, you can sacrifice a bit of money [for the sake of your values](https://benn.substack.com/p/your-companys-values-will-be-used):

> Most people don’t want to lead or work at companies that are singularly motivated to make money as ruthlessly as possible. Most people would prefer some moderation—they would trade some corporate profits for better employee benefits, or cleaner factories, or promises to treat customers respectfully. Most people also care about *how* their employer tries to make money. … Though these ideas necessarily put constraints on how much money a company can make…it’s a deal that most people, including founders, executives and boards, want to make.

But, you know:

> *Everyone* *knows* that if Airbnb [or OpenAI, or whoever] isn’t making enough money, it will fire a bunch of people and tell others they need to work more. *Everyone knows* that making money—at least enough to survive—[will always be more important to Airbnb](https://www.nytimes.com/2020/07/17/technology/airbnb-coronavirus-layoffs-.html) than *how* it makes that money.

When you commit to spending [$1.4 trillion over the next eight years](https://x.com/sama/status/1986514377470845007), as OpenAI has, making enough money to survive means making *a lot* of money.[^2] So, when people start [loudly abandoning your chatbot](https://x.com/Benioff/status/1992726929204760661), or declaring your competitors’ products [as better than yours](https://x.com/mckaywrigley/status/1997403091365441742) “and it’s not close,” the tensions between solving novel math problems and building something that a billion people[^3] want to buy [quickly become real](https://www.wsj.com/tech/ai/openai-sam-altman-google-code-red-c3a312ad):

> When OpenAI CEO Sam Altman made [the dramatic call for a “code red”](https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6?mod=article_inline) last week to beat back a rising threat from Google, he put a notable priority at the top of his list of fixes.
> The world’s most valuable startup should pause its side projects like its Sora video generator for eight weeks and focus on improving ChatGPT, its popular chatbot that kicked off the AI boom.
> In so doing, Altman was making a major strategic course correction and taking sides in a broader philosophical divide inside the company—between its pursuit of popularity among everyday consumers and its quest for research greatness.
> OpenAI was founded to pursue artificial general intelligence, broadly defined as being able to outthink humans at almost all tasks. But for the company to survive, Altman was suggesting, it may have to pause that quest and give the people what they want.

And specifically, Altman wants to turn the dial to optimize for engagement:

> And it was telling that he instructed employees to boost ChatGPT in a specific way: through “better use of user signals,” he wrote in his memo.
> With that directive, Altman was calling for turning up the crank on a controversial source of training data—including signals based on one-click feedback from users, rather than evaluations from professionals of the chatbot’s responses. An internal shift to rely on that user feedback had helped make ChatGPT’s 4o model so sycophantic earlier this year that it has been accused of exacerbating [severe mental-health issues](https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide-6b67dbfb?mod=article_inline) for some users.
> Now Altman thinks the company has mitigated the worst aspects of that approach, but is poised to capture the upside: It significantly boosted engagement, as measured by performance on internal dashboards tracking daily active users.

We have seen how this goes. We’ve seen what happens when social media becomes a metric, and we’ve seen how seductive chatbots [can](https://x.com/hashtag/keep4o?src=hashtag_click) be [when](https://futurism.com/users-addicted-gpt-4o-convinced-openai-bring-back) they [want](https://www.wsj.com/tech/ai/i-feel-like-im-going-crazy-chatgpt-fuels-delusional-spirals-ae5a51fc) to be [engaging](https://www.wsj.com/tech/ai/openai-loosened-suicide-talk-rules-before-teens-death-lawsuit-alleges-34e830c1).[^4] Moreover, AI isn’t “just” social media—the chatbots sit on top of the models, the models learn from the chatbots, and *the models are [replacing all of our software](https://martinalderson.com/posts/ai-agents-are-starting-to-eat-saas/)*. OpenAI’s turn towards engagement doesn’t just alter our interactions with ChatGPT; it potentially alters our interactions *with [everything](https://benn.substack.com/p/a-new-invisible-hand#:~:text=AI%20is%20surely,mediate%20our%20relationships)*:

> AI is surely becoming a new invisible hand pulling the levers in our minds. It is some inscrutable new force that’s writing the first draft of history. It’s interpreting our data; it’s creating our websites; it might soon summarize our emails and brainstorm our ideas and suggest our dinners and [mediate our relationships](https://x.com/im_roy_lee/status/1914061483149001132).

OpenAI is already [too big to fail](https://www.axios.com/2025/12/13/open-ai-too-big-to-fail). What happens when it becomes too integrated to remove? What happens when the [mission](https://www.merriam-webster.com/dictionary/heroine) becomes less important than the [drug](https://www.merriam-webster.com/dictionary/heroin)? What happens when we become too addicted to care?

I saw Lorde a few days ago at the Barclays Center in Brooklyn. I was sitting in the upper deck, a couple of rows from the front and a few seats from the aisle. At the end of the aisle, there was a small overlook, with a clear view of the entire arena.

Throughout the show, groups of teenagers and twenty-somethings took pictures of each other standing in front of the overlook. Each group took dozens of pictures—individual pictures, different pairings of friends, different angles, live shots of people cycling through poses, one picture immediately after the other, like a model in a shoot. One group turned into a lighting rig—a girl took pictures; another stood a few feet to the side, with her phone’s flashlight angled slightly away from the main subject; a third stood behind the camera, partially covering her flashlight with her fingers, creating a makeshift diffuser. Several girls cycled through twice, evidently unhappy with their first shoot. And twice, when a group wanted pictures of everyone together, a girl across the aisle from me was recruited to be their photographer. She instinctively gave the same practiced stage direction. “Pull your shoulders back; look more to the left; let your jacket hang lower.” There was something almost poignant in it—a kind of solidarity, where every teenager understood what it took to survive.

That’s the world our metrics made—one in which we don’t sing and dance when the music is being played, but take pictures of ourselves instead. One in which we go to shows not to watch, but to perform. One in which we never bother to take in the view behind us, because we’re addicted to the camera in front of us.

We’re doing it all again. Though we don’t know exactly how this will play out—and it will likely create a [different kind of buzz](https://www.youtube.com/watch?si=t9HBM5BT4MHKK__e&t=64&v=nlcIKh6sBtc&feature=youtu.be)[^5] than social media did, and be more complex than “people date their chatbots”—we know how addicting attention can be. We know how tempting it is to seclude ourselves [in our own realities](https://www.newyorker.com/news/essay/on-the-internet-were-always-famous). We know the dangers of rewiring society on top of technologies that are optimized to be perpetually engaging. We know how much money OpenAI has to make. We know what happens when companies feel backed into corners, and have to decide between survival and their supposed values. We now know how OpenAI responded to their first “code red:” to immediately up our dosage, and see if we might buy more.

I use AI every day. I [like](https://benn.substack.com/p/a-strange-delight) it; my life is increasingly dependent on it; the rest of my career will probably be built around it;[^6] if I could use it to pump some Substack numbers and collect[^7] a few badges, I would be tempted to do that too. But at what cost?

[This blog](https://benn.substack.com/p/the-internet-2022) is prone to [melodrama](https://open.spotify.com/album/2B87zXm9bOWvAJdkJBTpzF?si=WLTwfwayRtSUg6giBTf9IA), so let me ask it plainly: *What is the plan here? *To have faith that it will all work out? To do nothing? To [get the bag and get out](https://jasmi.news/p/bait#:~:text=%E2%80%9CEveryone%E2%80%99s%20just%20trying%20to%20get%20their%20money%20and%20get%20out.%E2%80%9D)? To trust that the people in charge will do the right thing? To [apologize](https://www.pbs.org/newshour/nation/watch-im-sorry-zuckerberg-says-as-he-opens-senate-hearing-with-apology) later, when we’re standing in the rubble? Or to just hope—to hope that we’re handing the world over to [something that will save us](https://a16z.com/ai-will-save-the-world/), and not to a [drug dealer](https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html#:~:text=A%20growing%20body,in%20his%20work.) that’s a trillion dollars in debt, and selling a cannon of [pure heroin](https://open.spotify.com/album/0rmhjUgoVa17LZuS8xWQ3v?si=l_cEvRitTruDDpJLYboJAQ)?


---


[^1]: The three divisions with the [most open roles](https://www.anthropic.com/jobs) at Anthropic are “AI Engineering and Research” and “Product Engineering and Design”—and “Sales,” because the third thing that AI companies do is incinerate money.

[^2]: According to [estimates from Tomasz Tunguz](https://tomtunguz.com/openai-hardware-spending-2025-2035/), they need to make about $600 billion in 2029, which is [more than every company in the world](https://companiesmarketcap.com/largest-companies-by-revenue/) other than Walmart and Amazon.

[^3]: Even if a billion people bought ChatGPT for $20 a month, OpenAI wouldn’t be halfway to $600 billion.

[^4]: In an [earlier post](https://benn.substack.com/p/ban-chatgpt) on this topic—this blog often repeats itself—I [asked](https://docs.google.com/forms/d/1jhsxrnJK2mPiH-YnIPsUENgq9Yy7eQLECG9u9857vsY/preview) if people supported banning or limiting general chatbots like ChatGPT. Fifty-seven percent of people said we should already be doing this, 37 percent said we might need to do it in the future, and 6 percent said no.

[^5]: [And a different kind of banger.](https://www.youtube.com/watch?v=IiQxgfj985A)

[^6]: Unless, [you know](https://www.youtube.com/watch?v=VC1_tdnZq1A).

[^7]: This originally said earn, but, would it be?