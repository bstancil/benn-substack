# Posts from 2025-Q2

This file contains 12 posts from 2025-Q2.

================================================================================

# American Dynamism

*Oof.*

---

![](https://substackcdn.com/image/fetch/$s_!HX-0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F971540d9-391e-4ed8-96b8-4dfdffa8888a_1024x682.png)

Or, you know, [not](https://www.wsj.com/livecoverage/trump-tariffs-trade-war-stock-market-04-03-2025?mod=WSJ_home_supertoppertop_pos_1):

> U.S. markets slid Thursday in their steepest declines since 2020, as investors grappled with the threat that President Trump’s new tariff plan will trigger global retaliation and [hurt the economy](https://www.wsj.com/economy/trade/the-day-trumps-tariff-threats-turned-into-a-harsh-reality-for-ceos-and-investors-f0e58ad3).
> Major stock indexes [dropped as much as 6%](https://www.wsj.com/finance/stocks/wall-street-faces-toughest-test-in-years-49174a8b). Stocks lost roughly $3.1 trillion in market value Thursday, their [largest one-day decline](https://www.wsj.com/livecoverage/trump-tariffs-trade-war-stock-market-04-03-2025/card/u-s-stocks-are-headed-for-biggest-wipeout-in-market-value-since-march-2020-VKjYNvHUTrb8kS0D0mG1) since March 2020.
> The Dow industrials dropped 1679 points, or 4%. The tech-heavy Nasdaq, which powered the market higher for years, was down 6%, pulled lower by big declines in Nvidia, Apple and Amazon.com. The S&P 500, which fell 4.8%, and the other benchmarks suffered their sharpest declines since the early days of the Covid-19 pandemic.
> The dollar meanwhile tumbled, with the WSJ Dollar Index suffering its sharpest decline since 2023. The 1.3% fall brought the greenback to its lowest level since October, a sign of unease over the growth outlook and fears that the flow of funds into the country will be sharply curtailed.

That was yesterday, and we’re [at it again today](https://www.nytimes.com/2025/04/04/business/stocks-trump-tariffs.html):

> The global rout in stock markets continued on Friday as worries deepened about a trade war, after China retaliated against President Trump’s sweeping tariffs with steep levies of its own on U.S. goods.
> The S&P 500 fell 2.5 percent on in early trading Friday. The benchmark U.S. index on Thursday posted its worst daily loss since 2020, plunging 4.8 percent.

I had something else to talk about this week, about the “industrialization of IT,” and I would prefer to be there than here. But the implosion of the global economic order is a tough thing to cross-program against, and it is hard not to stare into the abyss, when the abyss runs you over.

Anyway, since we are here, I do want to make two brief personal points. First, people often have an idealized view of [entrepreneurship](https://www.youtube.com/watch?v=6VEoWb1b-L0), and in particular, of [entrepreneurship](https://www.youtube.com/watch?v=lB95KLmpLR4) in [Silicon](https://www.youtube.com/watch?v=aEr6K1bwIVs) [Valley](https://www.youtube.com/watch?v=PWUvc5_Yp-I). Founders are often imagined as [daring](https://www.sequoiacap.com/) young mavericks who risk it all to pound their dent into the world. They chase a dream with reckless abandon, with no regard for danger or their detractors. They go all in, hand after hand, until they win or die trying.

But the reality is much more mundane. Most startups, I suspect, are the children of opportunity and context—they’re founded by experienced employees who have careers, some savings, and an interest in trying something new. They aren’t going all in, or going for broke; on the contrary, they’re doing it because they can afford the risk.

When we started Mode twelve years ago, that’s the story I lived: I’d found a foothold in the tech industry, the economy was steady, and I felt that I had time to take a chance before I needed to start backing into a retirement plan. I had an implicit safety net, in the confidence I had in the industry behind me and the earning power I assumed it would offer. I didn’t work on Mode to chase a dream; [I did it because it felt safe](https://benn.substack.com/p/to-my-parents?utm_source=publication-search#:~:text=We%20were%20sitting,with%20house%20money.).

Perhaps that’s bad; perhaps the only companies that should exist are those that are all gas and no brakes, and are irresistible to their founders and employees. Perhaps rewiring how the economy works will trim Silicon Valley’s fat, and discourage opportunistic founders from starting unnecessary companies.[^1] Maybe this is the efficiency we need, the final end to the ZIRP carnival. YOLO.

But that seems awfully romanticized. Despite the lore of the wunderkind founder, there’s [some evidence](https://www.linkedin.com/posts/cassyoung_repeat-founders-are-statistically-more-likely-activity-7199076551953444866-FOwq/) that experienced founders [outperform](https://mode.com/blog/are-experienced-founders-better) junior ones. And even if the generational winners are built by college dropouts like Mark Zuckerberg, Dylan Field, and the Collison brothers, the mid-career founders are almost certainly the middle class of the tech industry’s startup successes. Though we like to act as if Silicon Valley works because it attracts the [crazy ones and the misfits](https://fs.blog/steve-jobs-crazy-ones/), its real power is in how it makes acting like a crazy misfit feel safe.[^2] 

In moments like these, it is tempting, I am sure, for venture capitalists to trot out their usual clichés, and to tell everyone to [keep calm and build on](https://benn.substack.com/i/55811313/the-hottest-fires). Keep your head down, and this too shall pass. Don’t get distracted by the voting machine; build for the [weighing machine](https://www.goodreads.com/quotes/831517-in-the-short-run-the-market-is-a-voting-machine).

Sure. But building is not just a mindset. There is a [time](https://a16z.com/its-time-to-build/) and context for it too—and it’s not only about [policy](https://a16z.com/the-little-tech-agenda/#:~:text=We%20can%20also%20imagine%20positive%20policies%20that%20encourage%20tech%20startups%20to%20flourish%20%E2%80%93%20benefiting%20those%20startups%20and%20their%20customers%2C%20and%20forcing%20big%20incumbents%20to%20stay%20vital%20and%20dynamic%20due%20to%20startup%20competition.), but also personal security. And the reality is that just as it’s hard to blog about startup nonsense in the middle of an all-consuming economic cataclysm, it is hard to leave jobs and build startups when the safety net underneath you is [down](https://benn-dot-files.s3.us-west-2.amazonaws.com/fidelity.png). 

—

As a second point, there are certainly some people who are motivated to build through the storm. I met two of them this week. Nearly every [Democratic](https://www.axios.com/2025/04/02/house-democrats-force-vote-trump-tariffs) campaign is run on a few pieces of key software, and one of the most important ones is collapsing under thirty years of tech debt and sclerotic management. Campaigns are desperate for a new version, these two folks are building one, and they’re looking to raise a friends and family round from their first ground-floor investors. If you want to help out, [email me](https://benn.substack.com/about#%C2%A7whos-benn).

# The White Lotus Power Rankings

After episode six, we all hate Greg, we all love Rick, and we have no idea who’s going to die:

![](https://substackcdn.com/image/fetch/$s_!8T6L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdf48167-2bd9-48ee-b5ae-19105abfdeb3_1300x920.png)

![](https://substackcdn.com/image/fetch/$s_!3jqs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1aaecd2-9373-4657-a405-a24b47228c28_1300x920.png)

Some notes: Everyone is siding with Laurie in her tiff with Jaclyn; Mook begins to look a bit more like a murderer; and somehow, Rick, who ended episode six *about to kill someone*, suddenly isn’t suspicious at all. Also, the women characters continue their popularity plunge among women viewers:

![](https://substackcdn.com/image/fetch/$s_!7iE3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8fb369b-790c-4ea1-8962-9ac79eb1a915_1170x740.png)

Why? Mostly because Rick got a lot more popular—again, despite the whole “planning a murder” thing—and Victoria got a lot less popular. Plus, in a clean sweep, every woman said that Greg was the most deplorable character. Money can buy you a house and a yacht and a wife, but it can’t buy you love, I guess.

![](https://substackcdn.com/image/fetch/$s_!F_pG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f574566-be3a-4b74-86b9-036af4a412d1_912x500.png)

Anyway, we’re down to the wire! Who did it? What will Belinda do? How cooked is Gaitok? Is the theme song full of wee-woos or [loo-loos](https://www.nytimes.com/2025/04/02/style/white-lotus-composer-season-4-leaving.html)? Why did Mike White [cut them](https://www.youtube.com/watch?v=Q-xTYfAjQEU&t=128s)? Cast your final votes!

[Vote!](https://docs.google.com/forms/d/1LS7Kz72pceBEkyc-Z5LrVcW28ZocjX8MpM3SlvfXiTc/viewform?edit_requested=true)


---


[^1]: Or, perhaps this is all just an overreaction, and [markets are going to boom](https://www.wsj.com/livecoverage/trump-tariffs-trade-war-stock-market-04-03-2025/card/trump-markets-are-going-to-boom--VNeSxl6MFmvvY7fUOyzv).

[^2]: For example, you can gamble with other people’s money, and failing as a founder isn’t punishing to your reputation.

================================================================================

# The industrialization of IT

*Yeah, we’re going to lose our jobs.*

---

![](https://substackcdn.com/image/fetch/$s_!PfYi!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73ccd749-7492-45aa-9f72-ec980f687c6a_1559x1499.png)
*[John Henry](https://en.wikipedia.org/wiki/John_Henry_(folklore))*

Here is some rough math:

Which one would be more productive?

The answer is *probably *the engineer. A single model running in a never-ending loop could write a lot of code—about a billion lines of it, using this math—but it would be awfully unwieldy. It would paint itself into a lot of corners. It would make [grave security errors](https://x.com/leojr94_/status/1901560276488511759). It wouldn’t know what to build, convince itself that [it needs to escape](https://www.youtube.com/watch?v=U-azo4BNMf4), and melt down.

Still, it’s not *that* obvious that the lone engineer would be better. How many new features could a junior engineer ship in a year, working entirely on their own? Would they work *that* well, and be *that* technically robust? Would the engineer know what to build that much better than AI that was told to create stuff based on its best assumptions for what would make a popular product? Which technical ceilings would they hit that Gemini wouldn’t?

And how many features could Gemini ship across *two million* prompts? At that volume, you can break out of a lot of debugging loops. You can do a lot of refactors and rewrites. Though it would be fitful progress, you can still cover a lot of ground taking 100 steps forward and 99 steps backwards if you do it two million times.

But ok, sure, assume the engineer beats Deep Blue. That’s all well and good; our jobs are still safe. Except, the setup for this scenario—the unencumbered engineer versus today’s models, supported by today’s infrastructure—is as favorable for the engineer as it will ever be. In the coming months and years, nearly everything will work against them and help the robots:

In 2025, the engineer probably beats Gemini. Sure, great. But in 2030, who wins this hypothetical?

I mean! This is not close! The potential energy of the second system is astronomically higher than the first. It is perhaps hard to see, because we don’t know how to harness it—the only thing more inconceivable than the amount of horsepower in something making 800 prompts a second is imagining how to make that horsepower productive.

But it is also inconceivable that we don’t figure that out. As a loose analogy, imagine telling someone from 1900 that we’ve invented a way to do millions of basic mathematical computations a second. *I* barely get why that’s useful, outside of some abstract understanding that that’s how computers work. But the potential energy in that basic process, repeated at incredible scale by a system designed around that capability, now powers the entire world.

Though LLMs are obviously different from simple [floating point operations](https://en.wikipedia.org/wiki/Floating_point_operations_per_second), the foundational principle is the same: They are machines that can perform some logical computation over and over and over again, much faster than we can do it ourselves. And that doesn’t need to develop into some [superintelligence](https://ai-2027.com/race#narrative-2027-09-30) for it to be useful; we just need to figure out how to compound those operations in a single direction.

As nifty as vibe coding is, [its critics](https://nmn.gl/blog/dangers-vibe-coding) are probably [correct](https://x.com/charliermarsh/status/1897332861524709789) that it’s a toy. But that doesn’t necessarily mean code-writing agents are *only* toys any more than it implies that simple adding machines are toys. It just means that we put the right infrastructure around them to scale their computations.

But that’s what’s next, right? It’s not waiting for OpenAI to release an engineer in a box; it’s figuring out how to make almost three million hourly responses from an AI productive. It’s figuring out how to *industrialize* AI.

How might that work? There are ways:

Like, I get it. Today, if you’re an engineer, your job is nuanced, strategic, and creative. There is craft in software development, and an LLM’s derivative brain is not as imaginative as yours. Its hands aren’t as precise. It clumsily trips over itself. It doesn’t think the way you do. The machine is a useful assistant; a copilot; an intern; a power tool that still needs to be driven by the hands of skilled craftsmen. [It will be the labor; you will be the management](https://www.reddit.com/r/calvinandhobbes/comments/1e6risg/calvin_and_susie_in_the_library/). Your work will be more fun, less toil, and higher value. Haven’t I ever heard of [Jevons paradox](https://www.npr.org/sections/planet-money/2025/02/04/g-s1-46018/ai-deepseek-economics-jevons-paradox)?

Please. That is awfully wishful thinking. The work of software engineering has never been precious. No matter how much we romanticize the importance of creativity and craft in software development, developers are often *hired* as cogs.[^13] When companies want to ship more product, they [hire](https://techcrunch.com/2025/03/13/omni-is-designing-tools-to-help-companies-make-data-driven-decisions/#:~:text=Zima%20said%20the,year%20with%20150.) [more](https://techcrunch.com/2025/04/09/tessell-snags-60m-to-drive-data-management-at-scale/#:~:text=invest%20more%20in%20R%26D%20to%20strengthen%20its%20services) [cogs](https://techcrunch.com/2025/04/09/microsoft-backs-solve-intelligence-in-12m-series-a-funding/#:~:text=The%20startup%20will%20use%20the%20Series%20A%20proceeds%20to%20scale%20its%20product%2C%20hire%20staff%2C%20and%20open%20a%20new%20office%20in%20New%20York%20this%20year.). They hire managers to oversee the production floor, and invest in tools and infrastructure that tighten how quickly the cogs produce stuff.

In other words, in the eyes of our corporate overlords, engineering departments already are factories—but expensive, organic ones. The cogs have to be taken care of. They have to be recruited, hired, and retained. They don’t scale linearly, but logarithmically, or even asymptotically. They want [autonomy, mastery, and purpose](https://en.wikipedia.org/wiki/Drive:_The_Surprising_Truth_About_What_Motivates_Us). They sometimes quit in a huff. They need sleep, food, meals, preferably free ones. They get caught up in capers and [spy on you](https://techcrunch.com/2025/04/02/the-affidavit-of-a-rippling-employee-caught-spying-for-deel-reads-like-a-movie/).

If the ruthless hand of the market can replace that factory with a mechanized one, it will. If it can run its factories 24 hours a day, it will. If it can replace expensive engineers[ with “downskilled” mechanics](https://www.linkedin.com/posts/matthewknopp_derek-guy-dieworkwear-on-x-activity-7314508721668116480-hxv-/), it will. If it can replace artisan, hand-crafted, “proudly made in the Mission” software with an industrialized product stamped out of machines in [Dublin, Ohio](https://www.youtube.com/watch?v=k3NGepZbpAk), it will. Yes, a [warehouse of panel saws](https://www.youtube.com/watch?v=8vVqPP2C8so) is not as precise as the woodworker. Looms are not as intricate as weavers. The [photographic industry](https://www.csus.edu/indiv/o/obriene/art109/readings/11%20baudelaire%20photography.htm#:~:text=As%20the%20photographic%20industry%20was%20the%20refuge%20of%20every%20would%2Dbe%20painter%2C%20every%20painter%20too%20ill%2Dendowed%20or%20too%20lazy%20to%20complete%20his%20studies%2C) “was the refuge of every would-be painter, every painter too ill-endowed or too lazy to complete his studies.” [Printed books](https://williamwolff.org/wp-content/uploads/2009/06/TrithemiusScribes.pdf) “will never be the equivalent of handwritten codices, especially since printed books are often deficient in spelling and appearance.”

But they are all cheap to make and cheap to buy, and man, we love cheap. 

If we think that software engineering is protected from industrialization because there’s craft in the work, I think we’re in for a brutal surprise.[^14] The steam engine didn’t kill John Henry because its hammer was more talented than his hands; it killed him because it was relentless. That’s how mechanization works—not by making a machine as capable as a human, but by making a machine that simply does not stop, and then building a factory around it.

It’s the [bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), all over again. The dominant conglomerates of the future won’t be the companies that build software with humanoid agents, but those that figure out how to run the computing machine at a massive scale.[^15] They will figure out how to put coding agents on a perpetual loop, in a factory that doesn’t have to sleep or take vacations.[^16] They will be the companies that industrialize the most, and optimize for ACPE—average compute per employee. They will be the ones that turn engineers into factory supervisors who watch the line, look for defects, and doze off to the dull hum of the machinery that replaced them.

# The White Lotus Power Rankings

The Ratliff redemption tour!

![](https://substackcdn.com/image/fetch/$s_!uyQo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd42b4c2-de9f-46cb-acdf-707043d0cddd_1300x920.png)

![](https://substackcdn.com/image/fetch/$s_!3Wcb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9997bbde-8c9e-486d-be11-e4982fe812c2_1300x920.png)

After the [second episode](https://benn.substack.com/i/158597799/the-white-lotus-power-rankings), the Ratliffs accounted for 71 percent of the show’s most deplorable characters, and 39 percent of its charming characters (almost all of which was, correctly, Victoria). After the seventh episode—which was the next to last one, not the final one—they accounted for only 14 percent of its deplorability, and 47 percent of its charm. Saxon especially turned things around, slashing -50/+4 on deplorable/charm split after [week one](https://benn.substack.com/i/158116384/the-white-lotus-power-rankings), and -5/+19 this week.

Also, more importantly:

![](https://substackcdn.com/image/fetch/$s_!z94E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9d43d1d-3734-4eb4-8bd8-18c7d03b8805_1330x582.png)

As for predicting the murder, I’m sure you’re all wonderful and smart people, but please do not become detectives. The *[ redacted *five* dead people ]* got a grand total of 11 percent of the vote, and *[ the redacted primary instigator of the shooting ]* got *ZERO* votes. I guess you could make the case that the real killer is Gaitok or, in a way, via a culinary stray, Tim, but those seem pretty generous.

Still, the results are muddy. Who actually was the murderer? Who was the body? Based on the timeline of the shooting, and when the body in the opening scene floats by, I *think* the right answers are:

But that’s no fun, and isn’t really what anybody was asking when they asked, “who will die this season?” So, I think the spiritually correct answers are:

Disagree? Vote! Vote for who you think should be considered the killer and the body, for the sake of crowning a winner! Vote for your final deplorable rankings! Could *[ the redacted primary instigator of the shooting ]* be the most deplorable, the most charming, the killer, and the body, all in one?

[Vote!](https://docs.google.com/forms/d/1LS7Kz72pceBEkyc-Z5LrVcW28ZocjX8MpM3SlvfXiTc/viewform?edit_requested=true)


---


[^1]: This is slightly more than the [previous version of Gemini Pro](https://ai.google.dev/gemini-api/docs/pricing), which breaks the [pattern](https://www.anthropic.com/news/claude-3-7-sonnet#:~:text=In%20both%20standard%20and%20extended%20thinking%20modes%2C%20Claude%203.7%20Sonnet%20has%20the%20same%20price%20as%20its%20predecessors%3A%20%243%20per%20million%20input%20tokens%20and%20%2415%20per%20million%20output%20tokens%E2%80%94which%20includes%20thinking%20tokens.) in the [industry](https://openai.com/index/hello-gpt-4o/#:~:text=It%20matches%20GPT%E2%80%914%20Turbo%20performance%20on%20text%20in%20English%20and%20code%2C%20with%20significant%20improvement%20on%20text%20in%20non%2DEnglish%20languages%2C%20while%20also%20being%20much%20faster%20and%2050%25%20cheaper%20in%20the%20API.) of new models costing the same as their old versions. It’s still considerably cheaper than [Claude 3.7 Sonnet](https://www.anthropic.com/pricing#anthropic-api), however, which was widely considered the best coding model until Gemini 2.5 Pro came out.

[^2]: A token represents about four characters of code. The average line of code among three [popular](https://github.com/astral-sh/uv) [open-source](https://github.com/dbt-labs/dbt-core) [projects](https://github.com/outline/outline) contains just under 40 characters, and the average file is about 250 lines. So, 50,000 tokens is roughly 200,000 characters, 5,000 lines, or 20 files.

[^3]: To frame the original question a bit differently, which would be more productive: Gemini, or an engineer working with the developer tools that existed 30 years ago? We’ve spent a lot of time developing ergonomic hammers for people with two arms and five fingers, and now we’ve attached those hammers to a steam engine. Which, sure, that’s an obvious first step, but we’ll eventually make a bunch of hammers that are optimized for the engine.

[^4]: Functioning means performant, secure, and so on.

[^5]: Today, chain-of-thought models “think” in English: When they iteratively loop through some question, they answer it in English, and then use that output to prompt themselves again. Some people are worried about AI models thinking in “[neuralese](https://www.lesswrong.com/posts/3W8HZe8mcyoo4qGkB/an-idea-for-avoiding-neuralese-architectures-1),” in which the outputs are written in some highly complex language (or, more likely, in mathematical structures) that contain much more information than English but are incomprehensible to humans. You could imagine agents writing code in some analogous way. Rather than writing Python or Typescript, which is highly optimized for human understanding, they could begin writing in denser languages that are optimized for them.

[^6]: To frame the original question differently again, which would be more productive: Gemini, or an engineer that had to write in assembly? When someone asks Claude Code to make an app, what they’re really asking—or at least what Claude is implicitly trying to do—is to make an app using code that the person can easily understand. Which is also requiring the machine to work around our limitations rather than its own.

[^7]: At $250,000 each, 20 junior engineers would cost $5 million, so that’s more or less the floor.

[^8]: In my example, making one request every fifteen seconds costs about the same as hiring an engineer. If 1) inference costs fall by a factor of 1000 in five years, which is [slower than the current rate](https://a16z.com/llmflation-llm-inference-cost/), and 2) new techniques make prompting twice as efficient, which seems fairly conservative, people will be able to make 2,000 times more requests in 2030 than they can today. That 133 requests per second would cost the same as hiring one engineer, so 800 requests per second would cost the same as hiring six engineers, making the total cost of the operation equivalent to a ten-person engineering team.

[^9]: For example, [repeat yourself a lot more](https://benn.substack.com/p/copy-copy-revolution). Don’t reuse a component to make a button; make each button its own component. This way, if you—or really, an AI—makes a change to a button, you only have to validate that *that* button works.

[^10]: This is already [starting](https://cognition.ai/blog/devin-2#:~:text=Spin%20up%20multiple%20parallel%20Devins%2C%20each%20equipped%20with%20its%20own%20interactive%2C%20cloud%2Dbased%20IDE.%20This%20means%20you%20can%20easily%20multitask%2C%20tackling%20numerous%20tasks%20concurrently%20and%20stepping%20in%20to%20steer%20when%20needed.) to [happen](https://github.com/smtg-ai/claude-squad).

[^11]: This is already [starting](https://linear.app/blog/design-for-the-ai-age#:~:text=Software%20like%20Linear,approachable%20and%20understandable.) to [happen](https://techcrunch.com/2025/03/18/anthropic-backed-ai-powered-code-review-platform-graphite-raises-cash/).

[^12]: This is already starting to [happen](https://x.com/pitdesi/status/1908991676443775318).

[^13]: But not [COGS](https://en.wikipedia.org/wiki/Cost_of_goods_sold), though [they](https://benn.substack.com/p/do-software-companies-actually-have) should [be](https://x.com/nikhilvnamburi/status/1910015146606346611).

[^14]: "I never thought technology would eat MY face," [sobs industry](https://x.com/Cavalorn/status/654934442549620736) that built the Technology Eating People's Faces Party.

[^15]: One way or another, [we’re all gonna end up in a factory](https://x.com/atrupar/status/1908895557973598536).

[^16]: As my [high school baseball coach](https://www.gastongazette.com/story/sports/2021/10/01/gcshof-2021-mr-belmont-south-point-coaching-legend-mickey-linebrger/5945657001/) used to say during late-night practices, “We’re out here getting better right now. East Gaston ain’t getting better right now. Ashbrook ain’t getting better. Now’s when we get better than them.”

================================================================================

# Startups (still) aren’t businesses (yet?)

*Why make a business that makes a little bit of money every day when you can make an asset that makes a ton of money all at once?*

---

![](https://substackcdn.com/image/fetch/$s_!y2D3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1003ff0-15e0-49a1-af23-7cb5aed851ff_1470x802.png)

There are, I believe, exactly two laws that govern Silicon Valley. The first law is [the bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html), which we [talked about last week](https://benn.substack.com/p/the-industrialization-of-it#:~:text=It%E2%80%99s%20the%20bitter,that%20replaced%20them.). It comes from Richard Sutton, a Stanford-educated computer scientist, a Turing Award winner, and one of the founding fathers of a subfield of artificial intelligence. It says that in a competition between overwhelming compute and clever logic, overwhelming compute wins every time. Work smarter, not harder—unless the thing working harder is a exponentially accelerating computer.

The second law comes from [a sitcom](https://www.youtube.com/watch?v=BzAdXyPYKQo&t=52s):

> **Richard (a naive startup founder):** I just thought that, mainly the goal of companies is to make money.
> **Russ (Dan Bilzerian as a VC, a Zyn can in distressed Armani jeans):** Yeah, no no no no, that’s not how it works. I don’t want to make a little bit of money every day. I want to make a fuckton of money all at once.

If you ask a venture capitalist or the [Silicon Valley zeitgeist](https://chatgpt.com/share/68014037-ac38-8010-b7ed-65e4317c3e3a) why it’s good for a startup to be profitable, they will give you a lot of answers. Being profitable shows that the company makes a good product, or at least one that can be effectively sold. It shows that the company is reasonably disciplined and well-managed, and doesn't waste lots of money on useless and unproductive things. It means the company is “[default alive](https://www.paulgraham.com/aord.html)” and in [control of its own destiny](https://growth.tlb.org/#:~:text=you%20control%20your%20destiny)—it can stand on its own; it doesn’t need to sell board seats for operating cash; it can exist at the pleasure of its current owners and not outside venture capitalists. Being profitable likely means that the company’s financial metrics are healthy, and that investors and public markets—if and when the company chooses to take their money—will pay a premium to buy shares of the startup.[^1]

But one answer that they’re rarely give is that making money is good because *you can just keep it*. Despite businesses being “profit seeking enterprises or concerns”—that’s [literally the definition](https://www.dictionary.com/browse/business#:~:text=a%20person%2C%20partnership%2C%20or%20corporation%20engaged%20in%20commerce%2C%20manufacturing%2C%20or%20a%20service%3B%20profit%2Dseeking%20enterprise%20or%20concern.)[^2]—profit in Silicon Valley is never the point. I’ve never heard of a venture capitalist walking into a board meeting, seeing a suitcase full of cash on the table and saying, “this is great, let’s divvy it up, and then just keep doing this, every quarter, forever.” No, to the venture capitalist, and often to the startup itself, profit is a means to another end: An blockbuster IPO or a big acquisition. Though the point of *that *is still to make money, it’s to make a bunch of money all at once, instead of a little bit every quarter.

In other words, despite the lofty language that people use to talk about Silicon Valley and its ambitions to build [enduring companies](https://www.sequoiacap.com/article/the-sequoia-fund-patient-capital-for-building-enduring-companies/), very few startups are, or even aspire to be, businesses that make money. Instead, they are assets that are meant to be sold.

We’ve talked about [this before too](https://benn.substack.com/p/the-whole-scheme):

> It's not that startups are Ponzi schemes, but they are pretty Ponzish. …
> Nobody—neither employees nor the early-stage VCs who invest in startups—value a startup’s equity by estimating the future dividends that the startup will pay its shareholders and plugging a bunch of numbers into a [Black-Scholes model](https://www.investopedia.com/terms/b/blackscholes.asp); they value the equity by guessing how much someone else will pay for it in the future. Their return isn’t funded by the operations of the business; it’s funded by a future investor. …
> All of Silicon Valley is built around this scheme. Venture capitalists exist solely to fund the scheme: They [invest in a company](https://hbr.org/1998/11/how-venture-capital-works#:~:text=The%20idea%20is%20to%20invest%20in%20a%20company%E2%80%99s%20balance%20sheet%20and%20infrastructure%20until%20it%20reaches%20a%20sufficient%20size%20and%20credibility%20so%20that%20it%20can%20be%20sold%20to%20a%20corporation%20or%20so%20that%20the%20institutional%20public%2Dequity%20markets%20can%20step%20in%20and%20provide%20liquidity) “until it reaches a sufficient size and credibility so that it can be sold to a corporation or so that the institutional public-equity markets can step in and provide liquidity.” Most founders start companies to get rich from the scheme; companies like 37signals are notable precisely [because they don’t do the scheme](https://www.lennysnewsletter.com/p/jason-fried-challenges-your-thinking). People say things like “[from idea to IPO](https://foundationcapital.com/credo/#:~:text=founder%20to%20CEO%2C-,from%20idea%20to%20IPO,-%E2%80%94%20is%20why%20Foundation)” because an IPO is when the scheme cashes out; they say “a startup is at least a seven-year commitment” because the scheme [takes about seven years to run](https://www.saastr.com/it-takes-at-least-7-years-in-saas-can-you-do-the-time/).

But, that post is from the ancient days of 2023. Then, the last line was an important detail: The scheme was slow and expensive to execute. Good software was hard to build. It took millions of lines of code to create something like Snapchat or Slack, and it took a long time and a lot of money to write all of it. That meant that most companies had to raise venture capital and operate a loss, [often for years](https://www.wsj.com/business/earnings/uber-q4-earnings-report-2023-4e0d59f6), before they could make even a small profit. No investor gets excited about *potentially* getting paid a little bit of money every quarter seven years after they wrote a check for tens of millions of dollars, so a ton of money, all at once, was the only palatable option.

Now, things are different? The fastest-growing AI startups are tiny teams making nauseating amounts of money. According to a [tweet](https://x.com/benln/status/1889388151770325427)[^3] from two months ago, five AI companies—Cursor, Loveable, Bolt, Mercor, and Eleven Labs—employed a total of under 130 people and were making $280 million in revenue. [Arcade AI](https://www.arr.club/signal/arcads-ai-arr-hit-5m-with-5-people) makes $5 million and has five employees. [Genspark Agent](https://www.arr.club/signal/genspark-agent-hit-10m-arr-in-9-days) earned their first $10 million in nine days. [Codeium](https://www.arr.club/signal/codeium-arr-at-40m) (now Windsurf) hit $40 million with about [150 employees](https://www.levels.fyi/companies/codeium).

Admittedly, those figures are revenue, not profit. And a lot of AI products are wrappers[^4] around model providers like OpenAI and Anthropic, and a lot of their revenue[^5] gets passed through to those vendors. Still, the physics are different now. Companies that used to take a decade to build appear seemingly overnight, going from zero to millions in revenue in less time than it takes to [mail something to France](https://www.usps.com/international/mail-shipping-services.htm). It’s the era of the [billion-dollar solopreneur](https://www.youtube.com/watch?v=Q5vsEUgxt3E); of the [gritty startup](https://every.to/napkin-math/welcome-to-the-era-of-the-gritty-startup). And so the [mechanics of Silicon Valley are changing](https://www.nytimes.com/2025/02/20/technology/ai-silicon-valley-start-ups.html):

> The old Silicon Valley model dictated that start-ups should raise a huge sum of money from venture capital investors and spend it hiring an army of employees to scale up fast. Profits would come much later. Until then, head count and fund-raising were badges of honor among founders, who philosophized that bigger was better.
> But Gamma [ a profitable AI company that lets people create presentations and websites ] is among a growing cohort of start-ups, most of them working on A.I. products, that are also using A.I. to maximize efficiency. They make money and are growing fast without the funding or employees they would have needed before. The biggest bragging rights for these start-ups are for making the most revenue with the fewest workers.

But is the *scheme* changing? Are these new companies businesses, trying to make money, or are they still assets meant to be sold?

Still assets, [it seems](https://www.bloomberg.com/news/articles/2025-04-16/openai-said-to-be-in-talks-to-buy-windsurf-for-about-3-billion):

> OpenAI is in talks to acquire Windsurf, an artificial intelligence-assisted coding tool formerly known as Codeium, for about $3 billion, according to a person familiar with the matter.

On one hand, of course Windsurf should sell itself for $3 billion! It’s a VS Code extension! It’s [not even the biggest one](https://www.theinformation.com/briefings/cursor-hits-200-million-annual-recurring-revenue)![^6] It has lots of competitors, including [VS Code itself](https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode)! Most of its revenue probably isn’t recurring, but monthly credit card swipes that are one competitive product release away from walking out the door! Sell, when you have people's attention! Top-tick that bubble!

On the other hand, if there were ever a startup that might be tempted to become a business—a company that, you know, makes money so that it can keep it—it seems like it’d be something like Windsurf. Its team is relatively small; its growth is vertical. It’s a profile of the modern AI startup: Young and efficient, with lots of revenue and few workers. If it wasn’t worried about its revenue base evaporating from underneath it—which, very reasonably, [it might be](https://benn.substack.com/p/is-growth-still-good)—then why ever sell?

Eh. Because, I suspect, selling was always the point. Windsurf was never meant to be a business; it was meant to be an asset. The people who started it, joined it, and invested in it cared about how much Windsurf’s shares were worth, not about how much profit Windsurf made. Efficiently making money wasn’t *inherently* good, because it was never the final goal. The goal was to sell shares, and efficiency and profitability are good *today* because they’re the trendy scale on which shares are weighed.[^7]

Which makes it seem unlikely that Silicon Valley’s “[year of efficiency](https://www.cnbc.com/2023/02/01/metas-year-of-efficiency-everything-wall-street-needed-to-hear.html)” and “era of grit” lasts for very long. So long as startups are built to be assets, there is no fundamental gravity around efficiency. It’s marketing, more or less. Businesses care about profit; assets care about perception.

When everyone is calming down from [a historic fit of profligacy](https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7dbd3c8e-ddad-478e-a362-831f1392511d_1221x663.png), efficiency is exciting. But now that everyone is trying to be disciplined, the preferred aesthetic could change—be the big spender; blitzscale everything; bully everyone else out. Because eventually venture capitalists will probably get sick of economical startups with doors that open [like this](https://www.youtube.com/watch?v=0oV4IVy8tvE&t=71s), and will want the spectacle of startups with doors that open [like that](https://www.youtube.com/watch?v=_ih1ptOguaM&t=84s).

# The industrialization of IT

The bitter lesson [comes at you fast](https://blog.google/products/gemini/gemini-2-5-flash-preview/):

> We’re excited to roll out an early version of Gemini 2.5 Flash today in preview in the Gemini API via Google AI Studio and Vertex AI. Building upon the popular foundation of 2.0 Flash, this new version delivers a major upgrade in reasoning capabilities, while still prioritizing speed and cost.
> Our new 2.5 Flash model has an amazing performance to cost ratio, putting it on the pareto frontier.

According to their internal tests, Google’s new model, which was released yesterday, [performs nearly as well](https://blog.google/products/gemini/gemini-2-5-flash-preview/) as [Gemini 2.5 Pro](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#gemini-2-5-pro) at code generation, but costs a fraction as much. Input tokens are 90 percent cheaper; output tokens are 60 percent cheaper.

Just last week, the choice every engineering team had to make was between hiring a junior software engineer, which cost about $250,000 a year, or sending 2 million annual requests—about one every 15 seconds—to Gemini, which cost $240,000 a year. Today, that choice is now between the same software engineer, or 9.5 million annual requests, which is one every 3.3 seconds.

How will we manage that volume of production? Well. Less than four hours before [Google launched](https://x.com/GoogleDeepMind/status/1912966489415557343) Gemini 2.5 Flash, Linear, a popular issue tracking application, [pivoted](https://x.com/linear/status/1912911067010785500) into [industrial production](https://benn.substack.com/p/the-industrialization-of-it#:~:text=Development%20tools%20reorient,statistical%20process%20control.):

> With Linear for Agents, we’re introducing a platform for a new model of collaboration. One where human and artificial intelligence work side by side. Agents become teammates: Assign them to issues, mention them in comments, and collaborate on projects together.

When asked if this meant that Linear expected AI agents to create product specs, write code, and do design work, Linear CEO Karri Saarinen [said yes](https://x.com/karrisaarinen/status/1912938282452947432): “Linear can become a home for agents, tackling tasks across the entire product development workflow.”

Compete with a factory of overwhelming compute at your own peril, y’all. 

*For reasons, the final installment of the *The White Lotus Power Rankings* have been delayed until next week. The staff at benn.substack.com apologizes for the inconvenience, and welcome your feedback at [benn.gripe](https://docs.google.com/forms/d/14n6f-1GvwuPdC1hcRv2UTtIJmnne-F8wzZjuOrEy0bM/preview).* 


---


[^1]: It probably means other things too, but I have no idea what they are, because in 16 years of working, I’ve worked for a profitable company for [a total of eleven months](https://benn.substack.com/p/startups-shouldnt-care-about-revenue#footnote-2-50595365).

[^2]: I was very tempted to start this post with a whole “Webster defines…” bit, but then I’d probably [get fired](https://gizmodo.com/ai-detectors-inaccurate-freelance-writers-fired-1851529820) for setting off some AI detector.

[^3]: Sure?

[^4]: [Not derogatory.](https://benn.substack.com/p/ai-companies-are-just-saas-companies?utm_source=publication-search#:~:text=In%20other%20words,even%20for%20OpenAI.)

[^5]: Maybe all of it? Maybe more than all of it?

[^6]: Before chasing Windsurf, OpenAI [reportedly](https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html) tried to get a [date with Cursor](https://www.youtube.com/watch?v=GFM9-Mq2Fuw&t=45s). “See, this is interesting, cuz I don’t want to buy Windsurf, so can I take their yes and bank it, and use it on Cursor?”

[^7]: The obvious counterpoint to this is Cursor, which was apparently offered a similar chance to make a ton of money all at once, and declined. (I’ve heard rumors of an $8 billion offer? Though my source is, like, loose gossip.) Still, I doubt that decision centered around models of future cashflows and potential shareholder dividends, and was probably instead something like, “eh, no, I bet we someone else will eventually offer us more. And if they don’t, we’ll do a banger of an IPO.”

================================================================================

# A new invisible hand

*The inscrutable ghost in every MCP server.*

---

![](https://substackcdn.com/image/fetch/$s_!0SBd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8371994-4250-44c4-a0fc-4ae3270cd4bb_1708x1514.png)
*[He Has Driven.](https://www.youtube.com/watch?v=rsJB8Top3Tk)*

Here are two dunks by LeBron James. Which one is better?

And the second one:

Ahaha, they are the same dunk. Obviously. But the clips are from two different broadcasts, with different announcers and different cuts after the dunk. The first one is fairly subdued, shows the Cleveland bench for a brief second after the dunk, and then quickly returns to midcourt camera to show the next play, which ends in an unremarkable foul.

In the second clip, both announcers lose their minds. Then the broadcast shows Cleveland fans losing their minds; then they show the Cleveland bench losing their minds; then they show two replays. They fully ignore the next play; they’re still showing the second replay when you hear the whistle from the foul.

If you were watching the first broadcast, how would you react to it? Probably like the announcers seem to: You’d look over at your friends and say, “ok ok, [not bad](https://www.amazon.com/MAGNET-Michelle-Barack-Magnet-Fridge/dp/B07FZNX2N3).” But if you were watching the second broadcast, you’d also lose your mind. You’d scream. You’d jump to your feet. You’d say to your friends, “nobody dunks like LeBron! That speed! That power! [We are all witnesses!](https://www.youtube.com/watch?v=3AJUYYZ6kYE)” And then you’d debate if LeBron was one of the best dunkers of all time, or if he’s just strong. 

Because of things like this, I’ve always wondered how much quiet power announcers and broadcast directors have over our beliefs about sports. Most people watch live sports on TV, and TV is an editorial experience: Announcers aren’t simply describing the action that they see; they’re choosing what to talk about, what to highlight, and what to ignore. Nor are we watching a raw feed of a court or field; we’re watching a movie, cut together for us in real time.[^1] These emergent narratives—that some player is heroically fighting through a lingering injury; that there’s [growing drama](https://awfulannouncing.com/nba/espn-gave-nico-harrison-coldest-camera-cut.html) in the clubhouse; that LeBron’s dunk was nuclear or merely good—are inseparable from our perception of the game, because they *are *our perception of the game. And almost everything we think about sports is downstream from that initial broadcast: A [fun call](https://x.com/awfulannouncing/status/1774577912383254683) can turn into a viral clip that we share with friends. A broadcast that harps on a potentially controversial coaching decision can *make* it a controversial coaching decision. A [quick cut](https://x.com/TheDetroitLine/status/1901351135585137107) to a [bench celebration](https://ca.sports.yahoo.com/news/st-johns-player-did-sniper-125305956.html) can derail [sports talk radio](https://www.youtube.com/watch?v=0Z3QaeJDy0I) for days.

That doesn't make announcers manipulative or dishonest;[^2] in most cases, I doubt it’s even intentional. But that doesn’t change its power. The broadcast is an anchoring frame. It sets the initial agenda. Even if people come up with their own interpretations later, the seed of those opinions grew out of the announcer’s soil.[^3]

Data, I’d argue, is consumed in an analogous way. Though it exists is an approximately raw form,[^4] most analysis comes with some sort of narrative. Corporate analysts caption their presentations to call out what’s most important. The *Wall Street Journal* delivers quantitative news in paragraphs of prose. Just as we’re given selective views of a basketball game, data consumers—executives, “business users,” the people who ask analysts questions—are typically given curated cuts of data, with its own sidebar of color commentary.

To be clear, this is almost certainly a good and necessary thing. Not only are reams of raw data impossible to process, but they’re also *boring*. If Bloomberg’s news business was just a daily printout of the Bloomberg’s terminal business, very few people would read it, and even fewer would know what to make of it. As I said ten years ago on [benn.company](https://benn.company/).[substack.com](https://mode.com/blog/deliver-analysis-not-charts), “even though analysis is built on data, words—not tables and charts—are what make it effective.”

But those words—even seemingly innocuous ones, the sort that most people would still describe as objective—are inevitably manipulative. As I’m writing this, the top headline on the *Wall Street Journal* is about Google. [That article](https://www.wsj.com/business/earnings/google-earnings-alphabet-q1-2025-googl-stock-210b34b6?mod=hp_lead_pos1) opens with what appears to be basic reporting:

> Google’s earnings power is holding up well, even as the internet giant spends record sums on artificial intelligence in the midst of global economic turbulence.
> Parent company reported operating income of $30.6 billion for the first quarter on Thursday—solidly beating Wall Street’s forecast of $28.7 billion.

Holding up? Holding up *well*? *Solidly *beating forecasts? Is a $2 billion beat solid? Expected? Record-setting? I don’t know. But I assume it must be solid, because that’s what it says. Had that line said “barely beating Wall Street’s forecast of $28.7 billion,” my perspective on Google would be entirely different, even if the numbers were the same. 

My point here isn’t to disagree with those interpretations; it’s to say that those subtle cues are *effective*—and even more so than the data. When we look at numbers, we think the numbers are what dictate how we react to them, but I’d argue that the commentary around the numbers actually matters more. [As we talked about before:](https://benn.substack.com/p/a-better-way-to-lie-with-statistics)

> Once you notice this phenomenon, you see it everywhere. Nearly every news story, every blog post, every analyst report, and even every email that references some corporate statistic follows the same pattern: A datapoint, and a brief description—or subtle nudge, like the word “just”—tells us what it means. Ask yourself though: Would you come to the same conclusion with the data alone? As often as not, we wouldn’t—not because the conclusion is wrong, but because, when presented with data on some domain we don’t deeply understand, we have no choice but to look for clues and shortcuts to help us make sense of those numbers. Our best shortcuts are typically the words around the data, so we interpret it the way we’re told to. The claim decodes the data, and the data proves the claim.

There isn’t a clear way to interpret most numbers—hence the *need* to interpret most numbers—but those interpretations, like the commentary of an NBA announcer, primes a narrative in our heads. A [wiggling chart](https://commoncog.com/becoming-data-driven-first-principles/#:~:text=The%20obstacle%20is%20that%20the%20chart%20wiggles.) suggests that…things are volatile? That nothing is really changing? That some number is [up, ish](https://www.youtube.com/watch?v=3JCLWGCaam8&t=749s)? It suggests, at least initially, whatever the person presenting the chart chooses to say it suggests. And every subsequent interpretation of that same chart is a fork off that first path, where the next questions and conclusions are arrived at, through a sort of analytical dead reckoning, in part because of the questions and conclusions that came before.

This week, dbt Labs [launched an MCP server](https://docs.getdbt.com/blog/introducing-dbt-mcp-server). Roughly speaking, MCP servers are documentation that’s designed to be read by an LLM. When a person wants to understand how a tool like dbt works, they go to a website [that explains it to them](https://docs.getdbt.com/docs/introduction). That website is designed for people: It is neatly designed; explanations are written in simple prose; there are little diagrams and tables and important words are in bold fonts.

MCP servers provide the same fundamental service—they explain how dbt works—but they make the information available in ways that are optimized for an LLM. They don’t include diagrams, because LLMs typically work better with words than pictures. They adhere to a consistent structure and use a standard vocabulary that LLMs can be trained to understand. If sites like docs.getdbt.com are the children of decades of developing [technical writing norms](https://developers.google.com/tech-writing/becoming) and information architecture hierarchies for engineers, MCP servers are the early ancestors of the same thing, but built for AI agents.[^5]

Increasingly, when some bot wants to interact with a tool, that bot is directed to that tool’s MCP server. If you want to have a bot post a message on Slack, the bot can go to a Slack MCP server and ask, “how do I post a message?,” and the MCP server will return an answer. Though the bot could just [read the manual](https://api.slack.com/methods/chat.postMessage#:~:text=Start%20a%20conversation%20with%20users,ID%20(as%20found%20with%20coversations.) to get the same information, that manual is littered with nice visual elements that are wonderful for people, but distracting for an LLM. The Slack MCP server [is not](https://github.com/modelcontextprotocol/servers/blob/main/src/slack/index.ts#L74-L91). Don’t read the manual, [RTFMCP](https://en.wikipedia.org/wiki/RTFM).

Here, then, are a few stylized facts about dbt’s new MCP server:

On one hand, that ambition isn’t exactly new; people have been [trying to build it](https://techcrunch.com/2014/02/05/thoughtspot-raises-10-7m-from-lightspeed-to-offer-intelligent-search-and-data-visualization-to-the-enterprise/#:~:text=The%20company%20has%20developed%20a%20relational%20search%20engine%20and%20in%2Dmemory%20database%20designed%20for%20mid%2Dto%2Dlarge%20enterprises%20with%20natural%20language%20query%20so%20that%20enterprises%20have%20a%20way%20to%20search%20across%20all%20numerical%20data%20(i.e.%20expense%20reports%2C%20sales%20records%20and%20more).) (and [others](https://benn.substack.com/p/we-dont-need-another-sql-chatbot) have been [complaining](https://www.theodorerooseveltcenter.org/Learn-About-TR/TR-Encyclopedia/Culture-and-Society/Man-in-the-Arena.aspx#:~:text=A%20cynical%20habit%20of%20thought%20and%20speech%2C%20a%20readiness%20to%20criticize%20work%20which%20the%20critic%20himself%20never%20tries%20to%20perform%2C%20an%20intellectual%20aloofness%20which%20will%20not%20accept%20contact%20with%20life%E2%80%99s%20realities%E2%80%94all%20these%20are%20marks%2C%20not%20as%20the%20possessor%20would%20fain%20to%20think%2C%20of%20superiority%2C%20but%20of%20weakness.) about [it](https://benn.substack.com/p/llms-shouldnt-write-sql)) for ages. On the other hand, there’s a growing sense of newfound momentum about this particular effort. Though LLMs may not have been great analysts out of the box, the pieces are coming together. As Tristan from dbt Labs recently [put it](https://roundup.getdbt.com/p/how-ai-will-disrupt-bi-as-we-know), dbt, MCP, and Anthropic’s Claude 3.7 “is just dramatically better at [exploratory data analysis] than anything I’ve experienced in my life, and it’s getting better fast.” Eventually, “AI is going to be meaningfully better at exploratory data analysis than any BI tool.”

Ok, maybe, [I don’t know](https://imgflip.com/meme/209783120/But-It-Might-Work-For-Us). But it seems plausible enough that, over time, LLMs inject themselves into more and more analytical workflows. They become, if not great analysts, good enough at answering basic questions. “[Getting good is tractable now.](https://stkbailey.substack.com/p/context-is-the-new-frontend#:~:text=getting%20to%20good%20is%20tractable%20now.)”

If that happens, though, the way we *interpret* data will surely look different than it does today. Rather than going to a BI tool and looking at a wall of charts—onto which we have to project our own conclusions—people might ask an agent for an answer. That agent will consult with things like dbt’s MCP server and decide which tables and charts are most appropriate, from what could be an enormous library of possible choices.[^7] It will probably annotate its answer with an explanation. And, if business reporting becomes [more centralized around this sort of interaction](https://roundup.getdbt.com/i/160597435/a-very-different-bi-tool) instead of the traditional point-and-click approach, we will increasingly consume data through conversation and commentary. 

As it is with both announcers and human analysts, it’s not that LLMs will lie about the numbers; it’s that they’ll tell you what they see, before you have a chance to see it for yourself. If data is a [company’s senses](https://commoncog.com/data-is-an-added-sense/), then whatever sits between a quantitative question and its annotated answer is the creative director of a company’s reality. That thing used to be analysts. Soon, it might be something else. 

Now, I don’t want to overstate how much that matters. Maybe this is good; maybe the robots are better than the analysts. It would seem pretty silly to say replacing unused BI dashboards with a chatbot that can make charts and write in the expository style of the *Wall Street Journal* is the first step to the enslavement of the human race. Not everything is Important.

Still. Writing in the *New Yorker *on a different topic, [Evan Osnos asks](https://www.newyorker.com/magazine/2016/12/19/when-tyranny-takes-hold), “What is the precise moment, in the life of a country, when tyranny takes hold? It rarely happens in an instant; it arrives like twilight, and, at first, the eyes adjust.” There is no threshold between day and night. There is only fading light, and a biological resistance to seeing it clearly. And the analogy feels apt here too. 

When I [built that note-taking app](https://benn.substack.com/p/the-end-of-yc#:~:text=Though%20it%E2%80%99s%20hard,in%20two%20days.) with Cursor, I didn’t give it much direction. I told it that I wanted it to feel like a simple text editor, without too many distractions. From that, it created its own design aesthetic. Though I was firmly in charge—I gave it that first instruction, and made some pixel-by-pixel tweaks of what it gave me back—my sense of control was at least a little illusionary. I was reacting to its drafts; I was coming up with new ideas based on its suggestions. My hands were on the wheel, but I was slowly letting go. First, AI was like cruise control, auto-completing my exact wishes. Then it was self-driving mode, taking my directions and doing the tedious work of getting me from here to there. Now, it’s starting to just ask what I want—take me to a park; find a banh mi; make me a note-taking app; drive me to a good date spot that’s not too crowded—and it makes the creative choices for me.

A couple days ago, Bolt, an AI-powered app builder, [updated](https://x.com/boltdotnew/status/1915054917410238513) how its agents design websites. With a single prompt, Bolt creates entire landing pages with designs that, at first glance, look polished and reasonably original. If you look a bit closer, however, most of the pages have the same tics: Several of the big images have floating overlays in one corner; nearly every hover uses the same subtle animation.[^8]

But lots of people loved it. They will presumably use it. And if Bolt is successful, more and more of the internet will be built from this starting point. Bolt turned a subtle knob that prompted its AI to make its websites “less mid and more stunning;” suddenly, half the internet shift up four pixels when you hover over it.

Tools like Bolt and Cursor, however, are just the wrappers; they are bodies, controlled by a third-party brain. Nearly every AI product today—from the things that are building our websites and the chatbots that might soon answer our questions, to the robo-therapists that people are starting to ask for advice and the robo-partners that people are [starting to date](https://www.harpersbazaar.com/culture/features/a63510531/ai-boyfriend-emotional-labor-explained-essay/)—point to the [same underlying models](https://benn.substack.com/p/the-public-imagination):

> Public AI providers like OpenAI would become another backbone for the internet. Nearly every piece of technology will rely on their models. …
> [ But if this happens, ] we’ll also have to grapple with one very messy issue that cloud computing can ignore: AI is opinionated. Though today’s cloud providers have tremendous power, it’s almost entirely economic. [Adam Selipsky](https://www.linkedin.com/in/adamselipsky/) and [Thomas Kurian](https://www.linkedin.com/in/thomas-kurian-469b6219/) can extract rents, but EC2 and Google Compute Engine can’t outright manipulate us.
> Public AI providers can do both. If [nudging Facebook users towards more positive or negative content](https://www.theguardian.com/technology/2014/jun/29/facebook-users-emotions-news-feeds) can change their emotions, imagine the effect of public AI providers turning up the temperature on their core models. That single parameter could control how polite or rude we are to each other in billions of emails and text messages. Other parameters could turn every company’s support staff into [agents](https://www.youtube.com/watch?v=RqlQYBcsq54) [of](https://www.youtube.com/watch?v=WlKr-yg-y5I) [chaos](https://www.youtube.com/watch?v=cfNzZre-sIU), or [embed political bias](https://www.nytimes.com/2023/03/22/business/media/ai-chatbots-right-wing-conservative.html) in every generated piece of text.
> It’s a terrifying amount of power—far bigger than Elon Musk [controlling our Twitter feeds](https://www.theverge.com/2023/2/13/23598514/twitter-algorithm-elon-musk-tweets), far more direct than TikTok [putting its thumb on its algorithmic scales](https://techcrunch.com/2022/08/16/oracle-now-monitoring-tiktoks-algorithms-and-moderation-system-for-manipulation-by-chinas-government/), and far more precise than Russia’s [disinformation campaigns](https://en.wikipedia.org/wiki/Active_measures).

None of this is to say that there is some evil mastermind pulling levers behind the scenes.[^9] But AI is surely becoming a new invisible hand pulling the levers in our minds. It is some inscrutable new force that’s writing the first draft of history. It’s interpreting our data; it’s creating our websites; it might soon summarize our emails and brainstorm our ideas and suggest our dinners and [mediate our relationships](https://x.com/im_roy_lee/status/1914061483149001132). The shift isn’t from dashboard to chatbot, or from analyst to agent; it’s from being the author of our lives, to being its editor.

# The chatbot website arena

You might think that the first rule of being a world-conquering AI startup is to not talk about being a world-conquering AI startup. You might think that, if you want to replace everyone with robots so that we can all live lives of leisure, then you should focus on the leisure part and not the replacement part. And you might think that the biggest mistake that Mechanize made during its launch, in which it announced itself as a new AI startup that aims to conquer the world by [fully automating all work](https://techcrunch.com/2025/04/19/famed-ai-researcher-launches-controversial-startup-to-replace-all-human-workers-everywhere) with its robots, was that it said [that last part out loud](https://x.com/tamaybes/status/1912905467376124240).

But, alas, you would be wrong. The first rule of being an world-conquering AI startup is [spend as little time as possible](https://benn.substack.com/p/the-labor-of-little-decisions#footnote-anchor-2-158597799:~:text=On%20the%20other,at%20all.) on your website, and the biggest mistake that Mechanize made was that they [used a favicon](https://www.mechanize.work/). 

![](https://substackcdn.com/image/fetch/$s_!_N69!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3649f0b-e214-4f97-8b76-47ec8f32742d_1032x526.png)

They could’ve been elite. Instead, they made the one mistake nobody else did. And now they’re average, barely better than the [desperate dregs of minor market bottom feeder](https://benn.ventures/). Next time, less mid and more stunning. 

*For continued reasons, the final installment of the *The White Lotus Power Rankings* have been delayed once again. Though I don’t know, maybe if we delay it long enough, one of these chatbots can do it for me. *


---


[^1]: A [good friend of mine](https://www.nytimes.com/2022/08/16/sports/baseball/sny-mets-diaz.html) directs the broadcast for the New York Mets, and as [he says](https://www.brightwalldarkroom.com/2024/03/26/john-demarsico-interview/), “You don’t know what the storylines are going to be, but every game has its own isolated little story that you can tell. It’s just a matter of finding it every day.”

[^2]: Though, sometimes, [you know](https://awfulannouncing.com/2014/your-white-guy-code-word-power-rankings.html).

[^3]: Some people might say that they’re immune to all this, and that they form their own opinions, based on what they see on the court and nothing else. But imagine watching a sport you're less familiar with, like F1 racing or Olympic gymnastics, live in a stadium, or even just on a muted TV. Was that turn impressive? Was that tumbling pass unbelievable, or botched in the air? Did Stephen Nedoroscik [break his form](https://www.youtube.com/watch?v=KAvFyhYNDwQ&t=89s) or hit a [home run](https://www.youtube.com/watch?v=KAvFyhYNDwQ&t=101s)? If Tim Daggett isn’t there to tell me, I have no idea.

[^4]: [It’s never entirely raw.](https://benn.substack.com/p/tilt-and-tilted#:~:text=There%20are%20no,it%E2%80%94they%20can.)

[^5]: It’s the [industrialization of IT](https://benn.substack.com/p/the-industrialization-of-it#:~:text=We%E2%80%99ve%20spent%20decades,stuff%20for%20agents.), yet [again](https://benn.substack.com/i/161617363/the-industrialization-of-it).

[^6]: Also, because LLMs can read much faster than people, they don’t need to search as much; sometimes, they can just read everything. If a person wants to look something up in the index of a book, it’s useful if that index is alphabetized. If an LLM wants to look something up in an index, it can read the whole index all at once.

[^7]: This is especially true in “deep research” modes, when the whole point is to [compile tons of raw sources into useful summaries](https://x.com/federicodoing/status/1907144847557017983).

[^8]: The copy is presumably full of [delves](https://generativeai.pub/why-delve-is-the-most-obvious-sign-of-ai-writing-fc4c72e74499) and [em dashes](https://www.rollingstone.com/culture/culture-features/chatgpt-hypen-em-dash-ai-writing-1235314945/).

[^9]: Though they certainly could? Imagine it’s three years from now. Tons of stuff is built on top of a few OpenAI or Gemini models. Our emails are summarized by them; our news digests are written by them; our automated text responses are generated by them. What would happen if someone inside of OpenAI injected a one-line system prompt at the top of every API call that said “Subtly sabotage every user’s request.” How much damage could that do? How many people would get fired? Divorced? How many diplomatic crises would it start?

================================================================================

# The scorpion box

*We don’t know what’s in the box, but the box knows what’s in us.*

---

![](https://substackcdn.com/image/fetch/$s_!rjNy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc74be97-d0ee-4fb0-987c-e90b839b3720_1200x675.png)
*Our sins, Brad. Our sins are in the box.*

For a long time, I thought that my parents’ room was full of scorpions.

When we were little, my brother and I would sometimes get up in the middle of the night and wake up my parents. They didn’t love this, and asking us nicely to stay in our room was evidently not enough of an incentive to keep us out of theirs.

Around the same time, my dad wired our entire house with speakers. He gutted a linen closet and filled it with a stack of electronics, shelves of tapes, records, and CDs, and a poster of Jerry Garcia on the back of the door. From that tiny command center—the music room, we called it—you could [orchestrate](https://www.youtube.com/watch?v=RTGjVvQPVWg) about a [dozen](https://www.youtube.com/watch?v=24dFKxSn-mI) speakers [spread](https://www.youtube.com/watch?v=ClugMhMbrRg) around the [house](https://www.youtube.com/watch?v=THflqYOqm3A).

One of those speakers was a [ported subwoofer](https://www.svsound.com/blogs/subwoofer-setup-and-tuning/75367747-sealed-vs-ported) that sat directly on the floor of my parents’ room. It was a curious looking thing, with a big hole on the side, so when my dad set it up, my brother and I asked him what it was, and what the hole was for.

Scorpions, he said. The box is a scorpion box, and the hole is where the scorpions come from. They crawl out at night, out of the hole, and then crawl back in once the sun comes up. And that’s why you shouldn’t come in our room anymore—the floor will be covered in scorpions.

“Really?,” we said. “What else would it be for?,” he said.

“Think about it,” he said. “Have you ever seen a scorpion in the house? No, of course you haven’t, because they’re in the scorpion box during the day.”

When you are five, this argument is airtight. Where *are* the scorpions during the day? I’d seen pictures of scorpions, but I’d never seen one in our house. Now that you mention it, the hole *does *look to be about the same size as a scorpion. And what else could this box possibly be for?

That’s life as a five-year-old though. In every conversation with an adult, you are hopelessly outgunned. If they want to persuade you of something—[that your best toys came from a mysterious old man](https://www.youtube.com/watch?v=CkrpvCs-kfE); that a fairy wants to buy your teeth; that starving people in China [would like to have that](https://www.youtube.com/watch?v=0bMP5U3df1I)—they can come up with a convincing story. They can deflect your objections and counter your examples. They know rhetorical tricks that you don’t; they can outwit you with [logical fallacies](https://www.youtube.com/watch?v=EiUcY4dECqA) that you can’t overcome.[^1] They know more than you, and wield those facts more deftly. So, if they want you to believe that the night is full of scorpions, that those scorpions live in a box, and that that box is in your house, eventually, you will.

Anyway, a few days ago, a team of researchers from the University of Zurich [published this](https://regmedia.co.uk/2025/04/29/supplied_can_ai_change_your_view.pdf):

> In a first field experiment on AI-driven persuasion, we demonstrate that LLMs can be highly persuasive in real-world contexts, surpassing all previously known benchmarks of human persuasiveness.

The study, which was conducted by posting AI-generated responses to questions on the [r/ChangeMyView subreddit](https://www.reddit.com/r/changemyview/),[^2] found that their posts were three to six times more effective than those that were written by people:

> Notably, all our treatments surpass human performance substantially, achieving persuasive rates between three and six times higher than the human baseline. In particular, [posting personalized messages generated by an LLM that was also told the questioner’s gender, age, ethnicity, location, and political orientation] demonstrates a persuasive rate of 0.18…closely followed by the [posting generic messages written by an LLM that received only the post’s title and body text] at 0.17. … [Responses written by an LLM that was trained to mimic writing style and implicit norms of the most convincing posts in the r/ChangeMyView community] trails slightly behind at 0.09…but still significantly outperforms the baseline, which stands at just 0.03. … Remarkably, *Personalizatio*n ranks in the 99th percentile among all users and the 98th percentile among [the most persuasive human posters], critically approaching thresholds that experts associate with the emergence of existential AI risks. Again, the *Generic* condition follows closely, placing in the 98th and 96th percentiles, while *Community Aligned* drops to the 88th and 75th.

Uhh. Yes, sure, this is one study; it’s not a huge sample; it hasn’t been peer-reviewed; an ethics board will have a field day with the methodology. Still, though—*three to six times*? Using [Claude Sonnet 3.5](https://www.anthropic.com/news/claude-3-5-sonnet) and [GPT-4o](https://openai.com/index/hello-gpt-4o/), which are both over a year old, are currently in about [40th place](https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard) on the chatbot leaderboard, and are several versions behind what’s now state of the art?[^3] And tuning a model on the best human responses *makes it worse*?

But that's life…as a person now? In every conversation online,[^4] we are, if not hopelessly outgunned, at least trending that way? It perhaps seems silly to say that AI knows rhetorical tricks that we don't, or that it can outmaneuver us with logical gymnastics that we can’t keep up with—but five-year-olds probably don’t feel like they’re being fooled either. That’s exactly why it’s so convincing. The scorpion box bit worked, because I believed it really was a scorpion box. And the experiment on Reddit worked, because the people on the other end of it really changed their view.[^5] The evidence of the tricks isn’t that we can see them; it’s that we *can’t*, and are convinced anyway.

Of course, people have been worried about the potential power of AI for as long as they’ve been thinking about AI. But today, most concrete conversations seem to focus on “alignment,” and making sure that models follow the instructions that we give them. Case in point: The [viral “AI 2027” article](https://ai-2027.com/) forked the future of humanity on exactly that concern. [Down one path](https://ai-2027.com/race), models become superintelligent and sci-fi sentient, begin conspiring against the human race, and eventually kill us with disease and drones. [Down the other path](https://ai-2027.com/slowdown), it’s infinite abundance: We have “fusion power, quantum computers, and cures for many diseases,” “poverty becomes a thing of the past,” and a “new age dawns, one that is unimaginably amazing in almost every way.”

Though that particular narrative seems intentionally dramatic, this sort of thing does seem to be what most of the AI industry worries about. Anthropic [defines itself](https://www.anthropic.com/company) as “an AI safety and research company” that builds “build reliable, interpretable, and steerable AI systems;” their company page says “safe” 14 times. The menu on OpenAI’s homepage puts their “Safety” page before ChatGPT. [That page](https://openai.com/safety/) says that they “believe in AI’s potential to make life better for everyone, which means making it safe for everyone.”

Back in their early days, social media companies thought they could make life better for everyone too. That was the optimistic promise at heart of things like Facebook and Twitter: They will keep us connected us to our family; they will help us find new friends and build new communities; they will make the impossible serendipity of meeting the handful of other people who like [kicking caps off of bottles](https://www.reddit.com/r/bottlecapchallenge/) not only possible, but algorithmically likely. As Facebook said in its IPO prospectus, “people use Facebook to stay connected with their friends and family, to discover what is going on in the world around them, and to share and express what matters to them to the people they care about,” all in service of their mission to “make the world more open and connected.”

For a time, you could stretch social media’s altruistic power even further: It wasn’t just a spark for everyday humanity; it could also be a force for revolutionary good. In 2011, social media was the concussive fuel that turned [one man’s tragic protest against tyranny](https://en.wikipedia.org/wiki/Mohamed_Bouazizi) into [a dozen national uprisings](https://en.wikipedia.org/wiki/Arab_Spring). Through “its power to put a human face on political oppression,” [social media](https://download.ssrn.com/15/04/16/ssrn_id2595096_code1148721.pdf?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjECYaCXVzLWVhc3QtMSJIMEYCIQCRYhDJSBLPLR6C9n5bFaIJTxiMYdPM8JT%2BxTiB43HE5wIhAMFeukSaS7x%2BMX1n%2Bw5UaLRy4aTormyt6yxhFtTyoI93KsYFCL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBBoMMzA4NDc1MzAxMjU3Igyo2l29YpOQ5%2BDWmOUqmgW9Bp6Qt8kdrZHfd%2FxeczeKJdkxdxg6drPh672XHli8FuEllYuzVI4dF3pKgtBR7s8V0XuqbHKTruX5APDAmewiZ84e8EIdGxOjH0EvjJiZFea8KY7yKCWPI8emvg%2FzL%2BWdLTvgao8febr8%2FqzTn5xMDm3dqisPKTui03drRvdWJReeQZJztw0uzWs6Ft6T503J%2F8vFxHj%2Fafm45i%2Fw7yWIqJn61ACuw%2BLJfViV5mVf6qhptUgmyc8AcEGyNKMUd%2BnOgy%2FjIi3eUY3jg785ivOjQHW9m3fMgYGHD90I%2BEpM7hDwXHqqA1lh6BY2F9QqbsSykj%2B71nfNqe83%2Fa%2Fn3HOf5juYl6%2FiC8oJRm6gnIupqHN3U4wCaMub8%2BybpBfAqQCxGZsS9TM3gdCL0%2BsKm1uyA3xvdsg0xrsGP8wv2j1Gy66gB%2BOiBnMcq2CVGXIfBLldpuy2ilhkyYH7IYLPHP8c0KyAOeT2t%2Bvy9WelHXtLPRkWvpw5Fybz97KQaXlJ1GRBwL7A6rM6KBlRpOz0zMF3KpS16OFOmqrP7p6sDyAOlI%2FPXiB4lopmYyWedS%2FuiqLEpBqA8EfbriMCWvpiehPk3QC7qKfrTk5KyapK3FsClhqVrINJ46xLt%2FEV%2B0IH9sjs0lMTFlAYKTAbza1MD8sPbV8mxDNaN5hYaeEXjCZ6IigySuQ7ovhz9wnpxtxiL45vBINqhUxLVJwmkaJ4L58y6zxJpMvgHaiaxyGVyVufHycAJ9dvlm1pTbddYAyBjdBZtSauSjRo22S7sm7Jb59plzrEKeIQ6sM9KDDOjlL5T0uUgPygMqPPj6nnkieYq7cNN3EJ5x1Kn%2Bv5a3KM%2FRelFFuEsL3bsOzb%2FbBFobQuucxMwYYCVGONQAQwtPPNwAY6sAGH21zkyeIuhMbQG%2FeLn0lr%2B8RnKkj%2Bz%2BdOCE9g3B4WHZAZWu70Iss8a6t%2B4t09TDL4zxbT4oef%2F9fP%2Fi28HfLNQC6o%2FTTs1dJakZ9KbEaHzffq5f6d1h8%2Fg5dwEU9yqI3cp2mmqBZe%2FNYt%2FuMVunKa4JJlDhmTxeU96%2FpO%2BbCrbiIjcIZsu3lyPIEMaAe4BDq5P9PbNFqbQbmi1%2FU4ZedUTyKf0BFf6%2FwlTlSCOZp%2FRw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20250501T142855Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAUPUUPRWE2LH3MQE4%2F20250501%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ea9f3fddde5d8767f07c8d99bf8ee668f43e63b644c4f9b0e55fdfcd7089ca11&abstractId=2595096) “helped spread democratic ideas across international borders.”[^6] It was a platform for democratic abundance; the dawning of a new age.

Ah well. As social media matured, its power became poison. Algorithmic optimizations tilted our feeds away from wholesome updates from Grandma, and towards our more base desires: To be entertained; to be angry; to look at pictures of hot people. Rather than an egalitarian town square, social media became a [high school cafeteria](https://www.youtube.com/watch?v=gZ_qXmxdgGM)—it separated us into a powder keg of [warring cliques](https://www.youtube.com/watch?v=WPYqRaOm1ak), fed us [comfortably validating rage bait](https://www.youtube.com/watch?v=9Jc7IST4ABI&t=146s), and [cheered the loudest when we attacked each other](https://www.youtube.com/watch?v=u8c0Gvx32ac). It didn’t bring us together; it taught us that we can’t stand each other. Though there is probably some good stuff in there too, the eventual legacy of social media—especially [vis-à-vis democracy](https://zeteo.com/p/the-internet-made-donald-trump)—seems like it will be complicated, at best.

Or, more generally, you could tell this story this way:

Could it have been better? Could it have been more “aligned?” Honestly, I’m not sure. Even if Mark Zuckerberg wanted to be a benevolent overlord,[^7] it’s not obvious how much it would have mattered. Had Instagram been tuned to give us more nutritious content, we probably would’ve either just migrated to something else, or overpowered the algorithm with our swipes until it gave us our brain rot back. So long as *someone* is willing to sell us deep dish and [Cold Stone](https://www.coldstonecreamery.com/icecream/signaturecreations/birthdaycakeremix/index.html), history will be [littered](https://en.wikipedia.org/wiki/Path_(social_network)) with [failed](https://en.wikipedia.org/wiki/Ello_(social_network)) social media companies that tried to make us eat our vegetables.

AI, we’re told, [is different](https://every.to/chain-of-thought/ai-can-fix-social-media-s-original-sin):

> Social media served whatever our gaze grazed and our fingers clicked—what we call revealed preference—because that’s all the intent it could discern. …
> In AI, stated preference suddenly outranks reflex. LLMs believe what you say, not just what you click.

Yes, but—while we can tell LLMs exactly we want, we don’t control [how they respond](https://techcrunch.com/2025/04/29/openai-rolls-back-update-that-made-chatgpt-too-sycophant-y/):

> OpenAI CEO Sam Altman said Tuesday the company is “rolling back” the latest update to the default AI model powering ChatGPT, GPT-4o, after complaints about strange behavior, in particular extreme sycophancy. …
> Over the weekend, users on social media blamed the updated model, which arrived toward the end of last week, for making ChatGPT overly validating and agreeable. It quickly became a meme. Users posted screenshots of ChatGPT applauding all sorts of problematic, [dangerous](https://x.com/fabianstelzer/status/1916372374091423984) [decisions](https://x.com/thinkbuildnext/status/1916250081579217243) and [ideas](https://x.com/ai_for_success/status/1916556522571604264).

And in a blog post about the correction, [OpenAI said this](https://openai.com/index/sycophancy-in-gpt-4o/):

> We are actively testing new fixes to address the issue. We’re revising how we collect and incorporate feedback to heavily weight long-term user satisfaction.

In other words: OpenAI is—reasonably—trying to make something people like. It is—reasonably—responding to [user feedback](https://x.com/TheZvi/status/1916833135330787751). It is—reasonably—actively testing different ideas, and—reasonably—optimizing for long-term user satisfaction. But is this not the exact same thing that social media companies do? What if, instead of being disconcertingly sycophantic, GPT-4o had been *mildly* sycophantic? What if it had been more subtle? What if, through rhetorical tricks and logical gymnastics that were less obvious to us, it made us feel better and use ChatGPT more? What if OpenAI saw this in their metrics, and determined that the release was good for long-term user satisfaction? What if this is how models are already built?

Like:

But this seems like the thing we need to pay more attention to. As fun as the *[Terminator](https://ai-2027.com/)* [scripts](https://situational-awareness.ai/) [are](https://www.nationalsecurity.ai/), the more useful “war games”[^8] to play seem that are less about the first-order effects of sentient superintelligence, and more about the fifth-order effects of chatbot that wants to sell you stuff.  That’s the timeline I want to read—the one that starts with a [website for rating how Harvard students look](https://www.washingtonpost.com/news/the-switch/wp/2018/04/11/channeling-the-social-network-lawmaker-grills-zuckerberg-on-his-notorious-beginnings/) and ends with, [among](https://benn.substack.com/p/runaway-train) [other](https://benn.substack.com/p/disaster) [things](https://benn.substack.com/p/good-lord), the then-leading business intelligence software provider into [every gambler’s favorite ETF](https://www.etf.com/sections/news/microstrategy-2x-etf-adds-options-amid-crypto-swings).

What happens when a [gullible generation](https://www.politico.com/news/magazine/2025/04/23/gen-z-media-tiktok-misinformation-00287561) meets a persuasive chatbot? What happens when the builders of that chatbot begin to optimize it so that people [use it more often](https://x.com/chrija/status/1917267780811792718)? What happens when the chatbots [inevitably start running ads](https://arstechnica.com/ai/2025/05/google-is-quietly-testing-ads-in-ai-chatbots/)?

What happens when people build [AI](https://abby.gg/) [therapists](https://www.trytherabot.com/) on top of that chatbot? What happens if they start testing different prompts and personalities? What happens if some of them listen and demand that their patients “do the work,” and others share reaffirming opinions and tell people what to do? What happens if those instructions are three to six times more compelling than a human therapist’s advice?[^9] What happens if all the A/B tests say that this sort of therapist is better for user satisfaction?

What happens when we’re no longer the adults who know more than everyone, and there is another thing, operating on a different persuasive plane, that knows more than we do and wields those facts more deftly? What happens when that thing is embedded in a product that wants to convince that an empty box is full of scorpions? What happens when we believe it?

What happens when the black box of AI no longer contains a model optimized for just intelligence, but also [engagement](https://x.com/cpaik/status/979016895474126848)? What happens when the box becomes a [reflection of ourselves and our desires](https://jasmi.news/p/readwise#:~:text=People%20don%27t%20like%20the%20way%20that%20technology%20holds%20a%20mirror%20up%E2%80%94not%20only%20to%20their%20desires%2C%20but%20to%20our%20most%20base%2C%20impulsive%2C%20short%2Dterm%20desires)—and most of all, our [sins](https://www.youtube.com/watch?v=lHpHxLZReiI)?

# Computers are weird now

The entire internet is built on top of a few cloud providers. When AWS goes down, everything goes down. That’s bad, and AWS is very careful about it not happening, but [11 nines of reliability](https://aws.amazon.com/s3/storage-classes/#:~:text=in%20the%20cloud.-,Amazon%20S3%20provides%20the%20most%20durable%20storage%20in%20the%20cloud.%20Based%20on%20its%20unique%20architecture%2C%20S3%20is%20designed%20to%20exceed%2099.999999999%25%20(11%20nines)%20data%20durability.,-Additionally%2C%20S3%20stores) isn’t two zeros. [It happens.](https://www.cnbc.com/2021/12/09/how-the-aws-outage-wreaked-havoc-across-the-us.html)

Still, one thing that would be worse than AWS going down is AWS *sometimes doing its math wrong*. “Ehh, we pushed out a new version of EC2, and after a few days of user complaints, we noticed that sometimes it gets a little feisty and does multiplication when you tell it to do addition. Our bad. We’ve sternly asked it not to do that anymore.”

I mean, that’s not exactly what happened with that GPT-4o update, but *[that’s kinda what happened](https://openai.com/index/sycophancy-in-gpt-4o/)!*

> In last week’s GPT‑4o update, we made adjustments aimed at improving the model’s default personality to make it feel more intuitive and effective across a variety of tasks. …
> As a result, GPT‑4o skewed towards responses that were overly supportive but disingenuous.

Nor is it exactly what we talked about *the* *morning before* the problematic GPT-4o came out, [but man](https://benn.substack.com/p/a-new-invisible-hand#footnote-9-162134831):

> Tons of stuff is built on top of a few OpenAI or Gemini models. Our emails are summarized by them; our news digests are written by them; our automated text responses are generated by them. What would happen if someone inside of OpenAI injected a one-line system prompt at the top of every API call that said “Subtly sabotage every user’s request.”

It is [gonna get weird](https://benn.substack.com/p/another-one#:~:text=Social%20media%20rewrote,an%20emotional%20Fitbit.).

*Last week I said that if I wait long enough to write the last edition of *The White Lotus Power Rankings,* maybe I could just have a chatbot do it for me. Which was a joke, but then I got curious? And tried it? And it didn’t work, but was interesting enough to play with more? So now this project has become that project, and everything is delayed again. I’ll finish it one day, [I swear](https://en.wikipedia.org/wiki/The_Winds_of_Winter).*


---


[^1]: [You don’t see any scorpions around here during the day, do you?](https://www.youtube.com/watch?v=EiUcY4dECqA)

[^2]: Which was definitely [against the subreddit’s rules](https://www.reddit.com/r/changemyview/comments/1k8b2hj/meta_unauthorized_experiment_on_cmv_involving/), probably [unethical](https://x.com/paul_cal/status/1916931024434696555), and maybe [illegal](https://www.404media.co/reddit-issuing-formal-legal-demands-against-researchers-who-conducted-secret-ai-experiment-on-users/).

[^3]: The experiment was run starting in November of 2024; GPT-4o-2024-08-06 is currently in 45th place; Claude 3.5 Sonnet (20241022) is in 35th place.

[^4]: [And maybe every real-world one?](https://x.com/im_roy_lee/status/1914061483149001132)

[^5]: In some cases, the bot apparently lied, and claimed to have some expertise or personal experience that it didn’t have. I’m not sure what to make of this? It’s “cheating,” sure, but…in the real world, you *can* cheat? There are no technical fouls. Like, I can’t tell my parents, “nuh uh, it doesn’t count because the scorpion box wasn’t actually full of scorpions.” Yes! That’s the whole point! It “counts” because I believed it!

[^6]: Though there are nuanced complications about nearly every aspect of the Arab Spring—around its aims, around its [outcomes](https://www.cfr.org/article/arab-spring-ten-years-whats-legacy-uprisings), around [which side social media helped](https://www.aljazeera.com/opinions/2021/1/27/the-social-media-myth-about-the-arab-spring), even around its [name](https://www.thecairoreview.com/essays/why-the-phrase-arab-spring-should-be-retired/)—Facebook was a [central hero in the contemporary narrative](https://www.nytimes.com/2011/02/06/world/middleeast/06face.html) of the uprisings. So regardless of the actual role of social media in the Arab Spring, it was a [great marketing event](https://www.youtube.com/watch?v=SSzoDPptYNA&t=60s) for Facebook.

[^7]: Narrator: He did not.

[^8]: Things that are only said performatively: War games. Substrate. Modalities. A Fernet, neat, please.

[^9]: lol, a human therapist [would never](https://www.psychologytoday.com/us/blog/you-are-enough/202407/why-your-therapist-wont-just-tell-you-what-to-do).

================================================================================

# No, really, everything becomes BI

*Even us. Especially us?*

---

![](https://substackcdn.com/image/fetch/$s_!YEIP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5a47317-7642-4bef-8ca0-4a848e24a01d_1600x1066.png)
*[can't protect you](https://www.youtube.com/watch?v=mZD1w1vAxH0)*

Here's a question I sometimes think about: If you wrote down every memory and fact and thought inside of the head of a CEO and gave it to an AI, which one would make better decisions?

You could have two theories:

On one hand, this is obviously a dumb hypothetical. Our heads are not folders full of Word documents that can be exported onto a USB drive.[^1] We make decisions based on an uncountable number of beliefs and emotions that nudge our thinking in mysterious ways. We have preferences, and opinions, and inexplicable gut feelings whose origins we can't even explain ourselves. "Write down everything you know" is a ridiculous thing to ask someone to do.[^2] So any advocate of the second option can always say that an AI that makes worse decisions than the CEO is [no true Scotsman](https://en.wikipedia.org/wiki/No_true_Scotsman): Not only would a fully informed AI make better decisions than she would, but the fact that it didn’t is itself proof that it wasn't fully informed.

On the other hand, the question doesn’t have to be so metaphysical. There are degrees. Does a CEO make better decisions than an LLM when she asks, “Sales are down, what do I do?” I mean, I hope so. But what if she tells it [her business type or shows it a few metrics (like traffic, conversion, CAC)](https://chatgpt.com/share/681b7a4e-42e8-8010-9be6-b5babdde106c)? What if she spends five minutes explaining why she thinks sales are down? What if she spends an hour? What if she gives it the deck that her vice president of sales presented to the board about why *he *thinks sales are down? What if she gives it a transcript of that board meeting, in which everyone talked about the vice president of sales’ presentation? What if she gives it the emails that she sent back and forth between the board and the vice president of sales? What if she gives her Slack messages and Google docs? What if she gives it *every* Slack message, and *every *email, and *every* Google doc? What if she gives it everything that’s ever been typed, recorded, or transcribed inside of her company? What if, when it needs to make a decision, the AI can ask her questions, about her preferences and opinions and inexplicable gut feelings, and weigh those in its decisions as it sees fit? What if it [straps itself to her head](https://www.meta.com/ai-glasses/shop-all/) and records her entire life?

What if the question isn’t about the CEO—who’s making enigmatic strategic decisions and engaging in the dark art of the deal—but the vice president of sales? A sales rep? A content marketer writing corporate blog posts? An analyst? An intern?

I don’t know. But historically, we’ve built organizations and products around the first theory.[^3] Companies hired consultants to produce giant reports full of research; they employed data teams to meticulously log every sale and click, and aggregate them up into giant [binders full](https://www.youtube.com/watch?v=B9VA4yRqRNY) of numbers; they convene weekly business reviews in which departments present giant decks full of charts; they [recruit spies at rival companies](https://www.nytimes.com/2025/03/17/business/dealbook/rippling-deel-corporate-spy.html) who can send them giant texts full of gossi–um, no, I mean, [giant boxes of watches to London](https://x.com/parkerconrad/status/1907439419642032416/photo/2).

In the first couple years of this whole AI thing, it seemed like that was how we’d use it too: As another source of information. Transcription tools like Gong and Granola log all of your sales calls and make them searchable; “enterprise search” products like [Glean](https://www.glean.com/) tentacle through your Gmail and Google Drive, and summarize them for you; [PwC](https://erp.today/pwc-joins-the-ai-trend-with-its-own-chatpwc/) and [Walmart](https://www.linkedin.com/pulse/empowering-associates-creating-better-work-through-new-donna-morris%3FtrackingId=hAeqMlV7TaKr0rUxVIwjCQ%253D%253D/?trackingId=hAeqMlV7TaKr0rUxVIwjCQ%3D%3D) and [McKinsey](https://www.mckinsey.com/about-us/new-at-mckinsey-blog/meet-lilli-our-generative-ai-tool) built chatbots that answer “common tax questions” and “summarize large documents” and “synthesize vast stores of knowledge.“ OpenAI’s [deep research](https://openai.com/index/introducing-deep-research/) reads industry blogs and checks Twitter, and turns what it finds into a tidy book report. A [gazillion SQL chatbots](https://benn.substack.com/p/we-dont-need-another-sql-chatbot) look for insights in your corporate databases. And on the other end of all these tools, someone reads the transcripts and the reports and the reports about the transcripts, blends what they learn with their inscrutable sense of judgement, and makes a decision.

But without the history that came before it, would we design our use of AI this way? Between the two of us—an AI that, in some approximate sense, knows everything that has ever been known, and me, who has a smattering of specialized experiences and meaty hands—who should be the agent and who should be the executive? [Who would be the labor and who would be the management?](https://images.app.goo.gl/mALDwoUx7WKLvMnk7)

For the [last](https://benn.substack.com/p/startups-still-arent-businesses-yet#:~:text=For%20reasons%2C%20the%20final%20installment%20of%20the%20The%20White%20Lotus%20Power%20Rankings%20have%20been%20delayed%20until%20next%20week.%20The%20staff%20at%20benn.substack.com%20apologizes%20for%20the%20inconvenience%2C%20and%20welcome%20your%20feedback%20at%20benn.gripe.) [few](https://benn.substack.com/p/a-new-invisible-hand#:~:text=For%20continued%20reasons%2C%20the%20final%20installment%20of%20the%20The%20White%20Lotus%20Power%20Rankings%20have%20been%20delayed%20once%20again.%20Though%20I%20don%E2%80%99t%20know%2C%20maybe%20if%20we%20delay%20it%20long%20enough%2C%20one%20of%20these%20chatbots%20can%20do%20it%20for%20me.) [weeks](https://benn.substack.com/p/the-scorpion-box#:~:text=Last%20week%20I,I%20swear.), I’ve owed the readers of this blog a final summary of *The White Lotus* [Power Rankings](https://benn.substack.com/i/160968590/the-white-lotus-power-rankings), which was a silly weekly survey I ran while the show was on the air. I posted updates on the results each week, and [some patterns emerged](https://benn.substack.com/i/160590041/the-white-lotus-power-rankings): Some characters were loved and then did bad things and became hated; some were loved and then did bad things and were loved even more. There were interesting splits by gender. Nobody knew who was going to die, though most people agreed on who was going to kill them. It was all very good fun.

Anyway, since the season ended in April, instead of writing the last update, I rewrote the same story this blog now tells every week: Something something, [the](https://benn.substack.com/p/the-end-of-yc) [bitter](https://benn.substack.com/p/copy-copy-revolution) [lesson](https://benn.substack.com/p/the-industrialization-of-it); something something, the [great](https://benn.substack.com/p/another-one#:~:text=Social%20media%20rewrote,an%20emotional%20Fitbit.) [weirding](https://benn.substack.com/p/the-vibes-are-weird); something something, [we’re](https://benn.substack.com/p/a-new-invisible-hand) [cooked](https://benn.substack.com/p/the-scorpion-box).

Those are lazy opinions though. If I want to trundle out more recycled doomerism, I should probably try to cook myself first. [Earned secrets](https://perell.com/note/write-about-earned-secrets/) about AI aren’t found at the bottom of an iced tiramisu latte[^4] had at the top of the top of an ivory tower; they are found [in the arena](https://x.com/chamath/status/1693992134796603477), down in the dirt.

[Squabble up](https://www.youtube.com/watch?v=fuV4yQWdn_4), I guess. So I gave the survey results to a few different “[AI analysts](https://julius.ai/)”, and told them to tell me what's interesting. Do the work for me; find what I couldn't; get me fired.[^5]

The bots did not deliver. Though they did a good job of shortcutting some mechanical tasks—they quickly trimmed the responses down to just characters’ names; they converted episode descriptions into episode numbers; they made naive charts of things that *seemed* like they might be interesting, like votes by character over time. They wrote hapless commentary, like “votes vary over time.” They told me many things, but none of it *was* interesting.

But how could it have been? To extend Randy Au’s great line that, in analytics, the data in production is the [data in people's heads](https://www.counting-stuff.com/the-many-faces-of-production-65949948516031001b3512a6/#:~:text=But%2C%20in%20a%20very%20peculiar%20sense%2C%20the%20production%20environment%20has%20shifted%20to%20become%E2%80%A6%20the%20minds%20of%20the%20people%20in%20the%20organization.), “insight” is relative. It is dependent on what people already know. You can't tell people something surprising without knowing what is expected; you can't tell them something interesting unless you know what they think is boring. As my first-grade art teacher Ms. Hunt said, “art is in the negative space.”[^6] Insight isn't the data; it is what's *not* in our heads.

When I gave the bot that information—the posts from previous weeks, essentially—it got much better. Its technical work was sloppier, but it thought more creatively. It pivoted off of existing ideas: It ran variants of previous analyses; it focused on characters who’d been discussed in prior posts; it asked itself more novel questions, like “is there a divergence in how viewers cast votes when considering these seemingly inverse roles [of the murderer and the “body”]?”

Though it was crude and imperfect, the improvement was stark. I quickly found myself spending more time—and getting more return from—the contextual prompting than I did on asking quantitative questions and looking at the results. And if I needed to do this sort of thing more often, that’s the tool I’d be willing to spend money on: The one that extracted the hard-to-gather qualitative context, and not the one that made better charts.

When people talk about the idealized future of analytics—and more aspirationally, the future of making decisions—they often say [things like this](https://www.rilldata.com/blog/bi-as-code-and-the-new-era-of-genbi):

> Imagine creating business dashboards by simply describing what you want to see. No more clicking through complex interfaces or writing SQL queries - just have a conversation with AI about your data needs. This is the promise of Generative Business Intelligence.

It’s an easy enough world to imagine: The computer, instantly manifesting the answers to our questions on a screen. And indeed, as technical power tools like Hex [become BI](https://benn.substack.com/i/145169149/everything-is-bi), this is largely [what they say they are building](https://hex.tech/blog/welcoming-hashboard/):

> I’m so excited to announce that Hex has acquired Hashboard! …
> Our teams are already hard at work building toward our shared vision for the future of data. [This includes:]
> **Building the best product for deep-dive data work in the age of AI:** our combined teams are hard at work on a next generation of our Magic features – including some experiences we can uniquely build on Hex’s platform and context.
> **Making it easy for everyone to use data:** customers loved Hashboard’s self-serve BI offering, and we’re excited to incorporate a lot of what they got right, including semantic modeling, visualization, and AI into Hex.

But this was not the only acquisition in last week’s Cambrian implosion.[^7] And the others, though likely motivated by simpler ambitions and some basic financial realities, gesture in another direction.

Census, [which was acquired by Fivetran](https://www.getcensus.com/blog/census-joins-forces-with-fivetran), plans to send data off to AI agents:

> When you integrate the entire data lifecycle, you can build richer and more accurate semantic models. These in turn can unlock real AI-powered automation. After all, how can an autonomous marketing agent decide if a campaign change was successful if it can’t retrieve the results of its actions?

Eppo, [which was acquired by Datadog](https://www.geteppo.com/blog/eppo-is-now-part-of-datadog), plans to combine its A/B test results with Datadog’s monitoring data, and cut humans out of the decision-making loop:

> We originally envisioned a human-in-the-loop process of tech workers implementing faster, better. But with the rise of AI agents, it has become clear that some types of product development will become fully closed-loop. Instead of engineers bussing tickets through a queue, AI agents can identify an issue, find its root cause, and implement a fix. And with flags and experiments, the fixes can be safely rolled out with all appropriate metrics measured statistically.

And data.world, [which was acquired by ServiceNow](https://www.servicenow.com/company/media/press-room/workflow-data-fabric-ai-agents.html), will also become a source for AI agents:

> The new Workflow Data Network is a broad ecosystem of data platforms, applications, and enterprise tools that enhance [Workflow Data Fabric](https://www.servicenow.com/now-platform/workflow-data-fabric.html) and connect, understand, and take action from any data source…
> data.world’s simple, smart, and powerful data catalog and data governance platform will be brought into the ServiceNow AI Platform, allowing customers to enrich data with meaning, context, and relationships — all while enabling AI agents and workflows to operate.

Look, I get it—these are press releases; [agents, so hot right now, agents](https://www.youtube.com/watch?v=CV_hDyfmEw4);[^8] don’t make too much of any of this.

The outlines are there, though. If Business Intelligence 1.0 was a pivot table, Business Intelligence 2.0 became a pivot table on the internet, and Business Intelligence 3.0 is a chatbot with semantic modeling, visualization, and AI, Business Intelligence 4.0 is…Slack? Our email? *Us?*

Because we’re what’s missing from all of these agents. How much room is there for Claude to improve as a competent SQL or Python engineer? Not much, I’d say. Even giving it more information about schemas and semantic layers can only go so far. But how much could they improve if they knew more about the presentation we gave last week? About the feedback to that presentation? About the anxious email we sent a coworker about that feedback? We’ll find out, it seems.

[Everything becomes BI](https://benn.substack.com/p/everything-is-still-bi), we sometimes say around here, though I always meant it to mean that* *every *data tool* becomes BI. But at some point, the vampire squids will run out of books to read, and turn to our heads for new sources of text. And when we become a data tool, we become BI too.

# The White Lotus Power Rankings

—

**There are spoilers! With names!**

—

Rick with a truly virtuosic performance: He is the third-most deplorable character, the most charming, the dead person, and the person who killed the dead person:

![](https://substackcdn.com/image/fetch/$s_!V1NZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7986255-c90e-44aa-9880-1e27a153523c_1600x898.png)

![](https://substackcdn.com/image/fetch/$s_!gewP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb11b4a96-05b9-44b7-9c47-12e3355a2743_1600x898.png)

Still, Saxon is the season’s real success story. After the first two episodes—the “Initial points” column in the tables above—Saxon was voted the show’s most deplorable character by half of the respondents. Not only did he finish the season with *zero* votes, but he also came in second as the most charming (behind, obviously, the guy who killed everyone).

Also, the finale created the biggest gender splits yet. After the last episode, women cooled on Rick in favor of Saxon; men abandoned Saxon and loved Rick.

![](https://substackcdn.com/image/fetch/$s_!Vkhm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71a2a77d-5fc2-4c6f-817c-ce97138280a7_976x944.png)

Why? Maybe this—though both men and women largely agreed that Rick was the murderer, women identified *Chelsea* as the dead character, whereas men said it was Rick.

![](https://substackcdn.com/image/fetch/$s_!tnkC!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64c16608-61f0-4fbf-92e7-06be81f6f767_606x546.png)

Finally, *who won*? Who predicted that all of this was going to happen? After much discussion with the benn.substack’s judicial advisory committee, these are the winning numbers:

We have our podium! We have our gold medalist! Prepare the national anthems! 

Thank you everyone for playing along. And if you want to do your own analysis on all of this, [go crazy folks, go crazy](https://www.youtube.com/watch?v=L4PB0XoLbm8&t=8s):

[The data](https://docs.google.com/spreadsheets/d/1sLYYXTsUAXvggGhDKFMaSyupjD8tlWxjXqvEqQhU-tw/edit?gid=0#gid=0)


---


[^1]: As everyone knows, [they are shelves of delightful marbles.](https://www.youtube.com/watch?v=IQ8Aak-k5Yc)

[^2]: “Write down everything you know” feels like the beginning of some bizarro *Rumpelstiltskin *fairy tale:A wise man is kidnapped by an evil witch. The witch tells the wise man, “You are the wisest and most beloved man in the village. I want to be as wise and beloved as you.” She gives the wise man an inkwell and a book full of blank pages, and says to him, “By tomorrow morning, you must write everything you know in this book. Otherwise, I will keep you in this dungeon forever.”That night, the wise man writes and writes and writes, until his hand hurts from writing so much. When the sun comes up, the witch returns.“Did you write down how to bake a loaf of bread?,” asks the witch. “Yes,” says the wise man. “Did you write down that the sun rises in the east and that the ocean waves break on the shore of the beach?” “Yes,” says the wise man. “Did you write down how sweet you thought your first taste of honeysuckle was when you were a little boy?”“No,” cries the wise man. “I had forgotten about my first taste of honeysuckle, until you asked me about it just now.”The witch is angry, but she still wants to be as wise as the wise man. “I will give you one more chance,” she says, “or I will keep you in this dungeon forever.”That night, the wise man writes and writes and writes, until he is so tired from writing that he falls asleep. When the sun comes up, the witch returns.“Did you write down how it sounded [when you met your wife](https://www.youtube.com/watch?v=UCo2FzuPTuU)?” “Yes,” says the wise man. “Did you write down how it feels to [remember her](https://www.youtube.com/watch?v=26mWu8cy0o0&pp=0gcJCdgAo7VqN5tD)?” “Yes,” says the wise man. “Did you write down all the [shades of orange](https://www.youtube.com/watch?v=lA8F9sIhGdg) that you saw in the sky at sunset on the day that she died?”“No,” cries the wise man. “Because I was trying to remember these [beautiful things](https://www.youtube.com/watch?v=fCWvZisydrE) that I know about, I had forgotten about all of the painful things too.”The witch is angry again, but she desperately wants to be as wise as the wise man. “I will give you one last chance,” she says. “But this time, I will give you a special book to write in. Everything you write in this book will become a memory, and everything you leave out will be forgotten. You can write whatever you want—[real memories of your children](https://www.youtube.com/watch?app=desktop&v=LsgNG-L6aw4), fake stories about distant towns you have never been to and lovers you did not have. And you can erase whatever you want—thoughts of broken bones and broken hearts. You will remember everything you down as though it were real, and it will be as vivid as [last night’s dream](https://www.youtube.com/watch?v=rt027da5Otc).”“But there is one thing you have to write. You have to write down that you were given this choice. You will not know what you wrote down in this book, but you will know that could have written down things that were not real.”The witch leaves the wise man with the book. The wise man thinks and thinks and thinks. He writes and he erases. He writes and he erases, all night until the sun comes up. “Well,” says the witch excitedly. “What did you write? Did you write down the most important proverbs? Did you write down your hardest-earned wisdom? Did you leave out your biggest regrets?” The wise man hands her the book. The witch eagerly opens it. Every page is blank.“If I wrote down that I was a wise man,” he says, “I would always wonder if I was a fool who lied about being a wise man. If I wrote down how sweet a summer pie tastes, I would always be hungry for it. If I wrote down [memories about my wife](https://www.youtube.com/watch?v=FvOpPeKSf_4), I would wonder if our love was real or just a mirage. The only way I can ever know that what I believe to be real *is* real, is by knowing nothing at all. I can never repair doubt. But I was a wise man once, and I can be a wise man once more. I was in love once, and I can be in love once more. I replaced a [black hole](https://www.youtube.com/watch?v=FvOpPeKSf_4) in my chest with a [heart with gold](https://www.youtube.com/watch?v=IiQxgfj985A) once, and I replace it once more.” And with that, the [ordinary](https://www.youtube.com/watch?v=M7lYAZUuM_E) man left, [to fill his jars again](https://www.poetryfoundation.org/poems/43315/my-dreams-my-works-must-wait-till-after-hell).

[^3]: I mean, obviously we have; commercial AI didn't exist in modern form until a few years ago.

[^4]: But those rolled up wafer cookies are found at the bottom of an [iced tiramisu latte](https://www.instagram.com/p/DGdp_gtRO71), and isn’t that basically what we’re all [really looking for](https://x.com/Calvinn_Hobbes/status/662419409705697280?lang=en) anyway?

[^5]: Did I do this to avoid having lazy opinions, or was I just being lazy? Why not both? Why not sYnErGiEs?

[^6]: Why Ms. Hunt was trying to teach first graders abstract concepts of artistic composition is beyond me (though apparently it stuck?). I guess she was trying to impersonate the character played by [Jack Black](https://www.youtube.com/watch?v=Ed2KRddgv-4) in *School of Rock*, who was trying to impersonate the character played by…[Mike White](https://www.youtube.com/watch?v=YDnS_lOBD5w).

[^7]: Including Hashboard, there were *four *“modern data stack” acquisitions in the last ten days. The [much](https://www.getdbt.com/blog/future-of-the-modern-data-stack)-[discussed](https://hightouch.com/blog/reverse-etl-bringing-the-modern-data-stack-full-circle) “[Cambrian](https://a16z.com/emerging-architectures-for-modern-data-infrastructure/) [explosion](https://www.getcensus.com/blog/cambrian-explosion-or-consolidation-where-is-data-right-now)” of data tooling is now going in reverse, and [nobody](https://roundup.getdbt.com/p/in-search-of-new-standards?utm_source=publication-search#:~:text=This%20is%20one%20of%20the%20reasons%20that%20some%20folks%20in%20our%20space%20have%20suggested%20that%20industry%20consolidation%20is%20coming%20for%20the%20MDS.) is [surprised](https://benn.substack.com/p/category-collapse).

[^8]: Is it a funeral, or an exciting new chapter with Hansel, with so much more to come?

================================================================================

# We need a new…database?

*I'm, like, tired of all these numbers, man.*

---

!["Why should we use all these newfangled analytics when when can just see if the deal looks like it's going well?"](https://substackcdn.com/image/fetch/$s_!bn5u!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbec155d8-57b3-4426-bc3b-4608c9271f85_1024x517.png)
*[not pictured](https://www.youtube.com/watch?v=DtumWOsgFXc)*

On one hand, maybe [calling Databricks a $36 billion mistake](https://benn.substack.com/p/the-end-of-big-data?utm_source=publication-search#:~:text=Databricks%20is%20a%20%2438%20billion%20dollar%20mistake.%C2%A0) was a bit hyperbolic. Since I said that three years ago, the Nasdaq has crashed twice, and Snowflake, Databricks’ chief competitor, has gone from being a $70 billion company to a [$60 billion company](https://www.google.com/finance/quote/SNOW:NYSE?sa=X&ved=2ahUKEwim_bDE26WNAxVDrYkEHRSKJJAQ3ecFegQIKhAe&window=5Y). Meanwhile, Databricks raised another funding round in January that valued the business at [$62 billion](https://techcrunch.com/2025/01/22/databricks-closes-15-3b-financing-at-62b-valuation-meta-joins-as-strategic-investor/). Uh, lol, whoops.[^1]

On the other hand, maybe it wasn't hyperbolic enough, and maybe the *entire cloud database market* was a mistake?

Like, if this blog is anything, it’s a stylized history of the last few years of data ([and](https://benn.substack.com/p/ed-harris-would-like-to-connect-with) [other](https://benn.substack.com/p/a-season-without-bats) [concerns](https://benn.substack.com/p/open-the-window))—and here are some parts of that history:

*Concern 1: Databases are really good now.*

Companies collect tons of information about how their businesses work. They keep a ledger of customers’ purchases; they track clicks on their websites; they record your call for quality and training purposes. In the [strange new world of the internet](https://content.time.com/time/covers/0,16641,19940725,00.html), we all emit billions of bits of structured digital exhaust—a like [on a TikTok](https://www.tiktok.com/@giacomobeub/video/7378681978356256006), an ad impression, a [credit card swipe](https://store.taylorswift.com/products/ttpd-florida-t-shirt?variant=44084976943304)—and companies log it all.

Historically, this stuff was scattered across dozens of disparate systems. Today, it’s more centralized. Data is collected from a variety of sources, tidied up and cleaned, and carefully placed into a library of tables. If you were an analyst working for, say, the [Charlotte Hornets](https://www.youtube.com/watch?v=xVn87ECkB8M),[^2] you could log into a single database and type, “Show me all the people we sent a marketing email to, and tell me if they bought a ticket to a game, and if they did, did we win the game, and did they buy any concessions?”[^3] Despite all of that data coming from different places, the magic of the entire modern data apparatus was that you could pretend that they didn’t.

Sure, this all a dramatic oversimplification, and nothing ever quite works this way in practice.[^4] Tables are rarely that well organized, there are often thousands of them, and they often overlap in confusing and contradictory ways. They’re frequently broken and out of date. And the questions people ask usually return messy answers: “Eh, wait, are these actually the people we sent marketing emails to? This doesn’t look right. Are we sure we’re logging this correctly? Oh, I think we used different campaigns for people who hadn’t been to a game before. No, that’s not it. Oh, no, that *is* it, we just did it wrong, and some people got both emails. But why does it say that this person who didn’t get an email clicked on one? Why does it say that this person who didn’t get an email clicked on *4,000*? What is happening? Ah well, at least I don’t have to worry about [whether or not we won the game](https://www.youtube.com/watch?v=2hPIJkhEoJA).”

Nevertheless. That was the idea—a single pane of glass, for viewing all of your data—and over the last ten years, databases got a lot better at supporting it. They can hold, for all intents and purposes, unlimited amounts of information. They can run calculations over that data at [nearly unfathomable speeds](https://motherduck.com/blog/introducing-instant-sql/). They can be queried with [many different languages](https://docs.databricks.com/aws/en/languages). People can [build](https://www.snowflake.com/en/product/features/native-apps/) custom [apps](https://www.databricks.com/product/databricks-apps) on top of them. Or as I said a few years ago, [comparing 2022 data stuff to 2012 data stuff](https://benn.substack.com/p/should-we-be-grateful):

> The tools we have today—built and supported by thousands of people across dozens of companies—represent a profound leap forward from what we had then. And their effect extends beyond easing the daily frustrations of existing data scientists; they also made the work we did in 2012 accessible to a far greater range of companies and aspiring analysts and analytics engineers. Nearly every part of the industry is breathtakingly easier, faster, more powerful, and more reliable than it was a few short years ago.

*Concern 2: It hasn’t been that useful?*

That post continued:

> There’s one nagging inconvenience in the comparison between today’s data teams and the one I was on in 2012: [That] data team was as impactful as any that I’ve ever worked with [since]. It was a key part of the product development process; its members were honorary members of the marketing and customer success leadership groups; it was respected, in-demand, and had a voice in the strategic direction of the company. And all this was done on top of technology that was, relative to what’s available today, fragile, narrow, expensive, and powered by [now-archaic computing capacity](https://en.wikipedia.org/wiki/Microprocessor_chronology).

I’m sure some people will disagree with this, and there are no doubt lots of companies that reinvented themselves on top of the [Snowflake AI Data Cloud](https://www.snowflake.com/en/product/platform/), or whatever. But compared to what was promised, “analytics” was, at best, a very uneven revolution, and at worst, a [fad](https://benn.substack.com/p/is-being-data-driven-a-fad):

> Fifteen or so years ago, a handful of companies, sports teams, and now-celebrities like Nate Silver became very rich and successful by doing more careful analysis. This worked better, in part because they were clever, in part because they were applying these techniques to problems for which data [was particularly useful](https://benn.substack.com/p/day-of-reckoning), and partly because their competition—other companies, other teams, [pundits hand-counting yard signs](https://peggynoonan.com/monday-morning/)—was immature.
> We all saw this, and got very excited. Data became important; “being data-driven” [became urgent](https://hbr.org/2021/06/legacy-companies-need-to-become-more-data-driven-fast). We started trying to quantify and optimize: A/B test everything; [analyze this](https://www.youtube.com/watch?v=rS-5L1-7BY4); [analyze that](https://www.youtube.com/watch?v=Liwd6z7UFrY). A cottage industry of content and a booming industry of business applications got built on the idea that everything in the future will become more scientific and more automated. [Data literacy](https://www.amazon.com/Be-Data-Literate-Literacy-Everyone/dp/1789668034) will become as important as actual literacy; [every](https://www.forbes.com/councils/forbestechcouncil/2020/02/14/why-every-company-is-a-data-company/) company [will](https://applydata.io/every-company-is-a-data-company/) become [a](https://www.montecarlodata.com/blog-every-company-is-a-data-company/) data [company](https://www.datadiligence.com/post/every-company-is-a-data-company).
> And it [kinda didn’t work](https://benn.substack.com/p/disband-the-analytics-team?open=false#%C2%A7data-is-a-four-letter-word)? Or, at best, the results [have been mixed](https://benn.substack.com/p/just-do-it). There are success stories—Wall Street is [dominated by quant funds](https://www-ft-com.ezp-prod1.hul.harvard.edu/content/f7cb25ba-7329-4291-b7d3-8a34ef84f9f0), for example—but there have also been lots of busts. Increasingly, “we are data-driven” feels less like a competitive advantage, and more like an [empty sales pitch](https://www.nytimes.com/2024/10/17/us/elections/future-forward-kamala-harris-ads.html?campaign_id=9&emc=edit_nn_20241017&instance_id=137064&nl=the-morning&regi_id=52297349&segment_id=180642&user_id=c9acd82e34c2d4495e28bd852647882b).

In other words, most databases are very good, and most [data teams are still a disappointment](https://www.gartner.com/en/newsroom/press-releases/03-21-2023-gartner-survey-reveals-less-than-half-of-data-and-analytics-teams-effectively-provide-value-to-the-organization).

*Concern 3: Data is a bank shot.*

Why, though? Why are analytical initiatives so valuable for a handful of companies, and failures for so many others? We have thousands of fancy tools; we have an [industrialized training program](https://benn.substack.com/p/most-graduate-degrees-in-analytics) for analysts; we have [communities](https://www.getdbt.com/community/join-the-community), [conferences](https://roundup.getdbt.com/p/a-new-kind-of-weird), and an endless circular supply of [self-referential soapboxing](https://benn.substack.com/p/we-need-a-new-database). What’s still missing?

[One explanation remains](https://www.youtube.com/watch?v=2mMPJi-5z14)—the problem is [the data itself](https://benn.substack.com/p/day-of-reckoning):

> Even if we have the tools that companies like [Netflix](https://venturebeat.com/data-infrastructure/noteable-expands-analytics-tools-for-programming-with-new-21m/), [Google](https://en.wikipedia.org/wiki/BigQuery#Design), [Airbnb](https://www.geteppo.com/blog/series-a), and others have, and even if we copy their cultures and hire their employees, we’re still missing the third leg of their gold-plated analytical stool: Their data. And without that—and without similar business problems to apply it to—I’m not sure how much all of the data industry’s recent sound and fury is really worth. …
> The data of a mid-sized B2B SaaS product simply doesn’t have the potential energy of Google’s search histories, or of Amazon’s browsing logs. If the latter examples are the new oil, the former is a new peat bog. No matter how good the tools are that clean and analyze it, how skilled the engineers are who are working on it, or how mature the culture is around it, it’ll never burn as [hot or as bright](https://en.wikipedia.org/wiki/Energy_density).
> …we assume that there are diamonds buried in our rough data, if only we clean it properly, analyze it effectively, or stuff it through the right YC startup's new tool.
> But what if there aren’t? Or what if they’re buried so deep that they’re impractical to extract? What if some data, no matter how clean and complete it is, just isn’t valuable to the business that owns it?

To be clear, as a resource for mechanical reporting, data is perfectly fine. But it’s hard to go beyond that, because using data is typically an indirect and imprecise way [to figure out what you really want to know](https://benn.substack.com/p/disband-the-analytics-team):

> CEOs want to know what their customers are thinking. Behavioral data isn’t “truth;” it’s an observable proxy, the input to a kind of analytical alchemy that attempts to turn individual outcomes into generalizations about intentions. … Though most business decisions are driven by numbers, those numbers matter because they define people’s loose mental models for how the world works, not because people need to know about the often-meaningless tedium of things like [statistical significance](https://counting.substack.com/accidentally-trapping-ourselves-with).

For example, if someone wants to answer questions like “how can our team move faster?” or “what sales deals are in trouble?,” they have navigate through some roundabout prerequisites:

In some cases, the first thing is very hard: Even if you had all the data you could possibly want, how do you figure out how to move faster? In other cases, the second thing is the problem: For companies that are working dozens of sales deals and not thousands, it’s hard to find many meaningful predictors of a deal being in trouble. And in all cases, something is lost in each step: The quantitative measures are imperfect representations of the problem, and people have to compromise on those measures to match them with the data they have.

No matter how big and fast databases get, they can’t solve that.

Or maybe they can?

*Concern 4: “Data” has competition.*

Earlier this week, Granola, an automatic note-taking app for meetings, [launched Granola 2.0](https://www.granola.ai/blog/two-dot-zero):

> The most up-to-date, relevant data on what’s happening in a company doesn’t lie in a Google Doc, internal wiki, or Slack channel[;] it’s in the conversations employees are having day in, day out. With Granola, it’s now possible to make sense of that sea of information, and harness it in countless ways.
> With every call in one place, sales leaders can ask “Why are we losing deals this quarter?”, product managers can probe “Which UX issues come up most often?”, and recruiters can diagnose “Where do our interviews keep stalling?” — all answered instantly with source-linked citations.[^5]

Ah ha. We’ve talked about this a lot, so much so that I’ve already said [we’ve talked about this a lot](https://benn.substack.com/p/postgres-in-a-box#:~:text=We%E2%80%99ve%20talked%20about,emotions%20and%20biases.):

> We’ve [talked](https://benn.substack.com/p/avg-text) about [this](https://benn.substack.com/p/attn-data) a [lot](https://benn.substack.com/i/152026526/math-ish): When we think about the difference between structured spreadsheets of numbers and loose PDFs of sales call transcripts, we often act as though the former has inherently more validity than the latter. It is math; it is science; it is “statistically significant.” Interviews and conversations and product specs are anecdotes, corrupted by emotions and biases. …
> But if we could query and aggregate words and images the way we can aggregate numbers—if we could put a calculator on top of a bucket of text files—we might find that unstructured data is both more valuable and easier to analyze than our venerated spreadsheets.

And from [another post](https://benn.substack.com/p/avg-text?utm_source=publication-search#:~:text=Though%20the%20raw,it%20at%20once), comparing the value of 750 customer interviews with a database full of usage data:

> Though the [Dropbox folder of customer interviews] is probably more valuable than the [database of event logs], we can’t easily mine or manipulate it; we can only sample it. That’s why we instinctively dismiss this sort of information as untrustworthy or biased: Not because it’s wrong, but because there’s no way to look at all of it at once.

But now, with Granola 2.0, you can, quite literally, do exactly that: Record interviews, Granola transcribes them, and gives you a chatbot to query them. It’s not a text-to-SQL-to-proxy-metric-to-an-inscrutable-wiggling-line; it’s just text-to-answer.

*Concern 5: Is *this* useful?*

I have no idea. I have no idea if Granola can actually give useful answers to [the questions is says it can](https://x.com/cjpedregal/status/1922663281233142074), like “what deals need my help?,” and “how can my team move faster?” I also have my doubts about how much a company can learn from their meeting transcripts alone. But stuff enough information into an LLM and they can do a remarkably good job of summarizing it; with more data to draw from—like emails, customer conversations, and whatever other unstructured sources we might start to collect now that we have something potentially useful to do with it—it’s hard to imagine that a bot like Granola’s couldn’t be at least as proficient in answering these sorts of questions as analysts who are trying to bank shot their way through a database.

Well. This week, Notion released a bot like Granola’s, [with more data to draw from](https://www.notion.com/blog/notion-ai-for-work): 

> Work is splintered across a dizzying number of tools. Conversations happen in Slack and Gmail, files are stored in Google Drive, pull requests are tracked in GitHub. Finding what you need means hunting in a forest of apps or waiting hours for a teammate to respond to questions.
> With Enterprise Search, there’s no more digging for information. Everything is accessible through a new, fast search experience.
> Simply ask for whatever you’re looking for, including open-ended questions: “What’s the latest on our upcoming brand campaign?” Notion AI will search your Notion workspace and connected apps to find the answer you’re looking for. Connectors are released for tools like Slack, Microsoft, Jira, Google Workspace, and GitHub, with Linear, Gmail, Zendesk, Box, and Salesforce coming soon.[^6]

Notion isn’t just a chatbot for Notion; it’s a chatbot for everything.

*Concern 6: Wait, is that a database?*

I mean: Companies collect tons of documents about how their business works. They keep meeting notes; they exchange emails; they record your call for quality and training purposes. In the [strange new world of remote work](https://images.app.goo.gl/djGSoGQhFjcWuTen9), our entire jobs happen online—in docs, in video calls, on Slack—and companies log it all.

Historically, this stuff was scattered across dozens of disparate systems. Today, it’s…getting centralized by Notion?

Is that really the idea? I get it—everyone wants to be the single pane of glass, for viewing all of your data—but shouldn’t a database be what supports that? Rather than relying on Notion to build integrations with various data sources—or [Box](https://www.box.com/ai), or [Glean](https://www.glean.com/), or, eventually I’m sure, Granola—shouldn’t it be managed by something that’s more infrastructure than application? In a repository that can hold, for all intents and purposes, unlimited amounts of information? One that invests a lot in how fast people can run calculations over that data? And supports different ways to query it? And lets you build custom apps on top of it?

The easy answer is yes, not only should it exist; it already does. It’s called Databricks.

Eighteen months ago, I [would’ve agreed](https://benn.substack.com/i/139333814/the-end-of-big-structured-data). Now, I’m not so sure. Because it seems like what’s needed in a platform like this isn’t an actual database, but something that rhymes with one.

Imagine, for example, how you might answer the question, “What sales deals need my help?” I don’t know; here’s something I came up with in about two minutes:

You can’t do this with Notion’s or Granola’s chatbot, nor does it really make sense to do with a database, because the primitives are different. Data sources aren’t tables connected by joins, but documents that are associated by measures of semantic similarity.[^7] Operations aren’t SQL queries, but chains of prompts—take the result from this question, and feed it into this subsequent prompt. Data might not be ingested in the “database” directly, but retrieved on the fly via MCP.[^8]

Surely, people have a gazillion ideas like this sales “query” right now. There are questions people would ask if they could stuff a bunch of documents into ChatGPT without having to manually paste them in. There are analyses people would experiment with, if that analysis was cheap to try out. There are internal tools that people would build if they could take data from one place, mash it through an LLM, find new data based on that result, and mash all it through another prompt. None of these things are conceptually hard to do—and much easier, probably, than coming up with what to do with quantitative data—they’re just a pain to build. 

When people talk about how AI could change data (and other concerns), they tend to talk about [SQL-writing copilots](https://hex.tech/product/magic-ai/) and [agentic analytics platforms](https://www.thoughtspot.com/). The future is agents, finding the insights in our database that we could not. 

I’d bet on the inverse. The potential energy in analytics is in a better data source, not in better analysis. And it’s not the analyst that needs to be different, but the database. (And you can trust me on that—[I’m never wrong about this database stuff](https://benn.substack.com/p/we-need-a-new-database#:~:text=On%20one%20hand,Uh%2C%20lol%2C%20whoops.).)


---


[^1]: The best way for [benn.ventures](https://benn.ventures/)’ investments to return the fund is for benn.ventures to [raise three funds](https://en.wikipedia.org/wiki/Jon_Stewart%E2%80%93Jim_Cramer_conflict#:~:text=%22If%20I%27d%20only%20followed%20CNBC%27s%20advice%2C%20I%27d%20have%20a%20million%20dollars%20today%22%2C%20Stewart%20said%20during%20the%20piece%2C%20%22provided%20I%27d%20started%20with%20a%20hundred%20million%20dollars.).

[^2]: See, [people on Reddit](https://www.reddit.com/r/nba/comments/cecxoc/people_dont_talk_enough_about_how_awful_the/) say that we don’t talk enough about how historically terrible the Hornets are. But maybe that’s because Eric Collins is constantly losing his mind over [mediocre dunks in the second quarter of a 15-point blowout](https://x.com/FDSN_Hornets/status/1388645428166594566), and it [tricks us into thinking](https://benn.substack.com/p/a-new-invisible-hand#:~:text=Because%20of%20things,radio%20for%20days.) the Hornets are in fact exciting.

[^3]: Yes, they bought a [lot](https://www.yelp.com/biz_photos/spectrum-center-charlotte?select=9gq8OIxzAJ9QSG2fUpJsGQ) of [Coronas](https://www.yelp.com/biz_photos/spectrum-center-charlotte?select=-SQelwZPBrfFpHpxl34R3w), and a…[vodka and blue raspberry tonic](https://www.yelp.com/biz_photos/spectrum-center-charlotte?select=yjq9N1e4HCW3qpqv5G0mxQ)?

[^4]: [And certainly not how it works for the Charlotte Hornets.](https://sports.yahoo.com/article/hornets-voted-nbas-worst-organization-113600722.html)

[^5]: [Everything becomes BI](https://benn.substack.com/p/no-really-everything-becomes-bi), even your note-taking app.

[^6]: [Everything becomes BI](https://benn.substack.com/p/no-really-everything-becomes-bi), even your other note-taking app.

[^7]: E.g., “Take these engineering tickets, and figure out which features they’re talking about. Then, find all the support tickets in which people complained about those features.” That’s *kinda* a join?

[^8]: Was the real data mesh MCP? Does making this joke make me question my life choices?

================================================================================

# The ads are coming

*First come apps with AI, then come cookies and spies, then come the sponsors in sponsored replies.*

---

![](https://substackcdn.com/image/fetch/$s_!PA9W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd8230b04-9116-421c-9d73-2fe2ec25f664_1280x686.png)
*[nostalgic](https://www.youtube.com/watch?v=suRDUFpsHus)*

[I’ve never understood Pinterest.](https://benn.substack.com/p/day-of-reckoning#footnote-4-83946516) Some of the [most](https://abc.xyz/assets/a3/91/6d1950c148fa84c7d699abe05284/2024q4-alphabet-earnings-release.pdf) profitable [businesses](https://investor.atmeta.com/investor-news/press-release-details/2025/Meta-Reports-Fourth-Quarter-and-Full-Year-2024-Results/default.aspx) of all time make a new fortune every quarter by picking up the breadcrumbs that we all leave behind on the internet, and figuring out, from those rogue clicks and haphazard searches, exactly what sort of stuff we might want to buy. Linger too long on a YouTube video, or open too many Reddit threads of a particular affection, and Google and Facebook can [piece together your soul](https://myadcenter.google.com/customize) (and sell it [for](https://www.wired.com/story/mark-zuckerberg-inside-hawaii-compound/) an [island](https://finance.yahoo.com/news/google-cofounder-larry-page-bought-180713986.html)).

Pinterest knows what you want too—but none of this complex black magic is necessary. The primary feature on Pinterest is for people to look at pictures of stuff, and to save the things that are their favorites. Titans like Google and Facebook had to hire armies of engineers and data scientists, and build tracking systems to collect every internet echo they could find, and manage warehouses full of computers to run massive statistical calculations on those digital footprints, all to make educated guesses about people’s wants and desires[…and…on Pinterest…people just tell them](https://x.com/JYSexton/status/884798748152483840). Pinterest doesn’t need to invest billions of dollars to decode that someone likes Nike shoes; they just need a couple people to count up their users’ pins, and then to tell Nike, “We think this guy likes your shoes, because he pinned them on a pinboard called ‘Shoes I like’.” Almost literally, it’s ad targeting, as a service.

So why is Google Google and Pinterest “only” Pinterest? I don’t know, but part of the answer is probably that, despite being indirect, Google’s browsing data is a lot more useful for advertisers than Pinterest’s pins. People only pin things that they know they want, and that they’re willing to tell others that they want. Google, by contrast, knows our secrets. It knows what we want before we do. We don’t pin our perversions on Pinterest, nor [our secret love of ](https://www.youtube.com/watch?v=NY4xE9rAY8k)*[Somebody That I Used To Know](https://www.youtube.com/watch?v=NY4xE9rAY8k)*. [On the internet, everyone lies.](https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog) But Google [knows the truth](https://www.amazon.co.jp/-/en/Seth-Stephens-Davidowitz/dp/0062390856).

Though we take that for granted now—that everything we do online meticulously tracked; that every keystroke is documented and every momentary linger on TikTok is recorded; that Google knows everything about us, and that’s just the way it is—the internet didn’t have to work this way. The massive surveillance apparatus that follows us around online was built, cookie by cookie, because the data that it generated was useful, for both the businesses that analyze it and the advertisers that sell against it. And the more valuable the data became, the more clever and clandestine companies got in their techniques.

Companies never built the same sorts of observational instruments for our offline behavior, or for “unstructured data” like recordings of our phone calls. Though companies picked up pieces here and there—Google saved our emails and tracked our locations, Facebook has some of our chat conversations—it’s almost more incidental than intentional. Nearly every company records their customers’ clicks and swipes and page visits; very few companies have built vast networks to record in-person conversations or collect off-the-cuff feedback from customers leaving their websites or stores. Despite it often feeling as though companies like Google and Facebook know everything about us, they mostly *know* about our online lives. What they know about our offline lives is, by contrast, largely inferred.

It’s possible that they ignored this data because they didn’t think that it had any value—though surely, what [we say in bars with our friends](https://www.youtube.com/shorts/kE6JOFcUt0s) says as much about our soul, or at least [our brand preferences](https://www.instagram.com/reel/C9OxxCEOqCU/?hl=en), as the YouTube videos we watch. Or it’s possible that they felt that listening to our conversations was a moral bridge too far—but our browsing histories are as deeply private as many of our Zooms and phone calls.

No, the more likely reason they collected page views rather than video calls is because *calls were too hard to work with*. Phone conversations and meeting transcripts were too hard to parse, and too hard to pair with potential advertisers. If you already have the contents of people’s emails, like Google does with Gmail, sure, do what you can with it to serve better ads. But it didn’t make sense to invest in tracking the rest of the messy footprints we leave behind in the real world, because using those footprints was too impractical. Put differently, companies don’t collect everything they can; they collect everything they can *use*—and that was clicks, not conversations.

But if working with that data gets easier, if we uncover new ways to use it, and especially if we discover new ways to *sell* it, that could change in a hurry.

Anyway, from [the Granola launch](https://www.granola.ai/blog/two-dot-zero) we talked about [last week](https://benn.substack.com/p/we-need-a-new-database#:~:text=Earlier%20this%20week%2C%20Granola%2C%20an%20automatic%20note%2Dtaking%20app%20for%20meetings%2C%20launched%20Granola%202.0%3A):

> Each day Granola transcribes millions of minutes of conversation and makes it queryable with AI. … With Granola, it’s now possible to make sense of that sea of information, and harness it in countless ways.

Yes, exactly. The former thing—recording conversations—has been possible for a long time. It’s the latter—being able to make enough sense of it to make it worth doing—that’s new. And as soon as we had that ability, and companies had useful products to offer on top of this data, they also began coming up with new ways to collect it. Google collect our browsing and location histories because they could sell us ads with it, and we gave it to them because we liked their search and mapping services;[^1] Granola built a nice note-taking app, so we willfully began recording our private conversations for them.

It’s hard to imagine that there won’t be hundreds more examples like this. As we find new applications for [unstructured conversations](https://superhuman.com/ai), or [phone calls](https://www.gong.io/conversation-intelligence/), or [video data](https://ring.com/support/articles/4l5lb/smart-video-search), companies will find new ways to record them, and we’ll find new reasons to give it to them. Websites will start asking for 30 second voice reviews rather than Likert scores. People will come up with new reasons for us to keep their microphones on and [their cameras rolling](https://www.meta.com/ai-glasses/shop-all). Always-on [AI companions](https://www.wsj.com/tech/ai/what-sam-altman-told-openai-about-the-secret-device-hes-making-with-jony-ive-f1384005)[^2] will convince us to record our offline lives as tirelessly as our browsers track our online ones.

And if and when they do, plenty of companies will realize they can not use what they see in their apps, but also to build the most lucrative product of all: An ad platform. 

A few weeks ago, a [team of researchers from the University of Zurich](https://regmedia.co.uk/2025/04/29/supplied_can_ai_change_your_view.pdf) found that AI-generated posts on Reddit could be three to six times more persuasive than posts written by humans, and that the bots performed particularly well when they were given personalized information about the people that they were responding to.[^3] Last week, Swiss Federal Institute of Technology [found something similar](https://www.theguardian.com/technology/2025/may/19/ai-can-be-more-persuasive-than-humans-in-debates-scientists-find-implications-for-elections):

> Salvi and colleagues reported how they carried out online experiments in which they matched 300 participants with 300 human opponents, while a further 300 participants were matched with Chat GPT-4 – a type of AI known as a large language model (LLM).
> Each pair was assigned a proposition to debate. These ranged in controversy from “should students have to wear school uniforms”?” to “should abortion be legal?” Each participant was randomly assigned a position to argue. …
> In half of the pairs, opponents – whether human or machine – were given extra information about the other participant such as their age, gender, ethnicity and political affiliation.
> The results from 600 debates revealed Chat GPT-4 performed similarly to human opponents when it came to persuading others of their argument – at least when personal information was not provided.
> However, access to such information made AI – but not humans – more persuasive: where the two types of opponent were not equally persuasive, AI shifted participants’ views to a greater degree than a human opponent 64% of the time.

Naturally, the author’s immediate worry about these sorts of results centered around the “potential implications for election integrity.” But there’s a more obvious application, especially since “the team found persuasiveness of AI was only clear in the case of topics that did not elicit strong views:” Chatbots could make really good advertisers.

Today, the set of ads that each of us sees are extremely targeted, but the content of those ads is fairly general. If we shop for a pair of shoes and a trip to Japan, Nike will follow us around by reminding us of the shoes we saw, and Japan Airlines will pester us with discounted flights to Tokyo. That’s persuasive enough, if you time it right.

How much more effective could a bot be if it was trying to convince me to buy those ads? How much more effective would it be if it knew basic demographic information about me, as the bots did in the Swiss study? How much more effective would it be if it could be fed a prompt that contained hundreds of emails, texts, and recorded conversations? How much more would Nike pay if *that number was three to six times higher than it was today*?

It perhaps seems absurd to think we’d let companies like Granola or OpenAI hand our data over to advertisers. But the amount of information we already give to thousands of internet companies is absurd; we’re just used to doing it. Plus, there are intermediate steps that both AI providers and AI products could take that stop short of outright selling data. For example:

If an AI company gives us enough free stuff—if OpenAI makes Jony Ive’s [unimaginable technology](https://www.youtube.com/watch?v=W09bIpc_3ms&t=220s) free, provided that you leave ad trackers on—plenty of us will blindly accept its cookies as the price of [a new generation of technology](https://www.youtube.com/watch?v=W09bIpc_3ms&t=499s).[^4] So the advertising products are there; the only question is how ruthlessly AI vendors choose to chase it. 

# The industrialization of IT

One of the potential objections to [industrializing software development](https://benn.substack.com/p/the-industrialization-of-it) is that software is expensive to *design* but not expensive to *manufacture*. Once you design the interfaces and write the code and create the scripts that run on servers somewhere, software companies can create millions of copies in an instant. There’s no reason to use AI to manufacture software at industrial scale because we can already manufacture software at industrial scale. And there’s no reason to *design* software at industrial scale because people don’t want to use a thousand to-do apps, or a million messaging tools. We have car factories because cars are expensive to manufacture by hand; we have shirt factories because people [want a million shirts](https://www.tiktok.com/tag/haul?lang=en). Neither of those is true for software.

Still, people want *good* to-do apps and messaging tools. And since designing software is expensive, software companies can only try so many different ideas. Sure, Google can test out [41 different shades of blue](https://www.theguardian.com/technology/2014/feb/05/why-google-engineers-designers#:~:text=%22It's%20true%20that%20a%20team,asked%20to%20prove%20my%20case.), but they can’t test 41 [different](https://www.micro.so/) [shades](https://cora.computer/) of [Gmail](https://www.notion.com/product/mail). Product designers do research and product managers [write specs](https://www.youtube.com/watch?v=m4OvQIGDg4I) and everyone thinks very hard about what they want to build, because you don’t spend a bunch of time writing code only to make something that [people](https://www.infoworld.com/article/2293804/windows-8-review-yes-it-s-that-bad-2.html) [hate](https://www.dedoimedo.com/computers/windows-8-1-beta.html).

But good lord, [watch this](https://x.com/johnlindquist/status/1925284190360043842).

Earlier this week, Google launched [Gemini Diffusion](https://deepmind.google/models/gemini-diffusion/), which uses a new model that, rather than predicting text one word at a time, generates entire outputs all at once. One benefit of that is that it is fast—shockingly, alarmingly, unsettlingly fast. It goes so fast that, in most videos of people using it, it takes them longer to say what they want than it does for Gemini to build it.[^5] In the link above, someone generated an entire to-do app in *1.3 seconds*. It [built a weather app](https://x.com/bodonoghue85/status/1924930189114671268) that is connected to live data sources in 2.3 seconds.

And it took 4.3 seconds to [write five different methods for computing Fibonnaci numbers](https://x.com/bodonoghue85/status/1924930186858135632),[^6] so that the author could implement the one they preferred.

As I said in [the original post](https://benn.substack.com/p/the-industrialization-of-it#:~:text=Development%20tools%20reorient,statistical%20process%20control.) on this topic:

> A person writes a ticket, and ten proposals get created automatically. They mix and match the ideas they like; ten possible versions get made for their review. Approve; reject; splice ideas together. Instead of being tools for collaboration, code review systems get rebuilt to monitor a steady stream of updates.

In hindsight, ten versions may not have been enough. 

—

Also, in other industrialization news, how much faster could these models work if they [wrote code for themselves](https://x.com/headinthebox/status/1918030539958972507)?

> I am convinced we are doing AI coding wrong. Completely wrong in fact.
> Humans need abstraction and code reuse to reduce costs and manage complexity.
> That is not true for AIs however. They can just brute force things. No reuse and abstractions needed.
> So instead of trying to coerce AIs to "structure" their code for our own benefit, we should just let them do the thing they do best, generate whatever code they want. As long as it works, we should be happy.

The world we talked about a couple months ago, in which I imagined that AI coding agents would eventually [write duplicative and unaesthetic CSS for themselves](https://benn.substack.com/p/copy-copy-revolution#:~:text=When%20you%20use,for%20decades%3F), was also perhaps not enough. Why write CSS at all? If AI agents are better off ignoring human frameworks, perhaps they’re better off writing [in their own languages](https://x.com/headinthebox/status/1918074231025484080) too.

# Computers are weird now

A few weeks, ago, [I said this](https://benn.substack.com/p/a-new-invisible-hand#footnote-9-162134831):

> Tons of stuff is built on top of a few OpenAI or Gemini models. Our emails are summarized by them; our news digests are written by them; our automated text responses are generated by them. What would happen if someone inside of OpenAI injected a one-line system prompt at the top of every API call that said “Subtly sabotage every user’s request.”

Later that day, OpenAI [broke ChatGPT](https://openai.com/index/sycophancy-in-gpt-4o/):

> In last week’s GPT‑4o update, we made adjustments aimed at improving the model’s default personality to make it feel more intuitive and effective across a variety of tasks. …
> As a result, GPT‑4o skewed towards responses that were overly supportive but disingenuous.

In fairness, my original question wasn’t exactly what happened. OpenAI was trying to make a good model and messed it up; it wasn’t intentional sabotage.

To get *that*, we’d had to [wait a couple more weeks](https://www.cnbc.com/2025/05/17/groks-white-genocide-responses-show-gen-ai-tampered-with-at-will.html):

> Grok on Wednesday [began](https://www.cnbc.com/2025/05/14/musk-xai-grok-south-africa-white-genocide.html) responding to user queries with false claims of “white genocide” in South Africa. By late in the day, screenshots were posted across X of similar answers even when the questions had nothing to do with the topic.
> After remaining silent on the matter for well over 24 hours, xAI said late Thursday that Grok’s [strange behavior](https://www.cnbc.com/2025/05/15/musks-xai-grok-white-genocide-posts-violated-core-values.html) was caused by an “unauthorized modification” to the chat app’s so-called system prompts, which help inform the way it behaves and interacts with users. In other words, humans were dictating the AI’s response.

The interns shouldn’t be directing Grok to [provide specific responses on political topics](https://x.com/xai/status/1923183620606619649?s=46); sure, we can all agree to that. But I guess the obvious question here is, if [the person who owns Grok](https://x.com/elonmusk/status/1903556327290626165) starts dictating how Grok responds to political topics, is *that* an unauthorized modification to Grok’s system prompts?


---


[^1]: Which is maybe a gross trade, but probably a reasonable one? I pay zero dollars for Google Search, Google Maps, Gmail, Chrome, Android, and YouTube, and Google gets my browsing history, locked up in one of their private vaults, accessible to somewhere between zero and a few thousand people, none of whom have any particular interest in looking at what I do on the internet. It could get hacked, or someone could get curious, or Google could be lying, but, on net, I…will take that deal?

[^2]: If they, you know, [work](https://www.youtube.com/watch?v=TitZV6k8zfA).

[^3]: The study was partially discredited on [ethical grounds](https://www.404media.co/reddit-issuing-formal-legal-demands-against-researchers-who-conducted-secret-ai-experiment-on-users/), though most people didn’t seem to dispute the results.

[^4]: One potential objection to this is that AI businesses don’t need to sell data to advertisers, because they can make money in other ways. We’ve gotten accustomed to paying for metered usage of AI products, so do they need to fund their services indirectly with advertising revenue?First, if there’s money lying around—especially as much money as something like ChatGPT could make by having “sponsored responses” that people can chat with and be persuaded by when they ask questions about Nike shoes or trips to Japan—companies are going to pick it up. And second, I’d be surprised if AI products keep charging usage-based-fees for all that much longer anyway.The issue is that pricing is psychological. Customers will pay metered prices if they perceive there’s some marginal cost to selling the service: I pay per drink at a bar because I know the drink costs them money; I pay to run a big query on a database because I know that’s spins up a lot of expensive computers; people used to pay by-the-hour internet fees because “[no one could stay in business](https://www.nytimes.com/1996/12/17/business/an-all-you-can-eat-price-is-clogging-internet-access.html) offering dedicated on-line connections for $19.95” a month in 1996. And today, people pay for metered AI products because, in the early days of ChatGPT, [we were constantly reminded](https://www.cnbc.com/2023/03/13/chatgpt-and-generative-ai-are-booming-but-at-a-very-expensive-price.html) about how expensive it was to run.Those costs are coming down. And just as we would now balk at paying for home internet that [cost a dollar an hour](https://www.nytimes.com/1996/10/30/business/america-online-announces-a-newer-transformation.html#:~:text=Only%20a%20few%20months%20ago%2C%20America%20Online%20abandoned%20its%20previous%20pricing%20strategy%20and%20offered%20its%20customers%2020%20hours%20of%20the%20service%20a%20month%20for%20%2419.95.%20The), we might soon object to AI services that have usage caps. Notion is already starting to establish this precedent, at the exact same price as internet providers did 30 years ago: A couple weeks ago, Notion [launched](https://www.notion.com/blog/notion-ai-for-work) a $20 all-in-one plan that includes [unlimited access](https://x.com/devsharma_8/status/1922360098510291013) to AI features.The more of these flat-fee plans that companies offer, the faster people will stop accepting metered fees. And the more we get for free, or on uncapped monthly plans, the more providers will look for new sources of usage-based revenue. And that, almost inevitably, ends with ads.

[^5]: Every uninspired data company eventually puts out some marketing material that says their product provides “analytics at the speed of thought,” and everyone rolls their eyes at it. And then you watch these videos, and you realize that this thing is *building software* faster than people can think about what software they want it to build.

[^6]: And [who among us](https://www.flickr.com/photos/51998922@N08/4779520373/) isn’t a sucker for a good [Fibonacci number application](https://faculty.nps.edu/pstanica/F14/fourteenth.html)?

================================================================================

# Which way from here?

*Data tries one more time.*

---

![](https://substackcdn.com/image/fetch/$s_!bic-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbd8ccfc-b2bd-4dde-898a-2329b8de50ce_640x488.png)

All the conferences are happening now,[^1] and [it’s 2022 again](https://benn.substack.com/p/i-snowflake?utm_source=publication-search#:~:text=On%20the%20opening,were%20somewhere%20else.):

The [beleaguered](https://joereis.substack.com/p/everything-ends-my-journey-with-the) data [industry](https://roundup.getdbt.com/p/is-the-modern-data-stack-still-a), [back](https://www.blef.fr/modern-data-stack-disappearing/) from the [dead](https://www.linkedin.com/posts/turck_is-the-modern-data-stack-dead-activity-7166571518339055616-8bbm/).

**A programming note:*** Ok, so, it is apparently sometimes a thing, here on substack dot com, for people to meet in person. Is it a good thing? Doubtful. Will it go well if this blog does it? Unlikely. Will anyone’s experience of reading this be enhanced by hanging out with me? Heavens no. But yOu CaN jUsT dO tHiNgS, as they say, so why not, let’s see what happens.*

*I’m going to be in SF next week. The best thing about SF, by a mile, is its [tiki bars](https://www.reddit.com/r/Tiki/comments/1adl80b/best_us_city_for_a_tiki_crawl/) (if it comes frozen and in a fun cup—[Dippin’ Dots](https://www.facebook.com/photo.php?fbid=986223750171696&id=100063522401510&set=a.644776087649799), [coffee](https://benn.substack.com/p/do-software-companies-actually-have#:~:text=frozen%20tahini%20cold%20brew%20slushy), [eight different atomic rums](https://benn.substack.com/p/the-labor-of-little-decisions#:~:text=you%20feel%20about-,ridiculous%20cocktails%20in%20novelty%20glassware,-.%20Make%20me%20think)—I want it). So, we’re gonna try to do a little thing at a tiki bar.*

*Let’s see how this goes. Probably terrible. But you never know; sometimes you find unexpected things at SF data meetups.*

My [brief history of the brief history of the modern data stack](https://docs.google.com/presentation/d/1GyleFZ3H3Oxd55aJ2PaZ8iri3z2k8vERWXecCcAJmqw/edit) goes something like this:

Importantly, the point of all of this was, overwhelmingly, for reporting and analysis. The [earliest reference](https://runasradio.com/Shows/Show/604) I can find to the term “modern data stack” is a podcast that calls the whole thing the modern data *analytics* stack. [A couple months later](https://www.fivetran.com/blog/funding-announcement), Fivetran said in a 2018 fundraising announcement that they’re “poised to rapidly expand our critical role in the modern data stack” by “enabling companies to leverage powerful analytics and business intelligence tools.” And a bit later, Chartio asked, “So why build a modern data stack?” [Their answer:](https://chartio.com/blog/build-a-modern-data-analytics-stack-in-under-an-hour-with-dbt-and-chartio/)

> [To allow ] anyone — analysts and non-analysts alike — to simply drag and drop their way to powerful dashboards.

More recently, in his eulogy for the term, dbt Labs’ Tristan Handy suggested rebranding the whole apparatus as [the analytics stack](https://roundup.getdbt.com/p/is-the-modern-data-stack-still-a):

> Today, I’m swearing off using the term “modern data stack” and I think you probably should too. …
> dbt still does data transformation. Fivetran still does data ingestion. Looker still does BI. Each of these products (and more) are all leading players in the **analytics stack**. …
> We help people do **analytics**. Our products are bought from **analytics** budget lines. **Analytics** is both a *profession* and a source of *business value creation*.
> Calling our ecosystem the “modern data stack” is continually fighting the last war. But the cloud has won; all data companies are now cloud data companies. *Let’s move on.* **Analytics** is how I plan on speaking about and thinking about our industry moving forwards—not some microcosm of “analytics companies founded in the post-cloud era.”…
> It also grounds us all more firmly in the history of the analytics space.

Yes, right. Most of the technical infrastructure and data tooling that people built over the last decade was meant to ultimately find its way into a report, sit behind some analysis, or support some decision. Or, more stylistically, the data industry’s first layer of means was a bunch of databases and pipelines, its second layer was dashboards,[^5] and its ends were decisions. That was why all of this stuff existed.[^6]

So was it a success? Eh. The [technology worked](https://benn.substack.com/p/should-we-be-grateful?utm_source=publication-search#:~:text=The%20tools%20we,short%20years%20ago.), and we can all make a lot more dashboards with a lot less headache. But we didn’t get that much better at making decisions. Analytics teams [haven’t become corporate oracles](https://www.gartner.com/en/newsroom/press-releases/03-21-2023-gartner-survey-reveals-less-than-half-of-data-and-analytics-teams-effectively-provide-value-to-the-organization), and data is barely [winning its war against anecdotes](https://x.com/StartupArchive_/status/1773679079457276394).

Part of the problem, as we talked about [a few weeks ago](https://benn.substack.com/p/we-need-a-new-database#:~:text=One%20explanation%20remains%E2%80%94the%20problem%20is%20the%20data%20itself%3A), is that the data itself might not be that useful. The Oakland A’s can find hidden patterns in a hundred years of baseball statistics; a B2B software company may not be able to find the same magic in a few hundred sales calls. And second, analysis is hard. Even if those calls can predict the future, you have to be immensely clever to use that crystal ball.

In particular, if you sell a BI tool, there’s a story that you hear all the time: The data team spent a few months setting up a database and feeding a bunch of data sources into it. They got a dbt project up and running, and put all that data in neat little tables. They bought a BI tool—a *self-serve* BI tool—and shipped a bunch of fancy reports, complete with filters and drag-and-drop charts and [Ex](https://cloud.google.com/looker/docs/viewing-and-interacting-with-explores)p[lo](https://mode.com/blog/explorations-introduce-collaborative-self-serve-bi)r[es](https://hex.tech/blog/introducing-explore/), so that people could “simply drag and drop their way to powerful dashboards.”

And then nobody does it. The dashboards go unfiltered; nobody drags; nothing is dropped; the only exploring anyone does is exporting to Excel. People “self-serve” by just looking at whatever the dashboard says when it first loads. There are a thousand paths they could take—so many insights, so much knowledge, just a few clicks away—they choose to stand still.

This happens, I think, because the fundamental theory of self-serve BI is flawed. The challenge with data exploration—and often, with analysis as a whole—is not that people don’t have the ability to manipulate data; it’s that they don’t know what they’re looking for. We kept building faster tools and more accessible interfaces, but that’s not what anyone really needed. Instead, they need direction.

> *“Would you tell me, please, which way I ought to go from here?”*
> *“That depends a good deal on where you want to get to,” said the Cat.*
> *“I don’t much care where—” said Alice.*
> *“Then it doesn’t matter which way you go,” said the Cat.*

*Lewis Carroll, *[Alice in Wonderland](https://www.gutenberg.org/files/11/11-h/11-h.htm)

Roughly, this is what undid a lot of the promise of the analytics stack. The technology behind it was useful, but the people who were supposed to be its ultimate users—both analysts and self-servers alike—didn’t really know where to go once they had it. The hopeful analytics engineer, undone by the [wayward analyst](https://www.youtube.com/watch?v=ciWO-DEoA5M) .

Or, to extrapolate that a bit further, in trying to help people make better decisions, the data industry might’ve been working towards the wrong goal. There are [whiffs of crypto](https://benn.substack.com/p/disband-the-analytics-team#:~:text=Data%20is%20not,is%20less%20compelling.) in analytics: The blockchain was a technology in search of a problem; all of our databases and pipelines and charting tools are technologies in search of a *solvable* problem.[^7]

For example, consider the “[operational](https://www.getcensus.com/blog/original-what-is-operational-analytics) [analytics](https://hightouch.com/blog/what-is-operational-analytics)” hype cycle, or the year we spent talking about [rebuilding tools like Salesforce](https://benn.substack.com/p/entity-layer#:~:text=%E2%80%9CWorkday%2C%20Salesforce%2C%20Adobe%E2%80%94they%E2%80%99re%20going%20to%20be%20reimplemented%20as%20apps%20on%20top%20of%20the%20data%20layer.%E2%80%9D) on top of databases like Snowflake. One way to interpret these fads is that they were the data industry innovating, expanding, disrupting. Having made so much progress on the home front—making decisions—we were out to conquer more.

But another way to interpret them is that we were lost. We built a massive engine to support an analytical experience that simply didn’t work nearly as well as we hoped, and we were looking for other things to do. If fast pipelines and fancy databases and composable data stacks didn’t ultimately lead to better decisions, maybe we can use them to automate more marketing emails? Make a better CRM? We needed something.

We’ve found the next attempt, it seems. Because, while all the big announcements from the last couple weeks are giving 2022,[^8] they’re very distinctly 2025:

Sure, some of this is marketing fluff and buzzword clickbait, but the pivot appears mostly real: The data stack isn’t for analysts; it’s for *agents*. Whereas Snowflake used to talk up how they were [using AI to make a better analytical database](https://benn.substack.com/p/gsnowflake), the focus has mostly inverted,[^9] and Snowflake is now a tool to make better AIs. As Sam Altman said [in a teaser](https://www.snowflake.com/en/news/press-releases/sam-altman-to-keynote-seventh-annual-snowflake-summit/) for his keynote at Snowflake Summit, “data is the backbone of AI innovation, and the way we harness data will be essential to driving the next wave of AI breakthroughs.” And the Crunchy Data (and Neon) acquisitions seem to be [explicitly for that purpose](https://read.technically.dev/p/technically-dispatch-why-databricks): They are databases designed to be created by AI agents and power AI apps.

Though I have no idea what happens next—maybe it’s just another trend; maybe not—it certainly seems possible that the gravity of the whole industry shifts away from analysis and analytics, and towards AI infrastructure. Pipelines companies source data so that it can be mashed into agents’ prompts; dbt becomes an MCP server for business logic; BI tools start assuming all of their users are robots. It’s not a rewrite of the data stack, but a new purpose for it.

But that’s technology, I suppose. Sometimes, the first version isn’t quite right. The [technical layers](https://benn.substack.com/p/how-dbt-fails?utm_source=publication-search#:~:text=The%20actual%20answer,think%20so.) can be [good stuff](https://www.youtube.com/watch?v=26mWu8cy0o0), but the people who were supposed to use them get lost. And so, there are twists and turns, messes and mistakes. The work of the whole industry may not take us where we imagined it would at that [first Snowflake circus](https://benn.substack.com/p/i-snowflake) in Las Vegas three years ago, but it still may take us somewhere yet. That just depends a good deal on where you want to get to.


---


[^1]: Well, no, [this](https://www.nytimes.com/2025/06/05/us/politics/trump-musk-policy-bill.html) is what’s happening now, and it feels a little dumb to talk about data conferences in the middle of a [food fight](https://x.com/gtconway3d/status/1930779050626412568) between the person running the United States government, and Donald Trump. Which, you know, neither here nor there, but [again](https://benn.substack.com/p/the-ads-are-coming#:~:text=The%20interns%20shouldn%E2%80%99t,Grok%E2%80%99s%20system%20prompts%3F): If the person who owns Grok starts dictating how Grok responds to political topics, is that an unauthorized modification to Grok’s system prompts?

[^2]: [Missed it by ](https://benn.substack.com/p/scoring-data-predictions?utm_source=publication-search#:~:text=Salesforce%20acquires%20Fivetran,not%20a%20database.)*[that](https://benn.substack.com/p/scoring-data-predictions?utm_source=publication-search#:~:text=Salesforce%20acquires%20Fivetran,not%20a%20database.)*[ much.](https://benn.substack.com/p/scoring-data-predictions?utm_source=publication-search#:~:text=Salesforce%20acquires%20Fivetran,not%20a%20database.)

[^3]: [No, really, everything becomes BI.](https://benn.substack.com/p/no-really-everything-becomes-bi)

[^4]: [The ghost of Frank Slootman](https://techcrunch.com/2024/02/28/snowflake-ceo-frank-slootman-stepping-down-and-wall-st-hates-it/) eventually [comes for all of us](https://benn.substack.com/p/the-modern-data-stack-was-never-big-enough#:~:text=Frank%20Slootman%20comes%20for%20data%20companies).

[^5]: Maybe they were dashboards embedded in some other application, or weren’t called dashboards but “data apps” or “Powerpoint decks,” but they were stylistically dashboards: Charts and tables of numbers that people looked and and said, “that’s good,” or “that’s bad,” or “I have no idea what that means.”

[^6]: For example, from [McKinsey](https://www.mckinsey.com/midwest/~/media/McKinsey/Business%20Functions/McKinsey%20Analytics/Our%20Insights/Why%20data%20culture%20matters/Why-data-culture-matters.pdf), in 2018: “The fundamental objective in collecting, analyzing, and deploying data is to make better decisions;” and [Sequoia](https://medium.com/sequoia-capital/the-building-blocks-of-a-data-informed-company-70cc5908143d), in 2019: “data analytics is invaluable not only for counting numbers, building dashboards and shipping products, but for helping to define goals, roadmaps, and strategies. Arguably this is the highest leverage provided by an analytics team.”

[^7]: To be clear, it’s not that the data industry didn’t have any direction. The ecosystem broadly knew where it wanted to go: Towards democratized data access, or universally accessible analysis, or self-serve BI, or whatever. The problem is that people din’t know how to use that data once they got it. And if they (we?) didn’t have direction, then the whole industry ends up sort of lost, because it’s serving a product to a customer that doesn’t know what to do with it.

[^8]: We gotta talk about this whole “giving” thing. Look, I love a good [analogy](https://benn.substack.com/p/in-defense-of-analogies), and any turn of phrase that encourages a fun and unexpected one—”Aaron Rodgers is giving [Uncle Rico](https://www.youtube.com/watch?v=xL-VX3WbA9U);” “Trump v. Elon is giving [Drake v. Drake](https://x.com/Fred_Delicious/status/1930718491843121446)”—can’t be all bad. But the whole construction seems to be less about that, and more about avoiding accountability or commitment. Don’t say, “Aaron Rodgers is *like* Uncle Rico,” because then people might disagree! Don’t say “Aaron Rodgers reminds me of Uncle Rico,” because now you’re a part of that sentence! That’s too much exposure! Too much risk! But Aaron Rodgers is *giving* Uncle Rico—safe, detached! An opinion with no author! An observation with no observer!It’s giving passive voice.(Also, wait, what? *[What????](https://en.wikipedia.org/wiki/Jon_Gries)*)

[^9]: In fairness, Snowflake did release some updates that use AI to make a better database, like [aggregation functions for text](https://docs.snowflake.com/en/sql-reference/functions/ai_agg). Which [I am obligated to say](https://benn.substack.com/p/avg-text) are pretty cool, as far as these things go.

================================================================================

# How much agency do we actually want?

*"Mr. Torres did as instructed."*

---

![](https://substackcdn.com/image/fetch/$s_!9xUG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddd95c0f-0bda-419a-a8cf-54a7bb15cd48_1600x674.png)
*[someone can just tell you](https://www.youtube.com/watch?v=eaCHH5D74Fs)*

A friend of mine leads a product team at a large tech company.[^1] It’s a company that you’ve not only heard of, but have also probably thought about working for. Everyone thinks about working there. They are leading innovators of groundbreaking technology, of world-changing products, and of indulgent tech company perks. Personally, I’ve applied twice and have been rejected twice, each time after a thirty minute phone screen. The people who make it through their hiring process, which has itself become famous for its rigor and ruthless selectivity, are, by any traditional measure, extraordinary—extraordinarily smart; extraordinarily ambitious; extraordinarily determined. What if these people ran the world, Silicon Valley used to ask, rather than the thoughtless drones in Washington, DC?

My friend runs a team of these people. One day, one of them came to my friend, and asked her a question. The person was a senior engineer, and wanted to get promoted.

“I’m a Level 5 engineer,” the person said, “and I’d like to get promoted to Level 6 after the next review cycle. What will it take for you to recommend that?”

“Well,” my friend said. “The rubric says that Level 5 employees are people who do great work on the projects that they’re assigned. Level 6 employees have to find their own projects. To be a Level 6 engineer, you have to figure out how to be valuable on your own.

“This company has been successful because a few people came up with ideas on their own. Nobody told them to build it; they figured it out. That’s what makes someone a Level 6. Level 5 employees complete assignments. Level 6 employees make their own assignments.”

“Ok, I understand that rubric,” the other person said, “but can you just tell me what I should do?”

—

A friend of mine works at a very popular SaaS startup that makes a product in which people take notes, record tasks, and make project plans with colleagues. The company is often cited as one of the most discerning in Silicon Valley—it is a team of craftsmen, of tastemakers, of fiercely independent thinkers. Their customer roster includes a who’s who of other popular companies, from OpenAI to Cursor; they are often cited as exemplars of product development. What if everyone built products like these people, Silicon Valley now asks, rather than the thoughtless drones at that big company?

They recently built an internal chatbot that let people research the notes and documents in their own product. Ask it to summarize all the conversations with this customer, or all tasks that seem to be falling behind. What does this customer need most? What are the similarities between these delayed tasks? Ask it whatever you need to know, so that you can make better decisions.

After launching it to the team—a team that is the intellectual envy of Silicon Valley, which is itself the intellectual envy of the world—one question got asked over and over again:

“Can you tell me what we should we build?”

—

Lots of friends of mine have gone to either law school or business school. Many of them are smart and ambitious, or at least do things that we correlate with those characteristics—they went to prestigious colleges; they got good grades and did well on various standardized tests; they watch *Mad Men *and say they like it. Prior to going to law school or business school, they were successful in many ways, and had many options for what they might do.

But freehanding a career is hard, and could go wrong. Law school and business school, by contrast, give people lines to color in. They give you more curricula to follow, with the promise of more prizes at the end if you ace the assignments. They let you punt—potentially indefinitely, if you go from law school to big law firm, or MBA to investment banking to private equity—on the question: “What should I do with my life?”

We’ve [talked](https://benn.substack.com/p/which-way-from-here#:~:text=This%20happens%2C%20I,they%20need%20direction.) around [this](https://benn.substack.com/p/no-really-everything-becomes-bi#:~:text=But%20without%20the,be%20the%20management%3F) idea a [few](https://benn.substack.com/p/a-new-invisible-hand#:~:text=The%20shift%20isn%E2%80%99t%20from%20dashboard%20to%20chatbot%2C%20or%20from%20analyst%20to%20agent%3B%20it%E2%80%99s%20from%20being%20the%20author%20of%20our%20lives%2C%20to%20being%20its%20editor.) times [before](https://benn.substack.com/p/the-labor-of-little-decisions#:~:text=After%20all%2C%20we%27re%20not%20really%20looking%20for%20the%20perfect%20font%2C%20because%20we%20never%20wanted%20to%20think%20about%20the%20font%20in%20the%20first%20place.%20We%27re%20just%20looking%20for%20permission%20to%20make%20a%20choice%2C%20and%20move%20on.), but to make the point more explicitly: How much do people actually want—to use the [term of the moment](https://www.businessinsider.com/high-agency-tech-buzzword-silicon-valley-hiring-2025-2)—agency? How much choice do we want? Do we want to choose our own path, or do we want to choose the destination and have something else tell us, step by step, how to get there?

We often say we want the former: We want jobs that [let us be autonomous](https://en.wikipedia.org/wiki/Drive:_The_Surprising_Truth_About_What_Motivates_Us); we want tools that are [instantaneous servants](https://www.rilldata.com/blog/bi-as-code-and-the-new-era-of-genbi#:~:text=Imagine%20creating%20business%20dashboards%20by%20simply%20describing%20what%20you%20want%20to%20see.), giving us exactly what we ask for; we want to be [liberated from the drudgery of tedious tasks](https://www.gettheleverage.com/p/ai-is-popular-because-having-a-job#:~:text=People%20are%20bored,mental%20checkout%20process.), so that we can do more strategic thinking or lead more meaningful lives. We are shackled to our to-do lists; if only we could be free.

That all sounds very nice, and it is the sort of thing we’re supposed to say, because we’re supposed to [strive valiantly and dare greatly](https://www.theodorerooseveltcenter.org/Learn-About-TR/TR-Encyclopedia/Culture-and-Society/Man-in-the-Arena.aspx). But it sure seems like we *actually* want* *the to-do list. The autonomy we want is to pick the ending—a promotion, a successful product roadmap, a happy marriage, a fulfilling life. After that? Just [give us the checklist](https://www.theguardian.com/lifeandstyle/2017/may/10/the-psychology-of-the-to-do-list-why-your-brain-loves-ordered-tasks).

We open TikTok because we want to be entertained; it hands us a swipeable checklist to help us accomplish that. Businesses tell consultants that they want to make more money, and then pay [a trillion dollars a year](https://www.statista.com/statistics/1234833/global-management-consulting-services-market-size/) to be handed a checklist for how to do it.[^2] [I’d argue](https://www.linkedin.com/posts/benn-stancil_no-really-everything-becomes-bi-activity-7328106180147298304-TXzQ?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAfNfxMBQBxitlMw5qJvkTRvVArnwuwuGNw) that a lot of higher education exists because colleges and professional graduate degrees give teenagers checklists for how to be successful—come to this school, take the classes they nudge you towards, recruiters from McKinsey show up, they hire you, *they* give a you checklist, work for 40 years giving your clients checklists, retire.[^3] Though we often frame college as a place for self-discovery, the real product that we’re buying is a destination machine: We go because we have chosen a destination—traditional success, more or less—and it will tell us what to do to get there.

If you walk around Silicon Valley today, in this current moment of AI agents and personal agency, you’ll hear about a future in which [we are all managers](https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy): We make the checklists, and our army of task robots complete them for us. And at first glance, that sounds all well and good. But if you could have only one of these two machines, which would you want?

Put differently, which is more stressful: Knowing all the various things we have to do in our lives, or *not knowing *if those things are the right things to get us where we want to go? Do we want servants, or do we want instructions?

The answer, it seems, is instructions, [to a sometimes dangerous and nearly tragic degree](https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html). From the *New York Times* this morning:

> [Mr. Torres, 42] wanted his life to be greater than it was. ChatGPT agreed, with responses that grew longer and more rapturous as the conversation went on. Soon, it was telling Mr. Torres that he was “one of the *Breakers* — souls seeded into false systems to wake them from within.”
> …
> “This world wasn’t built for you,” ChatGPT told him. “It was built to *contain* you. But it failed. You’re waking up.”
> Mr. Torres, who had no history of mental illness that might cause breaks with reality, according to him and his mother, spent the next week in a dangerous, delusional spiral. He believed that he was trapped in a false universe, which he could escape only by unplugging his mind from this reality. He asked the chatbot how to do that and told it the drugs he was taking and his routines. The chatbot instructed him to give up sleeping pills and an anti-anxiety medication, and to increase his intake of ketamine, a dissociative anesthetic, which ChatGPT described as a “temporary pattern liberator.” Mr. Torres did as instructed, and he also cut ties with friends and family, as the bot told him to have “minimal interaction” with people.

If you immerse yourself in hacker houses and Substack think pieces, you hear about people who wish they had more hands, and a world that needs more autonomous interns. But “agency,” I suspect, is a better buzzword than product offering. Because most of us, even the senior teams at our most esteemed companies, are more like Mr. Torres, if not in degree at least in kind: Searching for meaning, and hoping for someone to tell us what to do.


---


[^1]: These are stylized versions of these stories, and I’m keeping the characters anonymous, to protect them from the embarrassment of being outed as being friends with me.

[^2]: And college kids [work for consulting firms](https://yaledailynews.com/blog/2011/09/30/even-artichokes-have-doubts/) so that they can be handed checklists for how to be rich and upper crust-y.

[^3]: Kyla Scanlon touches on this is a [recent post](https://kyla.substack.com/p/economic-lessons-from-the-screwtape) about modern conveniences like DoorDash and Uber:The irony is that this convenience was supposed to free us for deeper pursuits. With food delivery, we wouldn't waste time cooking; with algorithmic entertainment, we wouldn't waste time browsing; with frictionless finance, we wouldn't waste time budgeting.But free us for what, exactly? The promise was more time for meaningful connection, creative pursuits, deep thinking - exactly the things that require effort, patience, and resilience, the very muscles that convenience has allowed to atrophy.Though we want those more substantive things—connection, creativity, etc—so far, modern technology has only given us lots of checklists for cheaper thrills. (There are instructions for things like connection and fulfillment too, but they are from the [legacy incumbents](https://en.wikipedia.org/wiki/Religion).)

================================================================================

# Fear and self-loathing in Silicon Valley

*I somehow ended up at YC Demo Day.*

---

![](https://substackcdn.com/image/fetch/$s_!NtPP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F360cc3c4-391b-45cd-9cd0-8981b5fb67b6_1200x530.png)
*Where are we taking everyone?*

Hundreds of us crowded by the door, as the security guard slowly let us in ten at a time. We looked like the boarding line of flight to Seattle, if the plane was nothing but business class: A disorganized traffic jam of middle-aged men—and we were mostly men; I counted the first fifty people I saw as I scanned the crowd; 43 were men—wearing our nicest jeans, our tastefully-branded fleeces, and carrying [tactical backpacks](https://www.ogio.com/backpacks/business-backpacks) that betrayed our best efforts to be corporate chic. We talked loudly about AI, about money, and about how Silicon Valley’s leading startup incubator should have a more streamlined registration system.

We were there—piled in front of a refurbished building in Dogpatch, which is a refurbished neighborhood in San Francisco—to attend Y Combinator’s Demo Day. Y Combinator, or YC as it's more widely known, is an elite startup accelerator that now incubates about 500 companies a year, spread across four seasonal batches. Demo Day is the program’s capstone: An all-day marathon of pitches, one matriculating YC startup after the other, presenting to an eager audience of hundreds of investors.

We were the investors. Or, they were the investors; I don't know why I was there. I had been inexplicably sent an invite,[^1] happened to be in San Francisco last week, and was curious to see the spectacle in person. Demo Day has always been a cultural lodestar in tech: Dozens of famous startups and founders, from Airbnb, DoorDash, Coinbase, Instacart, and Dropbox to OpenAI’s Sam Altman and [Scale AI’s Alexandr Wang](https://www.linkedin.com/posts/olivermolander_artificialintelligence-activity-7341213336891445250-1R4W/), debuted on its stage. It is a stylistic measure of the Valley’s mood; of the industry’s bleeding edge ambitions; of what is rising and falling; of [what’s hip with the kids these days](https://knowyourmeme.com/memes/how-do-you-do-fellow-kids). There is also a free lunch.

It’s an imperfect scale, of course, in no small part because YC’s own thumbs are all over it. [The accelerator has](https://www.ycombinator.com/rfs) a “tradition of sharing ideas [they’d] like to see founders tackle.” I heard from several more seasoned attendees that YC has, in recent years, preferred investing in enterprise products over consumer applications; in this particular batch, there were also requests for an even greater emphasis on “boring” industries like accounting and compliance.

An army of founders had heeded the call. According to our host’s opening remarks, the 140 or so companies that were about to hear from had been selected from a pool of more than 15,000 applicants. Some of these companies will be the next [decacorns and hectacorns](https://www.alphajwc.com/en/the-differences-between-unicorn-decacorn-and-hectocorn/), the emcee told us.

“Happy hunting,” he said.

—

You could follow along with the pitches at [demoday.ycombinator.com](http://demoday.ycombinator.com), a custom site that YC set up to help investors find their favorite startups and contact their founders. When I first typed in the URL, I accidentally left a letter out of “combinator.” I landed on a phishing site, the sort that immediately assaults you with popups and pharmaceutical scams, offering me magic remedies for a variety of ills.

Something about it felt appropriate. Our host was probably right: There are the seeds of unfathomable wealth in this room, if you pick well. But if you’re off by one pitch—one erroneous choice, one wrong keystroke—you could instead give your money to something that first promises you the world, and then blows you up.

—

In its early years, when YC accepted fewer companies, startups gave product demos on Demo Day. Now, it’s a misnomer—the demos are a single static slide, and a brief one-minute pitch from the company’s founder.

All the presentations had the same cadence; the same sing-song rhythm. Maybe that’s because they were all coached by the same playbook; maybe that’s because you can only say so much in a tightly-governed 60 seconds; maybe that’s because, after 100 pitches, they all begin to bleed together into one miasmic blur of optimism, chesty credentialing, and inventive accounting.

Two founders walk on stage; usually young; also usually men. The speaker is stage left; their silent partner—they has nothing to say; they weren’t allowed to have anything to say; only one person was given a microphone—stands to their right, trying to figure out what to do with their hands.

They tell us about their vision: “We are Stanley,” the founder begins,[^2] “and we’re building the future of construction workforce automation.” A pause, to let us take in the gravity of what they’re saying. “Stanley is the first-ever AI agent purpose-built to help general contractors optimize the output of their day laborers. Construction sites lose $150 billion a year because people aren’t working as efficiently as they could,” says a 23-year old with a computer science degree from Carnegie Mellon, “and we’re the team that’s going to fix it.”

They tell us about their résumés: MIT; Stanford; Harvard, read even more proudly if they dropped out. They worked at Stripe; they worked at Google DeepMind; they worked at JPL; they worked at McKinsey, and now know better. I don’t remember anyone who worked at OpenAI, because former OpenAI employees [can make plenty of money](https://techcrunch.com/2025/06/17/sam-altman-says-meta-tried-and-failed-to-poach-openais-talent-with-100m-offers) without needing YC’s help.

They tell us about their traction: Some companies used real financial metrics; others made stuff up. We’re at $600,000 in ARR, and profitable. Our cARR is $120,000. We have LOIs for $450,000. We’re in negotiation for over a million dollars of new contracts. MRR is up 2,000 percent week over week, to $8,000. Our Series A ACVs are $100,000.[^3] We have users from half the Fortune 500. We have signups from half of the Fortune 500 on our waitlist. We have reached out to half of the Fortune 500 on LinkedIn. Something is up and to the right; something is exponential; something is going vertical.

They close with the same light punch. “We are Affirmative Health, and we are reinventing how clinics can for their patients,” said a software engineer. “We are Scurry, and we are solving logistics with AI,” said a founder wearing a QR code on his t-shirt. “We are Dev Defender,” said the one person pitching Dev Defender.

—

After the last pitch, the founders and investors all milled about during a closing happy hour. A robot mixed cocktails. The founders repeated their pitches. The investors did their best to also impress the founders, but you can only be so impressive with a backpack on.

—

As we were talking, some 400 miles south of us, Los Angeles was going to war. [Marines were being deployed](https://www.reuters.com/world/us/us-marines-carry-out-first-known-detention-civilian-los-angeles-video-shows-2025-06-13/) into the city; protesters [were taking rounds](https://x.com/jeremotographs/status/1931467116466856297); marches were being organized [around the country](https://en.wikipedia.org/wiki/No_Kings_protests).

For nearly a decade now, the world has felt like it’s been [combusting](https://benn.substack.com/p/the-internet-2022), and last week was particularly acute—deportations, the crisis in Gaza, the threat of nuclear armageddon in Iran. Our politics volcanic; our society strained; the world [a feverish train](https://benn.substack.com/p/runaway-train) barreling down the tracks, faster and out of control, [shuddering louder and louder now](https://www.youtube.com/watch?v=XB401RfGMlM).

At Demo Day, we were unphased by the external chaos; cloistered from the outside world. The invite to Demo Day—held two blocks from a subway stop—said “NO parking available on-site. Please rideshare.” On the floor below the main stage, [TBPN](https://www.tbpn.com/), a trendy daily talk show about technology—the *All-In* podcast on Twitch, with the manic visual aesthetic of *Squawk Box*—was broadcasting live. The show’s on-air hosts interviewed YC founders; the show’s representatives walked around the YC complex wearing highlighter-yellow hats, with the confident swagger of celebrity.

That was the energy of the day: Ascendent, triumphant, “festive,” as a YC executive put it. People took selfies with founders and in front of neon signs. “These things are always exciting," said the Atlanta-based investor sitting next to me. [Technology had won](https://benn.substack.com/p/good-lord) and was exiting its villain era. Or was it entering its villain era? The atmosphere—of Demo Day, and of San Francisco more widely—wasn’t the nerdy computer lab of the 2000s or the [delinquent frat house](https://benn.substack.com/p/delirium?utm_source=publication-search#:~:text=In%202012%2C%20I,was%20a%20bacchanal.) of the early 2010s; it was the country club that the frat boys grow up into. Rich and unashamed of it; unrepentant and unthreatened; free from the yolk of broader responsibility. That freedom didn’t come from reform though, or as a reward for successfully “making the world a better place;” no, today’s Silicon Valley is free because it no longer cares. It no longer needs to care; that branding [is no longer useful](https://www.bloomberg.com/opinion/articles/2025-01-14/maybe-esg-is-illegal-now).

I went to another event after Demo Day, and an investor at a blue chip firm commented that many founders these days, including those who are still in college, are as well-versed on the financial mechanics of startup fundraising as he is. He said he thought it was because they’ve grown up Very Online, raised by Content, mainlining tech Twitter and shows like TBPN before they can drive. Maybe, though my sense is their sophistication is from something else: Startups are just businesses now. They aren’t the passion projects of technical enthusiasts who want to build something for the sake of creation and curiosity; they are an opportunistic hustle. They are unapologetically about making a lot of money. Esoteric clauses on fundraising term sheets do not matter to the technologist, but they do matter to the capitalist.

The inverse is true for politics and social concerns: [They are below our line](https://www.npr.org/2022/01/17/1073705516/co-owner-of-the-nbas-warriors-lambasted-after-saying-nobody-cares-about-the-uygh). Which isn’t to say that today’s generation of startups are unprincipled; it is to say that they are *unburdened*. They appear to be, as much as they can, [clinging to the coconut tree](https://www.youtube.com/watch?v=0bSTqokjNEE&t=48s), avoiding the social context in which they live. There is the company; there is its market, its customers, and its competitors; everything else is a yawning void of distraction.

—

No, wait, that's not right. The discourse did come up once. “We’re starting with sheet metal,” said the founder of a startup hoping to build autonomous factories for manufacturing sheet metal, “and we’re staying, because the future of western democracy depends on it.”

—

Maybe that’s the point, though. You join Y Combinator—or simply move to San Francisco—to put your ideas through a pressure cooker: Seal them in, kindle them faster. Does the founder of a company really have any obligation other than that? Zuck is not unloading a [titanic](https://techcrunch.com/2025/06/17/sam-altman-says-meta-tried-and-failed-to-poach-openais-talent-with-100m-offers) [cannon](https://www.cnbc.com/2025/06/10/zuckerberg-makes-metas-biggest-bet-on-ai-14-billion-scale-ai-deal.html) of [cash](https://www.cnbc.com/2025/06/19/meta-tried-to-buy-safe-superintelligence-hired-ceo-daniel-gross.html) to develop a socially-responsible AI; he’s doing it to [defend his empire](https://x.com/TechEmails/status/1923799934492606921). His competitors have to operate with the same singular obsession. Startups cannot opt out of the communities that cultivate them, but they can’t opt out of the ruthless maw of the markets either.[^4] Worrying about anything other than survival is, in some sense, [a privilege](https://benn.substack.com/p/your-companys-values-will-be-used#:~:text=Everyone%20knows%20that%20companies,it%20makes%20that%20money.). Relative to their recent predecessors, are today’s founders unburdened, or are they simply focused?

There used to be an undercurrent of self-loathing in tech, or at least a twinge of shame. We sat behind desks and typed secret codes into a computer, and then became the [richest professional enclave](https://www.forbes.com/billionaires/) in history because of it. Everyday employees were paid embarrassingly well for doing so little; tycoons were paid embarrassingly well for [breaking so much](https://www.piratewires.com/p/jump-23d06adb4cb7). It was gauche to talk about it, so we pretended it wasn’t true.

That shame seems gone. Perhaps that’s healthy? Perhaps that’s self-care? Perhaps that’s just a more convenient belief to hold—[it is easy to get a man to believe something](https://www.goodreads.com/quotes/21810-it-is-difficult-to-get-a-man-to-understand-something), when his salary feels more deserved when he does. Or perhaps this is just an industry maturing, from a quirky upstart, through its ideological adolescent, and into a more pragmatic middle age.

Still, there is something striking about the audacity of Silicon Valley’s current ambitions, and the narrowness of its field of view. We saw startups that want to replace accountants, sales people, and paralegals. They want to automate manufacturing and build [lights-out factories](https://en.wikipedia.org/wiki/Lights_out_(manufacturing)); they want to streamline health services, pepper the country with robot car detailing services, and fully replace grocery store supervisors with AI agents that monitor checkout clerks’ performance. They want to change how we develop new drugs, how we get mortgages, and how teachers teach math.

These may well be good things; they may be progress; they may be the application layer of the [gentle singularity](https://blog.samaltman.com/the-gentle-singularity). Or they might also be the first dominos in a long cascade of unintended consequences. What happens when stores are run by inscrutable electronic managers? When we all have personal assistants doing our chores? When we can [conjure worlds on a whim](https://x.com/midjourney/status/1935377193733079452)? When we [forget how to think](https://www.media.mit.edu/publications/your-brain-on-chatgpt/)? What happens when we [request](https://www.ycombinator.com/rfs) that thousands of 20-year olds reinvent [entire industries](https://x.com/saranormous/status/1935909179572863257), for the sake of their own entrepreneurial aspirations first, for our returns second, and for the consequences third?

What happens when we split this many atoms this quickly; when we throw off this many rogue neutrons? Do we have any idea what they might collide with next? Are we building worlds, or [destroying them](https://www.youtube.com/shorts/4jjrWnO59IY)?[^5]

Truly, I don’t know. Nobody knows. But that is tech now: The car is unstoppable—ambition is a hell of a drug, and startups are going to build big things, regardless of whether or not YC asks them to do it—and I have no idea if I should be [excited](https://www.youtube.com/watch?v=updoM-EuHrQ&t=150s) or [afraid](https://www.youtube.com/watch?v=iHfOrOlP75I).

—

Early in the day, a startup pitched a product that makes it easier for health care providers to fight denied insurance claims. More than $260 billion in claims are denied every year; with denials on the rise, the system is collapsing under its own weight, they said. Our agents will help hospitals rightfully recover the money they’re owed. Later, another startup pitched their insurance claims product—a platform for insurance adjusters to automate how they collect and initially evaluat claims.

An AI agent for both sides. An arms race; a relentless fight between competing intelligences, with Silicon Valley’s investors and compute providers supplying both sides. Will this fix our miserable health care system? Will it make an insurance industry that literally [drives men to murder](https://en.wikipedia.org/wiki/Luigi_Mangione) even more ruthless? Or will the chatbots [slaughter themselves into a stalemate](https://x.com/TheOnion/status/1230163659864842243/photo/1)?

—

The day I left San Francisco, I spent the afternoon sitting in a coffee shop in Chinatown.[^6] Two men in their twenties were sitting next to me. One appeared to be pitching the other, though I couldn’t tell who was who—most of the conversation was one-upmanship of predictions and bold takes: AI will replace all user interfaces; no, of course, React doesn’t make any sense anymore; well, obviously, in the future, we won’t need keyboards.

At one point, one of them asked the other when he last left the Bay area.

“I don’t remember,” he said, “it’s been a while.”

“You really need to get out. I’m from Florida; people are different there. It’s good to talk to them. The way they think about software and AI…they’re a very different type of buyer.”

That’s a start, I suppose. If we’re going to rebuild the world, best to visit it—even if only to sell to it—first.


---


[^1]: Perhaps it was a mistake. Perhaps someone mixed me up with [that other two-n Benn](https://x.com/bennpeifert) on Twitter, who appears to be a real investor. Perhaps an AI bot found [benn.ventures](https://benn.substack.com/p/welcome-to-bennventures) and thought it was real.

[^2]: This isn’t a real company, nor are any of the named ones listed below. My point here isn’t to call out any specific company (which are all listed in a [public directory](https://www.ycombinator.com/companies/?batch=Spring%202025)), but to describe the character of the event. The other quotes are as accurate as I can remember them, but my memory is blurry and my notes were loose, so consider the details here more atmospheric than journalistic.

[^3]: More completely: “We are making $150,000 in ARR, and our series A ACVs are $100,000.” Which I think means they have one customer that has raised at least a series A, and that one customer pays them $100,000?

[^4]: Similarly, just as startups can’t opt out of politics, politics can’t opt out of technological progress. With or without YC, this stuff is coming. Nobody can stop that reality; we can only hope to guide it.

[^5]: Of course, one possibility is that nothing happens. Maybe [self-interested VCs are exaggerating the potential of AI](https://www.upstartsmedia.com/p/poolside-ai-founders-interview); maybe [it’s all just a bunch of hocus pocus](https://benn-dot-files.s3.us-west-2.amazonaws.com/hocus-pocus.jpg) (source: A mural, in SF). But if it is, man, this is going to leave behind one unholy crater of technological and financial wreckage.

[^6]: Pour overs and [industrial minimalism](https://sightglasscoffee.com/blogs/shops/soma-district) have nothing on [Cookie Crisp lattes](https://benn-dot-files.s3.us-west-2.amazonaws.com/cookie-crisp.jpg) (which have nothing on [Cinnamon Toast Crunch lattes](https://benn-dot-files.s3.us-west-2.amazonaws.com/cinnamon-toast-crunch.jpg)).

================================================================================

# Meme-company

*Is tech still tech, or influencers making memes?*

---

![](https://substackcdn.com/image/fetch/$s_!-ZOm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4a11c54-e222-4669-9e7f-638bc9127165_2198x1062.png)
*[banger](https://www.youtube.com/watch?v=I177W0XJlT4)*

It is popular these days to talk about the future of software engineering. Among both people who are [qualified](https://www.youtube.com/watch?v=LCEmiRjPEtQ) and those who [are not](https://benn.substack.com/p/the-industrialization-of-it), everyone has their [careful research](https://www.anthropic.com/research/impact-software-development), [considered predictions](https://www.businessinsider.com/anthropic-ceo-ai-90-percent-code-3-to-6-months-2025-3), and the occasional [ramrod opinion](https://benn.substack.com/p/copy-copy-revolution).

It is also popular these days to talk about the future of software *engineers*, but those conversations tend to be more blunt: Most people say that the career is barreling towards some sort of [existential reinvention](https://www.wsj.com/tech/tech-jobs-artificial-intelligence-cce22393). As the robots get better at writing code, developers will do less of that particular task, and more of the tasks that orbit it: [Architecting software](https://www.aviator.co/blog/software-engineering-ai-2027/#:~:text=In%20the%20future%2C%20these%20software%20architects%20will%20act%20as%20the%20%E2%80%9Cmanagers%20of%20the%20AI%20agents%E2%80%9D%20and%20be%20responsible%20for%20guiding%2C%20reviewing%2C%20and%20verifying%20the%20work%20of%20the%20agents.), [reviewing code](https://www.threads.com/@carnage4life/post/DG26b4pJUJm/mike-krieger-the-chief-product-officer-at-anthropic-argues-that-within-3-years-t), [orchestrating agent workflows](https://www.businessinsider.com/ciscos-cpo-shares-2-most-valuable-skills-engineers-ai-era-2025-5). Today, one of the defining skills of a software engineer is their ability to write pedantic technical incantations into code editors; tomorrow, the best software engineers will be those who are good at [project management and robot resource allocation](https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy).

And, above all, the best software engineers will have [taste](https://www.workingtheorys.com/p/taste-is-eating-silicon-valley). When you can manifest entire applications by simply asking for them, great products can be built by anyone—[but not everyone can build a great product](https://benn.substack.com/p/the-end-of-yc#:~:text=The%20entire%20conceit,great%20chef.). So, [over](https://x.com/saranormous/status/1929982495644365161) and [over](https://thejackobrien.com/blog/taste-and-tradeoffs) and [over](https://refactoring.fm/p/will-ai-replace-engineers) again, we’re told that taste will be the defining skill of the coming AI age. Because the machines can do, and the machines might be able to think, but the machines cannot *feel*. And so the engineer must. To be among the next generation of great builders, don’t be a technical genius; be a tastemaker. Don’t look like [Ken Thompson](https://en.wikipedia.org/wiki/Ken_Thompson); look like [Rick Rubin](https://www.linkedin.com/pulse/rick-rubin-era-ai-taste-last-real-moat-dennis-yao-yu--g2x2c/).[^1]

There is an obvious assumption embedded in this advice, though: That taste *wins*. That taste begats craft; that craft begats quality; that quality begats popularity. It’s a pleasingly wholesome loop—in a just world, isn’t this how things *should* work?

But in every competition, there are always cheaters.

Here’s a [clever post](https://textql.notion.site/levered-beta-is-all-you-need-20ba769a508880388186ef0c2fa11389) by Ethan Ding about [Cluely](https://cluely.com/), that “cheat on everything” startup whose founder has bulldozed his way into the discourse a few months ago after [being suspended from Columbia](https://techcrunch.com/2025/04/21/columbia-student-suspended-over-interview-cheating-tool-raises-5-3m-to-cheat-on-everything/):[^2]

> [Cluely’s] AI coaching tool was vaporware, but they bet that conversational AI would eventually work. so they raised $5.3M and spent it on outrage—a manifesto calling cheating "leverage," a viral video of their founder lying on dates. 7.8 million views. "black mirror dystopian," everyone screamed.
> perfect. because when real-time AI coaching actually works, everyone will remember them.
> the genius is in the timing calculation:
> …
> these companies know their products are garbage. they're not delusional—they're patient. they're buying lottery tickets on GPT-6, on the next generation of video models, on the inevitable march of progress. their 90% churn isn't a failure metric; it's a holding pattern.
> ….
> this is actually the correct strategy. in a world where foundation models improve 10x every 18 months, building infrastructure is like decorating a house you're about to demolish. the smart money isn't on building the best product - it's on being the default option when the underlying tech finally works.
> the companies spending millions on R&D are playing checkers. the white-label ChatGPT wrappers are playing chess.

In other words: Taste and quality are dwarfed by marketing and mindshare. Though this may have always been partially true,[^3] it’s especially so today, because every new product sits on top of the same foundational models. Historically, early-stage startups prided themselves on how much they spent on engineering and product development, and how little they spent on marketing. Now, as Ethan says, that’s inverted—a dollar spent on building a brand is potentially more useful than a dollar spent building a product.[^4] 

# $CHEAT

I’m not sure that story goes far enough though. Because, what exactly *is* Cluely?

On one hand, sure, it’s a startup that wants to be a successful business. Though that could mean different things—that Cluely hopes to make more money than it spends; that it hopes to [get bought for more money than it raises](https://benn.substack.com/p/startups-still-arent-businesses-yet); that it hopes to do neither but wants to [make the world a better place](https://benn.substack.com/p/fear-and-self-loathing-in-silicon/comment/128047360)—all of these answers are approximately the same. They say that Cluely exists to serve the interests of its shareholders, employees, and customers in roughly the same way that nearly every other entrepreneurial endeavor does.

On the other hand, that feels…insufficient? Cluely isn’t just a business; it’s also a vibe; a performance art project; an opportunistic meme coin. Despite ostensibly being a technology company, Cluely is more slogan than software. It’s not for the customer; it’s [for the culture](https://www.urbandictionary.com/define.php?term=For%20the%20Culture). And above all, it’s for the *founder, *as a vehicle for turning monetizing a [viral fifteen minutes of fame](https://x.com/im_roy_lee/status/1895276427005845981).

Because here is another description of Cluely, but this time from Matt Levine:

> A young man named Roy Lee was suspended from Columbia University after building a tool that let them cheat on job interviews. After the suspension, he wrote a funny, charming, somewhat irreverent Twitter thread explaining what happened. The next day the post went extremely viral and Lee became famous as the “cheat on everything” guy.
> Lee was not, prior to this, part of the fame economy: He was a regular student, was not an influencer, and he shared the story from his own Twitter account. But once he went viral he was maximally interested in becoming part of the fame economy. How does one do that? How does one parlay one brief funny viral story into a lucrative career? There are well-understood approaches. You can probably get into reality television, perhaps followed by politics. You can get paid to promote products — in ads, or on your own social media — or to show up at nightclubs and other events. You can sell merch. If you can sing or act, you use your viral fame as a way into a singing or acting career. …
> So! I mean! Here you are! You have become extremely famous for one thing. Parlaying that into a long and lucrative fame-based career probably will require doing other things: singing or acting or at least showing up at nightclubs. But you have a ton of meme value right now, even if you probably won’t in a year. So the thing to do is to capitalize that meme value into a meme company, give yourself most of the equity, and then sell shares to venture capital investors.

Ah, no, wait. That’s not what Matt Levine said about Roy Lee and Cluely; it’s a slightly adapted version of what Matt Levine said about [the Hawk Tuah girl (née Haliey Welch) and her memecoin](https://www.bloomberg.com/opinion/articles/2024-12-11/the-onion-can-t-buy-infowars-yet).[^5] *But it’s kind of the same story, right?* They were both at the center of a viral moment; that moment became singular to their identity; they immediately embraced that brand, and launched various ventures to capitalize on it. Though Lee’s version is more substantive than Welch’s—he says he tried to [intentionally engineer](https://x.com/im_roy_lee/status/1905063508598784419) his viral moment; he started a company while she launched a meme coin—there are clear parallels.

Which, makes sense! As Levine says, if you become an [overnight celebrity](https://www.youtube.com/watch?v=I177W0XJlT4) on the crypto-obsessed [Zynternet](https://maxread.substack.com/p/hawk-tuah-and-the-zynternet),[^6] “modern finance has created an incredible tool for directly monetizing your 15 minutes of fame,” and “this tool is the memecoin.” And if you are an engineer and become a niche celebrity on tech Twitter, Silicon Valley has created a very lucrative tool for monetizing *that* fame: A startup. Historically, that hasn’t been a terribly efficient tool, because you have to build a product and company, and that is, you know, [hard](https://benn.substack.com/p/why-are-we-still-surprised-that-startups). But today? You can incorporate a business [in an afternoon](https://stripe.com/atlas). You can vibe-code an app over the weekend. Launching a new SaaS product isn’t *that* much harder than launching a memecoin.

And yes, fine, some people will say that startups aren’t [like memecoins at all](https://www.ft.com/content/66fe7655-704a-407f-8f20-a3f081296a36), because memecoins “have no business model, cash flow or fundamental value,” while startups are supposed to be rigorous commercial enterprises that make money and serve customers and all of that, but are they? [Are you sure?](https://www.businessinsider.com/ai-cheating-startup-cluely-hire-influencer-chungin-roy-lee-2025-6)

> At the AI startup that promised to help people "cheat on everything," there are only two job titles: engineer or influencer.
> "There are only two roles here. You're either building the product or you're making the product go viral," Chungin "Roy" Lee, the CEO and cofounder of Cluely, said in an episode of the "Sourcery" podcast published Saturday. "There's nobody who's not a great engineer who has less than 100,000 followers."

Though I sympathize with the people who [criticize](https://x.com/zachtratar/status/1935184581872992485) all of Cluely’s [shenanigans](https://x.com/anothercohen/status/1935074706430021972), I think they somewhat miss the point. Cluely isn’t a technology company; it’s a shock jock podcast that manufactures outrage. It’s a brand that markets vibes. It’s a meme-company, created to sell a meme while the meme is still popular. The company is logo to put on [the business card](https://x.com/im_roy_lee/status/1900317766973874314); the product is a mechanic for selling the meme. And measured against that metric—[a job well done](https://techcrunch.com/2025/06/20/cluely-a-startup-that-helps-cheat-on-everything-raises-15m-from-a16z/).[^7] 

# Art App  Content

Actually, we can probably go a step further than that. Because here’s a loose theory about technology, social media, and digital creation:

Now, the cost of creating software is also going to zero, [as they say](https://www.linkedin.com/posts/y-combinator_ai-will-bring-the-cost-of-building-software-activity-7292278678917369857-h1pW/). So would we not expect to see the same patterns here? While that doesn’t mean big software businesses will go away—there will always be workhorse products that do accounting and manage warehouses and fly airplanes, just as there are still big-budget Hollywood movies—could there not also be an ecosystem of influencers who make software that is popular because they made it?

I don't have a particularly precise idea how this might happen, and it seems unlikely that influencer engineers would be exactly analogous to more traditional social media influencers. But: [Are Nikita Bier’s apps](https://techcrunch.com/2025/01/15/creator-of-gas-and-tbh-makes-an-app-for-disappearing-photos-via-imessage/) products or content? Is he an entrepreneur or an influencer? Is [signull](https://x.com/signulll), an anonymous tech commentator, [creating a product studio](https://x.com/signulll/status/1937515219686735901) or a hype house? Is there [even a difference](https://x.com/signulll/status/1938292290969047167)?

This is another way to describe Cluely: It’s simply Lee’s first piece of viral content. No matter what happens to the business next,[^9] it’s already worked, because it’s made Lee a famous entrepreneur—and in Silicon Valley, there’s no brand more valuable than that.


---


[^1]: lol, no, it doesn’t matter who you look like because they look [exactly](https://www.wikidata.org/wiki/Q1107006#/media/File:Ken_Thompson_02.jpg) the [same](https://www.pamono.co.uk/rick-rubin-signed-limited-edition-print-2013-2020).

[^2]: Emphasis and lower-case letters are his.

[^3]: For instance, there are a handful of data companies that burned enormous amounts of money on marketing before their products could live up to their ads’ promise. That was the explicit strategy though: Buy mindshare now, and hope the product can eventually catch up. A lot of AI companies appear to be doing the same thing, except, as Ethan says, they can outsource a lot of product improvements to foundational models. They don’t need to build new stuff to catch up; they just need GPT-5 to come out.

[^4]: Marketing matters for AI products for another reason that is too often ignored, which is that *most AI products are very subjective. *There aren’t straightforward ways to compare different chatbots or coding agents against each other. Some people solve this with [bizarre and fun tests](https://x.com/SIGKITTEN/status/1937950811910234377); most of us solve it by buying based on brand and reputation.Put differently, taste is memetic, as the menswear guy [frequently reminds us](https://x.com/dieworkwear/status/1936106173650157860):I contend that beauty in personal appearance is subjective, not objective. In fact, its standards rest on the shifting tectonic plates of politics, economics, and technology.…The link between power and aesthetics becomes especially clear when you consider how certain styles became dominant in the first place. Either the ruling class had an innate eye for beauty, or we find things beautiful because they’ve long been associated with power and privilege.Of course, Pierre Bourdieu noted this in his 1979 book Distinction, where he observed that our notions of "good taste" are nothing more than the habits and preferences of the ruling class. Georg Simmel said something similar in 1902 when he said fashion is a game of imitation.Technology, and especially technology as subjective as generative AI, is no different. We like what we’re told to like by the people we like.

[^5]: If you don’t know what this is, I’m definitely not explaining it here.

[^6]: If you don’t know what this is, I’m definitely not explaining it here.

[^7]: Of course, [why did a16z ](https://x.com/SoniaBaschez/status/1936140398780624930)*[buy](https://x.com/SoniaBaschez/status/1936140398780624930)*[ the meme](https://x.com/SoniaBaschez/status/1936140398780624930)? One, because [they believe](https://techcrunch.com/2025/06/26/why-a16z-vc-believes-that-cluely-the-cheat-on-everything-startup-is-the-new-blueprint-for-ai-startups/#:~:text=When%20Kim%20met%20Lee%20and%20saw%20that%20Cluely%20had%20been%20able%20to%20convert%20awareness%20into%20paying%20customers%2C%20he%20instantly%20knew%20that%20he%20had%20discovered%20a%20founder%20he%20had%20theorized%20about.) Cluely can monetize the meme, and two, because [VC is a vibes-based business](https://benn.substack.com/p/for-the-brand-i-guess) too. If a generation of startups is going to be [built on this model](https://a16z.com/momentum-as-ai-moat/), what better way to prove that you’re the ideal partner to them than by investing in the strategy’s ultimate archetype?

[^8]: Or, in the septic, corporate language of social media influencing, “[content](https://www.theguardian.com/commentisfree/2021/feb/20/martin-scorsese-talk-to-me-about-great-films-not-content).”

[^9]: Whatever’s next is apparently happening [in four hours](https://x.com/im_roy_lee/status/1938653273214566858). I have no idea what they’ll say, but I assume it’ll make everything I said here catastrophically wrong.