# Posts from 2021-Q4

This file contains 13 posts from 2021-Q4.

================================================================================

# The intergalactic data stack

*Falling further into the BI black hole—and charting a course out.*

---

![](https://substackcdn.com/image/fetch/$s_!iwji!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F63c6f878-cc45-4b67-8b9a-9cb1b5ccdad4_2196x1288.jpeg)

They say a big part of working in data is [telling people no](https://twitter.com/emilieschario/status/1427419697654419456), and I wasn't having it.

A few years into building Mode, we were standing on a growing pile of feature requests to improve our visualizations. People wanted more chart types, more ways to aggregate data, and more formatting options. Spending most of my time in support queues and fed up with constantly having to tell customers about frustrating limitations and annoying workarounds, I constantly bickered with Josh, one of Mode’s other founders, to start burning down the backlog. How hard could it be, I argued, to add rolling averages to a line chart? 

Every time I pushed, I was told no. I was told that, while we could build this option and that checkbox, these solutions were bandaids. Data visualization is both wide and deep, and tacking on whatever people are asking for today will only make it harder to build what they’ll want tomorrow. We needed to build a system. 

Over the next couple years, two things happened. First, we built the system. Second, I realized that Josh was right.[^1] 

Josh was right because visualizations are the ultimate [cookie](https://www.amazon.com/You-Give-Mouse-Cookie-Book/dp/0060245867). No matter how much a visualization technology can do, people will want more.

The first requirements are easy to anticipate. Give people a line chart, and they’ll want to add another line on a second axis. Then they’ll want to turn one of the lines into a bar chart; the bar chart will need multiple series; first stacked, then grouped.

If the chart is a time series, they’ll then want to group data by different intervals: by day, by week, by month. But do weeks start on Sunday or Monday? They’ll want to choose. Which time zone are dates grouped in? Can you exclude weekends? Can you [treat incomplete periods](https://twitter.com/teej_m/status/1438932370183254016) differently? 

At some point, the requests get more complicated. Plotting raw data isn’t enough; people want to derive running totals. And rolling averages, over 7 days; over 14 days; over 90 days—and, in cases where days are missing, interpolate those values as zero. But also let them sometimes choose to ignore the missing values and treat them as nulls. 

Standard calculations like these won’t be good for long though. People need to write custom calculations to derive new fields. They start basic enough—ratios, sums, fixed goal lines—but they turn into complex formulas for computing percent changes relative to the first value in a series; the last value in a series; the previous value in a series; the average of the previous seven values in a series; the average of the previous seven values in a series, but after ordering the series in a customized way.

Eventually, one chart isn’t enough either. People need [faceted layouts](https://www.google.com/search?q=faceted+charts&tbm=isch&ved=2ahUKEwiq_eWH4qXzAhUtqXIEHUqiAGsQ2-cCegQIABAA&oq=faceted+charts&gs_lcp=CgNpbWcQAzIECAAQGDIECAAQGDoHCCMQ7wMQJ1DyRVidWWDRWmgAcAB4AIABiwGIAYADkgEDMi4ymAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=WDBVYarxOq3SytMPysSC2AY), showing multiple charts in a grid—and each chart needs to support everything that one chart does. Only more, because once they have faceted charts, people want to compare values across each facet. Each chart should represent the percent of the total values of all the charts in the grid. Or the percent of all the values in each column of the grid. Or each row. Or the whole grid again, with separate totals for each series.

And all of this has to be formatted. Colors need to be semantic: red is low; green is high. Or green is low and red is high. Colors need to match brand styles. Fonts need to match brand styles. Add labels to every data point. Add labels that only highlight the important data points. Axes should show every three months; change monthly labels to quarters; to fiscal quarters; dates have to be formatted in European styles; currencies should be euros; use spaces instead of commas; use periods instead of spaces. Round the edges of the lines. Interpolate the missing data points. Round the corners of the bar charts.

And render it all, quickly, using a code-free UI that doesn’t require special training, on top of gigabytes of data. 

I didn’t anticipate any of this, but our early visualization team did. They saw that we couldn’t keep hanging feature after feature on our basic charting tools, like trying to find some ledge to balance another piece on a teetering Jenga tower. We needed—and the visualization team made—a foundation that left a place for all of these blocks. 

# The blueprint isn’t the experience

Despite the huge divergence in actual outcomes, the differences between what I was asking for and what the team built were mostly in implementation, not architecture. We all wanted to combine a better workflow for analysts with a drag-and-drop tool for everyone. Our sketches of Mode’s architecture were identical: from SQL IDE to visualization tool to reports and dashboards.

But blueprints aren’t experiences. We weren’t building diagrams; we were building a way to explore and share data. In creating that experience, the tactical details are just as important as the arrows we draw from a box labeled SQL to a box labeled chart.

When Mode’s visualization team told me to wait, they were thinking about this experience. They knew that building a tool with a low ceiling—what I was tacitly proposing—would wreck the experience people actually wanted. Whenever someone hit a wall in what Mode could do, they’d have to copy their work into another tool. If they wanted to make richer visualizations, they’d reproduce everything in Tableau; if they wanted precisely formatted charts for an executive deck, they’d have to do it in Excel; if they wanted an obscure chart type, they’d have to write the code to build it themselves. And they wouldn’t care about the reasons for Mode’s technical limitations, no matter how high we stacked our soapboxes when we explained it to them.

# BI is short for big

I was reminded of this period in Mode’s history during the [recent debate](https://twitter.com/ryanjanssen/status/1442162248693207041) about the future of business intelligence. On one side of that debate (the side I started in), [BI is transitioning](https://benn.substack.com/p/is-bi-dead) from helping non-analysts answer their own questions with code-free interfaces to a universal consumption experience. Rather than splitting self-serve from advanced analytics workflows, BI should include both, in one singular application.

Others disagree, arguing that governance layers (e.g., dbt, a metrics layer, the data mesh, a [data OS](https://benn.substack.com/p/the-data-os)) make this monolithic product unnecessary. Instead, consumption tools should be [thin solutions](https://roundup.getdbt.com/p/from-rows-to-people#:~:text=They%20will%20all%20be%20%E2%80%9Cthin%E2%80%9D%20solutions%2C%20insofar%20as%20they%20rely%20on%20all%20of%20the%20infrastructure%20from%20lower%20layers%20of%20the%20MDS%20and%20exclusively%20innovate%20on%20user%20experience.) that [target specific verticals and use cases](https://jpmonteiro.substack.com/p/a-friday-fight-and-the-internet-of). Because the [range of consumption problems](https://twitter.com/JPedro_Monteiro/status/1442743444129079296) is too big for one tool, the infrastructure layers of the modern data stack should act as a platform that [lowers barriers of entry](https://twitter.com/jthandy/status/1442840153345695744) for new, app-like solutions.[^2] 

Emotionally, I’m in the decentralized camp. Splitting BI into dozens of specialized apps, all coordinated by an OS-like layer underneath, feels both elegant and egalitarian. The parallel with mobile apps (an [analogy I’ve already endorsed](https://benn.substack.com/p/the-data-os)) is also compelling, and fits neatly into the grammar of Silicon Valley. For entrepreneurs, a data operating system is fertile soil for innovation; for VCs, it’s a marketplace for money to be made. Everyone [loves a platform](https://stratechery.com/2019/shopify-and-the-power-of-platforms/).

![](https://substackcdn.com/image/fetch/$s_!PiJB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0e3c688b-d64c-4b8f-8a2e-1ab44e846816_1782x880.jpeg)
*Mood “art.”*

But the harsh—and sometimes frustrating—reality that Josh beat into my head makes me skeptical of that idealized vision, for three reasons. 

First, any borders we put on our visualizations capabilities at Mode—if, for example, you could create line charts, but you had to go elsewhere to create faceted line charts—would feel, to our users, artificial. The technical reasons for the boundary are irrelevant; all people care about is creating the charts they need. For them, a [gerrymandered visualization stack](https://benn.substack.com/p/gerrymandering) is a bad experience. 

The same is true for BI. People don’t want to hop from Hubspot to Amplitude when they’re trying to figure out which product features recent webinar attendees are using; they don’t want to recreate a notebook’s output in Looker to make a dashboard out of Prophet forecast. The boundaries we put between these different types of data exploration—vertical-specific analysis, Python analysis, SQL analysis, pivot table analysis—are technical, not experiential. To the extent that we categorize these uses as discrete, we do so because our tooling compels us to; in practice, they’re overlapping bubbles on one long spectrum. [We should ship an experience](https://benn.substack.com/p/the-modern-data-experience) that mirrors what people want to do, not one that mirrors the org charts of the teams helping them do it.

Second, just as Josh and I drew similar architectural diagrams that ultimately mapped paths to two very different destinations, a neat theory about a data OS is a long way from a coherent solution. We should be skeptical of these diagrams—including my own—until they provide more specificity about the actual experiences they’d create. 

[​​Huy Nguyen called me out](https://ckarchive.com/b/0vuwh9hl0vqx) on this recently, saying these conversations are “speculative and interesting but not instrumentally useful.” Fair—as Huy says, the pertinent question is how do these diagrams actually make people’s jobs easier or better?[^3] 

On that, we’ve got a lot of details to fill in about how we’d build a decentralized BI layer on top of a data OS. Consider just one example: cross-app collaboration. If, for instance, I want to put my A/B testing results in a product analytics dashboard, how do I do this? Or if I create a chart in Tableau, how can I build on it in my forecasting tool? 

One potential solution is a shared protocol built on a backbone of [SQL queries and visualization configurations](https://twitter.com/JPedro_Monteiro/status/1442937947230126080). Which brings me to another lesson I learned from underestimating visualizations for several years, and the third reason I’m skeptical of decentralized consumption apps: Visualizations are really hard to build. Tableau, to take an obvious example, is breathtakingly far from being a simple charting configuration. All of the things it can do—derived calculations, facets, formatting, animations, and much more—are both complex and, to many of Tableau’s customers, necessary. Short of embedding it directly, there’s no reasonable way to port something created in Tableau into another product.

For this reason, I don’t think it’s feasible to make BI thin. Visualization on its own is a very heavy piece of technology, and that’s only a fraction of what BI tools need to do. For instance, they have to build permission paradigms that deal with not only the usual concerns about who can see, edit, and administer content, but also with an overlapping layer of permissions associated with underlying data sources. When granting someone edit access to a report implies that they can change a query about blog post traffic to `SELECT * FROM all_the_salaries`, it introduces a whole bunch of complications that most SaaS apps don’t have to address. There are similar challenges with versioning, collaboration flows, and other experiences that make a BI tool functional.

These problems aren’t straightforward. While it’d be great if they could be outsourced to a federation of apps, some systems, for better or for worse, [simply function better under central management](https://www.youtube.com/watch?v=jm9YKT0dItk&t=341s).

# From ecosystem to solar system

There is, however, a compromise to be had. In my original post about BI, I talked about the need for a “universal” consumption experience. That, as Ryan Janssen suggested, [goes too far](https://twitter.com/ryanjanssen/status/1442862594054758400)—and he’s right.

Consumption, instead, should be split into two categories. The first is generic exploration. This is the type of data consumption that starts with a business question and ends with a quantitative answer. Though the tools used in the middle may differ—Python, R, visual exploration, pivot tables, SQL, Excel—and the form of the output varies, the structure of this type of work is broadly similar.

In other cases, people need to solve specific problems. They want to analyze A/B test results; they want to examine the emotional sentiment in support tickets; they want to create financial forecasts based on standard accounting principles. Specialized tools are hugely valuable here—more valuable, even, than seamless interoperability with other tools. 

To extend the cosmic analogy, this suggests that a universal tool isn’t appropriate; instead, we need a planetary one. We need a global exploration tool that works for most general uses, surrounded by satellites that solve specific problems really well.[^4]  

![](https://substackcdn.com/image/fetch/$s_!ml_G!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf5b4d4f-b3a4-4a22-869d-d3583d973b6b_2170x1452.jpeg)
*Maybe speculative and interesting; definitely not instrumentally useful. But this is what happens when you draw this diagram a hundred times.*

This structure is already emerging in other parts of the stack. Snowflake is the storage layer’s planet; specialized warehouses like Clickhouse are its moons, dedicated to particular types of processing. Tools that ingest obscure sources (and potentially reverse ETL services?) resolve around Fivetran; products like [Zingg](https://roundup.getdbt.com/p/from-rows-to-people) that handle specialized transformations orbit dbt.

The BI planet hasn’t fully formed yet. But that, I think, is what we’re gravitating[^5] towards. 

# A final thought on open source

There’s another timeline in which the consumption layer is both decentralized [and open source](https://twitter.com/jthandy/status/1443185300554010624). I’m hardly an expert in open source issues, and mostly don’t know what I’m talking about here. But I’m naively skeptical of this approach as well.

As best I can tell, open source ecosystems do a much better job building technology than they do building user experiences—and data consumption is, at its core, an experience. This, I think, suggests that a data OS could be open source, but the most important apps that sit on top won’t be. This is especially true for enterprise customers, who care a lot about problems like security and user administration that open source tools rarely address. Snowflake, which built a [$90 billion database](https://www.google.com/search?q=snowflake+ticker&oq=snowflake+ticker&aqs=chrome..69i57.1406j0j7&sourceid=chrome&ie=UTF-8) in a sea of free open source options, is proof of this.

I am optimistic, though, about the possibilities for app marketplaces in BI. I have a lot of questions about economics of that, but they’re [beyond the scope of this post](https://twitter.com/aliboyle6/status/1201836904829931521).


---


[^1]: Right, at least, in his approach for building a visualization tool. There’s a debate to be had if this is the right decision for a business. Maybe for later, whenever this Substack makes its inevitable pivot from indulgent treatises about data to personal stories about building a startup in Silicon Valley. Consider this your warning.

[^2]: You could argue that there’s a [third camp](https://news.ycombinator.com/item?id=28608343) that believes all of this should be automated. I don’t agree with this because business decisions are far too nuanced and complex to automate in this way. More on this later, perhaps.

[^3]: This is why I’m bullish on dbt’s opportunity to become an operating system for the data stack. A data OS isn’t a new idea, and other companies have proposed things that are architecturally similar. For example, AtScale is building the [universal semantic layer](https://www.atscale.com/); Google is building the [Dataplex](https://cloud.google.com/dataplex); and The Modern Data Company is building the [DataOS](https://themoderndatacompany.com/)®. But dbt is already there, in people’s stacks, creating a universal governance experience that people like. It’s that experience, not a flow chart, that gives it such potential energy.

[^4]: [As I mentioned in the prior post on BI](https://benn.substack.com/p/is-bi-dead#footnote-3), this isn’t a claim of an unbiased observer. Because I believe in the value and inevitability of the self-serve and advanced analytics [worlds colliding](https://www.gartner.com/doc/3981930), our long-term aspiration at Mode is to be this planet.

[^5]: Get it???

================================================================================

# Chasing ghosts

*How do you get better at something you can’t see?*

---

![](https://substackcdn.com/image/fetch/$s_!MT-l!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe37e000-9345-4b08-8fef-95e73a5d2cea_3000x2655.jpeg)
*The Rose Walk by Claude Monet, painted as his sight was failing.*

At the center of Facebook’s [widening gyre](https://twitter.com/MikeIsaac/status/1444123425472081921), amid investigative [reports](https://www.wsj.com/articles/the-facebook-files-11631713039), *60 Minutes* [segments](https://www.cbsnews.com/news/facebook-whistleblower-frances-haugen-misinformation-public-60-minutes-2021-10-03/), Congressional [hearings](https://www.nytimes.com/live/2021/10/05/technology/facebook-whistleblower-frances-haugen), sinking [stock prices](https://www.google.com/search?q=fb+ticker&oq=fb+ticker&aqs=chrome.0.69i59j69i64.1244j0j9&sourceid=chrome&ie=UTF-8), [calls](https://twitter.com/SenWarren/status/1445144699354943494) to break Facebook apart, [calls](https://www.facebook.com/zuck/posts/10113961365418581) to protect Facebook’s valiant and compassionate efforts to build a more connected and communal world,  [defiant takes](https://www.piratewires.com/p/bombshell) from technologists who insist that Facebook is no different than TV or *Teen Vogue*, and, of course, server cages breached with [angle grinders](https://twitter.com/cullend/status/1445156376934862848), are a [few dozen slides](https://about.fb.com/news/2021/09/research-teen-well-being-and-instagram/) of charts and bullets that, if not global in their scale and cataclysmic in their implications, are no different than the mundane decks many of us routinely pass around in our own jobs. For those of us who want to measure ourselves by the impact of our analyses, the new bar has been set at lopping $50 billion off a company’s market cap in 48 hours.

The spectacle recycles a series of important issues that periodically bubble over in Silicon Valley, most notably about the [role of social media](https://benn.substack.com/p/runaway-train) in our society and precisely how cataclysmic it is or isn’t. There are plenty of further conversations to be had on these topics—and I’ll leave them to brighter minds than mine.

For me, a much smaller sideshow caught my eye among the circus’ main acts: The rare exposure of internal research, and the debate about how we interpret it.

# The call from inside the house

In late 2019, a research team inside of Facebook conducted a study to assess how Instagram affects its users’ mental health. The results, outlined in two decks that were leaked to the *Wall Street Journal*, present a nuanced set of results, including several alarming—though not exactly surprising—concerns about Instagram’s corrosive effect on teenage girls’ body image. The *Journal’s *story [emphasized these conclusions](https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739); Facebook responded by throwing everyone under the bus, including their own researchers (who, for now, remain anonymous). According to [Facebook’s annotations](https://about.fb.com/news/2021/09/research-teen-well-being-and-instagram/) of its own work, the original research used inappropriate and myopic language; its visualizations were misleading; it didn’t acknowledge when results were and weren’t statically significant; it implied that relationships were causal when they weren’t; and it was based on biased research methodologies. 

And thus, we arrived at a rather unusual destination: a public debate about the content of the research itself. At least on the surface, the leak spilled what are typically internal disagreements out into the open.[^1] The conversation wasn’t about the makeup of the research team or its mandate; it was about its actual work. 

This highlights a hole in the center of many of today’s public discussions about analytics. In the middle of the analytical field, in the eye of our swirling hurricane about titles and team structures and tooling, is analysis itself. It’s the data, the charts, the narratives, and the recommendations that contain the conclusions we uncover. It is, in many cases, the culmination of everything else a data team does—the point of all the other parts of the job we so frequently talk about.

We struggle, though, to look at it directly. The recent conversations about the analytical craft glace its direction, talking about [the skills we need](https://counting.substack.com/p/we-should-treat-data-science-as-a), how we [develop intuition](https://roundup.getdbt.com/p/recipe-for-data-intuition), and how we can [credential our skills](https://roundup.getdbt.com/p/analytics-is-a-profession). But the analysis we produce is still only in our peripheral vision, at the center a black hole: unknowable on its own, only detectable by its effects.

The common—and very reasonable—explanation for this is that most analysis, like most Facebook research, [is proprietary](https://raydata.co/analytics-crafting-a-way-forward/). To look inside an analytical report is to peer into a company’s soul. Most companies [prefer to keep that private](https://www.nytimes.com/2021/09/26/business/media/ozy-media-goldman-sachs.html).

That, however, makes our job as analysts a lot more difficult, especially for those just entering the field. To extend [Randy Au’s woodworking analogy](https://counting.substack.com/p/we-should-treat-data-science-as-a), the veil around analytical work forces us to talk about the saws we prefer, the types of wood we like, and the paths we can take through our apprentice program without talking about the actual chairs we build. 

And worse still, analysis isn’t a chair.[^2] Even if your woodworking classes can only gesture about chairs, you can at least easily judge the ones you build. You can see how it looks, or sit in it and decide if it’s comfortable. Can we do the same for analysis? If we can’t see others’ work, can we at least say what makes it good?

# Good analysis is...

The challenge isn’t to find an artificially empirical way to measure analytical work. But because we can’t score it precisely doesn’t mean we don’t score it at all. When we read some bit of work—a report a team member puts together; the Facebook slides; *[Dataclysm](https://www.amazon.com/Dataclysm-Identity-What-Online-Offline-Selves/dp/0385347391)*, the book inspired by the OkCupid blog—we make some determination about its quality. How? How do we complete the sentence, “this analysis is good because…”?

*“This analysis is good because it uncovers the truth.”* This misrepresents the problems many analysts are asked to solve. Though we’ve borrowed the term “science,” we don’t deal in absolute truths; we aren’t physical scientists trying to document the laws of nature. As the Facebook research shows, the truth is nuanced. Nobody disputes that Instagram affects teens; the question is how much and how meaningfully. Even seemingly simple questions like “what is our sales attainment rate?” [are littered with subjectively](https://benn.substack.com/p/tilt-and-tilted), with no ground truth underneath. 

*“This analysis is good because it leads to good outcomes.” *This only holds up when decisions are repeated thousands of times—for example, when you’re deciding to send a customer a promotion or to hit on a blackjack hand. Most business decisions, however, aren’t repeated like this, which complicates the usefulness of outcomes as a scoring mechanism. Just because we lose a single blackjack hand doesn’t mean we made the “wrong” call. But, conversely, it’s cold comfort for Seahawks fans to know that, across hundreds of different universes, [passing was the “right” decision](https://www.sbnation.com/nfl/2018/6/5/17426540/seahawks-patriots-super-bowl-49-malcolm-butler-interception-run-the-dang-ball).[^3] In neither case does the outcome of the decision feel like an appropriate jury.

*“This analysis is good because it’s persuasive.” *I’m sympathetic to this view, and I’m [not](https://twitter.com/teej_m/status/1436113522744717332) [alone](https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/). If our job is to influence decisions, our analysis only matters—and is only good—if it accomplishes that goal. But once again, the Facebook research shows the limits of using this as a ruler. On one hand, according to Facebook’s annotations, the research was too bold. It was careless in its conclusions and oversold a story that wasn’t really there. It needed more rigor, more nuance, and more measured language. By trying to be persuasive, the work undercut itself. On the other hand, the research was too muted. Despite trying to sound the alarm about Instagram, the report was mostly ignored. At best, Facebook responded to the concerns by commissioning more endless research.[^4] By this measure, the original report wasn’t persuasive enough. And more generally, in a world in which Joe Rogan can convince millions of people to forgo their vaccines, we probably shouldn’t say that persuasive analysis is good analysis. Smart people with opinions can make their opinions look smart.

*“This analysis is good because the experts say it’s good.”* This is riddled with problems. It’s circular; experts are presumably the people who do good analysis, begging the question of what good analysis is. It’s insular, and scores analysis by how much it [conforms to the views of those who are already in positions of power](https://benn.substack.com/p/who-is-the-community). And it’s incomplete, as it provides no direction when, in the Facebook example, the experts disagree. 

Perhaps there are other methods. Good analysis uncovers something expected—but unexpected results can also be wildly inaccurate. Good analysis is hard to poke holes in—but that implies that quality varies depending on who’s reacting to it.

It feels to me, then, that our actual answer is an analytical classic: It depends. There is no single axis on which we can measure our work; a combination of factors determines its worth. And ultimately, even that rough rubric can be overridden if we, like a book critic taken by a compelling novel, *feel* strongly enough.

In some cases, we’re swayed by [our own priors about the problem](https://benn.substack.com/p/tilt-and-tilted). In response to the Instagram leak, Mike Solana, a VC and self-proclaimed free thinker if there ever was one, [predictably sided with Facebook](https://www.piratewires.com/p/bombshell). [Alexandria Ocasio-Cortez](https://twitter.com/AOC/status/1444837806245830657) and [Elizabeth Warren](https://twitter.com/ewarren/status/1438581744815509504) read the same research and came to the opposite conclusions. 

In other cases, we develop an affinity for the analysis itself. OkTrends, the former OkCupid blog written by Christian Rudder and the precursor to *Datacylsm*, is [revered in analytical circles](https://time.com/3047936/okcupid-relaunches-oktrends-dating-blog/). Yet, it’s tragically biased, based on the preferences of a particular subset of a particular generation who used a particular dating app at a particular point in time. But it’s nonetheless part of our canon, because, I think, it’s two things that most analysis isn’t: entertaining and accessible.

The good news is that this points to a way forward. OkTrends is heralded because it’s considered to be among the best of what’s available to judge. We need a wider library to choose from, especially if analysis, like so many other crafts, is inherently subjective. While few of us are as entertaining as Rudder, plenty of people may be better analysts. But unless we see their work—unless we figure out how to talk about what’s currently hidden behind NDAs instead of talking about [teams](https://benn.substack.com/p/analytics-is-at-a-crossroads) and [languages](https://benn.substack.com/p/the-case-against-sql-formatting) and [tools](https://benn.substack.com/p/metrics-layer) and [tools](https://benn.substack.com/p/is-bi-dead) and [tools](https://benn.substack.com/p/the-modern-data-experience) and [tools](https://benn.substack.com/p/the-data-os) and [tools](https://benn.substack.com/p/gerrymandering)—we’ll never know how high the bar could be set. 


---


[^1]: Obviously, in this case, Facebook’s claims about the research are in part pretense for discounting the results in the report. While there’s nothing inherently sinister about disputing research findings—a company as large as Facebook produces an enormous number of internal documents, and plenty will be flawed or incomplete—these reports clearly aren’t amateurs' sloppy drafts. They are, by all appearances, the best efforts of world-class ([Facebook’s own term](https://research.fb.com/careers/)) experts. And not the kind of experts that tech stans put air quotes around, and smear as stiff bureaucratic suits who stifle innovation and cower from creative destruction; no, these are the experts who left academic jobs for the disruption, the Facebook employees who want to move fast, [stable infra be damned](https://www.nytimes.com/2021/10/04/technology/facebook-down.html). Unless, of course, the difference between an expert and an “expert” is whether or not you agree with their opinion.

[^2]: Facebook, of course, [is](https://www.youtube.com/watch?v=SSzoDPptYNA). (If Facebook wanted to discredit the work of their research team, they should’ve just pointed to this ad as proof that highly qualified people sometimes produce, uh, questionable work.)

[^3]: It’s tempting to define good analysis as leading to the right outcomes more often than not. But in cases when decisions are only made once, this becomes tautological. The analysis can’t be wrong if it’s also the instrument that tells us what would’ve happened more often than not.

[^4]: Zuckerberg’s [response](https://www.facebook.com/4/posts/10113961365418581/?d=n) to the story talks a lot about the teams Facebook funded and the research it supports; notably absent is any mention of anything that Instagram actually *did *in response to that research.

================================================================================

# BI is dead

*How an integration between Looker and Tableau fundamentally alters the data landscape.*

---

![](https://substackcdn.com/image/fetch/$s_!w5sQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3e682840-de44-4fe2-a0d0-72b8ab0c0b33_590x415.jpeg)

It wasn’t the war that redrew Europe; it was the peace. 

The Treaty of Versailles, signed in 1919 after more than four years of catastrophic conflict, [created a new map of Europe](https://en.wikipedia.org/wiki/Treaty_of_Versailles#/media/File:Map_Europe_1923-en.svg). The agreement established nine new countries and thousands of miles of new borders, forever altering the political landscape of the continent.

Earlier this week, in a treaty of staggeringly less consequence, two of the data ecosystem’s biggest adversaries [agreed to come together](https://techcrunch.com/2021/10/12/googles-looker-partners-with-tableau/). Salesforce’s Tableau and Google’s Looker—major BI vendors, both of which were acquired four days apart in June of 2019—announced they’d soon be launching a technical integration between their two products.

The specific details are a bit vague, though the thrust of the partnership seems clear. Customers will be able to model data in LookML, and use Tableau, in addition to Looker’s native visualization tool, to explore that model. For people using Tableau’s side of the integration, Looker will, I believe, be invisible. Just as many of Tableau’s users are unaware of the Fivetran pipelines or dbt models that feed the data in their charts, they’ll likely be unaware of the Looker configurations that define the fields and metrics they’re exploring. 

The market reaction to the announcement was a mix of surprise and indifference—surprise that two highly competitive companies would suddenly become friends, and indifference because two giants like Google and Salesforce are unlikely to get a complex integration like this one right. Moreover, even if the integration is technically sound, Tableau and Looker are both overlapping BI tools, and few companies use both at the same time. Companies choose Tableau *or* Looker, not Tableau *and* Looker.

I disagree on both fronts. Nothing about this is terribly surprising, other than Looker having the audacity to actually do it. And more importantly, the signals buried in this agreement have enormous implications for future of both BI and the broader data industry. 

# Looker = LookML = Governance ≠ BI

Looker, which combines a modeling layer with a visualization tool, has always been awkwardly arranged in today’s data architecture. The diagram below, from Andreessen Horowitz, illustrates the challenge of this pairing: Looker is split across multiple layers the stack.

![](https://substackcdn.com/image/fetch/$s_!wdCP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3429cc5f-5abb-4a64-9e50-1554c59be1c4_1667x1186.jpeg)
*[Emerging Architectures for Modern Data Infrastructure](https://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/)*

The industry’s [horizontal pivot](https://benn.substack.com/p/datas-horizontal-pivot), which breaks data transformation and consumption into separate layers, makes this divide even more uncomfortable. As I said in the linked post, “tools that cut across these layers—including Looker, in my view—will eventually get pulled apart to align with the horizontal grooves the industry is carving.” This integration, which cleaves Looker’s modeling layer from its visualization tool, is exactly that.

Looker choosing to partner with Tableau makes particular sense because Looker’s always been a transformation tool first, and a consumption tool second. Looker’s crown jewel is LookML; Tableau’s is visualization. I’d speculate that Looker originally built its visualization tooling in large part so that they could market and sell the value of LookML, rather than the other way around. By launching this integration, Looker is simply doubling down on that long-standing identity.

![](https://substackcdn.com/image/fetch/$s_!HJWf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa51e5eb9-0738-4c24-baf0-b0c3a72d6ba3_888x482.jpeg)

When Looker got acquired, I thought Google would eventually acknowledge this. I said in an 2019 internal note about Google and Tableau acquisitions that, “over time, I expect LookML to be spun out of the BI application entirely, and offered as an independent, *global* governance solution within GCP. This could be the beginning of the bifurcation of traditional BI into two worlds: One for data governance and modeling applications, and one for the visualization and analytics applications.” 

So far, the two layers have been peeled apart by products like dbt plucking elements of data governance out from under BI. This integration, though a continuation of that same trend, points to something bigger: Major BI tools are now also recognizing the combination of governance and consumption can’t hold. 

# The future of BI

To Google’s and Looker’s credit, it’s a bold bet. The market sees Looker as a BI tool, and this integration challenges that perception. Coincidentally, it directly raises a question that I [asked in a recent post](https://benn.substack.com/p/is-bi-dead#footnote-5): “If you split Looker into LookML and a visualization tool, which one would be BI?” Or, in the terms of this integration, if you have both Looker and Tableau, which one is your BI tool?

My blunt answer is Tableau. You answer your questions in Tableau; BI tools are, above all, where questions get answered. Looker, in this realigned world, is squarely in the transformation layer—and specifically, part of the [metrics layer](https://benn.substack.com/p/metrics-layer). As I see it, this integration is the start of Looker’s retreat from fighting with visualization and exploration tools like Tableau, and an opening salvo in its campaign against metrics tools like Transform, Supergrain, Trace, and Metriql.

But even this understates the magnitude of the change. The partnership, if it presages a broader market pivot in the same direction, fundamentally redefines what BI is. In the same internal note from 2019, I speculated at that, “with the modeling layer removed, today’s BI applications—including Looker—become little more than pivot tables and dashboards. The applications that dominate this space will be defined by the richness of their analytics applications and how efficiently they facilitate collaborations among and between all levels of data users.” 

In other words, [BI as we know it is dead](https://benn.substack.com/p/is-bi-dead). BI as [global exploration](https://benn.substack.com/p/the-intergalatic-data-stack) is ascendent.[^1] 

# Is the economy stupid?

As an analyst, I want to use the products created by this realigned world. It’s less clear, however, that I want to *buy* them.

A number of folks have already raised this concern. Tableau and Looker are both expensive BI tools. How do you justify buying both?

On one hand, easily—they do different things. Looker governs data; Tableau helps people explore it. The rationale for buying Tableau and Looker is no different than that for buying Tableau and Transform, or even Tableau and dbt.[^2] 

On the other hand, this hints at a bigger question about buying data tools. The list of what we need in a modern data stack—logging infrastructure, inbound ETL, a warehouse, a modeling layer, a metrics layer, an advanced analytics tool, a code-free exploration tool, a catalog, reserve ETL, an observability tool—is getting long. While most new tools are technically easy to deploy, they’re not always easy to buy, nor are they collectively affordable. In addition to a modern data experience [for users](https://benn.substack.com/p/the-modern-data-experience), we need a modern data experience [for buyers](https://twitter.com/tayloramurphy/status/1432729974600085513). 

I don’t know how this problem gets resolved. It’s possible that tools build white-label integrations with one another so that you only have to buy from a few vendors. It’s possible that most products [are absorbed by behemoths](https://benn.substack.com/p/the-modern-data-experience#footnote-6) like Google and Salesforce. It’s possible that independent vendors merge into companies like Atlassian that operate as a federation of independent applications. It’s possible that a market pops up for companies and services that manage all of this for you. It’s possible that we don’t figure it out, and we live with the headache. And it’s possible that it just never becomes that much of a problem.

That said, the Looker and Tableau integration provides at least one interesting signal. My belief has long been that consolidation under Google, Amazon, Microsoft, and Salesforce is the most likely outcome. These companies, [sitting on nearly $400 billion in cash](https://www.investors.com/etfs-and-funds/sectors/sp500-companies-stockpile-1-trillion-cash-investors-want-it/), aren’t going to sit on the sidelines of, according to Andreessen Horowitz’s Martin Casado, [a trillion dollar data market](https://www.youtube.com/watch?v=q1nERFM9brA&t=715s). They’ve already built enormous businesses on top of collections of cloud computing services; it seems natural for them to do the same on data services. 

Over the last couple years, Google (and specifically GCP) has been apparently moving in this direction. Google built BigQuery for data storage, Data Studio for visualization, and Colab for advanced analytics; they acquired [Alooma](https://www.alooma.com/blog/alooma-plans-to-join-google-cloud) for ETL, [Dataform](https://dataform.co/blog/dataform-is-joining-google-cloud) for transformation, and [Looker](https://techcrunch.com/2019/06/06/google-to-acquire-analytics-startup-looker-for-2-6-billion/) for governance and metric calculation. All the pieces for the Google Modern Data Experience™ are there, provided that they can make them all work together.

But this integration implies an interesting admission from Google: They don’t believe in their own data exploration tools just yet. In 2019, though I thought Google would strip LookML out of Looker, I assumed Google Data Studio would be the first integration. By choosing Tableau, Google’s conceding, at least for the time being, that their data stack ends with LookML’s metrics layer. 

This gives GCP some optionality. Because everything below the metrics layer is still, at least loosely, infrastructure, Google’s data services could just be another subheader in the GCP catalog. Their offerings are still services oriented around compute rather than seats, sold to IT teams, engineers, and devops teams and their [analytical equivalents](https://www.youtube.com/watch?v=YvU036Cpkz8). In this world, the cloud service providers become the major combatants in the market for data infrastructure, while data consumption products designed for end-users and sold on a per-seat basis—including exploration tools, a reconstituted BI, and data apps—are built by the rest of the ecosystem. 

Alternatively, Google could simply be regrouping. They, and their other trillion-dollar rivals, may see the entire data landscape as their next theater. Rather than a lasting peace, this integration could be a [momentary pause](https://en.wikipedia.org/wiki/Causes_of_World_War_II#Legacies_of_World_War_I), setting the stage for a fight over the next big data market: [data applications and experiences](https://www.youtube.com/watch?v=9fhlfykocO8). 


---


[^1]: Admittedly, I have a horse in this race. At the end of the same internal note, when talking about the breakup of transformation and exploration, I said, “that’s the world that Mode is focused on serving.” At Mode, we haven’t built traditional data modeling features—which is unusual for something that looks like a BI tool—because we believe in this pivot.

[^2]: I am interested, however, in how this realignment affects Looker’s pricing model. Looker charges its customers [based on several factors](https://looker.com/product/pricing), including seats. If customers use Tableau for data exploration, it’s not clear what Looker will charge for. (This is part of the reason I disagree with the reactions that the integration doesn’t make sense because it’ll cost so much. That assumes Looker doesn’t change its pricing model.) Looker likely can’t charge for seats, because far fewer people will need seats than they need today. And they can’t charge for compute, because Looker relies on the database to handle most of it. That may point to the plan, though: Google wants to use this integration to put LookML underneath a bunch of Tableau customers, with the hopes of selling them BigQuery later.

================================================================================

# The future of operational analytics

*A better way to make daily decisions is already here—just not at work.*

---

![](https://substackcdn.com/image/fetch/$s_!hgkE!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd3f769df-7b40-46d2-96df-3944dba5ec12_1200x509.jpeg)
*Choose your fighter. *

For those of us on the far side of thirty, planning a night out used to be a very different experience.[^1] If you wanted to get dinner with your friends, you’d gather people’s opinions and whatever rumors they’d recently heard about new restaurants. You’d then guess how crowded each place might be, and estimate how long a group of your size would have to wait for a table. If it was a particularly important dinner, you’d call a few places, one at a time, to see if they had open reservations. And finally, after making a choice, you’d estimate how long it’d take to get there, adding a buffer for potential traffic or a delayed train, and hope everyone arrived on time.

Dining by intuition and anecdote usually worked, but it wasn’t without its misses. Sometimes, traffic was worse than anticipated and you'd miss your reservation. Sometimes, the [restaurant was full](https://youtu.be/MgMS0xNOyMY), and you had to improvise. And sometimes, the recommendation was bad and you'd end up eating at a place whose signature ingredient was [Florida](https://rjgatorsbradenton.com/). 

Today, we do it very differently: We choose where to eat based on data. In fact, data-driven dining has become so natural, we barely even notice we’re doing it.

We start by looking up reviews on Yelp and Google. We don’t just mechanically favor the restaurants with the highest ratings, but assess the data analytically. Restaurants with fewer stars but more reviews might be better than those with just a handful of reviews; we check the recent reviews to make sure places are still good; we adjust star ratings by price. Once we find places we like, we use [Google’s crowd estimates](https://blog.google/products/maps/maps101-popular-times-and-live-busyness-information/) to see if we’ll be able to get a table. We flip through Resy to find reservations, which provides another analytical signal: We’re suspicious of a restaurant with too many openings. And finally, to make sure our chosen restaurant fits into the rest of our evening’s plans, we rely on Google Maps to tell us how we should get there and how long it’ll take.

Granted, it’s not always the fastest way to make a decision. But we almost certainly make *better* decisions. Case in point: If you had to plan an [important dinner](https://www.youtube.com/watch?v=VBl_gvTBO9g&lc=UgxSBLMYt54W0YFl7OJ4AaABAg), would you rather rely on the gossip networks of yesteryear, or data-driven research from Yelp and Google? Overwhelmingly, it seems, we choose the latter. 

For those of us who work in data, particularly those of us who toil away trying to make our organizations and their operations more “data-driven,” this should be breathtaking.

Yelp, Google, and other services like them have converted an intuition-driven process into one in which we consult some form of data before making almost any decision. Even when deciding what to order from apps like Doordash and Caviar, we sometimes lean on the “popular items” section—the data—to help us choose.

Moreover, we don’t just rely on Yelp when we’re dropped into an unfamiliar city; we even use it in our hometowns, in neighborhoods that we know. Data isn’t filling the gaps in our intuition; it’s *replacing* it.

Perhaps most remarkably, this experience is universal. People weren’t trained to think this way; nobody was onboarded to Yelp’s schemas; no data team carefully maintained a data dictionary to explain how to interpret Google’s reviews; no data scientist pressured us to be more analytical diners. We just did it, all of us, on our own.

Contrast this with the role data plays within organizations. There’s [an](https://www.gartner.com/smarterwithgartner/create-a-data-driven-culture-by-influencing-3-areas) [entire](https://hbr.org/2020/02/10-steps-to-creating-a-data-driven-culture) [cottage](https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-a-data-driven-company) [industry](https://www.forbes.com/sites/forbestechcouncil/2020/10/09/how-to-make-your-company-more-data-driven/) of “thought leaders” ([clowns](https://benn.substack.com/p/analytics-is-a-mess), [all](https://benn.substack.com/p/big-whiff) [of](https://benn.substack.com/p/self-serve-is-a-feeling) [them](https://benn.substack.com/p/analytics-is-at-a-crossroads)) built around helping organizations better use data. As analysts, we fret about people not using the tools we provide them. If they do, we fret about the analytical crimes they’ll commit on top of them. And we, and the [exact](https://www.gartner.com/smarterwithgartner/a-data-and-analytics-leaders-guide-to-data-literacy) [same](https://hbr.org/2020/02/boost-your-teams-data-literacy) [cottage](https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company) [industry](https://www.forbes.com/sites/tableau/2021/06/25/why-your-workforce-needs-data-literacy/), fret about how to make people more data literate.

There is no such coordination around Yelp and Google. There is no institutional push for data adoption, no Substacks full of tips and best practices. And yet, we all use Yelp’s and Google’s data, and we all survive.[^2] So what did they figure out that we haven’t? How do we make data fit as naturally into the decisions we make in businesses as it does when we make decisions about what to eat?

# Yelp for the enterprise

The secret, I believe, is in the subtlety. We don’t immediately notice how much we use data in products like Yelp, Google, and Resy because data isn’t detached from the rest of the experience. These services don’t attempt to make you “data-driven.” Instead, they focus on a bigger problem—choosing a restaurant, a means of transit, and a reservation booking—and integrate data alongside other features, like phone numbers, pictures of food, and links to menu, that help you address it. It’s all a single experience, with no clear line where the product ends and the data begins.

Consider what Yelp would look like if it took the same approach that we do inside of our companies. Rather than its current interface, Yelp would be a dashboard, full of options and toggles. To find a place to eat, you’d choose a cuisine from a dropdown; pivot the results by price; filter to a few neighborhoods; average the reviews for the last 90 days; no, compute the percent of reviews over the last year that are at least four stars; find places that have improved the most; write a custom formula to adjust by the number of reviews; make several charts; delete the charts; make a few more—and eventually, decide that finding the best restaurant “[depends on what you mean by the best](https://twitter.com/jas_hughes/status/1450537609768226816?s=21),” that every decision is just a tradeoff anyway, and end up going to your usual late-night Thai place because it’s the only thing still open. 

Though this dashboard may be more powerful than the current version of Yelp (and, admittedly, be fun to play with), it’d clearly be worse at solving the problem it’s meant to be solving. In the narrow context of deciding where to eat, dashboards like this would merely create an illusion of quantitative rigor. In practice, it’d make data hard to find, easy to misinterpret, and intimidating to use. 

This, however, is the model we follow for corporate decision-making. Most data is accessed through dashboards and BI tools, which are dedicated sites for exploring data that are divorced from decisions themselves. We “do our jobs”—sending emails, writing ad copy, designing products, creating decks—in one place, and use data in another.  It is, in short, a decidedly less seamless[^3] experience.

What would be a better version? The easy answer is to embed charts and tables in our workflows, like a dashboard stuck in Salesforce. Though better than nothing, this is a pretty unimaginative future. To think of how much further we could go, consider a less traditional example: Figma, a design tool.

Many product designers live in Figma, and when they do, they make dozens of small decisions about their work, which are often based on their intuition. When redesigning a user interface, they may make assumptions about how it’s currently used, or about the types of people that use it. When they want to check these assumptions, they turn to a data team or sets of dashboard, a process that is is often expensive and exhausting. As a result, it only happens on occasion, for the most important questions.

What if, instead, we embedded answers to their questions directly in Figma? Can we expose numbers—say, the number of times a button was clicked, or the percent of paying customers who use a feature—on mocks themselves? Could designers look at the current product and see an overlay of simple interaction metrics about its elements? Beyond just helping with decisions they know they have to make, this could also help uncover user behaviors that designers had never considered. The paths people take are not always [visibly worn](https://www.google.com/search?q=user+experience+path&tbm=isch&ved=2ahUKEwi52-ajuN7zAhUCUM0KHQ90DugQ2-cCegQIABAA&oq=user+experience+path&gs_lcp=CgNpbWcQAzIFCAAQgAQyBQgAEIAEMgYIABAHEB4yBggAEAUQHjoECAAQQzoGCAAQCBAeUIQSWIQSYKkTaABwAHgAgAEziAFlkgEBMpgBAKABAaoBC2d3cy13aXotaW1nwAEB&sclient=img&ei=8uZyYbmaHoKgtQaP6LnADg).

On Yelp, we don’t just look up restaurants we know; we also find new places we’d never heard of. *This* should be the ambition of operational analytics: to inform decision making so thoroughly that we use it even when we didn’t ask for it.

# The future is an experience

Martin Casado shared a [similar vision](https://www.youtube.com/watch?v=q1nERFM9brA&t=3458s) in a recent conversation with Sisu’s Peter Bailis. His hope—and his ask as a VC looking to make some investments—is for companies to rebuild the SaaS ecosystem as data apps. In Casado’s view, operational tools should be indistinguishable from data tools.

I’m less certain that the best way forward is to recreate tools like Figma rather than integrate with them. (I think there are a lot of interesting questions about the economics of this, which I’ll save for another day.) But I agree with direction of Casado’s ambition: Data should be as ubiquitous in companies as it is in dining. And for operational analytics experiences to get there, the industry needs to make a few changes.

First, operational data tools need to be focused on solving specific problems. Yelp and Google work because they know exactly what they’re there to do. Yelp’s homepage, for instance, makes it very clear what it's for: Find things near you. There’s no “exploring data” or “discovering insights” on restaurants. Instead, Yelp presents a problem that needs data to be solved. 

![](https://substackcdn.com/image/fetch/$s_!k1P9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb7cf4220-8530-470f-8318-1629fa5bf6ea_1600x936.jpeg)
*Ok, but state? Who’s searching for “Tacos near Texas?"*

Dashboards are the opposite. They’re often data, looking for a problem. In that light, it’s no wonder that people don’t use them—it’s often not clear what they’re supposed to use them for. 

Second, we need to be ruthlessly disciplined. Yelp only exposes two data points: The number of reviews, and a crude star rating, rounded—through some means of aggregation that they don’t tell us—to the nearest half star. There are no options for filtering out old reviews, or for only considering those from a certain demographic; we can’t examine other metrics, like median ratings or average ambiance scores. While we might want these things, their absence clearly [doesn’t stop us from wanting to use Yelp](https://www.yelp-press.com/company/fast-facts/default.aspx), and Yelp isn’t afraid to tell us we can’t have them. 

As corporate analysts, we rarely follow this principle. Taylor Brownlow [put this well](https://towardsdatascience.com/dashboards-are-dead-b9f12eeb2ad2): “After a dashboard had gone live, we were immediately flooded with requests for new views, filters, fields, pages, everything.” When we acquiesce to these requests, dashboards get cluttered with chart after chart, cohort after cohort, filter after filter. This isn’t serving our customers; it’s serving ourselves, punting the tough decisions about what’s important off to them.[^4] 

Third, our ambition shouldn’t be to make decisions automatically. At first glance, a product that tells us where to eat seems like an obvious hit. It’d be relatively straightforward to build, and we *really*[ don’t like picking restaurants](https://www.mcsweeneys.net/articles/with-god-as-my-witness-i-will-not-pick-the-restaurant). Yet, the only real attempts to do this [are jokes](https://wtfsigte.com/).

There’s no demand for this, I think, because people are reluctant to cut themselves out of decisions. We want to be guided—we want our options narrowed and ranked—but not fully replaced. If this applies to a decision as inconsequential as where we’ll eat on a Wednesday night in September, it almost surely applies to the expensive decisions we have to make about our companies and careers. 

Finally, to make all this possible, I believe we need [an “operating system” for the data stack](https://benn.substack.com/p/the-data-os). This layer would provide a single platform to build richer apps in operational tools by providing consistent APIs for interacting with data, by centralizing model and metric governance, and by coordinating changes between those apps.

As an industry, we’re drifting in this direction, but aren’t quite there. As useful as they are (and I’m a big fan), products like Census and Hightouch, which write data into operational sources like Salesforce and Zendesk, are currently pipelines that string data between databases and SaaS apps.[^5] They aren’t yet platforms for building experiences. Moreover, while [metrics layers](https://benn.substack.com/p/metrics-layer), an [open LookML](https://benn.substack.com/p/bi-is-dead), [dbt](https://twitter.com/getdbt/status/1449090582865981442), [lakehouses](https://databricks.com/glossary/data-lakehouse), and the [data mesh](https://benn.substack.com/p/the-modern-data-experience) all have whiffs of an operating system, they’re still primarily read-only layers that provide, in effect, a governed way to write queries. 

But all of these products are starting to scratch at the right idea: The [future is an experience](https://benn.substack.com/p/the-modern-data-experience), with data integrated into and inseparable from how we do our jobs. The technology underneath those experiences are merely a means to an end, no different than the wiring underneath Yelp’s review infrastructure. 

# The limits of analogies 

As an extended footnote, I recognize that the analogy with Yelp isn’t perfect. Deciding where you take your out-of-town friends for dinner isn’t as consequential or complex as allocating a $10 million advertising budget. While Yelp might be useful for a routine night out, it’s not much good for planning a wedding for a hundred people. For these sorts of events, we need more powerful tools.

The same is true in data. In these cases, narrow, operational tools aren’t sufficient. Important, strategic questions or cross-functional problems need open-ended tools. The future of these tools, however, is the same as the future of the entire stack: They too should be an integrated experience. Rather than fragmenting how we explore data [along technical boundaries](https://benn.substack.com/p/gerrymandering)—a dashboard for execs, a BI tool for operations, an advanced analytics tool for data scientists—we should integrate these functions into a single cohesive experience. People should be able to move between different modes of exploration, promoting a Python analysis to a dashboard or unfurling a visual analytics tool into a technical IDE. In addition to making data consumption easier, this [creates a shared workspace](https://kwokchain.com/2020/06/19/why-figma-wins/) for analysts and non-analysts alike. 


---


[^1]: Consider this post a petition to replace all of our [water-based terms](https://djpardis.medium.com/data-water-terms-6bf9e9c7aad6) with [food](https://roundup.getdbt.com/p/recipe-for-data-intuition)-[based](https://raydata.co/datas-secret-sauce/) [analogies](https://thesequel.substack.com/p/the-endless-data-buffet). Databases? Cupboards. Self-serve? Buffets. Business people? Diners. Dashboards? Plates. We took all the food out of the cupboard and put it on the buffet, but some of the diners overloaded their plates and accidentally mixed their peas with their chocolate pudding.

[^2]: [Usually](https://youtu.be/ATAjo60JZrw).

[^3]: Get it??

[^4]: We should be honest with ourselves that this is often what we want data for anyway. Making a decision is hard; it often takes courage to make one. Data gives us an out. If the decision goes well, we can praise ourselves for our smart analysis and clear thinking; if it goes poorly, we can say we were just listening to the data. Consider this thought experiment. Suppose you’ve got to make a big decision for your team, and you’re considering two options. Someone did a great bit of analysis that convinced your team that option 1 is clearly the best choice. However, you know, definitively, that option 1 has a 40% chance of success, and option 2 has a 60% chance of success. If nobody other than you ever knows those odds, which option do you choose?

[^5]: To be fair to these products, their initial focus makes sense; it’s a smarter way to build a business. My point is that the “operational analytics” space will need to expand. Census and Hightouch may well already have plans to do exactly that—[I have no idea](https://youtu.be/b_G5EPNEHDo).

================================================================================

# Data and the almighty dollar

*The data ecosystem is booming. The data economy has some things to figure out.*

---

![](https://substackcdn.com/image/fetch/$s_!tAf2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F115226c3-8076-4517-8d7d-e5efc9a09a41_800x491.jpeg)
*[The McNay Art Museum](https://collection.mcnayart.org/objects/7527/four-winds)*

Halloween, I’ve heard, is the second most important night of Uber’s year. If this Halloween is like [that of years past](https://www.nbcnews.com/business/consumer/how-uber-working-prevent-another-halloween-outage-n924926), Uber engineers and operations leaders will be huddled around monitors and dashboards, tracking ride requests and active drivers, making sure some imbalance doesn’t send [fares through the roof](https://www.nydailynews.com/news/national/uber-customer-outraged-billed-539-18-mile-ride-article-1.1997960). Metrics that people typically follow on a daily or hourly basis suddenly need to be updated every few minutes.

Though most of us haven't been in war rooms tracking the minute-by-minute [movements of an entire city](https://www.youtube.com/watch?v=Kr7AONv3FSg), many analysts are familiar with lighter versions of this experience. We’ve had product managers who want to follow how a feature is adopted on the day of a big launch, CMOs who need hourly reporting on Black Friday sales, and operations directors who need frequent updates on the number of new orders coming in during the days leading up to Christmas. In these moments, the typical, casual latency of our dashboards isn’t enough.

In one sense, the modern data stack makes solving this problem easy. Update how often Fivetran extracts data from source systems, schedule a couple more dbt runs, refresh the Tableau dashboard or Mode report more frequently, and each system magically scales itself up to support the necessary load. It’s clicks and configuration updates; no hard work required. 

In another sense, these changes are major headaches. Fragmented pipelines, spread across different vendors and tools, have to be kept in sync. Without a way to orchestrate them—whether that’s through a [data OS](https://benn.substack.com/p/the-data-os) or a [configuration standard like Terraform](https://roundup.getdbt.com/p/devops-and-the-modern-data-experience)—updates are disorganized and brittle. Fortunately, this fragmented user experience, and the need for [a better one](https://benn.substack.com/p/the-modern-data-experience), is now a problem that’s [getting](https://meltano.com/blog/meltano-the-strategic-foundation-of-the-ideal-data-stack/) [more](https://dagster.io/blog/dagster-0-13-0-a-new-foundation) [attention](https://roundup.getdbt.com/p/quasi-mystical-arts-of-data-and-the). 

But there’s a third—and largely unexamined—sense in which these changes can be problematic. Given the variety of tools wired underneath situation room dashboards, lowering their latency can lead to a cascading set of confusing and interconnected charges. 

Refreshing a dashboard more often in Looker, for instance, will push more queries down to your warehouse. If you’re using a database that meters usage, like Snowflake, BigQuery, or Databricks, these extra queries add to your bill. Moreover, some BI tools, like Amazon’s Quicksight, [collect their own fees](https://aws.amazon.com/quicksight/pricing/) when people log into them more often. 

Of course, for dashboard updates to be useful, you also have to refresh the data behind them more often. If you’re using dbt, this requires running more dbt jobs, again adding load to the database. If you’re using a metrics layer with its own cache, you likely have to run queries to extract fresh data, and pay the metrics vendor for marginal additions to their cache. And you need to pull data from source systems more regularly, adding even more queries to the database’s queue and spinning the data throughput meters on Fivetran, Stitch, and Segment a little faster. 

Lowering pipeline latency can have other indirect effects. Data observability platforms will run more tests; reverse ETL tools will fire more often. Both categories of tools typically bill for this extra usage themselves and, yet again, push more queries down to the database. 

Every company’s particular tangle of charges and fees will vary, depending on the collection of tools they’re using and how exactly they’re configured. But some version of this story exists inside of every modern data stack. In its normal operation, costs are intertwined and opaque. And bigger updates and changes—whether it’s scheduling dashboards to update more often, adding a new data source, or onboarding a new department of users—rotate a face of Rubik’s cube, which rings half a dozen cash registers as it turns. 

# The danger of the engineering analogy

Over the last few years, the heat in the data market has been [attracting hundreds of new companies](https://benn.substack.com/p/the-data-os#:~:text=In%202017%2C%20Y%20Combinator%E2%80%94an%20incubator%20of%20both%20startups%20and%20the%20Silicon%20Valley%20zeitgeist%E2%80%94funded%2015%20analytics%2C%20data%20engineering%2C%20and%20AI%20and%20ML%20companies.%20In%202021%2C%20they%20funded%20100.), each looking to cut their slice out of a ballooning pie. Some of these products will inevitably fail, but many have already found useful wedges that cleave off a new corner of the market. In an effort to differentiate themselves and [elbow others out of their part of the dance floor](https://www.tiktok.com/@kallmewhateveryouwant/video/7004966097027943686), companies are now looking for ways to define themselves as a new and necessary part of the modern data stack. So far, according to the [people who catalog such things](https://www.moderndatastack.xyz/categories), we’ve fractured it into 28 distinct pieces. 

Each category makes the data stack more technically robust—and more economically tenuous. 

In our current ecosystem, most data products are still expensive to build. They require architecting [new frameworks](https://transform.co/), developing [smarter AIs](https://sisudata.com/), designing [complex visualization systems](https://benn.substack.com/p/the-intergalatic-data-stack), or reinventing how [data gets processed](https://decodable.co/). Work like this isn’t cheap, and companies can only fund it if they promise to make real money on the other side. This sets a high floor for the price of data products.[^1] 

Furthermore, while high prices are a constant, data companies’ business models are not. Some products charge usage-based compute fees, some for user licenses, some for feature tiers, and some blend different mechanics. Some products are still searching for the best way to sell. And some, which bury their prices behind a handful of sales calls, don’t tell us what they charge for.

Data companies also sell to a variety of buyers. There are products that are marketed to data engineers and devops teams, to analytics engineers and analysts, to data scientists, to IT departments, to lines of business, and to uncertain mixes of different buyers. The “data” bill has no owner.

You could make the argument that this complexity is just a reflection of the growing importance and ubiquity of data. It is, in other words, the price of success.

Maybe so—but that doesn’t apply to other functions. In what other departments do companies need to buy a wide collection of expensive tools, bought by different people and priced in different ways, to solve a single set of problems? Equivalent scenarios border on the absurd. Imagine needing to build a CRM for a nascent sales team, and having to buy a tool for logging phone calls, a tool for logging emails, a tool that stores these logs, a tool that helps sales reps see the status of their opportunities, a tool that helps sales leaders keep track of their team’s performance, and a tool to alert you when other tools break. While products like these may get hung off of Salesforce at some point, they’re bought by growing sales teams, not integral legs to an eight-legged stool. 

The more common comparison is that data products (and [data teams](https://locallyoptimistic.com/post/the-next-big-challenge-for-data-is-organizational/)) are tracing the same path as web development stacks, which are also interconnected mobiles of tools delicately balanced against one another. In time, it's implied, our stacks will find the same equilibrium.

But the analogy is fatally flawed. Software stacks are built by engineers, who are comfortable wiring together closer-to-the-metal *technologies*. Many data practitioners are unwilling or unable to do the same. They want to buy hosted* services*. If we were generally comfortable managing Spark ourselves, Databricks wouldn’t be worth nearly $40 billion.

A services-oriented industry appears likely to keep prices high relative to a technology-oriented one for two reasons. First, in addition to building core technologies, which are hard enough to develop on their own, companies have to build administrative chrome—user management, security infrastructure, web interfaces, customer onboarding, support and success services—in their products. Second, open-source standards have a harder time taking hold. While LookML could’ve become a standard for semantic modeling, Looker had little incentive to open it up because most people wouldn’t want or be able to run it themselves. An open-source LookML is a gift to Looker’s competitors, not to the community.[^2] 

And so, here we are. The ecosystem is creating category after category, throwing out product after product. Thus far, the market has absorbed them—but the dynamic is unstable. With few dominant players and fewer agreed-upon categorical standards, customers are choosing from a large inventory of small companies, offering dozens of startups enough of a foothold to reasonably claim that they provide more value than they cost. Furthermore, because of the variance in buyers and business models, the true cost of the stack is amortized across different teams and obfuscated by irregular billing logistics.[^3] 

But data teams and IT departments have budgets. Even if every product is worth it on its own, the collective cost eventually becomes too much to bear.[^4] Something has to give.

# Bigger planets, better orbits

There are two simple ways out.

One is that nothing happens. Data becomes so valuable that none of this matters. We all [become data companies](https://www.youtube.com/watch?v=q1nERFM9brA&t=715s) and, just as we don’t blink at our AWS bills ([until we do](https://a16z.com/2021/05/27/cost-of-cloud-paradox-market-cap-cloud-lifecycle-scale-growth-repatriation-optimization/)), we accept the high price of data tooling as the necessary cost of doing business.

The second is a bloodbath. A few dominant players colonize most of the landscape, and small companies—and potentially entire categories—get squeezed out. The modern data stack becomes a cemetery of once-promising tools, and one of the surviving behemoths dances on everyone’s graves by [going public with “MDS” as their ticker](https://www.google.com/search?q=crm+ticker).

In a consolidated world, the stack’s economics start to make more sense. Everything collapses under one billing system, making purchasing easier to manage. And while different services may get broken out into their own line items, not every product has to run an independent profit. As long as the entire stack is worth its aggregate bill, customers and vendors both come out ahead.[^5] 

These aren’t the inevitable poles, though. There are potentially other, less severe ways to balance the economic equation.

Middle men could insert themselves between today’s vendors and buyers, offering everything from shopping catalogs of data tools[^6] to a layer of software to manage those tools. A [number](https://www.datacult.com/) [of](https://rittmananalytics.com/home) [consultancies](https://brooklyndata.co/) already do this manually; the [next wave of companies](https://www.mozartdata.com/) will do it automatically. 

Whether or not they’re people or software, these administrative layers make modern data tooling more accessible and easier to operate. To lower a dashboard’s latency, you only have to turn one dial, not six. But it’s not clear how they lower the overall cost of the stack, short of making decisions for you about which tools to include and which to exclude. 

Vendors themselves could also take steps to simplify the buying process as well. On the extreme end, companies could merge into large conglomerates, forming a suite of products akin to Atlassian (or [Match Group](https://en.wikipedia.org/wiki/Match_Group)). Or there could be a rise in soft M&A, in which companies white-label themselves behind other vendors and through revenue sharing agreements. These arrangements would probably be beneficial to the market, but are surely a nightmare to work out. 

There are also more complex solutions. Within each major category of the stack, a few key vendors (or [planets](https://benn.substack.com/p/the-intergalatic-data-stack), if you will) could serve as platforms—[in a real sense](https://stratechery.com/2019/shopify-and-the-power-of-platforms/)—for smaller services to build on. Salesforce, Slack, Stripe, and Shopify[^7] show how this can play out: Companies offer platforms for other people to build on; this enriches the market by [making it cheaper](https://twitter.com/jthandy/status/1442840153345695744) for everyone to build new products; those products simultaneously fill the platform’s gaps *and* reinforce the platform’s dominance. 

Forced to choose, I’d bet on the market consolidating into ten or so planets, with dozens of moons orbiting around each. This doesn’t necessarily imply, however, that the market is frothy, or that today’s startups aren’t worth the heady figures on their cap tables. The demand for these tools is there, and more is coming.[^8] The problem is the composition of the supply, which is currently broken apart into hundreds of asteroids with no clear orbits, haphazardly bouncing into one another. To make this whole thing work, we don’t need less mass in the solar system; we just need more organization.

# Saving our battery

According to the [historians of the modern data stack](https://blog.getdbt.com/future-of-the-modern-data-stack/), Redshift’s launch catalyzed the entire movement. Prior to Redshift, we had to be careful with our warehouses; they were slow, expensive, or fragile. Redshift and its successors changed that. They became bulletproof, capable of handling anything we pile into them.

And pile on we have. Across the stack, tools now lazily lean on warehouses, hammering them with query after indiscriminate query. Need to tweak a filter on a dashboard? Run a query. Need to update a table in a database? Run a query. Need to re-sync your entire users table? Run a query. Need to validate your data against a test? Run a query. Need to push an email list to Salesforce? Run a query. Need an alert when a metric crosses a threshold? Run queries constantly.

Today’s warehouses can handle it—happily. Our debits are their credits.

I have no idea how many of these queries are extraneous, but it could easily be a significant number. At some point, when costs come into focus and we start taking a harder look at our receipts, we’ll want to do a better job of coordinating query load across tools. At a minimum, we could reduce load during down hours; more advanced solutions could recognize when a dbt model doesn’t need to update because Fivetran hasn’t run, or when an observability test can be ignored because the underlying data hasn’t changed. 

![](https://substackcdn.com/image/fetch/$s_!ukML!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F89ec6d4a-0d4d-4695-878a-8541d71eb904_853x187.jpeg)

To extend the mobile operating system analogy, this could be another job of the data OS—offer a “battery saving mode” that allocates compute in intelligent ways. If nothing else, it’s an easy product to sell: It’s one thing to sell a tool that costs $10,000 with the promise of $20,000 of nebulous value on the other end; it’s something else entirely to charge $10,000 for $20,000 in Snowflake credits.


---


[^1]: This dynamic is particularly apparent if you talk to very early-stage data companies. Nearly every company, including those built on an open-source ethos or with community ambitions, has a plan for “moving into the enterprise.”

[^2]: dbt is an interesting exception here, which I partially attribute to dbt’s simplicity. In its earliest iterations, dbt didn’t need to be hosted; it just needed to be run. There’s a big difference between running a script on a schedule (though the first version of dbt Cloud proved that many data teams didn’t even want to do that) and managing a service like Airflow or running a database like Spark.

[^3]: Imagine, for example, if every tool charged a per-user fee. We’d be much more sensitive to overlapping charges, and procurement departments would put more pressure on data teams to consolidate costs. With every bill accruing in a different way—a user fee here, a usage-based monthly charge there, a flat annual fee somewhere else—the total cost of the stack is harder to tally.

[^4]: Is every Billie Eilish show worth more to me than the price of the ticket? Yes it is. Can I afford to go to all of them? Sadly, I cannot.

[^5]: Selling software suites also makes for bizarre accounting gymnastics. In 2012, Microsoft SharePoint was simultaneously a [$2 billion business](https://www.quora.com/What-portion-of-Microsofts-revenues-comes-from-its-SharePoint-product-line) and a product even people working at Microsoft didn’t understand.

[^6]: The modern data mall.

[^7]: Very clever of Snowflake to start their name with an S.

[^8]: Prove it, you may reasonably say. Fine—but later.

================================================================================

# A method for measuring analytical work

*Our only job should be to make people more decisive. *

---

![](https://substackcdn.com/image/fetch/$s_!Aodg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc358ea56-a1a0-4301-a423-4f00396f2cff_773x370.jpeg)
*To be, or not to be, that is the question. If only this analysis did a better job of helping me decide.*

One of the great ironies of the analytics industry is its utter inability to measure itself. Despite “defining key metrics” for ambiguous business processes being a key responsibility in [nearly](https://careers.airbnb.com/positions/3398395/) [every](https://stripe.com/jobs/listing/data-analyst-payments/2934034) [analytics](https://boards.greenhouse.io/airtable/jobs/4999279002) [role](https://www.lifeatspotify.com/jobs/data-scientist-personalization-2), we [enthusiastically reject](https://hex.tech/blog/data-team-roi) doing it for ourselves. Our work has been, and frustratingly remains, [unmeasurable](https://benn.substack.com/p/chasing-ghosts). 

Of course, we still have to pass judgement on what’s good and what isn’t. Teams have to make the case for bigger budgets; performance reviews have to be written; we have to decide when a project is ready to ship. But without a generally accepted way to determine the quality of a team, individual analyst, or piece of work, we fall back on informal—and flawed—proxies. 

In most cases, we simply rely on the opinions of “experts.” Analysis is good if good analysts say it’s good (which, obviously, raises the question of what makes a good analyst). This makes us little more than art critics: Even if we attempt to apply loose rubrics when assessing someone else’s work, [our emotions](https://benn.substack.com/p/tilt-and-tilted) often get to vote last.

When we want to be more rigorous, we try to judge analysis by its effect. Did it lead to a good outcome? But this is also applied selectively. While positive results are celebrated, we excuse bad results if we determine that the underlying analysis was sound (as determined by the experts, of course). These outcomes are merely bad luck.[^1] 

Worse still, we often can’t measure the result at all. Suppose, for example, a company is trying to decide if they should open a sales office in London or Tokyo. The analyst recommends Tokyo, and the office is a mild success. There’s no way to know if the decision was good or not, because there’s no way to assess the counterfactual. Maddeningly, the best method we have is the original analysis itself, which, almost tautologically, will of course confirm that Tokyo was the right choice.

This paradox—that analysis can only be measured in circular ways—has real effects that go beyond stressing out armchair philosophers with Substacks. It provides cover [for bias](https://benn.substack.com/p/tilt-and-tilted). It promotes nepotistic favoritism of supposedly good analysts’ analysis that makes our industry [more insular](https://benn.substack.com/p/who-is-the-community). And it makes it [incredibly difficult](https://benn.substack.com/p/chasing-ghosts) for young, aspiring analysts to grow and improve.

On this final point, consider a junior analyst joining a company without an established data practice. There are no “experts” to provide feedback. There are few public examples of corporate analysis that they can emulate. They can’t easily see the impact their work has on business outcomes. How can they measure themselves? On what scale can they weigh their work? How does an aspiring dancer, growing up in [Bomont](https://en.wikipedia.org/wiki/Footloose_(1984_film)) in 1984, with nobody to imitate and no Tiktok to watch, know if they’re good?

I’ve long felt trapped by this problem, but recently stumbled into a potential way out: Analysts should judge their work by how quickly people make decisions with it.

# He who hesitates is lost

The moment an analyst is asked a question, a timer starts. When a decision gets made based on that question, the timer stops. Analysts’ singular goal should be to minimize the hours and days on that timer. 

That’s the only metric we should measure ourselves on—straight up, without qualification or caveat. The lower the number is across all the decisions we’re involved in, the better we’re performing.

First and foremost, if the point of analysis is to help people make decisions, this measures that goal most directly. While we think of analytical experts as the best judges of our work, decision makers—the executives or business stakeholders who have the most context about a problem and are most invested in solving it—are better juries. They may not know the nuances of analytical or statistical law, but they’re the people we have to convince. Just as any decisive argument in court is a good one, convincing analysis is, almost by definition, quality analysis. And the faster the jury delivers a verdict—regardless of what the judge thinks about it—the better the case. 

The inverse is also true. Sloppy work—analysis that uses bad data, conclusions built on flawed reasoning, recommendations with major omissions or oversights—delays decisions because decision makers often see these holes and ask for work to be revised or redone. If the jury finds a lawyer ineffective, they are; if decision makers find us ineffective, we are.

Beyond measuring the right goal, focusing on the time it takes to make a decision has several other benefits, both in how it measures our work and in the incentives it creates for us as analysts.

First, it forces us to understand the problem we’ve been asked to solve. By tying ourselves to a decision, this measure discounts dashboards [searching for a problem](https://benn.substack.com/p/the-future-of-operational-analytics), or undirected exploratory analysis prompted by people who are “just wondering” something. We can’t minimize the time it takes to make decisions without knowing which decisions are being made. 

Second, it encourages us to see problems as others do rather than as we do. We have to understand the intuitions that people use to make decisions, and the operational context in which they make them. For example, if we’re trying to help the sales team rank leads, we can’t persuade sales reps to call engineers working in finance if they’ve constantly been frustrated by prospects in the banking industry and they know most engineers don’t answer their phones. Analysis will only be convincing if it respects those priors.

Third, it provides a useful counterbalance against analytical excess. One of the challenges for analysts is to figure out when something is done. How many threads do you pull on? How rigorously do you tie off loose ends? This metric provides an answer: You take the time that’s necessary to give someone the confidence to make a decision, and no more. 

Fourth, minimizing this time puts a clear—and appropriate—emphasis on the value of communication. Analysts have a tendency to riddle our reports with [caveats and hedged language](https://twitter.com/Pedram_Navid/status/1455924248615084036), or to include every detail of our research in our decks.[^2] But someone has to work through these nervous suggestions and wordy decks. If we measure ourselves by how quickly people cut through that noise, we’d do a better job of cleaning it up ourselves.

This also encourages us to pay more attention to how our work *looks*. It’s easy to discount aesthetics as shallow vanity, but people trust things that look good. 

Finally, even if we don't directly measure the time it takes to make a decision—it’s hard to know when, exactly, a decision was made, and some analyses affect many decisions—we can at least estimate it, or sense when things are taking a long time. And compared to something as squishy as “was the outcome good?,” it’s practically hard science. 

# Alternative facts

A skeptic might notice a small, politician-shaped hole in this proposal. If analysts see their job as helping others make a decision quickly, doesn’t this push them to be advocates for their opinions rather than the truth? Or, in extreme cases, wouldn’t this encourage analysts to omit results that complicate a decision?

I disagree with the premise of the first objection. Data teams aren’t faceless filing cabinets of static facts; analysts *should *have an opinion. While that opinion should trace its genesis to a different origin than those of other people—we rarely have a horse in the race, and we have to form our ideas on data rather than direct experience—that doesn’t it them any less of an opinion. 

To an executive, feigned analytical neutrality isn’t fair; it’s frustrating. Analysts have explored territory others haven’t; expeditions through data show us things others don’t seen. We develop gut feelings through these efforts, feelings that are more often rooted in real things we can’t quite describe than the meaningless psychic wanderings of our entrails. Withholding our opinions buries these feelings, conceding—incorrectly, I believe—that the only evidence that matters in making a decision is that which we can articulate with a chart. 

Moreover, no matter how hard we try, [we can never be truly neutral](https://benn.substack.com/p/tilt-and-tilted). Our analysis will always be colored by small biases. In the earlier example about Tokyo and London, for instance, we may have initially favored Tokyo. Regardless of the reason—sales in Asia have always been higher; we liked the Olympics; we hated *The Crown*—this bias likely makes us more skeptical of results that lean toward London. Without even noticing we’re doing it, we might dig into those conclusions more, present them with more qualifications, and accept results that favor Tokyo with less diligence. We’re better off acknowledging our opinion than pretending that it doesn’t exist. 

As for the second concern, it’s true that analysts, if incentivized to get people to make decisions quickly, might present misleading results and omit confounding information. But—so what?

To play out the different scenarios, suppose the marketing team came to me and asked me to recommend if they should spend more money on events or Facebook ads. My immediate preference is for Facebook.[^3] What if, rather than giving both options a balanced look, I just told the part of the story that makes the case for Facebook ads. I omitted promising evidence in favor of spending the money on events, and dressed up the case for Facebook as best I could.

In one world, the marketing team comes away unconvinced. They sense my tilt, start asking a lot of questions about events, and send me back to redo the work. This slows down the time to a decision, scoring my analysis as poor. Moreover, the hill is steeper next time, because the marketing team would start to look at my work with more skepticism or suspicion.

In a second scenario, I do a better job of presenting my case, and the team is convinced. In this case, the Facebook ads pan out; it’s money well spent. Though it’s tempting to tar this as a bad outcome, it led to a good decision that was made quickly. Is a slower path to the same destination really better? If someone consistently gives me good advice, I don’t care if it comes from rigorous analysis or from [Miss Cleo](https://en.wikipedia.org/wiki/Miss_Cleo); I just want the advice.

In the final scenario, I convince the team but my recommendation doesn’t work. The ads are a bust. When we try to understand what happened, people would either find the things I omitted or catch me with my finger on the scale. In either case, my reputation takes a hit. The next time the marketing team asks me for help—if they ask at all—I’ll get grilled.

That points to the final value of the speed metric: To whatever extent it creates bad incentives in the short term, it counteracts them by creating the right incentives over the longer term. If I want people to make a decision quickly tomorrow, I might be dishonest; if I want them to make fast decisions next year, I can only risk politicking for my opinion when I’m very confident it’s the right one. Which I’d argue is actually the correct behavior: If you know the right path forward, do whatever it takes—cheat, lie, it doesn’t matter—to convince me to take it.  

This reputational dimension also provides a useful nudge for analysts wondering where they can take their careers next. The second fastest way for us to influence a decision is for people to take our recommendations on their face, no questions asked. But the fastest way to drive a decision is to make it yourself. That, I think, is how analysts go from being advisors to executives: Build such a reputation for making convincing arguments that people simply hand the decision off to you.[^4] 

And that journey starts with a simple step: Ignore all the ambiguity around measuring analytical quality and ROI, and do whatever it takes to make others more decisive. 

# An aside about my writing process

People periodically ask me where these posts come from. Am I working through a big backlog of rants that I’ve collected over the last ten years? Or do I write them in a frenzied panic every Thursday, with no idea what I’m going to talk about next week?

The answer is a bit of both—ten years in any industry will make you salty and opinionated, but those opinions are messy, and I don’t have editorial plan from week to week. The eureka moment for most posts comes from reading things other people wrote, or having conversations with people in the industry. Those moments [provide the spark](https://benn.substack.com/p/the-calendar-takes-its-tax) by organizing loose ideas that are banging around in my head into something much more coherent. In that way, most of my posts are less original songs and more mixtapes of other people’s ideas, recut with too many words, too many analogies, and too many decades-old (or, in today’s case, [centuries-old](https://en.wikipedia.org/wiki/Hamlet)) cultural references. 

This post is a particularly extreme example of this sort of plagiarism. Last Friday, I had a very interesting conversation with [Boris Jabes](https://twitter.com/borisjabes), the founder and CEO of [Census](https://www.getcensus.com/),[^5] about today’s topic. Unlike other posts, which often contain short samples from a variety of conversations, this one was ripped from a single track. If you liked it, give most of the credit to Boris.


---


[^1]: Several weeks ago, the Braves and Brewers were playing in the first round of the MLB playoffs. In the eighth inning of Game 4, the score was tied and the Braves were coming up to hit. The Brewers sent out pitcher [Josh Hader](https://www.baseball-reference.com/players/h/haderjo01.shtml), their hard-throwing closer who strikes out nearly half the batters he faces and is one of the best lefties in the game. Hader came into the game in part to face Freddie Freeman, the reigning NL MVP. Freeman, a left-handed hitter, puts up [huge numbers](https://www.baseball-reference.com/players/split.fcgi?id=freemfr01&year=Career&t=b) against right-handers and is a slightly better-than-average hitter against lefties. [It didn’t work out for the Brewers.](https://www.youtube.com/watch?v=RJ7ZGRLjUe0) Freeman hit a home run; three outs later, the Braves won the game, won the series, and sent the Brewers home. Still, despite the catastrophic result, few people would say that the Brewers’ decision to put in Hader was wrong. Sometimes, good decisions just don’t pan out. And therein lies the problem. How, if not by its result, do we determine the decision was good?

[^2]: Optimistically, we do this because it’s truthful. The world is complex, and the “potential relationships” that “suggest” a “marginal effect” for the “particular subsets” of the population “with reliable data” reflect that. More cynically, we do this because sharing everything we know provides us with cover, leaving it up to the reader to navigate that complexity. But in neither case do these details help make a decision.

[^3]: Because, obviously, it’s full of [so much spontaneous fun](https://twitter.com/AnandWrites/status/1454524600105177098). Plug me into your totally human matrix, Mark.

[^4]: If a bartender recommends a stock, I’d want to hear a lot more about it before buying it. If Warren Buffett recommends a stock, I’d hand him my money and tell him to do whatever he wants with it.

[^5]: I’ve included this link to save you from having to figure out what to Google to find a data company named Census (it’s a great product, by the way).

================================================================================

# Does data make us cowards?

*The thin line between being analytical and being afraid.*

---

![](https://substackcdn.com/image/fetch/$s_!dKBO!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc351f96d-7573-40e4-b6c6-6a1d8dc4cc50_1280x720.jpeg)

*Let's talk about a hard decision:* Choosing a movie on Netflix. You and your roommates are looking for something to watch on a Friday night. After burning an hour watching trailers and wading through page after page of aggressively early holiday rom-coms and remastered director's cuts of *The Guns of Navarone*, you find two movies that everyone likes. The data is promising: Netflix says they're both popular; Rotten Tomatoes says they're both good. With half the room preferring one and the other half preferring the other, you check how long both of them are. Would you rather for both to be a reasonable length, or—truly; be honest—one of them to be way too long?

*Let's talk about a hard decision:* Planning a product roadmap. You're running a company that serves two audiences, and it’s pulling your product in opposite directions.[^1] You know you can't split the difference; you have to commit to one path. Three months of analysis show that each option is promising. Your company's leadership is divided on what's best. You hire a consulting firm to conduct their own research on the two markets you could potentially serve. Do you want the study to say that both options are extremely promising, or—truly; be honest—hope that it says one is good and the other is bad?

*Let's talk about a hard decision:* Settling on a pricing model. Your company is launching a new product, and you're responsible for deciding how to price it. You and the data team have been working for weeks trying to figure out the different implications of various options. The results are stubbornly inconclusive. No model is clearly better than the others. You're pretty sure a handful of proposals are equally good, though each has its own tradeoffs and internal advocates on the executive team. You've got a week left before the decision is due. Do you go ahead and pick one, or—truly; be honest—do you keep plugging away in hopes of finding some small new detail that finally breaks the tie?

*Let's talk about a hard decision:* Picking a restaurant. It's Monday night, and you're planning a surprise dinner for several out-of-town friends. They’re visiting from Barcelona, and, like [anyone who’s been to Barcelona](https://www.youtube.com/watch?v=jHfaxI5GxUo), love to remind you that they’ve been to Barcelona. Determined to show them that San Jose is a cool city too, you find two places that are well-reviewed on Yelp. One was Michelin-reviewed and is known for their scallops and ambiance; the other was a top pick in *The Infatuation *and serves cocktails in tiny top hats. Unable to decide, you check OpenTable. Do you want both to be available, or—truly; be honest—hope that only one is?

*Let's talk about a hard decision:* An internal promotion. You run a growing team full of star performers, and need to promote one of them to help lead it. You know two people, both of whom you've worked with for years, would make great managers. Both deserve the opportunity, and both want the job. To remove any appearance of bias, you decide to interview them, with the help of several other department heads. After the interviews, you convene the panel to get their feedback. Do you want them to confirm that both candidates are outstanding options, or—truly; be honest—do you hope that one candidate stumbled and there’s now a clear favorite?

*Let's talk about a hard decision:* Figuring out your holiday plans.[^2] A pandemic is finally ending. You haven’t seen your extended family, who lives in a different state, in two years. But neither has your significant other, and their family lives in a third state. You check plane ticket prices; you ask who else will be in town; you see how each potential trip affects your other travel obligations; you ask how you'll take care of pets and house plants. In asking these questions, do you want to make sure both trips are possible so that you can make the best decision, or—truly; be honest—are you looking for something to make the choice easier?

# Data-driven courage

Personally,[^3] professionally,[^4] and financially,[^5] I’m deeply invested in the value of data and the analysis of that data. Data, I truly believe, captures complex and abstract realities about the worlds around us that we wouldn’t be able to detect otherwise. Analysis makes us better equipped to react to and understand those realities. We should, in the shorthand of our time, listen to data and believe science.

But often, we turn to data for reasons other than education. In some instances, data is a [rhetorical club and dishonest cover](https://benn.substack.com/p/tilt-and-tilted), “a weapon for prosecuting your point, and a defense for protecting yourself as reasonable and impartial.” While this sort of lying isn’t always easy to see, there are at least [lots](https://twitter.com/GraphCrimes) [of](https://twitter.com/Chart_Crime) [people](https://twitter.com/ChartCrime) [looking](https://twitter.com/ChartCrimesPD) [for](https://twitter.com/ChartCrimes) [it](https://twitter.com/BadChart).

Decision makers, from CEOs to the person on the couch with the remote, also use data to serve a more subtle purpose: As a substitute for courage. In these cases, we don’t use data to lie to others; we use it to lie to ourselves. 

In all of the hard decisions above, the concluding piece of analysis wasn’t commissioned to find some novel insight, or to avoid a bad choice. It was a lifeboat, an escape from the [paradox of choice](https://en.wikipedia.org/wiki/The_Paradox_of_Choice), meant to carry us away from a tough decision. In each scenario, we’re looking for something to tilt the scales in something’s—anything’s—favor. Our analysis isn’t meant to take on the problem; it’s meant to dodge it. 

As an analyst turned executive (turned [disgruntled blogger](https://www.google.com/search?q=old+man+yells+at+cloud&tbm=isch&ved=2ahUKEwirj9Lrp4_0AhUIn3IEHScmD9IQ2-cCegQIABAA&oq=old+man+yells+at+cloud&gs_lcp=CgNpbWcQAzIICAAQgAQQsQMyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6BwgjEO8DECc6BggAEAcQHlDMDVjpJGDyJWgBcAB4AIABb4gBuguSAQQxNi4xmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=YIaMYavfOIi-ytMPp8y8kA0)[^6]), I relate to this temptation. In countless instances, leaders are asked to break ties in high-stakes decisions for which the analysis is inconclusive and other people’s opinions are split. Owning that decision is hard. You have to tell people that they won’t get their way and you’re the reason why. And if the decision doesn’t work out, you have to own that result too. 

Data offers an incredible out. If some bit of analysis can make the choice appear obvious, you can tell people who disagree with you that the decision wasn’t yours, not *really*—you were just listening to the data; your hands were tied; you want to be data-driven, right? Later, if the decision works out, you can claim credit for your cleverness. If it doesn’t, you can say you just did what any reasonable person would’ve done.

Analysis like this, that’s chasing a conclusive result for its own sake, is a cover for surreptitiously handing decisions over to chance. It’s an abdication of responsibility, motivated not by data or principled reasoning, but by fear. We do this when we’re afraid to commit to a choice, or when we [don’t want to admit to the option we’d prefer.](https://www.youtube.com/watch?v=9HKuO1JOYAA)

It’s also tempting because, frankly, you can usually get away with it. But it’s ineffective leadership. Leaders aren’t promoted or elected because they’re better at running cost-benefit analyses than everyone else. They’re in charge because they don’t shirk from their responsibilities when that calculus is inconclusive.[^7] They’re in power not to be calculators, but to be courageous.

# Making the leap

When people go fishing for courage, analysts can get caught in the crossfire, asked to be unwitting quantitative therapists for indecisive leaders. We can only do so much to resist this, though keeping an eye on[ how long it takes to make a decision](https://benn.substack.com/p/method-for-measuring-analytical-work) can at least make us more mindful of when it's happening. 

Still, these moments are instructive, not in what they teach us the jobs we have today, but in what they reveal about the jobs we could have tomorrow.  

Despite my [apparent](https://benn.substack.com/p/who-is-the-community) [inclinations](https://benn.substack.com/p/big-whiff) [to](https://benn.substack.com/p/third-rail) [the](https://benn.substack.com/p/tilt-and-tilted) [contrary](https://benn.substack.com/p/does-data-make-us-cowards), I'm long on analysts and their career prospects. They’re generally nimble and crisp thinkers;[^8] they’re comfortable [zooming in and out](https://roundup.getdbt.com/p/analytics-is-a-profession) in their work, moving from tactical problems to abstract strategy; they work across different business units, giving them a wide perspective on how companies work. These are good attributes to have on executive teams, in boardrooms, and walking through legislative halls.

But, we often have one fatal flaw: We hide in our data. To whatever extent that today’s executives are willing—even unknowingly—to dodge hard decisions with data, analysts would surely be worse. 

It's not exactly our fault—it's what we're trained to do. We're taught to turn ambiguous problems into mathematical models; we’re encouraged to be rigorous and objective; we’re told to be unrelenting in our pursuit of the unknown; and we're prompted when we do these things well. It's easy to assume, in a paraphrased version of the [Peter principle](https://en.wikipedia.org/wiki/Peter_principle), that this is what we should keep doing, all the way to the top.

For better or for worse, it's not. Not every problem is quantifiable; not every choice will have a clear consensus; not every decision can be data-driven. Sometimes, the most we can say is, “We don’t know, and we’re not going to know.” When that happens, someone still has to make a call—and they need to own that call, and its consequences, as their own. 

For some of us, that’s [deeply discomforting](https://twitter.com/imightbemary/status/1456720231263453187). That’s ok—presidents need advisors who don’t carry the same weight that they do. Those advisors, however, have to recognize that in some moments, their advice—their numbers and their charts—isn't what’s needed. 

In those moments, when the path ahead is foggy and people’s opinions are divided, it doesn't matter how smart we are if we're at the head of the table. When the room turns to us, they aren’t looking for a final insight to nudge one option ahead of the other. They need to know our opinion. They need to see our conviction. They need us to be courageous. 

Without that courage, we’re just clever puppets, dancing to whatever tune our data sings to us, hoping nobody sees the wires we’re submitting to. To be real leaders, we have to [prove ourselves brave enough](https://www.youtube.com/watch?v=cBTwgUwf76A&t=72s) to know when to walk on our own.

# On the discourse

Last week's post on [measuring analytical work](https://benn.substack.com/p/method-for-measuring-analytical-work) started some fights. First, fair. Second, being too-long winded for Twitter (and Slack, but that's a different rant for a different day), I wanted to give a proper response to those who objected.[^9] 

Though the details differed, nearly every objection took issue with focusing on speed “without qualification or caveat.” This approach, the arguments go, is [simplistic](https://twitter.com/raschneiderman/status/1457333918886203395) and [dangerous](https://twitter.com/imrobertyi/status/1458114964875464706). Analysis is complex, and we need [multidimensional](https://twitter.com/josephmoon_ai/status/1458125297815986181) [frameworks](https://twitter.com/sbalnojan/status/1458738308889075712) for assessing it. 

On one level, sure; analysis *is* complex, and there will always be exceptions to general rules. But, as far as guiding principles go, most analysts don’t need to be reminded to be more cautious. Our bias (as this week’s main piece argues) usually runs in the other direction. If, as an industry, we find ourselves barreling through warning signs—or outright misleading people for the sake of lowering a “time to decision” metric—I’d absolutely agree that this approach is misguided. But in our current context, in which we’re much more inclined to “well ackshually” a proposal than blindly agree to it, qualified descriptions of success only encourage that tendency. That—both in our analysis and in posts like last week’s—is exactly the problem with nuance: More than clarifying a precise point, nuance often muddies the idea, and gives people room to interpret it through whatever lens they find most comfortable. Given the choice between recommending that analysts focus on speed, full stop, and recommending they use a carefully balanced framework of competing and caveated measures, I enthusiastically choose the former. 

Beyond that general objection, I’d group people’s challenges to the post into three buckets:

*The [rubber stamp objection](https://twitter.com/dataklump/status/1456683170930307082): People have already made a decision, and it’s a bad one. They just want your analysis to prove them right. If we optimize for speed, we become sycophants. *

This is a valid concern, especially on the margins. If we know what someone wants to do, we might be less inclined to take a serious look at the other alternatives. To correct for it, it’s worth adding an addendum to the original principle: Start [by convincing yourself](https://twitter.com/borisjabes/status/1456762983669895172) of what’s right, and then convince other people as quickly as you can. 

*The [one-way door objection](https://roundup.getdbt.com/p/decision-speed-and-one-way-doors): We need to get big, irreversible decisions right. In these cases, speed is a bad metric. *

This is true, though as both Tristan and [Sven Balnojan](https://www.getrevue.co/profile/svenbalnojan/issues/meltanolabs-analyst-success-federated-computational-governance-thdpth-45-842208?via=twitter-card-webview) say, we tend to treat a lot of two-way doors as one-way doors. (We do this, I think, because going back through the door might require another hard decision. A risky hire, for example, is a two-way door that emotionally feels like a one-way door.) 

Even for true two-way doors, however, I don’t think it’s bad for *analysts* to still optimize for speed. The *decision maker* shouldn’t necessarily do that; their bar for what it takes to be convinced should be higher. But analysts should still be racing to get over that bar.

*The [ROI objection](https://twitter.com/prukalpa/status/1458847543891140614): One big decision that takes a long time can be way more valuable than a bunch of small decisions that are made quickly. This is related to the [“it’s just wrong” objection](https://twitter.com/imrobertyi/status/1458103839584776195): Analysts aren’t good because they’re fast; they’re good if they understand the problem and inform the decision.*

Both of these things are also true, though I think they misrepresent the original argument (or, more likely, the original argument misrepresented what was in my head). The point isn’t for analysts to make decisions quickly in an absolute sense; it’s to help people make decisions quickly given the decisions that need to be made. Implicit in [Kobe’s regime of making 2,000 shots a day](https://www.esquire.com/sports/a40090/kobe-bryant-mike-sager/) was that the shots are real, not dropped from a ladder above the rim. Similarly, implicit in any measure of analytical success is that we continue to work on real problems, and that we don’t game the principle by declining to take on anything that might slow us down.


---


[^1]: Based on a [true story](https://benn.substack.com/p/gerrymandering).

[^2]: Based on a true story. Either way, I promise I’ll be home for Christmas.

[^3]: I’ve been tracking some “quantified self” nonsense in two spreadsheets for more than 900 straight days.

[^4]: I have a weekly blog for yelling about data.

[^5]: [www.mode.com](http://www.mode.com)

[^6]: Launching soon, www.bennthoughts.gov.www\bennthoughts.

[^7]: “Building consensus” follows a similar pattern. In the face of difficult decisions, some leaders act as though their job is to convince everyone to get on board. While alignment is useful, consensus can also be a stand in for courage. It’s a way to share the burden of the decision, and to deflect blame—“this faction objected, so I couldn’t do it.” This, too, is wrong. Leaders are in charge to make decisions in the absence of consensus. Declining to do so is conflating what you can do with what you can comfortably do.

[^8]: Of course, we all have [our emotional lapses](https://benn.substack.com/p/open-the-window).

[^9]: I really appreciate all the comments. If you’re here for a real conversation, consider this an invitation to continue it. And if you read this and are like, “I just wanted to shitpost, we’re all talking about Taylor’s re-release of *Red*, move on already,” all good too, no hard feelings, you can stop reading, looking forward to the next one.

================================================================================

# The missing analytics executive

*We should redefine the role of the chief data officer. For our companies, for our careers, and for ourselves. *

---

![](https://substackcdn.com/image/fetch/$s_!l1ol!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9e56d3a-5561-4fb1-9b0f-5a34cb83ae56_916x611.webp)
*[Washington Post](https://www.washingtonpost.com/outlook/valerie-jarretts-winding-path-to-the-obamas-inner-circle/2019/04/11/acab2512-4595-11e9-8aab-95b8d80a1e4f_story.html)*

There’s a treadmill at the mountain top.

Among the data leaders I know, many of their stories are the same. After rising up the ranks of their organizations, from junior analysts and data scientists, through positions as team leads and managers, and eventually to directors and VPs, their data careers stalled. Somewhere between senior management and the executive team, they found themselves caught at sea, adrift between the land they loved and the aspirational new world they left it for. 

The shoreline behind them—the ones many of us leave, in the name of career advancement—are those of our intellectual homeland: The [creative work](https://benn.substack.com/p/analytics-is-a-mess) that attracted many of us to the data industry in the first place. By making the leap into management, we gave up data’s puzzles and problems to lead teams, set OKRs, and manage vendor contracts;[^1] we gave up giving in to curiosity; we gave up, in a more subtle sense, the work that makes many of us *us.*[^2] We traded them away for pay and prestige, and for a sense of professional progress.[^3] 

Our aspirational destination is a position of senior leadership. It’s in the CEO’s inner circle, in board meetings, in the [room where it happens](https://www.youtube.com/watch?v=WySzEXKUSZw). It’s where strategic decisions get made, and where we aren’t handling requests from other teams, but making them. It’s where, as the cliché goes, we have an impact.

Most people never make it. Companies rarely have data leaders that sit among those at the top of the org chart. Analysts are typically told to drop anchor just offshore, one step below the c-suite, buried underneath some other function and some other executive. 

In the rare cases where there is a chief data or analytics officer,[^4] the role is underwhelming. CDOs and chief analytics officers, unlike chief revenue, financial, marketing, and technology officers, are often second-class operational roles. They deal in [risk management and tooling governance](https://www.gartner.com/smarterwithgartner/understanding-the-chief-data-officer-role), and are more secretarial than strategic. Without the gravity of a large organization underneath them, these data executives play bit parts, pushed to the back of the board deck and relegated to the always-too-high G&A budget, an administrative asterisk next to the departments that are seen as making real products or real money.

Always stuck one door away from the inner sanctum, many of the data leaders I know bounced from company to company, looking for new ways in. But each time, they were trapped under the same mandate: Hire a team; rehabilitate broken data infrastructure; build a data culture. Across a range of company profiles—from enterprises “reinventing themselves” to tiny rocket ships, at companies growing quickly to companies imploding, with leaders eager for data and those skeptical of it—the outlines were the same, and the doors locked in the same place. The terminal point of an analyst’s career, it seems, is the data leader treadmill, hopping between different VP roles, always running but never moving forward.

Once in this loop, some people—a third of the ones I know, I’d guess—have stuck with it. The lucky ones do it out of a genuine love for management and a passion for helping others grow. Others are simply waiting it out, hoping, either through an official promotion or an informal advisorship,[^5] to get invited into the company’s highest echelon of leaders.

But most people didn’t last. Bored of the job and frustrated by its stubborn ceiling, a few returned to the ranks of individual contributors, surrendering their status and stock options for day-to-day satisfaction and [progressively weirder job titles](https://www.tiktok.com/@legitimatehermit/video/7031243364246867205). 

However, the overall majority of these data leaders—or, I should say, former data leaders—jumped ship entirely. Some transitioned into other executive functions, like marketing or finance, that still had room to grow. Others left for adjacent industries, most often venture capital. And many started their own companies, deciding that the only way to get a seat at the table was for them to create their own. 

There’s a small tragedy in this. Of all the things we’ve figured out as an industry—the [tools to build](https://continual.ai/post/the-modern-data-stack-ecosystem-fall-2021-edition), the [experience to create](https://benn.substack.com/p/the-modern-data-experience), the [functions to fill](https://jasnonaz.medium.com/analytics-engineering-everywhere-d56f363da625), the [pitches](https://www.bloomberg.com/news/articles/2021-09-20/andreessen-backed-fivetran-valued-at-5-6-billion-following-deal) [to](https://techcrunch.com/2021/09/15/matillion-raises-150m-at-a-1-5b-valuation-for-its-low-code-approach-to-integrating-disparate-data-sources/) [raise](https://venturebeat.com/2021/06/30/dbt-labs-raises-150m-to-help-analysts-transform-data-in-the-warehouse/) [astronomical](https://www.cnn.com/2020/09/16/investing/snowflake-ipo/index.html) [amounts](https://techcrunch.com/2021/09/28/sisu-data-raises-62m/) [of](https://www.forbes.com/sites/frederickdaso/2021/11/17/hightouch-raises-40m-at-a-450m-valuation-to-democratize-reverse-etl-for-all-business-teams/?sh=48059276560a) [cash](https://techcrunch.com/2021/06/24/firebolt-raises-127m-more-for-its-new-approach-to-cheaper-and-more-efficient-big-data-analytics/)—we haven’t figured out how to keep many of our best people. And without them, the persistent fight for influence will only be harder. 

# The executive analyst

The lack of analytical leadership on the executive team isn’t just a problem for analysts, however; it’s also a problem for the executive team. 

At their best, analysts are curious investigators, observing the problems around them and proactively looking for opportunities and solutions. Their value scales with what they can see: We can’t solve problems we don’t know about.

But there are no analysts in the rooms with the widest and most strategic views. Board meetings rarely have analytical observers, and there is no official designation for “senior data advisors” to the executive team. Nobody is directly responsible for helping a company make its most important decisions, or for exploring its uncharted strategic opportunities. There is no role committed to this work, and no title that acknowledges its value.

These jobs are instead done haphazardly. Sometimes, VPs of data do it, periodically LARPing as individual contributors.[^6] But they rarely have time to do this work, and never have time to do it well. Other times, requests are handed down to senior individual contributors, who lack the context that’s needed to do anything more than narrowly answer questions as they’re asked. And most often, strategic exploratory work isn’t done at all. It simply falls through the cracks, too opaque and sensitive for people outside of management, and [too creative and time-consuming](https://benn.substack.com/p/the-calendar-takes-its-tax) for people in management.

# A better chief analytics officer

A similar problem exists in technical organizations. Engineering leaders have to oversee both teams and technology, and those who are good at one aren’t necessarily good at the other. Companies solved this problem by splitting the role in two. 

Traditionally,[^7] the VP of engineering sits at the top of the engineering org chart, and is responsible for the day-to-day operations of the team. They hire managers, manage directors, and direct the machine that builds the company’s technology.

The CTO, by contrast, is shaped like an individual contributor. They don’t typically manage large teams (or, in some cases, any team at all). Instead, they’re “[an architect, a thinker, a researcher, a tester and a tinkerer.](https://avc.com/2011/10/vp-engineering-vs-cto/)” Their job is to evaluate the organization’s most important technical decisions and to push its technological frontier outward. They derive their authority from expertise and influence, not an official reporting structure. 

Despite the apparent discrepancies in title (CTO *sounds* higher than VP) and responsibilities (leading a department *sounds* more important than tinkering), the two roles are peers. Both are senior executives, and both often report to the CEO. The division of labor is a recognition not of hierarchy, but that there’s enough important labor in engineering that it needs to be divided: One role to manage, and one to advise. 

Data departments should follow the same pattern. Rather than being led by a single [ambiguously defined and overburdened CDO](https://hbr.org/2020/02/are-you-asking-too-much-of-your-chief-data-officer), data teams should have two representatives in senior management: A VP of data responsible for managing the team’s daily operations, and a chief analytics officer.[^8] 

Much like a CTO, a chief analytics officer would be charged with working on their company’s most important and far-reaching problems, but without the management responsibilities (or organizational authority) of a department head. In exchange for their wide latitude and generous leash, they’d be expected to deliver impact commensurate with that of a CTO. 

In some cases, this could be bold strategic research that uncovers a new market opportunity or an ambitious new model for forecasting future hiring needs. In other cases, it could be more superficially mundane—finally reporting on revenue correctly, say—but no less important. 

To see how this is different from our current approach, consider a senior analyst who sees that the sales team is struggling to sell to a particular market segment. In response, they could build a new model for recommending which prospects in that segment are worth pursuing and which ones aren’t. This would be, by today’s standards, a good result.

An experienced chief analytics officer could respond differently. They know, from a recent board meeting, of the strategic importance of that market segment. The leadership team decided that the best way to improve its presence there is through key partnerships with several adjacent companies. The chief analyst suggests evaluating acquisitions as well, and creates a series of analyses to assess different options.

This latter work requires not only [analytical craftsmanship](https://raydata.co/analytics-crafting-a-way-forward/), but also the ability to size markets, model sales dynamics, diagnose product metrics, and read financial statements. In a problem as multifaceted as an acquisition—especially if you have to generate the idea, not just respond to it—reasoning from first principles isn’t nearly enough. You need to have [seen some things](https://www.youtube.com/watch?v=QefqJ7YhbWQ&t=116s). 

Moreover, this example highlights another advantage executive analysts have that others don’t: They have access to privileged material. In extreme cases—acquisitions, financings, layoffs—information is carefully guarded. These problems, however, are in no less need of analysis than others; in fact, the fewer people in the know, the more important the issue probably is. 

The same applies to more routine problems. [As Bobby Pinero argues](https://wraptext.equals.app/the-curious-analyst/), the best analysis often comes from curious analysts piecing together ideas from the conversations they overhear. By sitting in strategic meetings, even as little more than an observer, chief analytics officers have access to the company’s most valuable conversations—and can connect its most valuable dots.

# A better career

For data leaders who want to be operational executives, this split lets them focus on [making decisions](https://benn.substack.com/p/does-data-make-us-cowards) and frees them from the uncomfortable burden of periodically being asked to be the board’s query mechanic. And for those who are good analysts but bad managers, this role is both cake they can have and cake they can eat. The promise of a chief analytics officer is the path for advancing their careers (and compensation) without having [Peter principle](https://en.wikipedia.org/wiki/Peter_principle) themselves into middle management oblivion. 

More broadly, the role acknowledges the importance of analytical work. It says great problem solvers, alongside operational leaders and great technologists, have a role on the executive team. If official advisory roles like these [work for the president](https://en.wikipedia.org/wiki/Senior_Advisor_to_the_President_of_the_United_States)—if it’s valuable to have people in the Oval Office who aren’t elected leaders or cabinet secretaries running large organizations—surely they could work for CEOs as well. 

Finally, this redefined chief analyst offers a way to step off the data leader treadmill without walking away from data entirely. Rather than having to chase impact and influence in other departments, great analysts can climb all the way to top by working on what they’re good at—and, usually, what they love to do. 

Of course, such a role wouldn’t be without its perils. Chief analysts could develop the same organizational pathologies as bad CTOs who operate as ungovernable mad scientists, ignoring processes, working in their own sandboxes, and refusing to play nicely with anyone else on the team. But this problem doesn’t prevent us from hiring CTOs, and shouldn’t prevent us from hiring chief analysts. 

In a less severe version of this problem, a chief analytics officer could also block other analysts’ access to meaningful work. I think this is a real risk, especially if they become the pet analyst of the CEO. But this isn’t insurmountable either. Chief analysts should proactively source much of their own work, adding strategic projects to the queue rather than plucking the best ones from the top of an existing list. Nor should they be loners. On projects for which it’s appropriate, they should recruit other analysts for help, with both working together in the trenches to solve a company’s most important problems. And just as engineering architects can operate as junior CTOs, senior analysts could forge a path to becoming chief analytics officers through parallel roles.  

The biggest obstacle, however, is probably organizational. [How many cooks](https://www.youtube.com/watch?v=JwSNbG8acrM) can we add to the executive kitchen?

It’s a fair question, but the alternative—analytical games of telephone, missed opportunities, and stalled careers—is surely worse. Adding a quiet observer to the executive team is a small price to pay for consistently putting the full force of the company’s best analysts behind its most pressing problems. 

There is, I admit, some irony in this proposal. During my time at Mode, I’ve had about a dozen jobs, including being a blogger, a PM, a support agent, and various stints running the data, marketing, product, solutions, and executive teams. The only consistent thing has been my title: *chief analytics officer.*

I tell myself that my eight-year rotational program is simply the life of a founder. But that may not be true. My spasms through Mode’s org chart may actually be a reflection of the general anxieties of those in the data industry who are searching for the right ambition for their careers. What I’ve been looking for, it turns out, [may have been here the whole time](https://www.youtube.com/watch?v=VuNIsY6JdUw). I just needed to [rewrite it to make it my own](https://www.youtube.com/watch?v=vwp8Ur6tO-8).


---


[^1]: So many [vendor contracts](https://benn.substack.com/p/data-and-the-almighty-dollar).

[^2]: For reasons I don’t entirely understand, analysts who move into management seem to give up some of their identity as an analyst. Design VPs, for example, still identify strongly as designers, simply in a new role. Data executives, by contrast, appear to lose that identity with each promotion.

[^3]: There’s a deeper disease here, endemic everywhere but especially potent in Silicon Valley, where we worry more about how fast we’re rising and less about where we’re going, much less if we actually want to get there. I have a much (much) longer rant on this that that I’ll publish someday.

[^4]: Or, heinously, a [chief data ](https://www.cio.com/article/3234884/what-is-a-chief-data-officer.html#:~:text=NewVantage%20Partners%20says%20in%202020%20many%20firms%20have%20adopted%20this%20combination%20of%20chief%20data%20and%20chief%20analytics%20functions%20into%20a%20single%20chief%20data%20and%20analytics%20officer%20(CDAO)%20role.)*[and ](https://www.cio.com/article/3234884/what-is-a-chief-data-officer.html#:~:text=NewVantage%20Partners%20says%20in%202020%20many%20firms%20have%20adopted%20this%20combination%20of%20chief%20data%20and%20chief%20analytics%20functions%20into%20a%20single%20chief%20data%20and%20analytics%20officer%20(CDAO)%20role.)*[analytics officer](https://www.cio.com/article/3234884/what-is-a-chief-data-officer.html#:~:text=NewVantage%20Partners%20says%20in%202020%20many%20firms%20have%20adopted%20this%20combination%20of%20chief%20data%20and%20chief%20analytics%20functions%20into%20a%20single%20chief%20data%20and%20analytics%20officer%20(CDAO)%20role.). I can only interpret this grotesque suggestion, from *CIO* magazine, as an act of war by one back office executive against another. Game on, nerds.

[^5]: And often without compensation.

[^6]: Many data executives are years removed from their days as analysts or data scientists. Speaking from experience, you rust.

[^7]: I.e., according to the blogs of [prominent](https://bothsidesofthetable.com/want-to-know-the-difference-between-a-cto-and-a-vp-engineering-4fc3750c596b) [VCs](https://avc.com/2011/10/vp-engineering-vs-cto/).

[^8]: And the term CDO should be relegated to its proper place as an acronym for the financial dynamite that took down the entire global economy in 2008. But [Lehman’s heart wanted what it wanted](https://www.youtube.com/watch?v=Pxr_FzpPM2Q), I guess.

================================================================================

# Lies, damned lies, and coffee cake

*This be madness, and there is not method in't.*

---

![](https://substackcdn.com/image/fetch/$s_!cG7v!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8b1b969a-53ca-4738-8647-4214d5416869_1600x1066.png)

> *“The only sensible way to live in this world is without rules.”*
> – The Joker, immediately before trying to burn down all of Gotham

I was 27 when I learned that there’s no coffee in coffee cake. It was a shocking discovery for everyone involved. I was shocked that such a plain and obvious name could be so misleading, and looked as though I’d just learned that there were no apples in apple pie. Everyone else was shocked that I could've possibly believed coffee cake would contain real coffee, and looked as though I told them cakes were made with Pennzoil. 

Years later, I now concede that I was incorrect—coffee cake does not, in fact, contain coffee. But I believe I was fooled by a cruel and dangerous deception. If, in the coming years and decades, we’re going to torch the earth, abandon civil democracy, and plug everyone into Mark Zuckerberg’s *Sims* funhouse, the least we can do for future generations is right this egregious grammatical wrong. 

My argument is simple: It’s called coffee cake. 

Blueberry jam? Full of blueberries. Maple syrup? From maple trees. Mustard? Made with mustard seeds. Eggs Benedict? Eggs. Potato salad? Mostly potatoes. Espresso martini? Vodka, Kahula, and espresso. I could do this forever.

Coffee cake, I’m told, is a reasonable exception because you eat coffee cake *with* coffee—suggesting, I suppose, that potato salad is a salad eaten with potatoes, or espresso martinis are regular martinis for [chasing your morning coffee](https://imgur.com/cPy7Zdr), or maple syrup is a sugary topping for trees. Foods are frequently named this way, they say. And in any case, coffee cake doesn’t taste anything like coffee.

First, sure, coffee cake may not taste like [320 grams of Finca Alcatraz brewed through a Hario V60-02 dripper](https://sightglasscoffee.com/brewing-guides/v60). But *my* coffee—a [Dunkin' Donuts brown sugar cinnamon latte](https://www.youtube.com/watch?v=LBO1WoDC2_c)—sure tastes a lot like cake. And even if coffee cake doesn't taste like coffee, so what? Olive oil doesn't taste like olives. Almond extract doesn't taste like almonds. Strawberry Kiwi Capri Sun doesn't taste like strawberries ([contains real juice!](https://www.walmart.com/ip/Capri-Sun-Strawberry-Kiwi-Flavored-Juice-Drink-Blend-30-6-fl-oz-Pouches/21096716)). When contemplating the ingredients of coffee cake, what are we to believe, the fickle, COVID-ridden perceptions of our taste buds, disoriented by the preceding meal, forced to search for a few ounces of coffee baked into layers of dough and sugar and cinnamon, like an amateur sommelier guessing the vintage of a Burgundy burned off in a [coq au vin](https://en.wikipedia.org/wiki/Coq_au_vin)? Or the word, right there in the name? 

Second, as for foods named after ingredients—let’s check the data. There are [267 types of cakes](https://en.wikipedia.org/wiki/List_of_cakes) listed on Wikipedia. Ninty of them are named after something that could conceivably be baked into a cake, like banana, or rock, or Queen Elizabeth. If we assume that cakes contain actual food—so, we're not chopping up plastic funnels for funnel cake, or baking [cakes full of kings](https://www.youtube.com/watch?v=T1HUAWaxMX8)—we're left with 62 cakes named after potential ingredients.

Of these 62,** **only 8 are missing the ingredient in their name. One is coffee cake. Five are named after animals, which, thankfully, they don't contain: Butterfly cake, caterpillar cake, frog cake, goose breast cake, and hummingbird cake. 

The remaining two, teacake and Madeira cake, are the only cakes—out of 267—that follow the coffee cake “rule.” But even these two cakes are confusing exceptions. Another type of tea cake, [tea ](https://en.wikipedia.org/wiki/Tea_loaf)*[loaf](https://en.wikipedia.org/wiki/Tea_loaf)*, does contain tea. And while Madeira cakes doesn't have Madeira, [wine cake](https://en.wikipedia.org/wiki/Wine_cake) has wine. 

Among the 54 cakes that *are* named after what's in them? Rum cake. Avocado cake. Orange and polenta cake. Beer cake. Cucumber cake. Brazil nut cake. Applesauce cake. Hash brownies (although, Wikipedia, are brownies a cake?). Onion cake. Coffee and walnut cake, which is made with walnuts *and coffee*. But coffee cake, without the walnuts? Only a fool would believe it has coffee.

![](https://substackcdn.com/image/fetch/$s_!dE5q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fba9d48d2-3535-4ffc-8c67-2b977701ad36_1176x1476.jpeg)
*A cake chart, I guess?*

Finally, to the people who say coffee cake should be named after coffee because you eat it with coffee, I mostly eat cake with ice cream. So by that logic, we should call cake “ice cream cake”...but we can't, because there's already an ice cream cake. And it has ice cream in it.

We can fix this. For the sake of those trying to learn this impossible language, who are already confused by endless exceptions and inconsistencies and can't bear another I-before-E-except-after-C-but-never-coffee “rule;” for the sake of parents, wanting nothing more to see their child grow up healthy and well, unnecessarily protect their children from coffee cake, thinking it will save them from a premature caffeine dependence but instead only deprives them of new flavors and experiences and deepens their eventual confusion about what on earth coffee cake is anyway; for the sake long-haul truckers, who, looking for a caffeine pick-me-up without having a drink that will force them into another bathroom break, eat a piece of coffee cake but get nothing more than a cheap sugar high that quickly fades on the dark open road, miles from the next rest stop; for the sake of all of us, it's time to end this nonsense. It's time to call it what it is: coffree cake.

================================================================================

# Data is for dashboards

*Animating an abstract world is hard, valuable, and worthy of celebration.*

---

![](https://substackcdn.com/image/fetch/$s_!y-5c!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe20652d4-17a3-4952-977a-c608c1517398_900x704.jpeg)
*The perfect crime.*

The [county I grew up in](https://email.mg1.substack.com/c/eJwlUEFuwyAQfI05WgsY4xw4VJHaW7-AMGwcWhssWDfy70sSaaXR7M5qNOMd4ZLLaQgrsT1XsnTuaBI-6opEWNhRsdgYDAsGtPB6ZrHaW0HcXFwN2495jd5RzOmpElJNE7ubGzjwNz2PYVCSc_RBCDd5iQCjCArfXu4IEZNHg39YzpyQreZOtNdOfnTisw2m_hF_444huj6Xpa2evMGXq9Q8r_lIdHbiar9zobu9upLXmByLRoDgXIDkCkANvejHGaQHrfTkRyUvuuejp58oVTfAtvC-HnMl5397nzdWzIwpNZ58XJtgeeZ9XVpk23A7UqTTYnLzisFQOZDRu8hXN3bBhKUVHKwjw0c5qUGOSnGt3-lbXcNwAQA5sGYdcvtKL9d_Dk6JiA) is known for three things: [Fred Durst](https://email.mg1.substack.com/c/eJwlUMuKwzAM_Jr6GPx2evBhofQ3jB9K6m3iBFvZkr9ftwXBIGnEaCZ6hHmrp0VoSPatocNzB1vg1RZAhEqOBtXlZEmy1PBoAsnNTRVg9XmxZD_CkqPHvJU3iws1juRhxzBJL7iWRk9SM0NVCDFdJ2kAjEn-q-WPlKFEsPAH9dwKkMU-EPd2ET8Xfu8FZXjlZ94hZT9sde6jd9_hXiG521H739lyyhnjVDBFqZIDH3SgIlKjzBi1ElczMB3xNwt1kXSd2dCO0NDH5xC3lVQboJTel5iXTpjf1j6b7s51XI-S8XRQfFggWawHEPxm9onBzVCg9iyT82iZFqOSQivFjPka7clIeaWUCkm6dNr6Vfmo_gMtM4GW), serving as the inspiration for *Talladega Nights: The Ballad of Ricky Bobby*,[^1] and being the home of several people who [stole $17 million](https://email.mg1.substack.com/c/eJwlUduupCAQ_JrhDcNV9IGH87K_YRB6lF0HjLTHzN9vO5MAXaSrL6mKAWGpx9sjNGR7bTjhewdf4GobIMLBzgbHlJNnyQunoptZbtPzAHiFvHm2n_OWY8Bcy81S2g4DW33oxzSOM0igG9yoemVcsCJASkE_h--scKYMJYKHXzjetQDb_Iq4t4f-eag_dK7r6q7Q1lwWrOUu6mJ9USIccc2_QGivW8YcG0E5jiMFoW480IMrcFwztW_8WiuP9dxSQYo78CvjyqXjr7xttD7Rn0oM_aAkN0YFbqIzPEQXuO2VTSCjcUYQjWWvhJJSCS2tENZ0qutnoaNw1g2xt3p0newj_s3aPox4LbJr59wwxH_3-uzwM5RC_xLzRoTl1vKTITkniq-zZHxPUMK8QfJ4nMDwa9JH92mBAgeZl6aAXvZ6sEb31krnvsqSFcaMQghtGI1OlarKZ-p_XaGkFQ) from Loomis Fargo in 1997. 

The Loomis Fargo heist—which Hollywood also turned into an [unflattering portrait](https://www.youtube.com/watch?v=zIkzuXDhCcQ) of Gaston County[^2]—was one of the largest and most absurd bank robberies in American history. One of the suspects, David Ghantt, was identified nearly immediately: He worked for Loomis Fargo, disappeared right after the money was stolen, and was caught on video loading "cubes of cash" into a van for over an hour.[^3] Needless to say, he got caught. 

The other perpetrators would’ve been harder to find, but within three weeks of the robbery, they moved from a mobile home into a $600,000 house in a gated community [twenty minutes from the scene of the crime](https://www.google.com/maps/dir/Loomis+Armored+US,+Stafford+Drive,+Charlotte,+NC/Cramer+Mountain,+Cramerton,+NC+28032/@35.2488518,-81.0394399,13z/data=!3m1!4b1!4m14!4m13!1m5!1m1!1s0x8856a26ff4cc6381:0x277af9a67e88f746!2m2!1d-80.9310253!2d35.2379478!1m5!1m1!1s0x885695ffa70aefc1:0x1f5ff1bb481abe49!2m2!1d-81.0781312!2d35.2345838!3e0). They also made a number of large purchases, in cash, of, among other things, a BMW Z3, a velvet Elvis painting, and a statue of a dog dressed like General Patton. One of the final straws came from a tip from a bank teller [who alerted the FBI](https://www.washingtonpost.com/archive/politics/1999/02/18/the-thieves-who-couldnt-cope-with-17-million/f2086821-442a-4c74-ac7a-5625de1c4740/) that a woman showed up with a suitcase full of $200,000 bundled in Loomis Fargo wrappers, and asked, "How much can I deposit without the bank reporting the transaction?" 

As ridiculous as the story is, its outline is similar to numerous other cases of fraud: People try to present one story, and small inconsistencies (or half-million dollar homes) put cracks in that reality. Elizabeth Holmes was a wildly successful and transformative CEO—until [John Carryrou became suspicious](https://www.businessinsider.com/john-carreyrou-theranos-2018-5) of her “comically vague” description of Theranos’ technology in a *[New Yorker](https://www.newyorker.com/magazine/2014/12/15/blood-simpler)*[ profile](https://www.newyorker.com/magazine/2014/12/15/blood-simpler). A few years laters, Theranos collapsed in scandal. Robert Hanssen was a senior FBI agent—until a [counterintelligence officer read a transcript](https://en.wikipedia.org/wiki/Robert_Hanssen#:~:text=fbi%20agent%20michael%20waguespack%20felt%20the%20voice%20was%20familiar%2C%20but%20could%20not%20remember%20who%20it%20was.%20rifling%20through%20the%20rest%20of%20the%20files%2C%20they%20found%20notes%20of%20the%20mole%20using%20a%20quote%20from%20general%20george%20s.%20patton%20about%20%22the%20purple-pissing%20japanese.%22) of a conversation between an American mole and a KGB agent, and realized that the mole used the same General Patton quotes that Hanssen did.[^4] A few years later, Hanssen was convicted of being a Russian spy.

When we want to make people believe that something is real, details matter. Inconsistencies in those details, from offhand remarks halfway through a six-thousand word profile in the *New Yorker *to a [limo ride to a Western Steer buffet](https://www.washingtonpost.com/archive/politics/1999/02/18/the-thieves-who-couldnt-cope-with-17-million/f2086821-442a-4c74-ac7a-5625de1c4740/#:~:text=he%20was%20along%20when%20chambers%20hired%20a%20chauffeured%20limousine%20to%20ferry%20the%20group%20to%20dinner%20at%20the%20modest%20western%20steer%20in%20nearby%20gastonia.), do more than just raise questions about what seems out of place. They raise questions about everything. 

# "Data is for decisions"

Ask ten analysts a question, and you’ll get eleven opinions—unless your question is about dashboards. On dashboards, the consensus is universal: They’re bad. Dashboards are [outdated](https://towardsdatascience.com/dashboards-are-dead-b9f12eeb2ad2), [brittle](https://twitter.com/EmilyGorcenski/status/1397065798762569730), [poorly built](https://docs.getdbt.com/blog/design-for-analytics-towards-analytical-applications), and [rarely used](https://twitter.com/sethrosen/status/1407019976469397514). Even our defenses of dashboards [are lukewarm](https://counting.substack.com/p/the-utility-of-an-unwatched-dashboard).

We all know how analysts and data scientists talk about dashboards: People who ask for them are analytical Philistines; businesses that show them off are a primitive company’s idea of a sophisticated company. Enlightened data teams shouldn’t be dashboard factories; they [should help people make better decisions.](https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/) Data is for understanding which market to expand into, what to charge for a new product, how to [model stock trades](https://www.bloomberg.com/news/articles/2015-02-20/high-frequency-trader-virtu-extends-nearly-unblemished-streak) that always make money, or [where to put a new headquarters](https://www.nytimes.com/2018/01/18/technology/amazon-finalists-headquarters.html). And dashboards are a distraction from this much more important work. 

I’ve said [lots](https://benn.substack.com/p/big-whiff) [of](https://benn.substack.com/p/the-future-of-operational-analytics) [things](https://mode.com/blog/dont-choose-dashboards/) like this before, and, strictly speaking, I don’t think they’re wrong. But I’ve come to realize that this reflexive dismissal of dashboards—and more generally, the discounting of old-school “reporting”—undersells something that we need data for that’s even more foundational than helping us make decisions: Data and the dashboards that display it create a shared sense of reality. 

Unlike you and I, companies don't exist in the physical world. When we walk down the street, we can see what's in front us, we can feel the sidewalk underneath us, and we can hear the cars driving past us. If we have to decide if it’s safe to cross the road, the data that goes into that decision—the speed of the traffic, the width of the street, and so on—are measures of that physical world, and generally not controversial. If I choose to cross and you choose to wait, the difference is explained by our analysis of the situation, not because we disagree about the presence of a passing bus. 

For companies, there is no physical street. There is no actual bus. These things only exist as abstractions. Data and metrics—revenues, retention rates, product usage patterns—don’t measure a company’s world; they *are* its world. 

Take ARR, for instance. Though ARR is related to the amount of money in a physical bank account, ARR is a construct.[^5] The code that says that ARR is the sum of the amount field on the Salesforce contract object, that overage fees are excluded, that contracts from partners are included, and that ARR is recognized on the date a contract starts rather than when it closes isn’t measuring ARR; it *is* ARR. If that code changes, our understanding of ARR itself changes. 

In other words, the Salesforce calculations or dbt models that encode an ARR metric are [accounting identities](https://en.wikipedia.org/wiki/Accounting_identity): They are true by definition. The code is the concept, and the concept is the code. 

In this way, companies don’t live in a physical world, but in a virtual one, like those in Pixar movies. The landscape around a company is artificial, and exists only as a rendered representation of the calculations that define it. And to make decisions in that world, you have to create it first.

For example, suppose a company is trying to decide which product to build next. They want to make a good choice; metaphorically, they want to safely cross the street. To do this, they’d first define the street by setting a goal, such as increasing product adoption. Next, they identify what represents the traffic, or the various factors that might be obstacles to their goal, like product NPS, customer churn rates, and measures of development cost. Finally, in order to [assess their path to the other side of the road](https://www.youtube.com/watch?v=v6vnEvRNa54), they then have to render this world by turning data into metrics. But like *Toy Story*, none of this is real; it’s an interpretation of numbers and a representation of code. If we define market share differently, we change the road under our feet. If we compute churn with a different formula, we could [conjure an oncoming bus out of thin air](https://www.youtube.com/watch?v=VZpMlm4xYG4). 

If this happens, is there really a bus? We can’t actually say, no more than we can say what the true color of a car is in a Pixar movie. If it’s white in half the scenes and black in the other half, all we can do is reconcile the differences in the code that defines it. But until that happens, neither is more true than the other.

You could make the argument that the true color of the car is what’s in the script—or, analogously, the true value of a metric is the GAAP-approved definition of it. But what do we do when the script doesn’t specify the color, and it’s up to the animator writing the code to choose? Most metrics work this way too. Like a car, “daily active users,” for example, has a generally understood shape, but the details often left to those who actually create it.

As data professionals, *this* is our first job—to be reliable animators for our companies.

# The corporate metaverse

For better or for worse, dashboards are the best tool we have for this. Every dashboard is a window into a Pixar scene, and every metric is a rendering of it. Strategic analysis, for all of its necessary benefits, is more like a magnifying glass: It’s great for uncovering detail and texture, but to get our bearings—to safely cross the road—we also need a wider lens. 

A broader view alone, however, isn’t enough. That view also needs to be consistent, across people and time. If a bus is flickering in and out of existence in the distance, or I see a bus and you don’t, nobody will be confident enough to step into the street. 

This is why questions like “Why doesn't this dashboard match what I see in Google Analytics?" are both irritating and pernicious.[^6] Looking at two dashboards that don’t match is like looking out two adjacent windows and not seeing the same thing. Even small or seemingly insignificant discrepancies—one dashboard says 107,102 people visited the homepage this month, and another says 106,988; the car down the street looks white outside of one window and black outside of another—do more than make us suspicious of a small, out-of-place detail. They’re [glitches in the Matrix](https://www.youtube.com/watch?v=z_KmNZNT5xw), or [hosts off their loops](https://www.youtube.com/watch?v=qkr-pj7HiqY): They make us [question the nature of our reality](https://www.youtube.com/watch?v=CCWvuOzjCzM). And for companies, with no physical world to fall back on, the reality that data teams create is the only one they have. 

In this light, defining metrics and creating dashboards isn’t banal busywork that [gets in the way of “the more rewarding aspects”](https://info.looker.com/looker-201/looker-a-modern-data-science-workflow) of analysts’ jobs. It’s one of the most important things that we do. And as an industry, rather than casting dashboarding aside is a necessary evil, we should recognize and celebrate its importance, just as we do for strategic analysis. 

The good news is we already have a model for how to do this: analytics engineering.

At its core, analytics engineering should be a mundane role. Analytics engineers spend most of their time tediously [maintaining data and managing code](https://www.getdbt.com/what-is-analytics-engineering/), filling an unglamorous gap between the work [engineers don’t want to do](https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/) and the work [analysts do want to do](https://towardsdatascience.com/why-so-many-data-scientists-are-leaving-their-jobs-a1f0329d7ea4). Just as we belittle building dashboards, analytics engineering could easily be tarred as a dull prerequisite to a more interesting job.

And yet, it’s gone in the opposite direction. Rather than running away from analytics engineering, people are [eagerly signing up for it](https://twitter.com/clairebcarroll/status/1465487642724683780). 

Why? The attraction, I think, comes from how much the community values the work. Instead of toiling away in the data stack’s lonely salt mines, analytics engineers—largely through the dbt community—can congregate, celebrate, and commiserate together. They can proudly share their accomplishments, and joke about their frustrations. By creating a home and identity for analytics engineers, dbt and its community leaders created a career for analytics engineers.

As data scientists and analysts keen on breaking away from the BI developer roles of yesteryear, we take a lot of shots at dashboards. We [implore people](https://mode.com/blog/dont-choose-dashboards/) to make their jobs about something more. We disparage building dashboards as being beneath us.

It’s not. Building consistent dashboards is hard.[^7] Creating a reliable rendering of a company’s world is enormously valuable. The only thing it’s not is cool.

We should make it cool. We should embrace our responsibility to create dashboards just as we’ve embraced analytics engineering. We should praise those who are good at it, give those people credit for the impact they have, and encourage them to take pride in doing it well. Because bad dashboards, just like the bad data that analytics engineers valiantly fix, [break stuff](https://www.youtube.com/watch?v=ZpUYjpKg9KY).


---


[^1]: I played soccer and Little League [at the elementary school](https://www.google.com/maps/@35.2108135,-81.0840328,3a,75y,114.09h,85.59t/data=!3m6!1e1!3m4!1sYtB7M0kCROh1LrlOtthtkw!2e0!7i16384!8i8192) where [this scene](https://youtu.be/S6YsAlYr5AU?t=94) was shot.

[^2]: Which itself was turned into the [most incredible engagement photos](https://nicoleadelephotography.com/jandice-david-a-purly-epic-engagement/) I’ve ever seen.

[^3]: To hide the robbery, Ghantt removed the tapes from two security cameras. Unfortunately for him, he left the tapes in...[sixteen other cameras](https://www.washingtonpost.com/archive/politics/1999/02/18/the-thieves-who-couldnt-cope-with-17-million/f2086821-442a-4c74-ac7a-5625de1c4740/).

[^4]: If you commit a crime, avoid anything to do with General Patton, apparently.

[^5]: And yes, I get that money is all code now, and it too is just an abstract concept on a Wells Fargo-leased server in an AWS data center somewhere. But whatever, if you want to talk about that, I’m sure there’s some crypto Telegram channel full of bored ape avatars that’ll gladly tell you that U.S. dollars are just a construct too.

[^6]: Substack, [what’s up?](https://twitter.com/bennstancil/status/1403003254489993217)

[^7]: To create a consistent reality with dashboards, you have to do a lot more than skim a couple Tufte books. You have to be disciplined: The more dashboards and metrics we build, the more opportunities we have to create inconsistent views. You have to be stern: If people ask for a new metric, even as a one-off request to “pull the numbers,” we are better off directing them to one that already exists. You have to be organized: Good metrics are built on smartly architected data models in dbt (and hopefully, clean definitions in soon-to-be [metrics layers](https://benn.substack.com/p/metrics-layer)). And you have to be communicative: Some apparent inconsistencies—like differences in [revenue, bookings, and billings](https://saasmetrics.co/bookings-vs-revenues-vs-billings/)—aren’t glitches, but [feel like they are](https://www.buzzfeed.com/natalyalobanova/living-simulation-matrix-funny-interesting-pictures-proof). We have to keep people confident in what they’re seeing, despite these quantitative illusions.

================================================================================

# Delirium

*We talk a lot about what data can borrow from software engineering. But on the biggest issue of all, the technology industry has a lot to learn from the analytics community. *

---

![](https://substackcdn.com/image/fetch/$s_!S_0C!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6a6b346b-6d90-473d-ab3b-f9a29ebab70b_1000x662.jpeg)

It took a marching band to wake us up.

The last job I had before moving to Silicon Valley was at a think tank in Washington, D.C. In that job, I wore Jos.A.Bank BOGO khakis, my office was a windowless closet that I shared with two other colleagues and boxes of spare printer paper, and the biggest perk was that we could pick at the leftovers after the occasional catered event. 

In 2012, I found myself in a job in San Francisco—and in an office on another planet. We wore whatever we wanted; we got two meals a day plus an afternoon snack; some days, the snack cart was followed by a liquor wagon. The office was full of nerf guns, video games, beer pong tables, and drugs. Every Friday was a party; every party was a bacchanal.

I was immediately hooked. The Kool-Aid was spiked, and I couldn’t get enough. 

For me—white, male, unattached, and down to get a drink—it worked, socially and professionally. (And it’s scary, frankly, how quickly it worked.) But for the female engineer who had to develop in a codebase full of sexist ASCII art; for the junior sales rep who was told by a senior account executive that they should play the next game of beer pong topless; for the black manager who was asked to pose for every corporate photo shoot; for the recovering alcoholic who was invited to yet another team happy hour, it was somewhere between uncomfortable and dangerous. 

At our company, the fever started to break after an annual holiday party that featured Cirque du Soleil performers, a full New Orleans marching band, two top-shelf whiskey bars, and multiple incidents of men cornering and harassing other employees’ dates. Within a few years, the [reckoning came](https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber) for the rest of the industry.

Despite the gradual improvements, I’ve never been able to escape the feeling that the raucous toxicity of the early 2010s wasn’t a phase, but endemic to the modern tech industry. The cultural aspirations of today’s tech companies are noble enough—reject hierarchies, energize stale office cultures, solve bold problems, pay people well for their efforts. The problem is that the recipe for achieving those goals cooks up a lot of problems as well. 

Tech companies market themselves to ambitious high achievers, attracting the sorts of people born to good school districts, tutored to good test scores, and connected to good jobs—and who believe they earned it, on their own, every step of the way. They’re built on technical jobs that are incomprehensible to outsiders, giving those on the inside an easy out for dismissing criticism. They celebrate technical brilliance, encouraging people to reject seeing others as people, and to see them as [employees to program](https://techcrunch.com/2015/01/01/everyone-in-management-is-a-programmer/), or [attributes to put “on chain.”](https://twitter.com/gregisenberg/status/1456590282124840963) And their patron saints—Steve Jobs, Jeff Bezos, Larry Ellison, Travis Kalanick, Elon Musk—are famously callous, megalomaniacal, and irreverent. 

In the best case, this insulates the industry from its faults. Without more diverse members among their ranks, the tech elite affirm to one another that everything is as it should be. In the worst case, it creates a culture where people are blind to the difference between right and wrong, and routinely step—or [launch themselves out of cannon](https://www.nytimes.com/2017/02/22/technology/uber-workplace-culture.html)—over the line. 

Which is a shame. The tech industry is one of profound possibility and promise, in the products it could build and the careers it could create. But it can also be a poison. And I’ve never been convinced that, given the soil from which the industry has grown, you can have the former without the latter. 

When we started Mode, we did it with two goals in mind: To build a hugely successful company, and to do it in a way that didn’t spread the same poison. Early investors, however, were interested in more tactical questions. What’s your wedge? How big is your market? Where will you find analysts to market your product to? Are there places they hang out that we could infiltrate? No, we’d say to the last question, but perhaps we could build one. 

In Mode’s early years, we took a couple disorganized swings at building that community. For a variety of reasons, they didn't work. Eventually, with products to build, customers to support, and targets to hit, we moved on. 

Several years later, the team at dbt Labs, *née* Fishtown Analytics, succeeded where we failed. They brought together a community of what’s now more than 20,000 members [in a Slack](https://www.getdbt.com/community/join-the-community) that’s become the center of the analytical universe, a constant hive of conversation about data tooling, teams, and memes. If someone in the data industry reaches out to me, more often than not, it starts as a DM in the dbt Slack.

The Slack is more than a gathering spot, though; it’s a culture. It’s a place of untiring enthusiasm, relentless support, and a lot of emojis. And though my experience as a white man established in my career may not be representative of everyone else’s, it’s a place that also appears to do a remarkable job of including anyone who wants to be a member. 

This cultural energy reaches its crescendo during [Coalesce](https://coalesce.getdbt.com/), dbt Labs’ annual conference. The conference ostensibly takes place over a number of live-streamed talks, but its beating heart is on Slack. Every talk inspires a tidal wave of excitement, encouragement, and general good cheer. Every channel is the parents’ section at track meet: Ready to erupt when their kid crosses the finish line, and equally ready to hop the fence and pick them up if they fall. 

Like the roar of a triumphant crowd, it's impossible to take in every individual voice. It’s only digestible as a vibe, as a delirious rave of celebration and sincere pride, as wild as any tech party I’ve been to, but fueled by a different drug. 

That vibe, if I’m honest, isn’t for me. I'm a grouch, and [grouches live in trash cans](https://www.youtube.com/watch?v=rxgWHzMvXOY). I’m more Eeyore than Tigger, the parent in the empty section of the stands, taking unnecessary notes on every small misstep, more critic than cheerleader. The [purple people](https://blog.getdbt.com/we-the-purple-people/) I most associate with aren’t [floppy goofballs](https://en.wikipedia.org/wiki/Purple_People_Eater_(film)) with infectious smiles and indomitable hearts, but the purple minions, who, in four Facebook stickers, capture my full emotional range.

![](https://substackcdn.com/image/fetch/$s_!sslJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F19b4e920-9389-45dd-a7e0-836c642d92b3_2710x906.png)

I like my lawn, and I prefer people to get off it. 

At this point, with this year’s Coalesce wrapping up early this morning, I’m probably supposed to say that I’ve changed. That the persistent decency of the community softened me. That my small heart [grew three sizes that day](https://www.youtube.com/watch?v=fGSs33DQ1F0), that the true meaning of community came through, and that I found the delight of ten Christmas morning Scrooges, plus two.[^1]

I didn’t. I’m just as ornery as before. I still hate emojis, and would rather die [than “woo.”](https://www.youtube.com/watch?v=QOXUog0mwMg)  But if Coalesce didn’t fix my heart, it gave me hope for the industry’s soul.

The analytics community is, if not concentric with the tech industry, directly adjacent to it. Tech companies are the biggest employers of its members. Analytics is as demographically homogeneous as the larger tech industry. And analysts are just as inclined as software developers to [wrongly turn emotional problems into empirical ones](https://benn.substack.com/p/does-data-make-us-cowards). The analytics community could’ve easily fermented into another toxic backwater, poisoned with everything from juvenile boorishness to dangerous misogyny.

But it didn’t. Though it’s [far from perfect](https://benn.substack.com/p/who-is-the-community), it blossomed into something better, healthier, and safer. Among all the characters in the community—the jesters, the cheerleaders, the philosophers and deep thinkers, the educators, the entertainers, the eager learners—one is conspicuously missing: the arrogant jerks.[^2] And that makes all the difference.

Was it saved by the decency of its leaders and early members? [By its distance](https://en.wikipedia.org/wiki/Fishtown,_Philadelphia) from Silicon Valley? By its close connection to the [R community](https://blog.revolutionanalytics.com/2017/06/r-community.html)? I don’t know. But it beat the odds, and we should all be grateful that it did. 

The story, though, goes well beyond those in data. The analytics community’s success is proof that, even if software eats the world, software *culture* doesn’t have to. It’s proof that the good things about the tech industry—the ambition, the impact, the financial opportunity—aren’t the causes of the bad. It’s proof we can throw out most of the bathwater, and keep the baby.[^3]

Given how much the data industry tries to learn from software engineering, maybe it’s time to go the other direction. Maybe it’s time for community leaders to push outward, into the tech industry and into its newer adjacencies, and to start teaching rather than learning. There are a lot of dark spots in tech, and [what a light, my lord, is needed to conquer so mighty a darkness](https://books.google.com/books?id=NT4PtLcsQY0C&pg=PA94&lpg=PA94&dq=%22what+a+light+my+lord+is+needed+to+conquer+so+mighty+a+darkness%22&source=bl&ots=69u--bcDlN&sig=ACfU3U0q-gEdcB29Mxk8R4FgfRG3LTYDQQ&hl=en&sa=X&ved=2ahUKEwiZitzH8tj0AhVwIzQIHV2YDTEQ6AF6BAgEEAM#v=onepage&q=%22what%20a%20light%20my%20lord%20is%20needed%20to%20conquer%20so%20mighty%20a%20darkness%22&f=false). But the best in this community have that brilliance. It’s time others get to see it.

Prior to my talk at Coalesce, Winnie from dbt Labs proposed a plan: 

The gang could take me, they said. The team—the community—could break me of my fighting spirit. They could win me over, convert me, make me hopeful, turn me into a believer. 

Though it may not always look like it—my spot is off to the side, [heckling from the balcony](https://en.wikipedia.org/wiki/Statler_and_Waldorf)—you and the gang already did, Winnie. You and the gang already did. 


---


[^1]: I know that I’m mixing my Christmas characters here. But after being (type)cast as Scrooge in a seventh grade play, I’ve always felt like more a Scrooge than a Grinch.

[^2]: [Maybe](https://www.youtube.com/watch?v=hZZwW10yTsc).

[^3]: It also points to the flaw in arguments [like these](https://twitter.com/dwr/status/1468300434376777729). The problem with crypto isn’t its primitives. The problem is the people it attracts. The tendency to convince yourself that you’re disliked for what you do, instead of how you do it, is exactly the sort of fiction that gives you permission to dismiss your critics, and to avoid the uncomfortable possibility that maybe they see something in you that you don’t.

================================================================================

# Fwd: Exec KPIs - Daily 

*in board call and revenue looks off, pls advise asap *

---

![](https://substackcdn.com/image/fetch/$s_!QZ8-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7b0f8968-0a4f-450d-b359-5acf08dad245_1024x768.jpeg)

The dashboard worked, but it didn’t *work*.

Somewhere, in the twisted labyrinth of its aging diesel engine, my friend’s forty-year-old Land Cruiser sprung a leak. The jeep would irregularly lose oil, sometimes shedding an entire quart in just a handful of drives. Other times, its pipes held together, and it’d go weeks without losing a drop. To compensate for the problem, my friend built up a variety of habits to make the car safe to drive. Before starting it, check the dipstick. Always store a spare quart in the glove compartment. On long drives, check the oil every time you get gas. 

The warning lights on the car's dashboard—the gas meter, the check engine light, the temperature gauge—all worked as intended, and were still useful for the problems they identified. But because the car’s designers didn’t anticipate that, after 200,000 miles and nearly half a century of wear, it’d randomly eject critical fluids, there was no oil alarm. And that omission, impossible to anticipate and potentially isolated to this single jeep, made an otherwise reliable car frustrating and dangerous. 

—

The dashboard worked, but it didn’t *work*.

Somewhere, in the tangle of ETL pipelines, transformation jobs, Jinja templates, SQL queries, and visualization encodings, retention rates started to drift. The complicated process for booking renewals in Salesforce, plagued by the various details necessary to distinguish between an upsell, a multi-year renewal, and a coterminous contract addition, was inconsistently followed. To compensate for the problem, we developed a habit of spot checking every renewal, comparing KPI dashboards with sales directors’ notes to make sure everything always matched. 

The warning lights on our data stack—Fivetran alerts, dbt run failure notifications, automated anomaly detection—all worked as intended, and were useful for the problems they identified. But because the dashboard’s designers didn’t anticipate every possible quirk and edge case that would find its way into a two-year step-up upsell with tiered triggers for overages, there was no alarm for catching when the numerator on our retention rate started to double-count several renewals. And that omission, impossible to anticipate and isolated to a few opportunities, made an otherwise reliable metric wrong. 

And unlike the story about the Land Cruiser, this one ended in a crash: misreported numbers, bad decisions, and eventually, an embarrassing and painful correction. 

Every data team has war stories like these. We all know the panicked feeling when we realize that a key metric has been wrong for three straight board meetings;[^1] we’re familiar with the terror of seeing an error in a CSV that's already been sent to a customer; we go through the same internal debate of asking ourselves if that inflated number in the deck we just presented is worth correcting.[^2] 

More than anything, these are the problems—the quiet failures, the lurking mistakes, the [unknown unknowns](https://www.youtube.com/watch?v=O9MvdMqKvpU&t=14s)[^3]—that keep us up at night. They're the ticking time bombs that prevent a data team from resting easy, and the anxieties that make no subject line more triggering than “Fwd: Exec KPIs - Daily.” 

# Modern data complexity

The modern data stack, unfortunately, makes this stress worse. The simple Salesforce dashboard has been replaced by ELT jobs unloading data from Salesforce, batch loads into a warehouse, overlapping dependencies of templatized SQL queries, YAML files that define measures and metrics, and visualization parameters that configure the final dashboard. It’s a delicate balance of complex operations, each as critical as the next.[^4]

In response to this problem, we did what we do best: created a new category, and built more tools. In the last few years, data observability—the warning lights for our data infrastructure, the dashboards for our dashboards—was born, [broke out](https://www.dataliftoff.com/the-year-in-data-and-analytics-2021/), and, as is in vogue these days, [drowned](https://www.montecarlodata.com/monte-carlo-raises-series-c-brings-funding-to-101m-to-help-companies-trust-their-data/) [itself](https://www.bigeye.com/series-b/) [in](https://www.anomalo.com/post/read-our-series-a-announcement) [cash](https://www.datafold.com/series-a).[^5] 

I don’t yet share the same excitement. Observability tools solve a useful problem, but, like the Land Cruiser dashboard that ignores an oil leak, they don’t ease my paranoia about what problems could still be hidden in the engine. 

Though each product is different, observability tools generally help companies see the structure of their data pipelines, and what’s actually flowing through them. The first view is a map (or DAG, if you prefer) that draws lines from data sources to dashboards and other analytical assets. It also defines how those pipelines should be shaped—expected schemas, data types, and other structural elements. If something in this diagram finds itself out of place, we’re alerted to this structural anomaly. 

The second view monitors what’s happening in those pipes. It records when data is extracted from a source, how many records were updated, how long it took, and if anything went wrong in the process. A second category of alerts are triggered by statistical anomalies, when some data point is outside an expected bound (a user enters their age as 450 years old) or if data volumes deviate from normal ranges (including, especially, if volumes fall to zero). 

In other words, data observability tools provide two windows into a data stack: One tells you if your data pipelines are built correctly and if they *should* work, and another tells you if they actually did.[^6]

This is all well and good, and certainty catches problems we may not otherwise see. And for massive datasets feeding sensitive models, like a stream of credit card purchases that back a fraud prediction algorithm, this may be all that’s necessary. But for most of us, there’s a third category of anomaly that’s more common than a Segment event stream going haywire, more difficult to track down than a broken Fivetran pipeline, and more insidious than a flatlining dashboard: The semantic anomaly.

Semantically anomalous data is structured correctly—it has the right schema, strings are indeed strings—and is statistically uninteresting—it’s an acceptable number of records, and doesn’t include a row for a transaction of negative eighty trillion dollars—but is still wrong. It’s data that misrepresents the business concept it’s supposed to capture. It’s data that, on the trip from measurement to meaning, got lost in translation.

These anomalies happen when an account manager enters a renewal contract in Salesforce without closing out the existing contract, double-counting the customer’s revenue in a key KPI dashboard. They happen when the operations team adds a new stage in the sales process, and sales cycle lengths are still computed using the old sequence. They happen when a new product release starts logging background events on the latest version of an iPhone app, and these events lead the mobile team to gradually overstate the number of daily active users. 

These cases, and the millions of other versions just like them, create results that are just as wrong as those built on top of broken data pipelines. Unlike a broken pipeline, however, they don’t look suspicious and they trigger no warnings, in observability tools or in our manual spot checks. Instead, they often linger undetected, slowly and silently pushing the analytical assets that use them further and further from reality—until, during a board meeting, on a customer call, or in an angry midnight email from the CEO, the bomb goes off.

# Keep talking and nobody explodes

Admittedly, most observability tools aren’t trying to address this problem directly. As an individual vendor, that’s a reasonable choice. Startups have to be focused, and semantic anomalies are different in degree *and *kind than structural and statistical ones. Moreover, today’s observability companies aren’t just building status pages for the modern data stack; some are more focused on keeping logging infrastructure clean, or helping teams profile data as they’re updating it. 

Still, as a category, data observability can only go so far without addressing semantic anomalies. For people who want to know if they can trust the data they’re seeing—for people who want to know their data is reliable—the distinction between a broken pipeline and a misreported metric is irrelevant. 

So how do we defuse the bomb? We acknowledge it, we isolate it, and we talk about it.

Acknowledging the problem requires admitting what *won’t* fix it: More rule-based and statistical tests. Though it’s true that most semantic anomalies could be reduced to assertions like “this field should always have values in this range,” or “the value in this date field should always be earlier than the value in that date field,” it’s impossible to write a rule for every potential problem. Data, like an old Land Cruiser engine, can go wrong in more ways than we can enumerate. Moreover, unlike a car engine, businesses are constantly changing, and no test suite could ever keep pace.

It’s also tempting to monitor the outputs as well as the inputs, and build tests and outlier detection systems on dashboards themselves. But this doesn’t really help either; semantic anomalies are often problematic precisely because they look normal. A handful of incorrectly labeled ad conversions would easily slip through this type of test, even though misattributing this data could lead to millions of dollars being spent on the wrong marketing campaigns. 

Instead of generalized tests, we need specialized tools that directly target and isolate semantic anomalies. One version of this could focus on common sources of confusion: duplicated assets, [organizational entropy](https://twitter.com/clairebcarroll/status/1454197410645913603), and data stacks’ general states of disrepair. If we could all [prune stale data models](https://dagster.io/blog/good-eggs-3) as efficiently as Good Eggs or [dedupe metrics](https://eng.uber.com/umetric/) as reliably as Uber, we’d have a much easier time maintaining the assets we keep.[^7] 

Another, more ambitious version of this approach would aim to solve semantic problems with semantic solutions. Just as general BI tools know nothing about the meaning of the data they contain (Mode, for instance, knows if fields are numbers or strings, but has no concept of what revenue means), general observability tools have no conceptual awareness of what they’re monitoring. Tools like Amplitude, by contrast, are semantic BI tools. They can more easily figure out when something’s gone wrong in a dashboard—for example, if a user retention rate is more than 100 percent—because their dashboards understand what they represent. 

Vertical observability tools (or vertical features in existing observability tools) could follow the same principle. If we know that data comes from Salesforce and that it represents customer contracts, we can create semantic assertions like, “Can a single customer have multiple active contracts?” These sorts of tests are not only easier to maintain and understand, but they can automatically compile the various technical assumptions—the tests in general observability tools—that are implied by each assertion.

Finally—in the inevitable note about people being at the [bottom of everything](https://roundup.getdbt.com/p/he-tangata-it-is-people)—we all have to keep talking. No observability tool, from the nascent ones in the market today to some future sentient AI, is a substitute for the data team knowing what the marketing team is doing. Relying entirely on automated alerts trains us to put too much trust in something that [isn’t intended to drive entirely on its own](https://www.nytimes.com/2020/02/25/business/tesla-autopilot-ntsb.html). 

But, even in the absence of autonomous semantic observability, we could use more assisted semantic observability. While all undetected anomalies are bad, it’s the semantic ones that really sting. A failed pipeline has the feel of an inevitable outage, a [buck that can be passed](https://twitter.com/borisjabes/status/1471194962125459457), an [act of God](https://en.wikipedia.org/wiki/Act_of_God) that’s just part of life with computers. Semantic anomalies are mistakes. They’re human errors, the things we should’ve caught and didn’t. They’re the biggest bombs waiting to be dropped into our inbox, and the ones I’d pay a lot of money to disarm.


---


[^1]: And like dropped toast with jelly, they always fall in the wrong direction.

[^2]: “There were lots of numbers in the presentation, will anyone notice if we just change it, no, no way they do, plus, it’s better for the team if I don’t say anything, if I say something people won’t trust us, yeah, this is about the team, definitely, if it were just me I’d say something, of course I would, not saying something is actually *harder*, I’m being brave, for the team, it’s for the team.”

[^3]: Betcha thought you were gonna get a [Donald Rumsfeld](https://en.wikipedia.org/wiki/There_are_known_knowns) reference there but NOPE THAT’S NOT HOW WE DO IT AT BENN DOT SUBSTACK DOT COM.

[^4]: There’s another, softer effect of the complexity too: People are reflexively more skeptical of it. Rightly or wrongly, tools like Google Analytics appear more trustworthy because there are fewer visible moving parts.

[^5]: For full disclosure, I’m a small investor in Bigeye.

[^6]: Other people who think much more deeply and clearly about these sorts of things (i.e., the makers of data observability tools) [describe these categories](https://towardsdatascience.com/the-four-pillars-of-data-observability-95a96a1a24e7) in a more granular and technical way: Observability is about metrics, metadata, lineage, and logs. That works too, and bonus points for the catchy alliteration.

[^7]: Does the metrics layer solve this? Yes and no. On one hand, it narrows the problem. The fewer places metrics are represented, the fewer places they can be wrong. On the other hand, it makes the problem harder by adding more layers of abstraction between a data source and the person interpreting it.

================================================================================

# The more the merrier

*Steal this writing process, and join me on the dance floor. *

---

![](https://substackcdn.com/image/fetch/$s_!odct!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F25db01dd-d0fa-426d-a60f-78607e83e68d_600x600.jpeg)

I should start off by saying that I have no idea what I’m doing. My formal writing education started and stopped with the five-paragraph essay, a sentence-by-sentence recipe taught to North Carolina public school students for the sake of passing a [seventh grade writing test](https://webarchive.wcpss.net/results/reports/2004/0434_writing2004.pdf). Ever since that test, and the weekly essays we hand-wrote to prepare for it, I rejected the entire enterprise. I wish I could say I did it because the formula was stifling, and I refused to cram such a creative endeavor into a standardized 34-sentence box. But that’s not true. I ran away from it because I nearly failed the test. Embarrassed and frustrated, I became a “math person,” the teenage precursor to a professional “data person.”

I outran the ghost of my “needs improvement” score for fifteen years. I studied math and economics in college, in no small part because those classes didn’t require me to write papers. I took jobs that wanted me to communicate in plots rather than prose. I embraced spreadsheets, Nate Silver, and (obnoxiously) lecturing people about the need to think probabilistically.  

But in 2013, I ran out of places to hide. In the months immediately following Mode’s founding, there was no math for me to do. We had no customers, no users, no product, and no data—and I, as the person appointed to analyze it, [had no job](https://benn.substack.com/p/a-brief-programming-note). So I found myself writing [blog posts](https://mode.com/blog/all). 

The leap was less uncomfortable than I expected. In college, a rare essay meant burying myself in the library stacks, tweaking on free Folgers and creamer, and racing 3,000 words on social choice[^1] to a 9 a.m finish line. The Mode blog—and now, this Substack, and its informal Friday deadline[^2]—has required a lot less caffeine, fewer all-nighters, and has been, in the biggest surprise of all, kind of fun?

My newfound amusement in writing these pieces comes in part from wriggling free of the seventh grade straightjacket. Rather than writing to impress an underpaid and faceless assembly-line grader forced to score thousands of templated essays against a manufactured rubric created by an overpaid and faceless administrative state committee, I started doing it to entertain myself. I wrote about what I was interested in, told the stories I wanted to share, and made the jokes I thought were funny. I don’t know if 400-word detours through tangential stories about middle school or footnotes about Griff[^3] would’ve helped my score back then (though they couldn’t have hurt), but now, that’s the [good stuff that helps me forget about the messes I used to make](https://genius.com/Griff-good-stuff-lyrics).

The other nice thing about this Substack—also missing from seventh grade essays—is an audience. You can only shout into the abyss for so long, and I’m very grateful to [anyone](https://jpmonteiro.substack.com/p/a-friday-fight-and-the-internet-of) [and](https://roundup.getdbt.com/p/purple-people-the-impact-of-analysts) [everyone](https://wraptext.equals.app/who-are-analysts-technically/) [who’s](https://towardsdatascience.com/modern-data-stack-its-time-for-your-closeup-28f867cf5a81) [shouted](https://blog.getdbt.com/we-the-purple-people/) [back](https://petrjanda.substack.com/p/bring-data-analyst-to-the-table). 

My hope for 2022 is to shout with more of you. My hope is that new blogs like [Ashley Sherwood’s](https://compilerqueen.substack.com/) and [Emily Thompson’s](https://scientistemily.substack.com/) start a much bigger avalanche, for the sake of the community [finding new voices](https://benn.substack.com/p/who-is-the-community), for the sake of others finding the same unexpected satisfaction in it that I did, and, selfishly, for the sake of me having more people like Ashley and Emily to find inspiration in. 

To the folks on the edge of the dance floor—please, join us. I understand the hesitation: It’s hard to stare down a blank page; it’s hard to know what to talk about; it’s hard to imagine people will read it, much less like it; it’s hard to see yourself as someone with a blog; it’s hard to know what you’re niche is, or what to call it. 

I clearly can’t help with the [last problem](https://benn.substack.com/about). But on the others, I’ve figured out some things that work for me (to the extent that you do or don’t judge anything here as working). If you’re thinking about being part of the party, take what’s useful, discard what isn’t, and [let’s dance](https://www.youtube.com/watch?v=ipsPgNEmAXI). In the words of Nate Dogg,[^4] even if you feel like you’ve got two left feet, it’s real easy if you follow the beat. 

This is my beat. 

# TikTok, not Twitter

People tend to equate blogging to Twitter, seeing the former as an [extended version of the latter](https://twitter.com/paulg/status/1468979840166641664). To me, it’s a bad analogy. Twitter encourages a kind of pseudo-intellectual arms race, a back-and-forth dunking on one another, with everyone seemingly trying to prove they’re the smartest person on the internet. On Twitter, it pays to appear to be the most contrarian. 

TikTok, by contrast, is almost overwhelmingly derivative. The entire app is built to help creators riff on one another, react to one another, and repackage trends and challenges into new variations. Thumb through TikTok for an hour, and you’ll see the same joke told over and over again. And yet, it’s TikTok, not Twitter, that’s the [most popular website](https://qz.com/2105400/tiktok-overtook-google-as-the-most-popular-website-in-2021/) in the world.

The magic of TikTok’s medium is that it’s built around stories, not takes. It’s emotional, not intellectual. It celebrates people for their trademark individually, not for how smart they are. We don’t doomscroll on TikTok; we just scroll.

I think blogging should be the same. Rather than chase new ideas, or feel the pressure to make everything original, I try to accept that everything’s already been said.[^5] Old stories, told from a new perspective (i.e., with new [analogies](https://benn.substack.com/p/in-defense-of-analogies)), can still find an audience. 

The good news is coming up with things to say gets easier as you go. Posts begat conversations, conversations begat ideas, and ideas begat posts. In this sense, blogs become self-sustaining, with each post planting the seeds for the next one.[^6] 

# Bullets kill

Once I have an idea, it is with [great regret and self-loathing](https://www.reddit.com/r/ProgrammerHumor/comments/59h5d2/slack_developer_takes_web_socket_error_personally/) that I have to agree with [The Writing Guy™](https://twitter.com/david_perell/status/1445390288621539342)[^7]: I write as much about it as I can, as quickly as I can. I don’t think of this as a first draft, but an opening conversation. 

However, unlike what’s suggested by “Pixel method,” my version of this phase is more appropriately described as, to borrow the language of Silicon Valley, the [rubber duck method](https://en.wikipedia.org/wiki/Rubber_duck_debugging). The goal isn’t to position a bunch of sentences to be refined later; it’s to wander through an idea, and see where it takes me. I approach it as though I’ve been asked a question and I have to not only answer it out loud, in full sentences, but I also have to [filibuster for ten minutes](https://www.youtube.com/watch?v=j1tkwdfz7n4) when doing it. 

This isn’t an entirely [original idea either](https://twitter.com/david_perell/status/1455313434996789257), though I think “write to someone else” is an insufficient bit of advice. The point isn’t to narrow your audience, or to talk to one person; the point is to be conversational and to skip the literary preamble. It’s to imagine someone asking me, “What’s your opinion on Taylor Swift?” over dinner, and I’m answering the question without worrying about organizing ideas coherently or coming up with a clever opening line.

Critically, I write this in full paragraphs and not bullets. No bullets; never bullets. Bullets cut ideas short. They let me glance at something and convince myself I’ve seen it, while staying comfortably on my original path through a topic. But the most interesting things are off the trail, viewed carefully and up close.

Bullets also frame the exercise as drafting an outline. At this stage of the process, outlines are deadly. I don’t want to worry about structure; I don’t want to think about narrative threads; I don’t want to trace the lines to color in later. Quite the opposite: I often don’t even know what I’m drawing yet.

To help with this, I typically dictate this “conversation” in a code editor like Sublime instead of Word or Google Docs. This isn’t about avoiding the distractions of the internet—I still constantly command-tab to Chrome, no Slack, no Spotify, no Chrome, no Slack, no Chrome, no Slack, no Chrome, no Slack, no Chrome, no Slack, no Spotify, no…TikTok?, no, fine, back to the text editor. Instead, I use Sublime to avoid the need for polish. I don’t want to correct misspelled words or fix grammatical errors, nor do I want to worry about formatting. I just want ideas on paper. 

This phase is often fast, just as an actual conversation would be. I usually do it in one or two sittings, each taking less than half an hour. For this post, [I did this](https://gist.github.com/bstancil/033be1caaf50975a1d863daa65e2288e) in about twenty minutes, and produced a fairly typical collection of messy, rambling ideas. 

# Like it twice

My next step is to walk away. I don’t want to get the topic out of my head—once the mental trains are moving, they’re hard to stop anyway—but reset the narrative. Inevitably, in the course of shotgunning ideas at a page, some structure starts to take shape. Usually, it’s a bad one, ill-considered and half-formed. Away from the paper, I try to find better narrative studs. What story can I hang the main idea off of? Could something make a good hook? Are there any analogies or turns of phrase I particularly like?

I usually bounce through a few iterations, and try to find a structure I like twice—when I first think of it, and again, later, after the thrill of its novelty wears off. Once I have something I like (or, more realistically, can tolerate), I return to the original doc, and type a shallow outline at the top. 

I use bullets, usually fifteen or so, each about a sentence long. At this stage, I want to lay out the major points of the plot—say this, then this, then this. Bullets keep me from getting lost in the wording. But it’s still not a proper outline, with sections and headers and multiple levels of indentation. 

It’s also not a summary of the ideas I wrote down in the first phase. That collection is just a that—a collection to draw from, a grab bag, an unordered list. They’re ingredients, and the bullets—like [these](https://gist.github.com/bstancil/4ed8b94e54a2f5899e6b959507888690), created for this post—begin to sketch out a recipe based on the good ones.

# A slowly building panic

Next, [the real work starts](https://twitter.com/Ray_Sturm/status/1063885093859553280). 

Using the bulleted list as a thin storyboard, I try to write a first draft. I draw from the knot of ideas I first wrote, though I never copy from it directly. Those ideas were written without knowing where the story was going; by typing them again, I can rework the details that hold the plot together. 

This is also the point I start to apply some polish (and therefore, when I copy everything into a Google Doc). I’ll linger on sentences and syntactic choices, sometimes finding things I like, and sometimes settling on something that’s good enough to hold the idea and advance the story. 

As I’m doing this, I work the doc into four loose sections. The actual draft is at the top, slowly building down from the narrative outline. That outline sits below it, and all of the original notes below that. I delete bullets and ideas, sentence by sentence, from the middle two sections as they’re incorporated; over time, those sections shrink as the draft grows. And ideas or phrases that I like but can’t find a place for are added to a list—the fourth section—at the bottom. 

I suspect this is all weirdly pedantic, but I’ve found it helps [keep my station clean](https://www.pbs.org/food/features/cleanliness-is-next-to-impossible/) through the messiest and hardest stage of the writing process. Because if a post falls apart (read: if I fall apart), this is when it happens. This transition is when you find out if the design of the post’s bones will hold the weight of its body—and often, it doesn’t. You find a point that needs to get made twice in different places; a transition that doesn’t work; a key story that takes too long to tell. 

These lumps can sometimes be massaged out, like a tight calf on a foam roller. But not always. If you grind through a sore spot and it never loosens up, the problem may not be the muscle, but the bone. In these moments, which are hard to recognize and harder to accept, you sometimes have to [kill your darlings](https://roundup.getdbt.com/p/devops-and-the-modern-data-experience), and redesign the entire skeleton.

Without exception, these are the darkest hours (or days) of every post. They’re the periods of the doubt and grinding despair, when when I’m working through the details but nothing is certain. It’s writing via dead reckoning, plotting the course of each paragraph based on the preceding one, but not yet knowing if anything is headed in the correct direction. 

Fortunately, this also suggests a solution: Find a fixed star. Once I can anchor myself to a title, an opening line, or a short passage that I *know *is right, navigating the rest of the post is much easier.[^8] 

Beginning with that star, the piece finally takes shape. Ideas I like turn into paragraphs I like, which turn into sections I like. This is also when I usually figure out the tone of the piece. Is it long and melodramatic? Short[^9] and punchy, serious, personal, technical, distant? I usually find this voice in the phrases that I like, or in the rhythm of the scenes I don’t want to cut. 

# “Until you can stand it”

Once the studs are set, the rest is polish. In this final stage, the best advice I’ve heard is from Jia Tolentino (via, again, Angela): “Read it over and over again until you can stand to read it.”

Like listening to our own voice, most of us instinctively wince at what we write. It’s easy to excuse that as some mix of self-criticism and imposter syndrome, as an inevitable inconvenience that makes us incapable of assessing our own work. 

This, I think, is wrong. As Tolentino suggests, you can like it—it just takes work. If a sentence is clunky, write it again. If it’s still clunky, write it again. Over and over until you truly, honestly, like it. This can be a grind (again), but no great piece of furniture was made when the carpenter got tired of sanding it; it was made great when the carpenter finally liked how it felt. 

Deadlines being what they are, not everything turns out great. I’ve written as many things for this blog that I hate as I love. But it’s useful to know I *can* love it, if only I put in the time to do it.

Appointing yourself as your own judge has one other benefit: It helps pieces keep their character. Not everyone will get every joke or follow every reference, and that’s ok. If it’s fun for me to write, maybe it’ll be fun for other people to read.[^10] Edit, but don’t sterilize. 

The only New Year’s resolution I ever made that stuck was one that I stole (thanks Aroop; after eleven years, still going strong). To the more resolute out there, debating if now’s the time to join the conversation, please, repay the favor and steal this album. The remake is often [better](https://www.youtube.com/watch?v=yXlULkwhgrc) [than](https://www.youtube.com/watch?v=8AHCfZTRGiI) [the](https://www.youtube.com/watch?v=TLV4_xaYynY) [original](https://www.youtube.com/watch?v=mzRbeHyIomk).


---


[^1]: On one hand, I’ll never forgive you, Dr. Heckelman, for sneaking *multiple* papers into an econ class. On the other hand, you taught me about [Arrow’s impossibility theorem](https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem), which is a very cool theorem. So we’ll call it even.

[^2]: The whole Friday thing was half accident, half Angela Wu Li seeing the unconventional potential in the vibe of arguing about data on Fridays. And speaking of Angela, everyone should follow her (all-too-infrequently) updated Substack, *[human not dancer](https://human.substack.com/)*. Compared to this one, it’s better written, has much better musical tastes, and is considerably more, well, human.

[^3]: As I was saying about this Substack’s musical tastes…

[^4]: As I was saying about this Substack’s musical tastes…

[^5]: And in data, there’s really [only one thing to say](https://twitter.com/bennstancil/status/1426276002012016643).

[^6]: This post, in fact, came from a conversation I had with two people in the data community.

[^7]: Twitter is full of con jobs, but one of the most irritating (and, in fairness, probably least harmful) is the Born Again Hustle Horoscope. They’re all written by Very Online combinations of Tony Robbins and get-rich-quick stock brokers, each with their own beat—[Writing!](https://twitter.com/david_perell) [Spiky POVs!](https://twitter.com/wes_kao) [Growth frameworks!](https://twitter.com/SahilBloom) [“Deconstructing things”!](https://twitter.com/julian)—and backstory, typically about having survived the corporate grind to reemerge as an enlightened sphinx, full of borrowed and bite-sized proverbs packaged into threads of punchy multi-line tweets that always end feeling vaguely like a Ponzi scheme: “For more threads of unconventional wisdom, subscribe to my newsletter *The Courage to be Candid*!” These threads, which often read like [ironic](https://twitter.com/david_perell/status/1450484108690341899) [and](https://twitter.com/sahilbloom/status/1437388241620111368?lang=en) [self-contradicting](https://twitter.com/david_perell/status/1441786570802176000) [riddles](https://twitter.com/Julian/status/1437295319046242308), are too trite to be helpful, and instead seem to prey on the dissatisfaction of the college-educated millennial who’s got two-coffee-a-day hustle, a good resume, and a well-paying desk job that they know, *know*, is holding them back from their true potential. It’s grift, shallow inspiration and no substance, written for retweets rather than actual reinventions, 280 characters about owls and lessons on how to draw two circles, with nothing in between.

[^8]: Unfortunately, I rarely know if I like something until it’s fully formed, which is why formal outlines don’t work for me. This process would be much easier if I could fix a bunch of stars with an outline, and then add the details around them. But without those details, I can never tell if the stars are actually good.

[^9]: “There are short pieces?,” the confused reader says.

[^10]: “It’s not,” the exhausted reader says.