# Posts from 2022-Q2

This file contains 13 posts from 2022-Q2.

================================================================================

# We all have an audience

*To talk about what we say, we have to talk about who we say it for.*

---

![](https://substackcdn.com/image/fetch/$s_!W4Ym!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbea512e-1db8-4c5d-aff8-6f31f6b60545_1280x720.jpeg)
*We just want to popular, even Elizabeth Holmes.*

This Substack has about three dozen editors. Not literally, of course—the only true editor is Google autocomplete—but every post is guided by the anticipated reactions of a handful of real people who occasionally read this blog. They are the influencers in the industry, the people who run companies or control capital, and the people who have audiences far bigger than mine. I don’t write *for* them, but it’s difficult to get their imagined voices out of my head when I choose how decisively to take a stand or how far to go in some bit of criticism or praise.

I didn’t start this way. In this blog’s early days, I wandered through different topics, ranging from [gossip on Clubhouse](https://benn.substack.com/p/a-slur-on-clubhouse?s=w), [complaints](https://benn.substack.com/p/its-hard-to-hate-up-close?s=w) [about](https://benn.substack.com/p/startup-wealth-tax?s=w) [Paul Graham](https://benn.substack.com/p/the-calendar-takes-its-tax?s=w), charts of [Twitter profile pictures](https://benn.substack.com/p/twitter-profile-pictures?s=w) and [baseball seasons without bats](https://benn.substack.com/p/a-season-without-bats?s=w), and [whatever this was](https://benn.substack.com/p/open-the-window?s=w).[^1] Over time, however, I saw what got reactions and likes—[posts](https://benn.substack.com/p/self-serve-still-a-problem?s=w) [about](https://benn.substack.com/p/metrics-layer?s=w) [data](https://benn.substack.com/p/analytics-is-a-mess?s=w) [tools](https://benn.substack.com/p/analytics-is-at-a-crossroads?s=w)—and what vanished into the abyss of the internet—just about everything else. I liked the attention, and my editorial calendar and I chased after it. What started as a blog for a relatively general audience became, in fairly short order, a clubby publication about itself. 

Moreover, as I saw the names of those who signed up or commented, I found myself overweighting the reactions of the people I either respected or who, cynically, “mattered.” More than wanting everyone to like what I had to say, I wanted *them* to like what I had to say. If a hundred people hate what I write but Andrew Gelman calls it sharp, Gia Tolentino says it’s well written, or Michael Lewis applauds the story, I’ll be proud of it. And if everyone loves it, but Michelle Obama tells me she’s disappointed in me, I’m shutting this whole thing down.[^2] 

Admitting this goes against the ethos of a Free Thinker—a label I wouldn’t have applied to myself before, and something I certainly can’t claim now, not after torpedoing the illusion that I somehow operate above the influence of the rich, the powerful, and the popular. But like anyone, I’m corrupted by the same basic motivations that plague middle schoolers and former presidents alike: I want the people I respect to respect me. To paraphrase David Foster Wallace’s [oft-cited graduation speech](https://web.ics.purdue.edu/~drkelly/DFWKenyonAddress2005.pdf), we all worship *something*, even those of us whose entire brand is our supposed unbiased, data-driven atheism.[^3] For people who talk on the internet, our religion is the opinions of other people who talk on the internet—particularly those who are more successful, who make more money, who are more widely followed, or who simply talk and write better than we do. 

Once you get a bit of attention, this insular dynamic feeds off itself. You cater to the influencers’ club; you’re invited further in; your views become more aligned with theirs, either intentionally or because of the gradual conjoining of contexts and desires. Even for me—a gnat compared to people with real reach—I’ve noticed how easily you become the center of your own conversational universe. People ask you questions about what *you* think; they engage with what *you* write; the opinions you read are increasingly reactions to *you*. Your window into the world used to be your feed; eventually, your window becomes your notifications. 

# A brand, not an antidote

As professional data people, we often act as though we're above this impulse. Our day jobs, analyzing data to find The Truth, compel us to position ourselves outside of irrational religions and emotional desires. For many of us, this posture is both a [professional brand](https://newrelic.com/blog/nerd-life/attention-data-nerds-why-new-relic-gives-away-t-shirts) and [personal identity](https://twitter.com/bennstancil/status/1109479030128955394): We have conquered our feelings and balanced our scales with nothing but math and reason, and have the [Deming quotes](https://www.ibm.com/blogs/nordic-msp/in-god-we-trust-all-others-must-bring-data/) in our slide decks to prove it.

But we haven’t. We haven’t done any of these things. We’re just humans—as emotional, corruptible, and in need of therapy as much as anyone else. We respond to the roar of an online crowd,[^4] the praise from our bosses, and the disappointed looks of our peers just as everyone else does. The type of affection we’re chasing may be different—we want people to think we’re smart; we want people to believe us to be coolly detached and unshakably empirical—but we’re still chasing it, all the same. 

As Tristan [wrote a few months ago](https://roundup.getdbt.com/p/saying-true-things-is-hard?s=r), this affects how we operate within our companies. An analyst, he says, is “not actually a disinterested observer. You are compromised by your very existence as a self-interested human on the team, with stock options, a track on a career ladder, and human relationships you care about. You are deeply, deeply compromised.”

This, however, doesn’t stop at our employer’s door. It can also infect us en masse.

# Inside the Beltway

Data conferences used to be staid affairs. Conference headliners, scattered among technical discussions and command line demos, were typically drawn from adjacent industries. They served, indirectly at least, as reminders of who we worked for, and what the point of our work was. 

As our industry has grown—as it’s created enormous companies, [minted a number of billionaires](https://www.forbes.com/sites/kenrickcai/2021/05/26/accidental-billionaires-databricks-ceo-ali-ghodsi-seven-berkeley-academics/#:~:text=Already%2C%20Ghodsi's%20magic%20act%20has,CEO%20and%20cofounder%20of%20Databricks.), elevated community celebrities, and stoked an entire ecosystem of well-respected and well-funded venture capitalists—we no longer need this external validation. An entire conference lineup can be populated with homegrown influencers and entrepreneurs, without any need to look beyond our own rolodexes. 

Last week in Austin, at [Data Council](https://www.datacouncil.ai/austin), the first major in-person data conference in two years, this is exactly what happened. The data community—and just the data community—came together for two days of conversations about our tools, our jobs, and the companies we founded or funded. Those from adjacent industries were nowhere to be found.

The critics were swift. Rather than gathering to talk about business problems and the “end users” of our work, those of us in attendance, who were mostly, it seemed, vendors and venture capitalists, [talked about ourselves](https://twitter.com/juansequeda/status/1506709882845736967). We lost ourselves in our own navels, [delighted in the same indulgent debates](https://twitter.com/g_xing/status/1508148185188896772) that we have on Substack and Twitter, and ignored the questions about business impact that we’re all ostensibly paid to answer. Relative to the prior versions of Data Council, which promoted technical talks and stories from the trenches of the tech industry’s most advanced users of data, this year’s edition was, [as Drew put it](https://roundup.getdbt.com/p/keep-data-council-weird?s=r), very different. 

Though I agree with Drew that there’s nothing wrong with some conferences evolving into trade shows built around product demos and branded happy hours,[^5] the thrust of the criticism, which extends well beyond Austin and into the mash of Substacks and Twitter conversations that dominate today’s discourse, is fair. We are more inward-focused; we do talk a lot about insider industry news; we do write about the stacks we’re building and [not what we’re using them for](https://twitter.com/sarahcat21/status/1509049980530544643). Speaking as someone who’s contributed their fair share to this corpus, it’s worth asking the uncomfortable question: How did we lose our way?

The answer, I think, is simple. We stopped talking to other people. The success of the industry (or at least, the rush of venture capital into it) paved paths to success that don’t require engaging with end users or business problems. We can build companies, careers, and reputations on each other alone. Just as this blog tumbled down a self-referential rabbit hole, so too did the community.

The solution, then, is both easy and incredibly difficult: We have to bring other people back into our conversations. The challenge, though, is we can’t just evoke their needs or remind ourselves to think about them—we have to make them our audience. We have to write for them, and give talks to them. We have read their blogs, reference their tweets, and chase their affection. Without that, the same self-interested demons that lurk in this blog and in our daily decisions at work—we want to be respected, and we inevitably cater what we say to those whose opinions we care about—will keep us focused on ourselves, and not those who we’re supposed to be helping.

There’s a useful parallel between this and political journalism in the United States. Every election cycle, political writers [file countless stories](https://thecounter.org/trump-rust-belt-diner-presidential-race-election-2020/) about the opinions of “real Americans” eating at diners in Kansas. Putting aside the obvious point that people who live in cities are just as real as those who live in Topeka,[^6] these stories are mostly a charade. *Axios* writers don’t write about Nebraska because they care about Nebraskans; they write about Nebraska because they think [other journalists will view it as astute](https://twitter.com/daveweigel/status/1329760907686195201). In this way, dispatches from Denny’s are no different than Beltway gossip stories: They are judged, not by how Nebraskans view them, but by how elite readers view them.

So long as we only talk to one another, conversations about the “end user” will come to serve the same purpose. We’ll throw around the phrase to grandstand to each other how wise we are. But the imaginary editors on our shoulders will remain the same; we’ll write to impress the same readers; we’ll tweet to get retweets from the same people. End users will become our slang de jour—another way to celebrate our savvy and show off for our friends—but nothing else will change. 

Changing this is easier said than done. Stepping out of our comfortable community is difficult. And speaking for myself, my drafts folder is still full of titles like “Model-view-controller design patterns in the modern data stack.” I'm also, like most people, still a teenager at heart, wanting to be liked by the cool kids. But, to add [George’s](https://twitter.com/g_xing/status/1508148185188896772), [Juan’s](https://twitter.com/juansequeda/status/1506709882845736967), and [Sarah’s](https://twitter.com/sarahcat21/status/1509049980530544643) voices to the chorus of critics in my head, I think it’s worth all of us remembering that there are lots of cool kids—and, of course, “business value”—beyond the halls of the data industry.

# An update

*April 4* – After posting this on Friday, there's been a swirl of conversation about tools, conferences, and vendor content, and their role in community discourse. Though I’ve struggled a bit to follow the thread of the discussion (and, this being the internet, threads are always frayed anyway), the consensus seems to be settling on three points: Vendor content is undesirable; we talk too much about tools; and we should talk more about practical stuff, like the problems we’re solving and how we’re building the teams that solve them.

All three of these points could potentially be extrapolated from this post as well. That’s not quite what I meant here; if it was read that way, consider the addendum below and extended correction and clarification.

First, on the role of vendors in the community: I don’t have any objection to vendors participating or making content; that’s how businesses do business these days. I’ll gladly let [LeBron and Leo sell me tequila](https://www.instagram.com/p/CZ-14XML4od/) on Instagram if that keeps the internet free, and I’ll gladly read content hosted on vendors’ blogs or watch talks at vendors’ conferences if it saves us from courtesy calls and being visited by traveling salespeople. 

That said, I would make a distinction between vendor participation—which is usually transparent in its motivations—and community astroturfing, which is more common among VCs and angel investors. If you're an investor and you believe in an idea or market, say that you believe in that idea and [you're proudly backing such-and-such company to make it a reality](https://benn.substack.com/p/disclose-your-angel-investments?s=w). Instead, some investors have a habit of parroting the talking points of their portfolio companies, but not disclosing exactly who they’ve invested in. (You see this a lot in crypto; investors will talk about how they believe there’s a big need for decentralized financial services for the middle class in southeast Asia without explicitly saying they’ve invested in a company that provides decentralized financial services for the middle class in southeast Asia.) Generously, I think investors want to be seen as serious thinkers, and they don't want people to assume their intellectual viewpoints are biased. Cynically, they do it because the best ads are the ones that don’t disclose that they’re ads. Either way, this type of content, unlike run-of-the-mill vendor content, does have a corrosive effect on the health of a community.

Second, on conversations about tools: I don’t have any objections to these conversations either. Tools are useful, and talking about how to make them better is useful too. Many of us in this industry have devoted significant chunks of our lives to building tools; if we didn’t think they were worth a few blog posts and tweets on an infinitely scrollable internet, we’d have some much bigger decisions to question. 

Moreover, even if talking about tools *isn’t* useful, that’s ok too! When we talk about community content, there’s often an implied assumption that that content has to have some practical application. There should be lessons to be learned, key takeaways to take away, slides to take pictures of and bring back to your team. 

Speaking for myself, that’s not why I write this blog or give talks. Bluntly, I don't have that much to teach anyone, and I'm lousy at teaching the things that I do know. I talk about what I talk about because I’m interested in it, and I enjoy talking with other people who are interested in it too. In that way, this blog is, much like data dad jokes on Twitter, entertainment. Nerdy, narrow, niche entertainment for [the most boring people in the world](https://www.businessinsider.com/boring-jobs-hobbies-profession-personal-traits-scientists-study-2022-3?r=US&IR=T), but entertainment nonetheless. I read books like *[Dataclysm](https://www.amazon.com/Dataclysm-Identity-What-Online-Offline-Selves/dp/0385347391) *and *[Everybody Lies](https://www.amazon.com/Everybody-Lies-Internet-About-Really/dp/0062390856)* because I think they’re fun; I’d read blog posts about the [COGS of green onions](https://twitter.com/jthandy/status/1510377693832830977), not to learn anything practical, but because it’s fascinating. My aspirations here are to provide the same. If people come away from what I write asking themselves interesting questions, or reflecting on something in a different way, great. But most of all, I hope they just enjoy the few minutes they spend reading it. 

Which, I suppose, raises the obvious question: What was the original post about, then? Where, if not in talking about tools, did “we lose our way?” 

The point I’d hoped to make was that it’s not the content of what we talk about that matters, but who we make that content for. Talking about tools is fine if we recognize that, in most cases, it’s an entertaining indulgence for us, as industry people, to have low-stakes debates about. The problem arises when we make those debates more meaningful than they are by losing sight of how small the room is that’s having them. That room has definitely gotten bigger—and richer—over the last few years, but compared to the corporate environments in which we operate, we’re still in the closet.

More specifically, my concern is that it’s easy for us to assume, given the energy in the space, that *our* problems, like how do we architect a data stack, are capital-M Meaningful. If we don’t talk to [audiences beyond ourselves](https://roundup.getdbt.com/p/come-write-with-me?s=r), we’ll hear that they are, indeed, quite Meaningful. The only way to get perspective on what is and isn’t is to go beyond the community, and [talk to people](https://twitter.com/sarahcat21/status/1509660232024092673) who don’t, by default, care that much about what we do.

This applies to conversations about topics other than tools as well. We can just as easily lose sight of what’s important when talking about organizational structures and business problems as we can when we talk about tools, if those conversations are still just had amongst ourselves. Debating the ideal structure of a data team or the best way to run an experiment can be just as much of an insider indulgence as debating a data stack.

Ultimately, for me, the concrete lesson in all of this—the takeaway, if you will—is not to stop writing for my Andrew Gelmans, Jia Tolentinos, Michael Lewises, and Michelle Obamas ([this offer still stands)](https://twitter.com/bennstancil/status/1433834729367908353). There may not be business value in some of these conversations, but there’s [connective, human value](https://twitter.com/tayloramurphy/status/1510006747011944453), and that’s still worthwhile. The lesson, instead, is to find people like them, whose professional opinions I respect and whose professional respect I want, *outside *of the data world, and write for them too. 


---


[^1]: And a long promised and never delivered [opus on Pitbull](https://benn.substack.com/p/a-brief-programming-note?s=w). [The bigger they are, the harder they fall](https://genius.com/2935552).

[^2]: As far as I know, these people don’t read this blog. Which is for the best, because [I don’t think I could handle it](https://www.youtube.com/watch?v=jenXxXNxQhI). But a few others who I respect just as much do, and their opinions can make or break my feelings about a post.

[^3]: Many of today’s “independent thinkers” are clearly infected by the same intellectual rot. Writers like Matt Yglesias and Bari Weiss talk about how they’re willing to tell clear-eyed and courageous truths in front of a frothy mob of cancel culture warriors. I’m dubious. They write not for the unwashed masses, but for each other. They have the “courage” to say what they say because they know the others in their club—the people who they actually respect; the hosts of the parties they actually want to go to—will agree with them, or at least applaud them for saying it. This is why, given enormously complex problems, from how to respond to Covid to how to address centuries-long social problems in America, these supposed free thinkers, constrained by no editor and driven by nothing other than their prodigious intellect, always seem to agree with each other. Either they’re just smarter than us, or they’re chasing their own religion: The approval of one another.

[^4]: I.e., six likes and a quote tweet that says, “I agree with this theory, but don’t think it’s right in practice.”

[^5]: Unless your happy hour includes an actual, living anaconda—which allegedly happened in Austin—in which case I’ll enthusiastically join a frothy mob of cancel culture warriors to banish you from polite society.

[^6]: Why are we so obsessed with the opinions of rural Americans? [We will never know.](https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=99538)

================================================================================

# The end of Big Data

*Databricks, Snowflake, and the end of an overhyped era.*

---

![](https://substackcdn.com/image/fetch/$s_!MqVK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8aa9755d-43fc-4c33-b2c8-80fc45db3ffd_1431x591.png)
*Thirty-eight billion dollars isn't cool. You know what's cool? Being boring. *

Databricks is a $38 billion dollar mistake. 

As a [ninth largest](https://www.cbinsights.com/research-unicorn-companies) private tech company in the world,[^1] banking [$800 million of revenue](https://techcrunch.com/2022/02/17/as-databricks-reaches-800m-arr-a-fresh-look-at-its-last-private-valuation/) per year, it’s a mistake all of us would be lucky to make. But it’s hard not to look at Databricks and see a company selling to a bygone era. And the dizzying success of its competitors—Snowflake is worth $70 billion, even after its stock’s [brutal five-month slide](https://www.google.com/search?sxsrf=APq-WBvYwO8P4K3o5oJnc-F0FSR__e8qrA:1649371716994&q=NYSE:+SNOW&stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdMqKkwqjKuMeBaxcvlFBrtaKQT7-YcDAAk-NmdKAAAA&sa=X&ved=2ahUKEwjQ3qy6hIP3AhWjg4kEHT1zAz0QsRV6BAhaEAI&biw=1792&bih=1016&dpr=2); BigQuery, I’ve heard, books as much as $3 billion a year—suggests that, with a couple pivots, a repositioned Databricks could capture far more potential than it does today.[^2] 

I first heard about Databricks in 2014. It was Silicon Valley hype, manifest. Databricks’ founders were brilliant computer scientists turned reluctant entrepreneurs. They were reinventing big data, which itself was reinventing the entire world. Growth rates were straight up, and overloaded sales reps were leaving their phones off the hook. 

When I looked it up, my first reaction was that it was built for people smarter than me. Instead of a demo or product screenshots, I found technical papers explaining something I didn’t understand. The case studies talked about real-time enterprise workloads, streaming Spark applications, and distributed, highly-scalable data science model development. 

I needed a database. I was, at the time, spinning up a (pre)modern data stack: Segment, Fivetran, Mode, and, at the center of it all, Redshift.[^3] Though Redshift worked reasonably well, it was starting to cause a few headaches. Keeping it up required regularly shuffling a couple large tables between it and S3, and the cluster status page was gradually creeping up my shortcut list on Chrome. 

Eventually, after a failed attempt to migrate to Athena and Spectrum, we made the decision to go shopping. BigQuery was our presumptive favorite. It was frighteningly fast; it required no management; and several customers had recently told us about their successful transitions from Impala[^4] to BigQuery. We took a call from Snowflake out of obligation—to see what else is out there; to do the diligence; to request the proposals. 

The pitch we heard from Snowflake was both the dumbest and most effective sales pitch I’ve ever heard. We were told that it was the same as Redshift—and really, the same as Postgres—but big, fast, and stable. We didn’t see any glossy slide decks filled with stock images of strikingly handsome business professionals huddled around a conspicuously unbranded computer. We didn’t hear any customer testimonials from bank executives about how their five-year initiatives came in on schedule and under budget. There were no forced mentions of digital transformations, distributed systems, or, God forbid, [the blockchain.](https://twitter.com/bennstancil/status/1503204739256827905) They never even told us what we could use Snowflake for. We were told to just keep doing what we’d been doing, except if we did it with Snowflake, they’d host the whole thing, back it with bottomless storage, and run our queries faster than ever before—a strictly better, [Pareto improvement](https://www.investopedia.com/terms/p/paretoimprovement.asp#:~:text=A%20Pareto%20improvement%20is%20an,make%20any%20available%20Pareto%20improvement.).[^5] 

The pitch (and Snowflake) worked masterfully. As they undoubtedly anticipated, we started using Snowflake the same way we used Redshift, but quickly, after becoming accustomed to its speed and scale, found new things to do with it. Rather than worrying about precisely tuning our incremental loads in dbt, we started doing more full refreshes. We stopped carefully vetting which logs we wrote into our warehouse. We found new ways [to share data with customers](https://mode.com/developer/discovery-database/introduction/). We didn’t buy—and wouldn’t have bought—Snowflake for these things, but once they were so accessible, we happily picked them up. 

Throughout our entire evaluation, we never considered Databricks. 

In hindsight, we should’ve. Databricks is, just like Snowflake, a fast, hosted, almost infinitely scalable database. And, unlike Snowflake, it supports a [wider range of languages](https://docs.databricks.com/languages/index.html) that could’ve opened up entire classes of new applications that, once accessible, we would’ve been excited to try. But we never connected these dots during our evaluation because the story Databricks told was buzzwords. Snowflake’s was boring, and all we wanted—at least at first—was boring.

# Data for the middle class

When the history books on the modern data stack get written,[^6] two moments will thus far define its arc. One is dbt Labs stampeding through the ecosystem in 2020 and 2021, and the other is  Snowflake’s IPO. 

These moments capture several key features of the era. First, they highlight two companies that at the technological center of what the industry is has been building for the last decade. Second, they validate its commercial success, through an [enormous IPO](https://www.cnn.com/2020/09/16/investing/snowflake-ipo/index.html) and a two-year [fundraising tear](https://www.crunchbase.com/organization/dbt-labs/company_financials). But most importantly, these moments finally closed the door on the breathless age of Big Data. 

For years, data was talked about as if it were a massive stack of technological tarot cards. We’d read about it in [cryptic special reports](https://images.app.goo.gl/R281v95W8GFopng7A) in the *Economist* that said we were [hockey-sticking](https://images.app.goo.gl/xiytY7NY232GDpJm7) towards a future governed by digital *Minority Report* mystics. The [premier events](https://www.oreilly.com/conferences/strata-data-ai.html) in the industry, bankrolled by first-wave big data companies like Cloudera, Hortonworks, and MapR, hyped the same narrative: We have tons of data, and we’re going to change the world with it.

This story has completely changed. Indecipherable technologies have been replaced by boring ones, like a big Postgres database worth north of $50 billion, and open source SQL templates. And the conversation has moved from focusing on rare problems to common ones. For [all that’s been said about Data Council](https://roundup.getdbt.com/p/come-write-with-me?s=r), there’s one way in which it was more firmly anchored to reality than nearly any other data conference before it: The problems people talked about were relatable. In 2014, for example, Strata, the leading data conference at the time, [included talks titled](https://www.forbes.com/sites/centurylink/2014/02/07/strata-2014-6-dont-miss-sessions-to-further-your-tech-strategies/?sh=45f8da4b1ce7) *​​Information Visualization for Large-Scale Data Workflows, Scaling Charts with Design and GPUs, *and *Getting a Handle on Hadoop and its Potential to Catalyze a New Information Architecture Model.* These aren’t problems most organizations had in 2014 (or ever). At Data Council, [many of the topics discussed](https://www.datacouncil.ai/austin), while niche, are familiar to any data team: How to track data lineage; how to run an experiment; how to govern your results.

These talks reflect the implicit ethos behind Snowflake and dbt: Our problems aren’t new, we don’t want to reimagine, reinvent, or revolutionize how we work to solve them, and we don’t want to be hit in the face with new innovations. We just want the same tools we’ve always had—a database and some SQL—with some modern new magic quietly tucked behind them. 

# The boring industry

Over time, I expect the rest of the industry to follow Snowflake and dbt away from its history of technological hype and up the “[slope of enlightenment](https://en.wikipedia.org/wiki/Gartner_hype_cycle).”[^7] For most of us, this looks like embracing what we consider pedestrian, talking about problems and not technologies, and listening to a [wider array of professional voices](https://benn.substack.com/p/we-all-have-an-audience?s=w).

I think there’s a more explicit lesson, however, for Databricks, and for technologies, like real-time and augmented analytics tools, that currently have more promise than widespread practical application.

For Databricks, be boring. There’s a version of Databricks that’s centered around a polished whitepaper about the Data Science Platform™—it’s a company with a website that’s more “Solutions” pages than “Product” pages, that’s defined by what it enables and not what it does, and depicts itself, abstractly, as a serene oasis in middle of the howling chaos of enterprise data management.[^8] 

This approach has sold software to CIOs for decades, and it’ll surely work here. But I’d hazard a guess that it wouldn’t sell as well as a simpler pitch: Databricks is a big, fast database that you can write SQL and Python against. Don’t sell Databricks as a new architecture for an all-in-one AI platform; sell it as centralized warehouse—the kind that turned Oracle into a $220 billion dollar company, and [made Microsoft $5 billion a year](https://www.crn.com/news/cloud/300072551/microsofts-enterprise-software-price-hikes-paying-off-as-sql-server-business-hits-5-billion-mark.htm) *in 2014*—that’s hosted, has effectively no storage limit, is really fast, and can be queried directly with Python and R. Don’t sell it as a new category; sell it as a replacement to my vanilla analytical warehouse, but bigger, faster, and polyglot. Don’t sell me use cases and testimonials; sell me this diagram. Once I buy it—and I would buy it—I’ll find everything else Databricks can do, just as we did with Snowflake.[^9]

![](https://substackcdn.com/image/fetch/$s_!RPvB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F529a45d1-09e7-48cd-9ec1-318afd87ecce_1932x1162.png)

The same lesson can be applied to a handful of other industry subsegments that are selling emergent technologies that don’t yet have clearly defined applications. 

Take real-time products, for example. Most businesses have little use for true real-time experiences. But, all else being equal, real-time data is better than latent data. We all have dashboards that update a little too slowly, or marketing emails we wish we could send a little sooner. While these annoyances don’t justify the effort currently required to build real-time pipelines, they do cause small headaches. 

But if someone came along and offered me a streaming Fivetran, or a reactive version of dbt, I’d take it. If the cost of a real-time architecture was low enough, regardless of the shoehorned use-cases, there’d be no reason to turn it down. And just as we came to rely on Snowflake after we chose it as a better Postgres, I’m certain we’d come to rely on streaming pipelines if they replaced our current batch ones. We’d start doing more real-time marketing outreach, or build customer success workflows around live customer behavior. 

Over the next five years, I’d guess that real-time data tools follow this exact path: They’ll finally go mainstream, not because we all discover we need them, but because there will be no reason not to have them. And once we do, we’ll find ways to push it to their limits, just as we did with[ fast internet connections and powerful browsers.](https://www.debugbear.com/blog/is-the-web-getting-slower)

The same could apply to other tools, like augmented analytics platforms and AI applications like [Continual](https://continual.ai/). In Continual’s case, most of us don’t have an immediate need to enrich our data pipelines with ML models. If the barrier to doing so is low enough, however—if we can easily classify leads’ job titles, or add health scores to our customer models, without sacrificing anything about how our existing pipelines already work—many of us would. 

Erik Bernhardsson [identified a similar dynamic](https://erikbern.com/2020/12/16/giving-more-tools-to-software-engineers-the-reorganization-of-the-factory.html) in software development. People who had little corporate use for software, like a small dentist’s office, built their first websites not because they suddenly had a huge need to do so; they created them because it became cheap to do it. This initial, “there’s no reason not to”-inspired foray into software uncorked a rush of latent demand: If you have a website, why not let people use it to book appointments? Why not build a system to message patients? Why not run a few ads that direct people to the site? If people don’t need something—but recognize that it’s better if they have it—few things can catalyze a market to grow faster than making it easier for people to buy it. 

By following the same path, Big Data is finally starting to live up to its potential. It’s getting there, ironically, by giving up many of its hyped promises for a very boring one: lower costs for marginally more useful things. With Snowflake—and hopefully, with Databricks—we don’t get flying cars or predicting the future; we just get a little less headache. But, it turns out, that’s exactly what [us boring people](https://www.businessinsider.com/boring-jobs-hobbies-profession-personal-traits-scientists-study-2022-3?r=US&IR=T) need. 


---


[^1]: Now [eighth](https://www.cnbc.com/2022/03/25/instacart-slashes-valuation-by-almost-40percent-to-24-billion-.html)!

[^2]: Warning: This is wild speculation. Read this blog; buy some NFTs; bet everything on black. These are all the same thing.

[^3]: Ah, simpler times.

[^4]: Impala is one of those pieces of technology, like Meerkat, or Secret, that precisely dates anyone who knows anything about it.

[^5]: And, in the one bad thing they didn’t tell us, it will `YELL AT YOU EVERY TIME YOU WRITE A QUERY.`

[^6]: Or, if we’re lucky, when the scandalous [Apple TV docu-series](https://en.wikipedia.org/wiki/WeCrashed) gets made.

[^7]: There’s no way [this page](https://en.wikipedia.org/wiki/Gartner_hype_cycle) wasn’t written by someone at Gartner.

[^8]: No data, no substance, all vibes.

[^9]: Of course, I'm not a CIO at a Fortune 500 company, so my opinions on this issue may not matter at all. Like I said, I’m just out here taking cuts.

================================================================================

# Has SQL gone too far?

*The case for better business models. *

---

![](https://substackcdn.com/image/fetch/$s_!-aAU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6cb6d63-ae28-4bde-b241-0bc2f4d9719e_1480x833.jpeg)
*[Hang on a minute…](https://www.youtube.com/watch?v=Ope-1Zb5t-k&t=110s)*

Death, taxes, and SQL.

Amid all of the growth, upheaval, and reinvention in the data industry over the last decade, the only durable consensus has been our appreciation of SQL. Every time we flirt with some NoSQL alternative, we end up rebounding back to SQL. Every time someone puts out a new proprietary rewrite—[JQL](https://mixpanel.com/JQL/), [NRQL](https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/), [Juttle](https://juttle.github.io/)—the community responds with the same pleading reaction: [Please stop doing this](https://twitter.com/seldo/status/1513599841355526145). 

Remarkably, our attachment to a half-century old technology isn’t inspired by some Churchillian acceptance of our lowly lot in life—“SQL is the worst way to interact with data, except for all the others that have been tried.” No, it’s an active advocacy, in which we don’t want to just protect SQL’s current beachhead as the dominant way to extract and manipulate data, but also want to expand its reach further: SQL for [AI](https://continual.ai/); SQL for [real-time applications](https://www.decodable.co/);[^1] SQL for [data pipelines](https://hightouch.com/#:~:text=Activate%20your%20data%20warehouse%20with%20SQL.). 

Of course, few people would claim that SQL is the best language for everything. I haven’t seen anyone argue that we should use SQL to describe a data visualization, or to create complex statistical forecasts. No matter how deep our affection for SQL runs, we know—obviously and uncontroversially—SQL has limits.[^2] 

As a technical luddite who still can’t make conceptual heads or tails of how to do anything with a Pandas dataframe, I’ve long been an advocate of pushing those limits.[^3] I’ve worked almost exclusively in SQL for much of my career; just as [English defines how I see the world](https://www.nytimes.com/2010/08/29/magazine/29language-t.html), my understanding of data has been rewired around relational notions of tables and joins. [Some people think in sentences, some in non-verbal thoughts](https://twitter.com/KylePlantEmoji/status/1221713792913965061)—and data people, it seems, think in SQL. The more we can do in our native language, I’ve long thought, the easier our jobs will be. 

In recent weeks, however, my faith has started to waver. Perhaps, *perhaps*, we’ve overreached. Perhaps, to nail a disputation on the church door,[^4] one of the core responsibilities of a data team—modeling a business, and defining a semantic layer—is best done in another language.

# Business models aren’t relational models

After years of [languishing in the backend of BI tools](https://blogs.sap.com/2011/04/05/sap-businessobjects-bi-40-the-new-semantic-layer-asug-webcast-summary), semantic models—the set of definitions and specifications that inject raw data with meaning, like a formula that determines how to compute revenue from a list of credit card transitions—are having a moment. In the last twelve months alone, [Looker branded themselves](https://cloud.google.com/blog/products/data-analytics/lookers-universal-semantic-model) as a “universal semantic model;” [dbt declared](https://blog.getdbt.com/next-layer-of-the-modern-data-stack/) that a semantic layer is the next layer of the modern data stack; AtScale said that the universal semantic layer is [more important than ever](https://www.atscale.com/blog/the-universal-semantic-layer-more-important-than-ever/); and [multiple](https://transform.co/) [companies](https://singleorigin.tech/) launched dedicated semantic layer products. To cap it off, not only has a [new role](https://www.getdbt.com/what-is-analytics-engineering/) emerged to maintain the semantic model; it was proposed [as the world’s sexiest job](https://tdwi.org/Articles/2022/02/28/PPM-ALL-Analytics-Engineers-Have-Sexiest-Job.aspx?Page=1).

The recent trendiness of the semantic layer runs parallel to that of SQL. dbt championed the idea of [modeling data in SQL](https://www.getdbt.com/product/what-is-dbt/); dbt’s popularity galvanized the creation of a transformation layer; the importance of that layer gave rise to analytics engineering; all of these things together coalesced into a universal semantic layer. As a result, today’s semantic layers are inseparable from SQL itself.

More concretely, in this modern, dbt-inspired construction of a semantic model, a user is defined by the hand-written query that creates a users table; revenue is defined by the similarly manual query that computes it. This structure has two big benefits: It’s accessible, and it’s fast. Anyone who writes SQL can both understand and extend it. Moreover, business concepts are rendered as tables, which [are conceptually easy to understand](https://benn.substack.com/p/ghosts-in-the-data-stack?s=w). 

This type of semantic layer has its problems, though. Most notably, there is no *true* model. Queries are related to one another through a simple lineage graph, not through any sort of semantic definition. If you change the segments that you sell to, you have to update every query that uses the outdated segmentation.[^5] 

In other words, defining a semantic layer in pure SQL is like animating a movie by hand. Lots of people can make a simple flipbook, and make it quickly. But to add a new character to an existing scene, you have to redraw every frame. The more intricate the scene, the more tedious that work, and the easier it is to draw the new frames inconsistently. 

A different approach is to create a Pixar movie. Pixar’s animators don’t have to draw Woody into every shot; instead, they define each scene with an underlying model, which renders every frame consistently. It’s more work up front, but—if you know how to write [Presto](https://en.wikipedia.org/wiki/Presto_(animation_software))[^6]—it’s more reliable to maintain.

Most BI tools, from [Microstrategy](https://www.microstrategy.com/pt/resources/video/what-is-a-semantic-graph) to [Looker](https://www.looker.com/platform/data-modeling/), follow this pattern, as do some metrics layer vendors like [Transform](https://transform.co/product/). In all of these products, analysts construct a semantic model by defining how tables in a database are related, and how those tables should get aggregated into metrics. When people interact with these tools, the semantic model translates requests for a metric or dataset into a SQL query. If segments need to be redefined in this framework, they can be updated in the model, and every subsequent translation would use the new definition. 

At their core, however, these tools are just thin recipes for SQL queries. In LookML, for instance, you can almost see [the SQL query peeking through](https://docs.looker.com/data-modeling/learning-lookml/what-is-lookml). Joins between tables are defined explicitly; metrics are slightly doctored snippets of SQL syntax. In this regard, these semantic layers are little different than dbt—they both rely, wholly and completely, on us telling the layer what SQL to run.

*But lots of business concepts aren’t easily defined this way. *Consider, for instance, a sales funnel in which prospects move through a series of stages, like “In trial,” “Contract negotiation,” and “Under legal review.” These stages often have a expected order, but not a strict one. Some prospects skip stages, some proceed through them in a different sequence, some stages happen concurrently, and sometimes, if a sale cycle goes sideways, steps get repeated. 

How do you model this funnel in SQL? How do you write a query that computes how long legal teams typically take to review a contract? How do you express the semantic nuances of this business process in LookML?

For most companies, the answer, I suspect, is you don’t. Rather than writing a web of queries that handle all of the possible intricacies and edge cases, you model a simplified sales funnel that you know isn’t real, and accept that some prospects, like those who repeat stages or proceed through them in an unconventional order, will get miscounted. Metrics come with a caveat—”This assumes every closed account entered a trial prior to purchasing.”

In some cases, these approximations are probably fine; the only perfect map of the territory is the territory itself. But, given the increasing importance of semantic layers, especially their aspirations to be the universal arbiter of the capital-T Truth, these fudges—rooted in the limitations of SQL—could become very problematic. 

Which leads us to the heretical conclusion: Just as SQL can, but shouldn’t, be used to define complex statistical analysis, perhaps SQL can, but probably shouldn’t, be used to model the complex operations of a business.

# BusinessML

Two tools offer a glimpse of a different path forward. The first is actually dbt. Though most code in dbt is SQL, it’s not just SQL—there’s a lot of Jinja too.

In the dbt projects I’ve seen, Jinja is most often used as a kind of programmatic shortcut to generate queries that people would otherwise write by hand. For instance, instead of writing five repetitive lines of SQL to parse each individual UTM parameter from a URL, dbt developers will write a Jinja loop that does it in a single line. It’s not, [as Tristan says](https://twitter.com/jthandy/status/1351869077254524928), that you couldn’t write the same query without Jinja; it would just be painful to do it. But it’s easy to imagine this going much further, where dbt developers stop thinking in queries and instead think in Jinja.

Consider the sales funnel again. To model this funnel in dbt today, I (and I assume others) would first think about how to model it in SQL. If there were repetitive steps, like a bunch of joins of the `salesforce_stages` table onto itself, I’d simplify those with a Jinja loop. The logic behind this model, though, would be expressed in SQL, and my ability to model it would go only as far as the cleverness of what I could do in a query. 

Could Jinja, or some forked version of it specifically designed for expressing business logic in dbt, help me go further? Could I define this sales funnel in this language—these are the stages, these are how prospects progress through them, these are the steps that can be skipped—and rely on dbt to figure out how to turn these nested relationships into SQL for me? With marcos and metrics already tilting in this direction, it certainly seems conceivable that our dbt projects become less and less SQL and more and more Jinja, just our web applications are less and less HTML and more and more React and Rails.[^7] 

The second tool exploring this idea is Malloy, an open source project led by LookML creator Lloyd Tabb. Whereas LookML is built on join relationships and SQL snippets, Malloy is built on direct expressions of business logic. 

This has two big potential benefits over LookML. First, because these logical expressions can be layered on top of each other like functions, Malloy is much more composable than LookML. To extend the Pixar analogy, in LookML, you can model a car into a scene, and that car will appear consistently in every frame of that scene. Malloy goes further—it lets you define the concept of a car, which you can then add to any scene in the entire movie.

Second, just as a heavily Jinja-ified dbt could write more complex queries than we’re able to as people, Malloy writes SQL that better retains the realities of the business logic it’s meant to represent, which is often SQL that an analyst would never write themselves. For example, nested relationships between entities—this city is part of this state, this state is part of this region—are [maintained as nested relationships](https://looker-open-source.github.io/malloy/documentation/language/join.html) in the results Malloy returns. This provides a path for solving the sales funnel problem: The funnel could be defined as a logical expression in Malloy, and Malloy figures out how to write the ugly, recursive query that is necessary to describe that funnel accurately. 

We could actually go one step further though. While Malloy and an evolved dbt would both create, in effect, a new language for modeling business logic, they’re still rooted in SQL. The logic they can express is constrained by the SQL they can write. On the edges, there are surely business concepts that can’t be expressed in SQL at all, no matter how many clever window functions and self-joins we use. Or, there are processes that can be defined in this way, but can’t be queried performantly.[^8]  

This opens up yet another type of semantic layer: One that doesn’t render to SQL at all. 

Admittedly, this an ambitious endeavor, as it requires creating a new database that can be queried via a language other than SQL. But if you can pull it off—and companies like [RelationalAI](https://relational.ai/) are attempting to do exactly that—it allows for much more complex (and performant) expressions of business logic. 

Though this may seem like a marginal improvement, consider it in the context of [George’s recent Twitter thread about Lyft](https://twitter.com/g_xing/status/1505664351268585476). As George tells it, Lyft turned major parts of their business around by building a growth model of their operations, and leaning on that model to make decisions. We would all benefit from these sorts of models, but we often don’t build them—and rarely create them into the semantic layers that are supposed to underpin every decision we make—because they’re nearly impossible to express in SQL. If they exist at all, [they usually exist in Excel](https://twitter.com/g_xing/status/1505664354263310336). 

The promise of something like RelationalAI is the ability to create that model more easily and to embed it directly into the semantic layer. It is to pull out the logic that’s buried in load-bearing Excel files—the weekly forecasting sheet, the master marketing funnel workbook, the global growth model—and make them accessible to every analyst and data application in a business. 

Of course, none of these ideas are entirely new.[^9] Semantic modeling languages have come at the king for decades, and [they’ve all missed](https://www.youtube.com/watch?v=WP-lrftLQaQ)—SQL still sits on its throne. 

Every once in a while, though, that which is supposed to be certain, isn't. A year ago today, [it was taxes](https://www.irs.gov/newsroom/tax-day-for-individuals-extended-to-may-17-treasury-irs-extend-filing-and-payment-deadline). This weekend, [it's death](https://www.calendardate.com/easter_2022.htm). And next year, it may well be SQL. 


---


[^1]: I’m a [personal investor](https://benn.substack.com/p/disclose-your-angel-investments?s=w) in Decodable.

[^2]: …get it?

[^3]: I’m also a purveyor of a [SQL-based product](https://mode.com/), so I’m not exactly unbiased here.

[^4]: Quick, while he’s gone, question everything!

[^5]: You could, in theory, architect a dbt project such that every bit of segmentation logic cascades from a single model. That’s very hard to do though, and it’s nearly impossible to do, simultaneously, for every one of the dozens of other business concepts that you’d want to cascade down in the same way. In practice, a few core concepts will get defined at the beginning of the lineage graph, while others will get scattered across it.

[^6]: Wait, what?

[^7]: For what it’s worth, I’d argue there are very big downsides to doing this in today’s Jinja, which isn’t really designed for this. But Jinja could change.

[^8]: A third of the time I write a self-join it works, a third of the time I completely butcher the logic, and a third of the time I forget some join condition, fan an event table out into whatever a trillion times a trillion is, and bring down the database.

[^9]: In particular, Microsoft has [done it all before](https://docs.microsoft.com/en-us/analysis-services/multidimensional-models/mdx/mdx-query-fundamentals-analysis-services?view=asallproducts-allversions).

================================================================================

# A better way to lie with statistics

*Use words.*

---

![](https://substackcdn.com/image/fetch/$s_!k1QL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0fb182ce-e524-422f-8158-1f9a48b9944a_2992x1486.png)
*The subtle art of misdirection.*

Statistics, it would seem, has a branding problem.

Over the last fifty years, [the best selling text on the subject](http://www-stat.wharton.upenn.edu/~steele/Publications/PDF/TN148.pdf) is *How to Lie with Statistics*. Google “quotes about statistics,”[^1] and the first result is “There are three types of lies—lies, damn lies, and statistics.” The most common lesson people seem to remember from their high school or college stats class is a cliché warning: “Correlation doesn’t equal causation.”[^2]

We’ve collectively taken this education to heart. We’ve become eager detectives, gleefully hunting for the next [truncated axis](https://heap.io/blog/how-to-lie-with-data-visualization), [biased sample](http://mediashift.org/2018/01/twitter-add-warning-label-polling-feature/), or [spurious correlation](https://www.tylervigen.com/spurious-correlations) that we can [roast](https://twitter.com/GraphCrimes) [on](https://twitter.com/ChartCrime) [Twitter](https://twitter.com/ChartCrimes).

Though I appreciate an [EPIC TAKEDOWN](https://www.youtube.com/watch?v=fYWtbMb8Fhw) of a ridiculous Fox News chart as much as anyone, our fixation on misleading statistics and deceptive visualizations distracts us from another way that numbers deceive us, which is far more common, far more direct yet far more subtle, and, oddly, far less discussed: Lying not *with* statistics, but *around *statistics, with words*.*

On July 25, 2019, we narrowly avoided a global disaster when a large asteroid, estimated to be between 200 and 400 feet across, passed within 45,000 miles of Earth.

In 2021, Minnesota Twins first baseman Miguel Sano, in almost a thousand defensive chances, committed only thirteen errors. His fielding percentage of 98.6 percent was nearly perfect.

COVID cases spiked in New York City in April, with the daily case count rising from 650 in early March to nearly 1,700 a month later. 

Last January, a California man [posted a video](https://www.tiktok.com/@stuftnacho/video/6913970754455407878) on TikTok pledging to exercise every day until Taco Bell brought back the [Grilled Stuft Nacho](https://tacobell.fandom.com/wiki/Grilled_Stuft_Nacho). [The clip went viral with hundreds of thousands of views.](https://www.washingtonpost.com/lifestyle/2022/04/20/taco-bell-chris-sandberg-exercise/#:~:text=The%20seven%2Dsecond%20clip%20went%20viral%20with%20hundreds%20of%20thousands%20of%20views.)[^3] 

Reels, Facebook’s new TikTok competitor, [accounts for only six percent](https://www.barrons.com/articles/tiktok-meta-stock-facebook-51646242851) of the time users spend on Facebook and Instagram.

We read sentences like these all the time. By most standards, they’re fair, well-written, and adhere to [Amazon’s](https://twitter.com/david_perell/status/1208930197702995968?lang=en)[^4][ pop principles of good writing](https://twitter.com/david_perell/status/1208930197702995968?lang=en), by replacing adjectives and “weasel words” with data. If we were to see one of these claims in a news story or a company deck, we’d likely not only take it at face value; we’d applaud its balanced tone and quantitative rigor.

But they’re not balanced. All of these examples are either confusing, misleading, or outright false—they just do a much better job of hiding it than a deceptive y-axis. 

The asteroid [was real](https://www.washingtonpost.com/nation/2019/07/26/it-snuck-up-us-city-killer-asteroid-just-missed-earth-scientists-almost-didnt-detect-it-time/), and the figures about its size and proximity to Earth are accurate. However, to a layperson (or, at least, to this* *layperson), the numbers are  meaningless on their own. I have no idea if 300 feet across is big for an asteroid (it seems kinda big?) or if 45,000 miles is close (it seems almost incomprehensibly far?). My entire perception of the story is defined by the word “narrowly.” Had it said “we comfortably avoided a global disaster,” I would’ve read it completely differently. In this case, the data is indecipherable, and it serves little purpose other than to provide an aura of scientific certainty that makes me, baselessly, more convinced that whatever narrative the story presents is true.

Miguel Sano’s stats are also accurate—but framing his season as “nearly perfect” and including “only” in the sentence makes it close to an outright lie. Among all first basemen in the major leagues, [he had the worst fielding percentage](https://www.espn.com/mlb/stats/fielding/_/year/2021/order/true) and made the most errors. Still, successfully doing anything nearly 99 percent of the time *sounds* good, and most of us, including [stats-minded baseball fans](https://benn.substack.com/p/a-season-without-bats?s=w), would be fooled by the original claim. We wouldn’t interrogate the number; we wouldn’t ask if Sano’s performance was good relative to other first basemen in the major leagues (by this measure, it was bad), relative to other positions (by this measure, [it was pretty good](https://www.espn.com/mlb/stats/fielding/_/year/2021/position/ss/order/true)), relative to anyone who plays baseball recreationally (by this measure, it was outstanding), or relative to Sano’s prior seasons (by this measure, it [was one of the best of his career](https://www.baseball-reference.com/players/s/sanomi01.shtml#standard_fielding)). Instead, we’d do as we do with most numbers we read but don’t entirely understand: gloss over it, assume the number and the adjectives that describes it are correctly associated, carve a subconscious groove between “Miguel Sano” and “good fielder” in our head, and move on.

The COVID case figures are also correct. But was it a spike? That’s entirely subjective. It’s not a spike [because it’s an increase from a low baseline](https://twitter.com/NateSilver538/status/1512542115808616454). It is a spike [because case counts are meaningless](https://fivethirtyeight.com/features/coronavirus-case-counts-are-meaningless/); you have to adjust for testing rates. It’s not a spike because people are taking far fewer precautions than they were earlier in the pandemic, so some increases are expected. It is a spike because more people are vaccinated; relative to the size of the unvaccinated population, the case count is alarming. 

As with Sano’s stats, a superficial read of the original argument would likely make us think we’re in the midst of another surge.[^5] But unlike Sano’s stats, COVID cases are hard to contextualized. It’s a gray area, and people can easily tilt us to one side or the other by simply saying which one they want us to believe—and in this case, by doing nothing more than using the verb “spiked.”

The TikTok story is just one of many examples where something is described as “going viral,” and some big-sounding number of views or shares is tacked on to prove it. But going viral (appropriately, like “a spike in cases”) is a vague, idiosyncratic term. Was Chris’ post widely viewed? Is hundreds of thousands of views a lot? On one hand, it’s certainly more than your average blog post on the [future of SQL as a semantic modeling language](https://benn.substack.com/p/has-sql-gone-too-far) gets. On the other hand, some of Chris’ videos now [get tens of millions of views](https://www.tiktok.com/@stuftnacho/video/7030502034319215878). Other TikToks—like [slightly hypnotizing ten-second clips](https://www.tiktok.com/@bellapoarch/video/6862153058223197445) of head bobbing and lip syncing—get 686 million views and [launch pop careers](https://en.wikipedia.org/wiki/Bella_Poarch). And some YouTube videos—like [slightly nauseating jingles of cheap ](https://www.youtube.com/watch?v=XqZsoesa55w)*[Blue’s Clues](https://www.youtube.com/watch?v=XqZsoesa55w)*[ knockoffs](https://www.youtube.com/watch?v=XqZsoesa55w)—have been watched ten *billion* times. So how do we judge Chris’ first Taco Bell TikTok? According to how the *Washington Post* tells us to.

Finally, the Reels figure is the most challenging of all. It’s true that Reels “only” accounts for six percent of people’s time on Facebook, but there’s no realistic way to know if that’s an impressive number or an abysmal one. What do you benchmark it against? The last time a company that has [three billion active users](https://investor.fb.com/investor-news/press-release-details/2022/Meta-Reports-Fourth-Quarter-and-Full-Year-2021-Results/default.aspx) launched a product designed to compete with [the most popular website on the planet?](https://www.wsj.com/articles/tiktok-was-the-internets-most-visited-site-in-2021-even-beating-google-11640204147) While Facebook surely has internal targets, they’re likely inventions of bias and PR-motivated sandbagging. Moreover, Facebook is free to spin the Reels rollout however they want—just as he did in February, when [he declared the product a smashing success](https://www.facebook.com/zuck/posts/10114335272495801). As outside observers, we have little choice but to cautiously accept his position, or to categorically deny it because, of course that’s what he’d say.

The point of all of this isn’t to say that data is worthless, or that all numbers are unredeemable lies. The point is that people often use data to tell a story—we almost went the way of the dinosaurs; Miguel Sano is a good fielder; we can’t shake COVID; a single TikTok video launched a movement; Facebook’s new feature is a flop. In doing so, people are sometimes compelled, by dishonesty, bias, or the simple desire to say something interesting, to twist that story to fit a particular narrative. As readers, we’ve been taught to be vigilant against such transgressions, and to watch out for doctored data, lying charts, and deceitful statistics. But to the talented con man—or more generously, the clever marketer—these flamboyant crimes are a distraction, [a magician’s misdirection](https://www.youtube.com/watch?v=Lo5BRAKvJoA) from the real, direct action that’s taking place right under noses: People can spin stories simply by [telling us what to think](https://www.youtube.com/watch?v=sbVPcPL30xc). It’s not the data that gets us, but the adjectives that describe it.

Once you notice this phenomenon, you see it everywhere. Nearly every news story, every blog post, every analyst report, and even every email that references some corporate statistic follows the same pattern: A datapoint, and a brief description—or subtle nudge, like the word “just”—tells us what it means. Ask yourself though: Would you come to the same conclusion with the data alone? As often as not, we wouldn’t—not because the conclusion is wrong, but because, when presented with data on some domain we don’t deeply understand,[^6] we have no choice but to look for clues and shortcuts to help us make sense of those numbers. Our best shortcuts are typically the words around the data, so we interpret it the way we’re told to. The claim decodes the data, and the data proves the claim.

So what do we do about it? I’m not sure there’s that much we can do. Most people aren’t trying to deceive us; we can’t throw out every number as a conspiracy theory; there’s a fine line between healthy skepticism and tin hat paranoia. Sometimes, we have to have faith in the system, and accept that the odds that we botch [“our own research”](https://www.nytimes.com/2022/01/03/opinion/dyor-do-your-own-research.html) are higher than the odds we’re being lied to.

But we should at least acknowledge that we should be as wary about words as we are charts. As Cassie Kozyrkov put it in her retort to [W. Edwards Deming’s famous quote](https://www.goodreads.com/quotes/7327935-without-data-you-re-just-another-person-with-an-opinion), “without data, you're just another person with an opinion,” *with data*, you’re still [just another person with an opinion.](https://towardsdatascience.com/becoming-a-real-data-analyst-dcaf5f48bc34) Though we often assume these opinions are camouflaged in clumsy chart crimes, it’s far more common for them to be spelled out in plain language. And when people tell us their opinions, [we should believe them](https://twitter.com/drmayaangelou/status/609390085604311040?lang=en).


---


[^1]: Tell me you’re putting together a presentation on data science without telling me you’re putting together a presentation on data science.

[^2]: It’s so cliché that, after typing “correlation doesn’t eq”, my [Google editor](https://benn.substack.com/p/we-all-have-an-audience?s=w#:~:text=the%20only%20true%20editor%20is%20Google%20autocomplete) suggests the rest for me.

[^3]: As it happens, I know this California man. Delete this email; close this tab; unsubscribe from this Substack; read the *Washington Post* article;  follow him; join his movement. You won’t be disappointed.

[^4]: [And David Perell’s](https://benn.substack.com/p/the-more-the-merrier?s=w#footnote-7).

[^5]: Which raises the question: What is a surge?

[^6]: Which, for most of us, is every domain, minus maybe one or two.

================================================================================

# How much is 265 billion dollars?

*A few ways to quantify the unquantifiable. *

---

![](https://substackcdn.com/image/fetch/$s_!kKea!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F32bad06f-c540-4b3d-8d3c-29b1475c0bbf_1920x817.jpeg)
*[burning billions of dollars.](https://www.reddit.com/r/theydidthemath/comments/215i6y/how_much_money_did_the_joker_burn_in_the_dark/)*

In case you didn’t hear, earlier this week, Elon Musk bought Twitter. Unfortunately for all of us, this is now the only thing we can talk about. The news is full of armchair psychologists trying to parse Elon Musk’s every motivation; Silicon Valley is full of newly minted management consultants offering their opinions about Twitter’s executive team; Twitter itself is full of amateur Constitutional law scholars, making up stuff about free speech. [We’re drowning in takes.](https://twitter.com/MattZeitlin/status/1519742313349668864)

Despite that, there’s one character in this story—the main character, in a way—that’s been almost entirely ignored: Elon Musk’s money. Yes, every story about him makes the obligatory mention that he’s the world’s richest person. But the [scale of his fortune](https://www.google.com/search?q=elon+musk+worth&oq=elon+musk+worth&aqs=chrome..69i57.3015j0j7&sourceid=chrome&ie=UTF-8)—$265 billion—is a number that’s nearly impossible to comprehend, the sort of thing that we gawk at but make no real attempt to truly understand. Most efforts to explain it are absurd “comparisons”—Elon Musk is worth more than all but [25 companies on the S&P 500](https://fknol.com/list/market-cap-sp-500-index-companies.php)! If you took 265 billion one dollar bills and laid them end-to-end, they’d stretch from here to Venus!—that are no easier to grasp than the original figure. I have no idea how to value S&P 500 component [Fastenal](https://en.wikipedia.org/wiki/Fastenal),[^1] and likening unfathomable amounts of money [to unfathomable distances](https://images.app.goo.gl/wMtc7dVACSB1ox5w8) doesn’t help me much either. 

So, if we’re all going talk about Elon Musk as much as it seems like we’re doomed to do, we owe it to ourselves to better describe his most defining attribute. Here are some other attempts:

—

If you made $10 million for every point Steph Curry [scored in his entire career](https://www.basketball-reference.com/players/c/curryst01.html#totals)—banking $300 million from [Wednesday night’s game](https://www.espn.com/nba/game/_/gameId/401430255) alone—you’d still have less money than Elon Musk. 

—

Jeff Bezos, the world’s second richest person, is worth $178 billion. If Bezos founded and entirely owned Southwest ($27 billion), United ($16 billion), Delta ($28 billion), and American Airlines ($12 billion), he’d also be worth less than Elon Musk.

—

Speaking of airlines, in 2019, before travel was shut down by the pandemic, people flew [just over a billion flights](https://www.faa.gov/air_traffic/by_the_numbers/media/Air_Traffic_by_the_Numbers_2021.pdf) in the United States. The [average airline ticket](https://www.fool.com/the-ascent/credit-cards/articles/the-average-cost-of-domestic-airfare-is-260-5-tips-to-save-more-money-on-air-travel/) costs $260, implying that Elon Musk could afford to buy every commercial airline ticket in the entire country for a year.

—

[According to the World Bank](https://pip.worldbank.org/home), the poorest 583 million people in the world make, on average, about $1.25 a day. Elon Musk could personally pay all of these people—roughly seven percent of the global population—for a year. 

—

During the Reddit-driven [GameStop short squeeze](https://benn.substack.com/p/runaway-train?s=w) in January of 2021, shares of GME rose thirty-fold, from $17 to over $500 at their peak. [Keith Gill](https://en.wikipedia.org/wiki/Keith_Gill), the straw who stirred the entire frenzied drink, was the first Redditor to take a major position in GameStop. Through a series of high-leverage trades, he turned his original $53,000 investment into as much as $48 million. If Gill sold his GameStop position at its peak, reinvested all his earnings into another meme stock that went just as vertical as GameStop, sold *that *stock at its peak, and then put his resulting $44 billion of wealth into the S&P 500 (which averages a 7.5 percent annual return), he’s be worth $265 billion in 25 years. 

—

I work out at an average-sized Crossfit gym.[^2] By rough count, the gym has 2,800 pounds of plates, 900 pounds of bars, 1,100 pounds of dumbbells, and 1,100 pounds of kettlebells. [Gold currently costs](https://www.bloomberg.com/quote/XAU:CUR) $1,900 an ounce. At this price, my gym could replace all of their equipment with weights made of solid gold for $177 million. With his money, Elon Musk could replace the weights of nearly 1,500 gyms with solid gold. [There are 1,149 Crossfit gyms in all of Brazil. ](https://www.livestrong.com/article/13730816-crossfit-statistics/)

—

Over the last fourteen years, Marvel Studios [has put out 27 films](https://en.wikipedia.org/wiki/List_of_Marvel_Cinematic_Universe_films) that have cumulatively grossed $25.6 billion worldwide. If one person made every Marvel movie on their own, and pocketed every dollar of ticket sales from every film, they’d have to continue making movies, at the same pace and scale of success, for the next 130 years to be as rich as Elon Musk. Over that time, they’d need to make 252 more Marvel movies.

—

There are roughly [one million restaurants](https://www.foodindustry.com/answers/how-many-restaurants-are-there-in-the-united-states/) in the United States, and the average chain restaurant [has 130 items on the menu](https://www.restaurantbusinessonline.com/consumer-trends/does-menu-size-matter#:~:text=The%20average%20number%20of%20offerings,trending%20as%20we%20enter%202019%3F). If you assume the average item costs twenty dollars, Elon Musk could order the entire menu from every restaurant in the country for more than three months. 

—

The biggest California Powerball lottery prize is currently [$454 million](https://www.calottery.com/draw-games/powerball#section-content-1-3). Imagine you won this lottery. Now, imagine, you spent your entire winnings on 227 million [$2 California Dreamin’ lottery scratchers](https://www.calottery.com/scratchers/$2/california-dreamin-1506), and every single one of them was a $1,000 winner—each ticket beating the 1-in-157,107 odds. You’d still be worth $40 billion less than Elon Musk. According to Google’s calculations, the odds of this string of events happening is one in infinity.

![](https://substackcdn.com/image/fetch/$s_!RYDT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa7e41b4c-9dab-43f2-a298-a1ab83fbd412_1314x178.png)

—

The city of San Francisco takes up [47 square miles](https://en.wikipedia.org/wiki/San_Francisco), or thirty thousand acres. An [acre of forest](https://gvwire.com/2020/09/15/california-forests-80-600-denser-than-150-years-ago-uc-researcher-says-biomass-is-one-of-the-answers/) contains about 170 trees, and trees have, [by one estimate](https://www.wired.com/2012/12/how-many-leaves-are-on-this-tree/), about fifty thousand leaves. If all of San Francisco was a forest, and every leaf on every tree in that forest was replaced with a one dollar bill, the forest would contain $255 billion.

—

[Economists estimated](https://data.worldbank.org/indicator/NY.GDP.MKTP.CD) that the global economy produced $84 trillion worth of goods and services in 2020. This averages out to $230 billion a day, suggesting that Elon Musk could, for one day, buy everything produced in the entire world.[^3] 

—

In *Monster, *[Nicki Minaj said](https://genius.com/34679?) she was paid “50K for a verse.” Last year, [432 major hip hop albums](https://en.wikipedia.org/wiki/2021_in_hip_hop_music) were released, rap albums [have an average of 16.1 songs](https://www.homemusicproducer.com/how-many-songs-should-a-rap-album-have/), and I’d guess the average rap song has three verses. If Nicki Minaj wrote every verse on every album in 2021—and was paid fifty grand for all of them—she’d make just over a billion dollars. For her to be worth as much as Elon Musk is today, she’d have to have been producing verses at this rate for the last 254 years, since 1768. Beethoven was [born in 1770](https://en.wikipedia.org/wiki/Ludwig_van_Beethoven).

—

The average life insurance policy in the United States [pays out $168,000](https://www.retireguide.com/life-insurance/statistics/#:~:text=average%20life%20insurance%20payout%20is%20roughly%20%24168%2C000). If the governor of Maine took out a policy on [every person in the state](https://www.google.com/search?q=maine+population&oq=maine+population&aqs=chrome..69i57.3510j0j4&sourceid=chrome&ie=UTF-8)—and then murdered them all—they’d collect slightly less money than Elon Musk is worth.

—

The [cumulative salary](https://www.basketball-reference.com/contracts/players.html) of the entire NBA is $4.25 billion. If you garnish the wages of every player in the league, you’d be worth as much as Elon Musk in 62 years, in 2084. For comparison, Wilt Chamberlain made his NBA debut [62 years ago](https://en.wikipedia.org/wiki/Wilt_Chamberlain#Philadelphia/San_Francisco_Warriors_(1959%E2%80%931965)).

—

About [sixty tech companies](https://news.crunchbase.com/news/heres-whos-gone-public-in-2021-so-far/) went public in 2021, including Coinbase (valued at $86 billion), Roblox ($30 billion), Rivian ($67 billion), and Didi Chuxing ($73 billion). These companies IPO’d with a cumulative market cap of just over $750 billion dollars. If you founded all 62 of these companies, and managed to retain a [very respectable ten percent](https://craft.co/reports/how-much-equity-do-founders-have-when-their-company-gets-to-ipo) equity stake in every company, you’d be worth $75 billion dollars. To be worth the same amount as Elon Musk, you’ve have to repeat this feat for two and half more years, founding and taking public a total of 218 companies.

—

In *Office Space, *several of the characters develop a scheme [to shave fractions of a penny](https://www.youtube.com/watch?v=yZjCQ3T5yXo) off of every financial transaction processed by Initech, their soulless corporate employer. Suppose you masterminded your way into an engineering position at Visa, and applied the same [salami slicing](https://en.wikipedia.org/wiki/Salami_slicing_tactics#Financial_fraud) malware to their payment processing system. If you were able to shave half a cent off of every transaction, you’d collect about $1.2 billion a year from the [232 billion transactions](https://usa.visa.com/dam/VCOM/global/about-visa/documents/aboutvisafactsheet.pdf) Visa processes every year. To be as rich as Elon Musk, you’ve have to run this scheme for 220 years. 

—

According to this [random set of calculations on Quora](https://www.quora.com/On-average-how-many-faces-does-a-human-being-see-in-his-her-lifetime), we see about 3 million faces in a lifetime. [Americans have a median net worth](https://www.forbes.com/advisor/investing/average-net-worth/) of $121,000. That means, if you’re an American and in your thirties, Elon Musk is probably worth about the same as the combined net worth of every person you’ve ever seen in your entire life. 

—

$265 billion is *less* than the [market capitalization of Coca-Cola](https://twitter.com/elonmusk/status/1519480761749016577).

While we're here, I do have one final, brief thought on this whole circus. There is a plain and obvious problem with Elon Musk owning Twitter: One man will have taken complete control of *the* major artery of mass political communication and elite discourse. He can, if he so chooses, browse fifteen years of politicians’ DMs. He can, if he so chooses, resurface fifteen years of deleted tweets. He can, if he so chooses, put his finger on dozens of invisible scales that tilt the global discourse in whatever direction he prefers. He may not—as his supporters like to say, [he has other companies to run](https://www.inc.com/justin-bariso/elon-musk-twitter-multitasking-productivity-how-to-solve-problems.html). But the vault is his; he can make do with it as he pleases; and if he does, we’re unlikely to ever know.

Proponents of the deal ignore this clear danger because, I suspect, they like Elon Musk. Yes, he’s one man who bought the digital nuclear codes, but he’s *their* man. Better those codes be in his hands than owned by a board they don’t respect, or a few thousand employees whose imagined values they don’t like.

I don't like Elon Musk. I don't like the blind eye he turns to the [racial discrimination and bigotry](https://www.latimes.com/business/story/2022-03-25/black-tesla-employees-fremont-plant-racism-california-lawsuit) happening on his watch. I don't like his [dumb middle school jokes](https://twitter.com/elonmusk/status/1517707521343082496). I don't like his idea of fun, and I don’t want [a maximum amount](https://twitter.com/elonmusk/status/1519495072802390016) of it in the world. 

But even if I attempt to put that aside, I don’t like a private citizen, accountable to no one, buying an enormously influential piece of our social infrastructure. Some things—nuclear weapons, access to the pictures on every iPhone on the planet, the entire world’s Chrome browsing history, Gmail’s servers—shouldn’t be for sale.[^4] 

If you disagree—as [Ted Cruz](https://twitter.com/SenTedCruz/status/1519144947991130118?ref_src=twsrc%5Etfw) does—cover Elon Musk with a [Rawlsian veil of ignorance](https://ethicsunwrapped.utexas.edu/glossary/veil-of-ignorance). Suppose someone conquered the infinite odds of the California Powerball, and outright bought YouTube, Instagram, or iMessage. Suppose this unknown buyer—a retiree in Modesto, a teenager in Portland, [Joe the Plumber](https://en.wikipedia.org/wiki/Joe_the_Plumber), AOC, Tila Tequila,[^5] Ronan Farrow, Vladimir Putin, anyone—now has unfettered access to the knobs that drive public debate, and to a decade of your personal communications, like, say, [Ted Cruz’s likes and DMs](https://www.theguardian.com/us-news/2017/sep/12/ted-cruz-twitter-account-likes-pornographic-tweet). Do you support the deal? 

There are only two answers. You can either support people’s right to spend money how they please—you know, [free speech](https://www.brennancenter.org/our-work/research-reports/citizens-united-explained)—and accept the anonymous purchase, or you can object to it, on general principle, because no one person should be entrusted with that power, no matter how many lotteries they win. 

The only other option is to just admit that you like Elon Musk, that you like the idea of him being in charge, and that nearly everything else is a rationalization for rooting for your guy.


---


[^1]: We’re all trying to make fancy tech companies, and Fastenal is out here building [a $33 billion business](https://www.google.com/search?q=fastenal+ticker&oq=fastenal+ticker&aqs=chrome..69i57.1945j0j7&sourceid=chrome&ie=UTF-8) on…I don’t know, tape and screws?

[^2]: Unsubscribe [here](https://benn.substack.com/action/disable_email).

[^3]: And, honestly, I’d sell him a day’s worth of work if it meant that, after that one day, he was out of money and we never had to hear from him again.

[^4]: Yes, most of these are owned by private sector companies, and employees and executives could, in theory, go spelunking through these things just as easily as Elon Musk could at Twitter. But boards and public companies provide a mix of shared accountability and collective disorganization that make it much more difficult for one man to bend the world to his whims.

[^5]: Who apparently [became a Nazi](https://en.wikipedia.org/wiki/Tila_Tequila)?

================================================================================

# The case for consolidation

*It’s what the people want.*

---

![Crush Them': An Oral History of the Lawsuit That Upended Silicon Valley -  The Ringer](https://substackcdn.com/image/fetch/$s_!Fll-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc550a2-cc63-4c2c-88b3-95011a4051c8_1400x830.jpeg)
*Just don’t call it a monopoly.*

We were going to change the world, but for $1.2 billion, we settled for trying to change Microsoft.

My first job in the tech industry was working as a data analyst at [Yammer](https://www.microsoft.com/en-us/microsoft-365/yammer/yammer-overview), a company that built a social networking and communication tool for businesses. Our mission was to revolutionize workplace collaboration by dragging people out of email chains and [reply-all meltdowns](https://www.nytimes.com/2016/09/02/technology/when-im-mistakenly-put-on-an-email-chain-should-i-hit-reply-all-asking-to-be-removed.html?_r=0),[^1] and into the feeds, groups, and threads that had been pioneered by social media companies. Though I’m generally too ornery to say nice things about starry-eyed visions like these, Yammer, when used to its full potential, lived up to its promise. 

Shortly after I joined, however, we were [acquired by Microsoft](https://techcrunch.com/2012/06/25/its-official-microsoft-confirms-it-has-acquired-yammer-for-1-2-billion-in-cash/).[^2] We got absorbed into the Office division, our product roadmap became an integration roadmap, people starting leaving, and eventually, [Yammer was relegated](https://www.microsoft.com/en-us/microsoft-365) to the "More" line item in the Microsoft 365 product catalog. 

We didn’t always think we were doomed to this fate. Microsoft wouldn’t assimilate us, we told ourselves at the time of the acquisition; we’d indoctrinate *them*. I still remember the all-hands meeting after our executive team came back from their first meeting in Redmond. We were told how we were going to change how Microsoft built and shipped software; how we were going to make them more data-driven; how we were going to be a beacon of technology, innovation, and culture inside of the buttoned-down, tucked-in, khaki, IT giant. 

The presentation struck me as odd. Yammer was collecting revenues in the low eight figures and burning through a bonfire of cash every quarter. Microsoft, by contract, practically ran a printing press in their basement. They made [$73 billion in 2012](https://www.microsoft.com/en-us/Investor/earnings/FY-2012-Q4/press-release-webcast#:~:text=For%20Microsoft's%20fiscal%20year%202012,billion%2C%20and%20%242.00%20per%20share.), bringing in more money every five hours than we had in our entire company's history. We were going to tell them how to make software? We were four years old, had a few hundred employees, an HR team of two, and the most defining part of our culture was our weekly, uh, "alcohol"-fueled parties. They employed [nearly 100,000 people](https://www.statista.com/statistics/273475/number-of-employees-at-the-microsoft-corporation-since-2005/). Their HR team was so big that [its chief](https://en.wikipedia.org/wiki/Lisa_Brummel) could afford a WNBA team. We were going to teach her how to build a corporate culture, and how to fix their performance management framework?

To be clear, Microsoft didn't get everything right, and Silicon Valley would crucify me as a traitor to the founder class if I said we should listen to the old guard rather than disrupt them. But Microsoft certainly didn’t get everything *wrong*. Even though our brash, opinionated ideals had won us some measure of success, seeing such staggering prosperity, built on an approach that was antithetical to ours, should’ve led us to ask if our doctrines were as bulletproof as we thought they were.

Which brings me to the modern data stack.

# Microscopic

[As](https://twitter.com/sarahcat21/status/1509049980530544643) [has](https://sarahsnewsletter.substack.com/p/modernity-value?s=r) [been](https://roundup.getdbt.com/p/keep-data-council-weird?s=r) [discussed](https://twitter.com/juansequeda/status/1506709882845736967) [at](https://benn.substack.com/p/we-all-have-an-audience?s=w) [length](https://twitter.com/g_xing/status/1508148185188896772), the modern data community talks about tools a lot. If you spend any time around today's data water coolers—on Twitter, in dbt’s and Locally Optimistic’s Slacks, scattered across a few dozen newsletters and Substacks—you'll find endless discussions about startups and the products they build. We hype products [in closed betas](https://twitter.com/__kvm/status/1521590108884926465);[^3] we ask if it’s time to [unbundle and reinvent software that’s been around for seven years](https://humansofdata.atlan.com/2022/03/great-data-debate-unbundling-bundling/); we all aspire to [be the next Snowflake](https://accelerationeconomy.com/data/next-snowflake-neo4j-firebolt-raise-452-million-cloud-database/), the crown jewel of the modern data stack.

Microsoft is often nowhere to be found. There are no discussions about the latest Synapse updates,[^4] or what’s on PowerBI’s roadmap. SQL Server comes up from time to time—usually when people are trying to debug some integration with a different tool, or when they want to migrate away from it entirely. In the [countless](https://future.a16z.com/emerging-architectures-modern-data-infrastructure/) [diagrams](https://twitter.com/ValentinUmbach/status/1418242294952644611/photo/1) [we](https://www.datafold.com/blog/modern-analytics-stack) [draw](https://continual.ai/post/the-modern-data-stack-ecosystem-spring-2022-edition) of the modern data stack, Microsoft is persona non grata.

But in the market, Microsoft is anything but. PowerBI is the—probably overwhelming—leader in business intelligence. By [one estimate](https://www.trustradius.com/vendor-blog/business-intelligence-statistics-and-trends), it captures more than a third of the total spend on BI, nearly double second-place Tableau’s share and six times that of Looker.[^5] And PowerBI has opened up a [Secretariat-sized lead](https://www.youtube.com/watch?v=AG_27cCW5bw&t=103s) in Gartner's [magic quadrant](https://www.cxtoday.com/analytics/gartner-magic-quadrant-for-analytics-and-business-intelligence-platforms-2022/) for analytics tools. 

SQL Server's numbers are even more impressive. Microsoft reportedly [made $5 billion](https://www.crn.com/news/cloud/300072551/microsofts-enterprise-software-price-hikes-paying-off-as-sql-server-business-hits-5-billion-mark.htm) from the database *in 2014*. Assuming SQL Server’s been growing by a relatively modest ten percent a year since then, that figure could be as high at $10 billion today, across [180,000 customers](https://enlyft.com/tech/database-management-system). By comparison, Snowflake [closed their year](https://investors.snowflake.com/news/news-details/2022/Snowflake-Reports-Financial-Results-for-the-Fourth-Quarter-and-Full-Year-of-Fiscal-2022/default.aspx) with six thousand customers and $1.1 billion in revenue. While these aren’t quite apples-to-apples numbers—SQL Server solves operational and transactional warehousing needs that Snowflake doesn’t yet try to address—the broader point remains: Microsoft is a dominant player in the data industry. SQL Server and PowerBI alone—to say nothing of Synapse, Cosmos, Azure’s analytics and AI tools, and especially Excel—probably make more money than the entire "modern data stack" ecosystem does put together. 

And yet, the two communities don't interact. They occupy the same space but pass silently by one another, like matter and dark matter, one in the [Upside Down](https://strangerthings.fandom.com/wiki/The_Upside_Down) and the other in the Right Side Up (?).[^6] Customers, too, live in these parallel worlds, evaluating modern data stack vendors or evaluating Microsoft, but rarely crossing over. 

One explanation for this is boring: The sets of tools solve different problems for different people. Microsoft has historically dominated the mid-market and middle America. Pick a random company from the Russell 2000, like [Vitamin Cottage Natural Grocers](https://en.wikipedia.org/wiki/Vitamin_Cottage_Natural_Grocers), and I bet they’re a Microsoft shop. The modern data stack, by contrast, is—or at least, was—by and for the tech industry. 

This probably isn’t the only explanation though. Much of Silicon Valley looks at Microsoft in the same way that we did at Yammer: As aging, wooden, and square; as the makers of Sharepoint, Outlook, Internet Explorer, *Zune*. The tech community—and by extension, the data community that lives in it—doesn’t value things for where they are, but for how fast they're rising. Nobody talks about the CEO of a public company growing at twenty percent a year, or the VP who’s been a VP for six years. We talk about the people and companies *on the cusp*—the rocketships, the wunderkinds, the new new things.  

Like Yammer, we in the data world should pay more attention to Microsoft.[^7] We should ask if it’s us—and not the company that’s worth more than [Marvel Studios would be if it keeps making huge blockbusters for a thousand years](https://benn.substack.com/p/how-much-is-265-billion-dollars?s=w)—that’s missing something.  

# Proprietary, monolithic, locked-in

Over the last several years, a few ideas have become axioms in the data community: Open-source languages are better than proprietary ones; tooling should be modular, so that customers can mix and match their favorites; vendor lock-in is bad. Though we quibble about specifics, these issues are, for all intents and purposes, settled law.[^8] 

On one hand, I agree—these principles are noble ambitions, and, all else equal, better than their alternatives. 

On the other hand, all else isn’t equal. Building an ecosystem on these ideals comes at a cost. And if Microsoft is any guide, it’s not clear that customers want to pay it. 

Because Microsoft—which owns arguably the most successful suite of data tools in the world—represents the opposite point of view. Microsoft’s languages and tools are, though not strictly proprietary or closed off, largely segregated from the rest of the market. Microsoft [tightly](https://powerbi.microsoft.com/en-us/power-bi-and-azure/) [integrates](https://powerbi.microsoft.com/en-us/power-bi-and-office/) its products, [aggressively packages](https://www.microsoft.com/en-us/microsoft-365/enterprise/e5?rtc=1&activetab=pivot:overviewtab) them together, and generates as much as [95 percent of its commercial revenue](https://blogs.microsoft.com/blog/2019/02/05/inspired-and-powered-by-partners/) through its [enormous partnership ecosystem](https://en.wikipedia.org/wiki/Microsoft_Partner_Network). This creates an insular dynamic where, if you use Microsoft infrastructure, you’re strongly incentivized to put Microsoft tooling on top. Unsurprisingly, that’s what data teams do: In the last 12 months, there have been [four times as many searches](https://trends.google.com/trends/explore?geo=US&q=PowerBI%20Azure,PowerBI%20AWS,PowerBI%20Snowflake) for “PowerBI Azure” as “PowerBI AWS” and “PowerBI Snowflake.”

This, combined with Microsoft’s dominant position in the market, suggests that customers actually* *don’t care about modularity. They don’t actually mind proprietary languages. They want products that work, and products that work together. Modularity and flexibility are useful to the extent that they’re means to those ends. 

Take vendor lock-in, for example. When we [bought Snowflake](https://benn.substack.com/p/the-end-of-big-data?s=w) a few years ago, we took some comfort in the fact that it supported a vanilla flavor of SQL. If we found ourselves wanting to migrate away from Snowflake, it would be reasonably painless. But how many product improvements would we have traded that optionality for? Would we prefer Snowflake adhere to the ANSI standard, or offer a set of proprietary functions or [features](https://docs.snowflake.com/en/user-guide/data-sharing-intro.html) that we like? The answer then, now, and in the future, is the latter. We don’t want to be locked in, but more than that, *we don’t want to have to migrate at all*.

The same applies to other principles. I prefer open-source frameworks—unless [Fivetran](https://www.fivetran.com/blog/fivetran-vs-stitch) is just more reliable than [Stitch](https://www.stitchdata.com/blog/introducing-singer-simple-composable-open-source-etl/) or [Airbyte](https://airbyte.com/etl-tools/fivetran-alternative-airbyte). I like modularity—until [it leads to](https://en.wikipedia.org/wiki/Phonebloks) “drops in signal quality, lower data transfer speeds,” and a [failing user experience](https://benn.substack.com/p/the-modern-data-experience). As they say, a value isn’t a value until it costs you something. And if I’m honest with myself, thinking as a buyer rather than builder of data tools, I’m not willing to pay very much to hold on to them.[^9] 

If Microsoft’s customers are any indication, I’m not alone. Quite the opposite—the world appears to be full of people who will pay a premium for a consolidated collection of tools, packaged and bundled into a neat little suite, sold on a single bill. 

# The idealist versus the army

Maybe, in the long run, our principles pay off. But there’s an alternative scenario: We’re building the next Slack.

Slack burst onto the scene around the same time as the modern data stack. It, too, was the darling of Silicon Valley, the envy of every startup, and the subject of [breathless profiles](https://www.singlegrain.com/casestudies/growth-study-slack-the-fastest-business-app-growth-in-history/) chronicling its rise. 

And then, it got [bulldozed by Microsoft Teams](https://kinsta.com/blog/microsoft-teams-vs-slack/). Slack’s heralded product-led growth was no match for the reach of the Office bundle and the ruthlessness of Microsoft’s sales legions. Consolidation and convenience—[especially for enterprise buyers](https://www.vox.com/recode/2019/9/19/20874094/slack-startups-microsoft-kruze-etr-charts)—sells better than a delightful product. 

In Silicon Valley, where [Slack remains popular](https://www.vox.com/recode/2019/9/19/20874094/slack-startups-microsoft-kruze-etr-charts), this outcome is almost unthinkable. Slack executed perfectly, and built a product everyone loved. How is it not the winner in the space it created?

The answer, I think, is that for those of us who work in software, it’s easy to place undue value on [craftsmanship](https://dannorth.net/2011/01/11/programming-is-not-a-craft/). In some modified version of [Goodhart’s law](https://en.wikipedia.org/wiki/Goodhart%27s_law), we make the ideal the product, and (unwittingly, I’d say) assume the best products are those that best adhere to those ideals.

In data products, modularity, flexibility, and composability are markers of our craftsmanship. But [most people](https://dannorth.net/2011/01/11/programming-is-not-a-craft/) “don’t care about the aesthetics of software in the same way non-plumbers don’t care about the aesthetics of plumbing—they just want their information in the right place or their hot water to work.” They just want software that helps them sell more vitamins at the grocery store.

Microsoft, which can provide those ends without our idealistic means, is perfectly happy to cast craftsmanship aside. They’re happy to consolidate everything under one branded, proprietary banner, make it all work together, and send out an army of sales reps to steamroll the rest of us with it. 

If this strategy worked against Slack, it could easily work against the disjointed and sprawling modern data stack. Consolidation, it turns out, may be less of [economic necessity](https://benn.substack.com/p/data-and-the-almighty-dollar?s=w), and more of a product opportunity. 


---


[^1]: If you have any friends who worked at Microsoft ten years ago, ask them what they think of [TDD Dojo](https://twitter.com/MemesArentData/status/299241515027402753).

[^2]: In a story that’s still ridiculous to me, news of the deal leaked because [someone tweeted that they overheard people](https://twitter.com/SarahTaylor/status/213066291915923456) talking about it in a coffee shop a few blocks from the Yammer office.

[^3]: I’m a [personal investor](https://benn.substack.com/p/disclose-your-angel-investments?s=w) in Modal.

[^4]: Pop quiz: What’s Synapse?

[^5]: Ok, real question: What’s the protocol on citing sites [like](https://enlyft.com/tech/database-management-system) [these](https://www.trustradius.com/vendor-blog/business-intelligence-statistics-and-trends)? Or places like [Statista](https://www.statista.com/statistics/267805/microsofts-global-revenue-since-2002/), which look almost reputable, but have a few too many ads and paywalls to be fully trusted? Are these numbers real, or are they just nerdy content farms that generate random charts and blogs programmatically, like the [creepy channels on YouTube Kids](https://www.theverge.com/culture/2017/11/21/16685874/kids-youtube-video-elsagate-creepiness-psychology)? Their numbers seem in the ballpark, but every time I go to one of these sites, I feel like I’m somehow being had.

[^6]: It’s left to the reader to decide who is who.

[^7]: After Microsoft acquired us, our collective response to their changes was to say “ok boomer,” and leave. In the ten years since the deal, Microsoft’s stock is up 900%.

[^8]: Ha.

[^9]: Put another way, how much more would you pay for Fivetran if the product were exactly the same, but it was built on an open-source framework? How much less would you pay for dbt if it were proprietary? Yes, these changes might make vendors build better or worse software, but that’s the point: Tenets like these are a means to an end, and as a customer, I pay for the ends.

================================================================================

# The best decision is one

*Optionality kills. And why data teams aren’t here to help us make better decisions.*

---

![JCVD: Why a Volvo Ad is Jean-Claude Van Damme's Biggest Hit in Years -  Variety](https://substackcdn.com/image/fetch/$s_!5DYl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb609308a-2f9b-4998-b248-55e4b3ceded5_1000x562.jpeg)
*[Startup Roadmap (Live Test)](https://www.youtube.com/watch?v=M7FIvfx5J10)*

In the course of talking about data startups on the internet, people on the internet occasionally ask me for my thoughts on their data startups. Most of the time, the questions are from founders who are just starting out—they have no employees, a couple rough ideas of what they could to build, and a big decision to make about which one to choose.

Until recently, I’ve tried to answer their questions by doing my best impression of a good analyst. I’d weigh their ideas against each other, try to assess the likelihood that a small company could build each product and make enough noise in crowded market to pick up early customers, match that with my own guesses about the trends in the industry, and, once all the numbers were totaled, read them the printout from my adding machine. I’d then say that I’m just one person; take my thoughts with a healthy grain of salt; keep doing your research; talk to prospective customers; listen to other voices in the community. Until you have more feedback, more evidence, and more conviction, keep your options open. 

With apologies to anyone I’ve had this conversation with…this was bad advice.

Instead, I should’ve said one thing: It doesn’t matter what you choose. If you’ve already done some research and narrowed a dozen mixed ideas down to a couple promising ones, both are probably good. The work you have left to do isn’t more research; it’s to make—and commit, fully and truly—to a decision. 

To propose an analytically heretical axiom about big choices like these, *making the decision is more important than the decision you make*. The success of a startup—or of a strategic decision in an established company, or even, to go all *Chicken Soup for the Soul *for a moment,[^1] of decisions in life and love—doesn't depend on the specific choice. It depends on how committed you are to that choice. Often, we don’t fail because we choose the wrong thing; we fail because we refuse to choose anything at all.

# The euphemisms of indecision

There's nothing terribly interesting about saying it’s good to be decisive. The world is full of quotable lines that make this point—[fortune favors the bold](https://en.wikipedia.org/wiki/Fortune_favours_the_bold);[^2] [if you fail, fail while daring greatly](https://en.wikipedia.org/wiki/Citizenship_in_a_Republic); [disagree and commit](https://en.wikipedia.org/wiki/Disagree_and_commit); [it’s a leap of faith, Indy.](https://www.youtube.com/watch?v=sBBbq2g7yf8) If anything, startups publicly [overstate their confidence in what they’re doing](https://benn.substack.com/p/metadata-money-corporation?s=w#:~:text=You%20need%20to%20extrapolate%20six%20months%20of%20paid%20trials%2C%20sold%20to%20friends%20and%20previous%20coworkers%2C%20into%20a%20five%2Dyear%20revenue%20projection%20that%20exceeds%20%24100%20million.), and why it’s destined to succeed.

But there’s a difference between the bold claims in pitch decks and the corporate aphorisms that purportedly define our management style, and how many startups are actually run. In practice, a lot of companies are much more tentative—they just hide it behind euphemisms about iteration, optionality and [weakly held opinions](https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/).

Consider, to use the example from earlier, an early stage startup looking to decide which product to build. 

The company starts by doing their market research, as [the gospel](https://en.wikipedia.org/wiki/Lean_startup) instructs them to. They talk to industry experts, identify key competitors, find unsolved problems, and confirm those pain points with potential customers. They begin to build a product and develop a market position that addresses all of these needs. 

Wisely, they're measured in their commitments. We've only talked to a tiny corner of the market, they say, and our sample is badly biased. It would be foolish to extrapolate a ten-year vision from a couple dozen interviews and feedback from our immediate network.

As they launch their initial private alphas and open betas, the company stays closely engaged with their initial customers. They bless these relationships by christening their first customers as “design partners”. Their react to their users’ reactions: Some features unexpectedly resonate and they double-down on them; others matter less than anticipated, and get trimmed from the roadmap. Early customers nudge the company closer to product market fit.

Some questions, however, remain unanswered. Should the company build for this adjacent persona? Should they try to solve that related problem? We’ll figure this out over time, the startup says. We’ll keep our options open. As we grow and gather more feedback, the right choices will become clear. The [paradox of choice](https://en.wikipedia.org/wiki/The_Paradox_of_Choice) is a fallacy; our flexibility, responsiveness, and close observation of the data will give us an advantage over large but rigid incumbents. 

This strategy sounds solid, and it matches what most startup manuals will tell you to do. But it’s often be a bad one, because it can get overwhelmed by another, more powerful force: The erratic and enticing pull of the market. 

Early stage startups are often hungry for customers, and, out of a genuine and noble desire to solve problems for people, eager to help people who see potential in what they’re building. When you’re looking for whatever traction you can find, it’s difficult to turn down excited users, and even harder to not be swayed by their opinions.

This introduces a dangerous dynamic. Most customers don’t buy a startup’s product for what it is; they buy it for what they hope it will become. Unless the startup clearly and consistently tells their customers exactly where they’re headed—which is antithetical to agility and informed iteration—customers will do that extrapolation themselves. They’ll see features one and two, and draw a line to features three through ten. For some customers, this roadmap will be an educated guess as to where the startup is headed; for others, it’ll be an unconsciously biased projection in the direction that they want the product to evolve; and for the shrewd ones, it’ll be the feature set they intend to actively pressure the company to build. 

Regardless of their motivations, customers will not only tug in slightly different directions, but their continued use of the product will also be, to some degree, contingent on the startup responding to their pull. None of this is said so explicitly though; it happens subtly and slowly, one roadmap chat and prioritization exercise at a time. At each step, the logical step for the startup is to be receptive to the feedback, to leave the door open for future customers and segments, to stay flexible to a changing market, *to maintain optionalit*y. But eventually, the company will find itself stretched across multiple visions, unsure of where it’s supposed to go next and who it’s building for, precariously perched between markets and customers that aren’t nearly as stable as [Volvo Dynamic Steering](https://www.youtube.com/watch?v=M7FIvfx5J10). And unlike Jean-Claude Van Damme, most of us can’t do the splits.

# Know thyself

To save ourselves from being quartered by the market, we have to take choices off the table. We have to *remove* optionality. To warp another line from Amazon’s corporate handbook, we have to artificially [turn two-way doors into one-way doors](https://www.inc.com/jeff-haden/amazon-founder-jeff-bezos-this-is-how-successful-people-make-such-smart-decisions.html).

The problem with maintaining choice is that it allows us to drift between decisions. For the startup that “keeps its options open,” early setbacks might encourage it to experiment with other ideas. They might divert time and money towards the second idea or architect their product in ways that make a potential pivot easier, undercutting their efforts to make the first idea successful.[^3] 

But more often than not, either idea would work, so long as the company is sufficiently committed to figuring out how to make it work. That’s because most business decisions aren’t like picking a number on a roulette wheel, where we lay down our bet, and wait for the fickle winds of fate to tell us how we did. Instead, outcomes depend on both what we choose *and what we do after we choose it*. 

[Loath as I am to admit it](https://benn.substack.com/p/how-much-is-265-billion-dollars?s=w), people like Elon Musk are effective executives for exactly this reason. For all their downsides, megalomaniacs can have one advantage over more grounded leaders: They’re unwilling to even entertain alternative points of view.[^4] Once they’ve made up their mind, their egos refuse to allow them to turn around.[^5] The companies and employees under them have one choice: Make the decision work. 

To be clear, I’m not advocating for all startups to [be run like Tesla](https://www.npr.org/2022/02/11/1080073061/california-sues-tesla-racism-fremont), or for CEOs to model their leadership style after that of Elon Musk.[^6] And committing to a decision doesn’t have to create the “fight or die” pressure that the [original boat burner](http://blenheimpartners.com/wp-content/uploads/2019/01/Burn-the-Boats.pdf) (and the [CEO of Costco](https://www.businessinsider.com/costco-founder-warned-ceo-not-to-raise-hot-dog-price-2020-9)) tried to engineer. My point is less dramatic: There are lots of paths to success, but the paths are often long. Once you choose one, stay on it. Stay firm in your identity to both yourself and your customers. And worry about overcoming the particular obstacles on the road you’ve chosen, rather than wondering if the other paths are shorter or less challenging.

# Data teams aren’t here for decisions

Data teams have a role to play in this effort. If you ask an experienced analyst what their job is, the enlightened answer is that it’s to help companies make better decisions. I’ve said this [plenty of versions of this](https://benn.substack.com/p/method-for-measuring-analytical-work?s=w) myself, and when I ask questions like this to [our job candidates](https://boards.greenhouse.io/modeanalytics/jobs/4055629), it’s the answer I like to hear. 

I’m coming to realize, however, that it’s probably wrong. As data folk, we’re not here to help organizations make better decisions; we’re here to create better results. While that distinction can seem pedantic—isn’t a good decision one that leads to a good result, and a good result the outcome of a good decision?—there is a meaningful difference. 

As mentioned earlier, good outcomes come from both good decisions and a commitment to see that decision through. Data is often helpful for the former requirement. It can be much more problematic for the latter.  

If the data tells a clear story, it can corral diverging opinions into a clear consensus. For the startup debating their product vision, a conclusive piece of analysis can constantly remind people, through the ups and downs of building that roadmap, why it’s still the right one.

But in the more common case, data fails to tell such a neat story. It usually paints a more nuanced picture, full of uncertainty, probabilities, and estimates of “[epistemic status](https://www.lesswrong.com/posts/oDy27zfRf8uAbJR6M/epistemic-effort).” There will always be reasons why some strategy might be wrong, or why the road not taken might’ve been right. Data that highlights this creates a lot of room for doubt in decisions—doubt that tends to linger long after they’ve been made. In this light, careful, unbiased analysis can flip from an invaluable asset to a subversive liability the moment a company transitions from evaluating their options to executing on them.

As analysts, it can be tempting to say this isn’t our problem. Our job is to figure out what’s true. If those truths require us to reevaluate our prior choices, so be it.

I want to say this. I want this to be my job, to stand on the principle that something [roughly shaped like the truth](https://benn.substack.com/p/tilt-and-tilted?s=w) is out there, and to leave the politics of that truth to those [who have the courage to make decisions with it](https://benn.substack.com/p/does-data-make-us-cowards?s=w). 

But I think that’s a dereliction of our duty. Pharmaceutical companies can’t take credit for the therapeutic wonders of their drugs without taking responsibility for how they can be abused. And we can’t turn a blind eye the effect that our caveats and analytical exceptions can have on a company’s commitment to its prior decisions. Our job—like everyone else’s—is to make things better. It’s to improve results. And we can’t do that just by helping people make decisions. We also have to help people stick to them. 


---


[^1]: Gotta love that the Chicken Soup for the Soul franchise is owned by a (publicly traded?) [parent company](https://en.wikipedia.org/wiki/Chicken_Soup_for_the_Soul) called Chicken Soup for the Soul *Entertainment*, which really [gives away the grift](https://benn.substack.com/p/the-more-the-merrier?s=w#footnote-7) on what these supposed inspirational self-help brands are really all about. (Also, if there was ever a time for blithe, uncomplicated stories about how it’s all going to work out, you’d think it’d be in the middle of a stock market crash. [Guess not](https://www.google.com/search?q=csse&oq=csse&aqs=chrome..69i57j69i60l2.945j0j7&sourceid=chrome&ie=UTF-8).)

[^2]: No word yet on if fortune favors [sleazy confidence men for borderline-criminal pyramid schemes](https://www.youtube.com/watch?v=9hBC5TVdYT8) that [bankrupt people](https://www.bloomberg.com/opinion/articles/2022-05-11/terra-flops).

[^3]: This is true in plenty of other domains as well. In writing this blog post, for example, I was waffling between it and a piece on the market’s recent swan dive. Up until 24 hours ago, my mind constantly wandered to that piece, and this post is worse for that indecision.

[^4]: [issuing a preemptive correction on this post, regarding megalomaniacs. you do not, under any circumstances, "gotta hand it to them."](https://twitter.com/dril/status/831805955402776576?lang=en)

[^5]: Falling stock prices, on the other hand, seem to be [more persuasive](https://www.washingtonpost.com/technology/2022/05/13/musk-twitter-bid/).

[^6]: There’s also a potential logical problem with drawing any lessons from people like Elon Musk. In many competitive environments, the biggest winners are often those who operate with reckless abandon. But that’s different than saying that those who operate with reckless abandon often win. In Silicon Valley, we see the successes like Elon Musk, but rarely hear about the failures. So before we celebrate Elon Musk’s managerial style, we have to consider how many other people tried it and didn’t get so lucky.

================================================================================

# Free fall

*Reflections on a crash.*

---

![](https://substackcdn.com/image/fetch/$s_!YYXs!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0b34bab7-17a7-4d02-9492-a5deac6d61ca_1200x600.jpeg)
*[Everyone’s looking for the bottom.](https://www.youtube.com/watch?v=QGHAjoVUQjQ)*

For the third time in my adult life, giant charts of plunging stock markets are back on the front pages of the *New York Times* and *Wall Street Journal*. The last time this happened was 2020, as COVID and pandemic-induced lockdowns halted the global economy; the time before that was the 2008 financial crisis, and the Great Recession that followed. 

I was a senior in college at the beginning of the 2008 crash, and I wasn’t terribly concerned by it. At first, it was a disaster happening at a distance. 

That space closed quickly. Within a few weeks, the jobs I was applying for started to disappear; then the one job offer I had got pulled. In the spring of 2009, I shotgunned out an array of new applications, and ended up with a position at a think tank in Washington, D.C.

When asked, in polite company, why I moved to DC, I would’ve said something about my interest in economics and policy, or made general gestures at the service my employer provided to the country and world. But this wasn't true. I didn't see DC or my job as a lever for impact; I saw them as a ladder to success. Underneath my socially acceptable answer about creating a better world was something much more vain and self-serving: I wanted a good résumé. In the absence of a professional passion, I was blindly chasing prestige. I'd lived my adolescent life collecting trophies—grades, a college degree, snotty extracurriculars. The job I was offered in 2009 was the best option I had to add something new to the case, the “[next opportunity for extrinsic validation](https://yaledailynews.com/blog/2011/09/30/even-artichokes-have-doubts/).”

I was by no means alone. From aimless twenty-somethings who went to law school or became McKinsey consultants because it "would give them the most options in the future," to nakedly ambitious politicians and political operatives, DC is full of people who are strivers first, and everything else second. 

The social strata of DC were defined by this scaffold. People sorted themselves by where they stood on the hierarchy, and measured their success in the same way. How notable was the NGO that you worked for? Who did you know on the Hill? How many floors at the State Department was your office from Hillary’s? When ambition is your professional stimulus, it quickly becomes your social sieve and, worse still, the scale on which you weigh your personal worth.

San Francisco is built on similar ground. Over the last decade, people—again, myself included—moved to SF not for our love of technology, but to achieve. At what, we didn’t know and didn’t exactly care. But the city was overflowing with accomplishment and money, and we wanted a piece. 

Like in DC, most people in the tech industry aren’t so gauche as to say this outright.[^1] We were there, we say, to “have an impact,” the cliche that’s replaced its now-parodied predecessor, “[make the world a better place.](https://www.youtube.com/watch?v=B8C5sjjhsso)” But as in DC, the silent scoreboard that hangs over SF’s entire professional order has nothing to do with impact or social good; it has to do with money and startup hype. How much venture capital did your employer raise, at what valuation, and how early did you join? Conference speaking slots, times on calendars, and even party invites are dolled out according to the answers to these questions. 

In this context, fundraising rounds and startup valuations are more than financing mechanics; they’re yardsticks for our careers, and an unspoken sorting algorithm for social interactions.[^2] In the most cynical cases, companies get created not to build products, but to manufacture accomplishment.[^3] Ambition and success—measured almost exclusively by the size of your associated numbers on Crunchbase—became ends unto themselves.

# The hottest fires

In recent weeks, those numbers have turned ugly. The S&P 500 is on the precipice of entering its [third bear market](https://www.nytimes.com/article/stock-market-correction.html) of the last two decades, and tech stocks have led the way down. The Nasdaq has lost nearly a third of its value in the last six months. Venture capital markets are seizing up. Startups that investors would’ve valued in the billions six months ago are now thought to be worth a fraction of that.[^4] 

The drop triggered the usual flurry of reactions from investors. Some VCs turned to scolds, lecturing startups about how the last two years were all fantasy.[^5] Some looked to exploit the crash for clout, and rushed out their apocalyptic “[RIP Good Times](https://articles.sequoiacap.com/rip-good-times)” predictions. Some beat their chest about the need for belt tightening and pencil sharpening, and blustered on about how, “back in their day, they had to walk to Sand Hill Road, in the snow, up hill, both ways, just to get told that their profitable company wasn’t ‘a good fit,’” and how that was all the motivation they needed to keep building. 

The more helpful VCs have tried their best to [read the tea leaves](https://docs.google.com/presentation/d/1Hyn4FWHSNRrWJeddi0BMEQIMlmXy2SNj50T8jJcrKbw/edit#slide=id.g11953bc14ff_2_47),[^6] and [provide guidance through the turmoil](https://www.youtube.com/watch?v=vBkzm4a7iY4). Though [most assessments](https://techcrunch.com/2022/05/19/yc-advises-founders-to-plan-for-the-worst/) [are bleak](https://future.a16z.com/framework-valuation-navigating-down-markets/), they close with the same tepid [pep](https://future.a16z.com/framework-valuation-navigating-down-markets/#:~:text=Some%20of%20the%20strongest%20businesses%20are%20forged%20in%20the%20toughest%20times) [talks](https://www.youtube.com/watch?v=vBkzm4a7iY4&t=1548s): Great companies are built in tough times; it’s good to focus on sustainability over growth; Silicon Valley was too frothy; this correction is a healthy reset. 

For most of us in Silicon Valley, the situation is not, in any real sense, dire. We have well-paying jobs, and employable skill sets if we were to lose them. Still, speaking as a startup employee caught up in the maw of the storm, I initially resented these VC talking points. Even if they’re true, pithy, regurgitated lines about the hottest fires forging the hardest steel feel like framing a bad performance review as an “opportunity for improvement”—a thin euphemism for a steeper road leading to a smaller prize. For a preeminent VC, more disciplined valuations represent a couple years of lower returns and more rigorous diligence;[^7] for people in the arena, they’re the invisible hand of the market taking a hatchet to how you and your entire professional network value what you’ve spent years building. 

On reflection, though, there is wisdom in these points. They’re just aimed at the wrong problem. For it’s not the technical dynamics of the venture market that need a reset—it’s us.

# The fall will set you free

When Zoom filed for an IPO in 2019, Silicon Valley [was in awe](https://twitter.com/josh_coyne/status/1109195249614614528) of its business. Eighteen months later, after Zoom became a [word of the year](https://www.forbes.com/sites/barrycollins/2020/11/23/zoom-zings-into-the-oxford-dictionary-words-of-the-year/?sh=6ba4e0c5a465), the company’s stock was up 400 percent. According to some Wall Street analysts, [its ceiling was another 400 percent higher](https://finance.yahoo.com/news/zoom-stock-has-surged-nearly-400-is-it-time-to-buy-hold-or-run-away-161839582.html), equal to the combined value of Verizon and AT&T. Over the next year, the price nearly doubled. 

Today, amid the receding pandemic and the market crash, Zoom is *down *85 percent from its peak. 

Little, I imagine, about Zoom has actually different. Its product hasn’t gotten 85 percent worse; its culture isn’t a fraction of what it once was; Eric Yuan, Zoom’s CEO, is probably the [same caliber of CEO](https://india.sequoiacap.com/article/zoom-ipo-how-eric-yuan-delivers-happiness/) that he was in 2019. By most sensible measures, Zoom hasn’t changed that much over the last three years, despite financial markets not being able to decide if it’s worth $18 billion or $160 billion. 

In other words, if Zoom’s stock price is its scoreboard, it’s a terrible one—driven by a mix of [randomness](https://en.wikipedia.org/wiki/A_Random_Walk_Down_Wall_Street), [animal spirits](https://en.wikipedia.org/wiki/Animal_spirits_(Keynes)), [the murderous whims of an egomaniacal dictator](https://en.wikipedia.org/wiki/Vladimir_Putin), and worldwide [Acts of God](https://www.investopedia.com/terms/a/act-god.asp). Zoom judging itself by its stock price is no different than Zoom judging itself by the day’s weather.

And yet, in today’s tech industry, it's how we judge ourselves every day. The startup valuations and financing rounds that stratify Silicon Valley may not shift as often as a stock, but they’re just as fickle. 

Rather than despair during bad storms such as these, we should use them as an opportunity to let go. No matter how much we want to stay dry, we can’t control the weather. There’s no sense in congratulating ourselves for sunny days, or in crying when it rains. 

This isn’t a call for nihilism or to reduce our ambition; it’s a reminder to pay attention to what we’re ambitious about. Instead of chasing money and hype, we can chase the things we can both control and say we’re motivated by—creating things that make people happy, building a company that provides good jobs, working with people we like, and enjoying what we do every day. 

Despite its builder ethos, the zeitgeist in Silicon Valley will demand we keep staring at its current scoreboard. The tech press report on new fundraisings; VCs will promote their latest unicorns; conferences will book their CEOs as speakers. But we can choose to see value in other things. We can celebrate our professional peers the way we do musicians—by what they create, not by their record deals—and doctors—by the good they do, not by what they’re worth. We can listen to people who aren’t rich, and, just as importantly, don’t have to listen to everyone who is. We can choose to look away from the stock market. We just have to have the courage to let go of what it represents.


---


[^1]: This is one thing I appreciate about New York: Rich people say they’re here to be rich. A huge swath of the financial industry may be a collective leech on the American economy, but at least they’re direct about why they’re doing it.

[^2]: Go to a party or conference in SF, and you can see this happen in real time. As people figure out who else is there, they slowly cluster themselves by their respective “ranks.”

[^3]: To ask the uncomfortable question, how many of [these companies](https://benn.substack.com/p/the-data-os?s=w#:~:text=In%202021%2C%20they%20funded%20100.) were started to solve a problem, and how many were started because the founders wanted to be founders?

[^4]: In slightly more technical terms, revenue multiples, the ratio of a company’s valuation to its annual revenue, are compressing. In 2021, quickly growing companies raised rounds at 100x multiples or more (which is, historically, astronomically high), meaning that company that made few million dollars a year might be valued at more than $1 billion. Today, that same company would likely be worth closer to 20x revenue, or less than $100 million.

[^5]: One such lecture came from a fund that, a year ago, bragged to a prospective investment about how little diligence they would do on their proposed round, which valued the company at several hundred times its revenue.

[^6]: [I believe the market is going to fluctuate.](https://quoteinvestigator.com/2013/09/28/market-fluctuate/)

[^7]: And cheaper prices.

================================================================================

# The technical pay gap

*The culture we build is the culture we buy. *

---

![The 'real' Rosie the Riveter dies at 96 | CNN](https://substackcdn.com/image/fetch/$s_!Fe7K!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F73e3a09d-0e1f-4567-98ee-11438c36556c_1200x675.jpeg)

If you ask ten data organizations what titles they use on their teams, you’ll get eleven different answers. Some teams call everyone data analysts; some teams call them all data scientists. Some teams have data analysts, data scientists, and data engineers. Some now have analytics engineers and [machine learning engineers](https://careers.twitter.com/en/work-for-twitter/202103/905948c1-caca-4173-89bf-2f5231182003/bebfcb6f-143c-4864-b158-1a07afeead1e.html/senior-machine-learning-engineer-topics-nlp.html). Some prefer [BI developers](https://jobs.apple.com/en-us/details/200380219/frontend-bi-developer?team=MKTG). [Some call](https://medium.com/@chamandy/whats-in-a-name-ce42f419d16c) data analysts data scientists, and data scientists research scientists. Some have [business analysts](https://g.co/kgs/ikZrzt), or [business data analysts](https://g.co/kgs/3Anacn), or [data business analysts](https://g.co/kgs/7hYjxi). Some put [data scientists on analytics teams](https://boards.greenhouse.io/doordash/jobs/2173764), and some put [analysts on data science teams](https://g.co/kgs/HKuBmm). And some just give, mash it all together into a Russian nesting doll, and call it a [data science analyst/engineer](https://jobs.nyulangone.org/job/15612736/associate-data-science-analyst-engineer-new-york-ny).[^1] 

This [mangled Venn diagram](https://twitter.com/ElenaRunsNYC/status/1483651998335614978) of disputed boundaries and overlapping responsibilities makes it very hard to figure out what people’s jobs are. It makes it even harder to figure out what they should get paid.

Though job titles can sometimes seem like little more than an aesthetic (in)convenience, they serve an important financial function. When companies create pay scales and salary bands for different roles, those bands are typically benchmarked against industry standards for that title. For example, when a company wants to figure out what it should pay a senior data analyst, it often starts by asking what the market pays senior data analysts, and adjusts from there. 

Without a clear consensus on titles—if there’s no commonly accepted definition for what a data analyst is—this entire exercise happens on very unstable ground. This is bad for teams, who want to match roles with the right candidates. It’s bad for companies, who want to fairly compensate their employees. And it’s bad for job seekers, especially those new to the industry, who are trying to figure out which skills to acquire and how much they should be paid for doing so.

No blog post is going to fix this. Even in the simplest of cases, compensation is a frighteningly complicated subject; a few hundred words on the subject is a pathetically shallow attempt to swim in very deep water.[^2] 

However, we can’t stay out of that water entirely—especially not right now. The last few years have been a whirlwind for the data industry, with the introduction of hundreds of new tools, dozens of new responsibilities, and several new roles. If we don’t talk about pay—because it’s complicated, because it’s taboo, or because we assume it’ll just sort itself out—pay bands and industry habits will settle along the same [biased](https://www.pewresearch.org/science/2021/04/01/stem-jobs-see-uneven-progress-in-increasing-gender-racial-and-ethnic-diversity/#:~:text=of%20STEM%20workers.-,STEM%20workers%20often%20earn%20more%20than%20others%2C%20but%20there%20are%20sizeable%20pay%20gaps%20for%20the%20typical%20STEM%20worker%20by%20gender%2C%20race%20and%20ethnicity,-Pew%20Research%20Center) [lines](https://venturebeat.com/2021/09/14/data-science-hasnt-fixed-its-huge-gender-pay-gap/) that they always have. We shouldn’t waste this opportunity to outline something better.

# Unequal pay for unequal work

To follow [Erica Louie](https://twitter.com/ericalouie/status/1525254273398820864) and [Michael Kaminsky](https://twitter.com/Mike_Kaminsky/status/1525622949641854977), both of whom rightly led us into this water last week, I have one principal hope for how these salary norms develop: Analysts and analytics engineers should *not* be paid the same.

Generally speaking, the two roles do different things, and one tends to be more complex than the other. Analytics engineers are responsible for maintaining ELT pipelines, writing a lot of SQL in dbt, architecting a DAG and authoring tests, and keeping a close eye on Snowflake bills. They also have to work with non-data folks to translate their semantic understanding of the business into tables and metrics that accurately reflect that definition.

Analysts, by contrast, often embed themselves alongside non-technical teams, turn ambiguous, qualitative problems into quantitative ones, build dashboards (reluctantly), do in-depth analyses (excitedly, supposedly), and try to influence decision makers with their work. They work in tools like dbt as well, though they’re typically more concerned about the logical details in individual models than the overall cleanliness of the DAG.

These sets of responsibilities require different skills, some of which are much harder to acquire and hone than others. We should pay people accordingly—and, therefore, analysts should make more than analytics engineers. 

Wait, what?

It’s telling, I think, that this feels like a radical proposal. Even suggesting it feels like a troll, a hot take, a cheap controversy for some clicks. Whenever we talk about the relative pay of analysts and analytics engineers, there seem to be two options: They get paid the same, or analytics engineers get paid more. I’ve never actually heard anyone suggest that it’s analysts, in fact, who do the more valuable, harder, higher-skilled work. 

But you could easily make the case that they do! People in both roles need to know SQL, probably to an equal degree. Python is helpful, though not entirely necessary. The two roles live in similar tools, and both have to work closely with other people at the company to understand their business needs.

There are a couple places where the roles diverge. Analytics engineers, who need to be comfortable with git and know their way around the command line, are marginally more technical than analysts. This isn’t a huge technical leap though, and many analysts have a passing familiarity with these tools.

For their part, analysts are often engaged in more “soft” issues. They have to identify which business challenges are most pressing, figure out how to solve squishy, shape-shifting problems, and package their conclusions into persuasive narratives, all while navigating their stakeholders’ organizational politics. It’s [messy](https://benn.substack.com/p/analytics-is-a-mess), [uncomfortable](https://benn.substack.com/p/does-data-make-us-cowards), and—at least in my experience—far harder than git.

Case in point: The Analytics Engineering Club offers [a thirty- to forty-hour course](https://analyticsengineers.club/course-overview/) to help analysts learn the skills necessary to become an analytics engineer. It would take far more than a week’s worth of work to train a data engineer to become an even passing analyst.[^3] 

If analytics engineering skills aren’t harder to acquire, why do we generally assume that, if anyone’s to be paid more, it’s the analytics engineer? Why, until writing an entire (now ripped up) draft of this post, did I not even consider the possibility of the reverse?

# New rules 

One explanation is that analytics engineering is a new role, so it’s a supply problem; salaries will come down, at least relative to analysts, as the field cools.[^4] That seems possible, especially given the [current hype](https://www.businessinsider.com/data-analytics-engineer-dbt-tech-job-salary-skills-needed-2022-5) around the role. 

Another explanation is that the job is viewed as tedious or dull, and higher pay is necessary to attract people into it. Unlikely; if anything, analytics engineering has a [reputation for the opposite](https://tdwi.org/articles/2022/02/28/ppm-all-analytics-engineers-have-sexiest-job.aspx).

A third possibility is that analytics engineers are a subset of analysts. They have to have the same skills, and then some. While that may be true in some companies, it’s atypical. The [tweet that prompted](https://twitter.com/chetchavat/status/1525188296908865540) Erica’s original thread suggests the roles are overlapping, but not concentric. 

Do analytics engineers produce more valuable work than analysts? Maybe, though this is immensely difficult to measure. Moreover, most people’s assumption that analytics engineers should get paid as much as analysts seems to be rooted in their gut reaction to the comparison, not in a careful study of which role’s nebulous output creates more shareholder value.[^5] 

To me, the most plausible explanation is a simpler one: Silicon Valley overvalues technical skills. For several reasons—some with understandable origins, some with [deeply sexist ones](https://www.thenation.com/article/society/gender-silicon-valley/)—the industry puts inherent and unquestioning value on being able to write code. If you can do it, you get paid more, full stop. Engineers are unimpeachable; those who architect HR policies or write effective marketing copy are replaceable.[^6] 

Within the data industry, we’re affected by the same gravity. Analytics engineering, through its name and its gesturing in the direction of data engineering, paints itself with a thin technical veneer. In Silicon Valley, that type of touch up—the sort that lets you rebrand yourself as a “systems thinker,”[^7] as a shape rotator and not a wordcel—comes with a raise.

I don’t think this is a good thing. The work analysts do, especially the non-technical, interpersonal parts, is valuable and exhausting. If the natural tilt of Silicon Valley encourages us to pay analytics engineers more, we’ll pull analysts, including those who are uniquely talented in *that* role, to move into a different one for higher pay and more prestige. 

Given the choice, I’d rather the hill slope the other way. I’d rather overvalue analysts. People who are great at working on uncertain questions, digging for tough answers, and fighting to make sure others hear them are fewer and farther between than people who’d rather cancel their Zoom meetings to write code. If a wide net is needed to find the best [“above replacement”](https://en.wikipedia.org/wiki/Wins_Above_Replacement) talent, it’s needed for analysts.

By paying analysts more, we can also break down some of the historic rot that has denigrated “feminine” soft skills. The data industry can signal that, no, we don’t blindly pay for technical ability, nor do we use gendered credentials as proxies to figure out if you’re smart. Instead, we pay you to work with people; to communicate; to influence; to understand and listen and support. 

The data community has made commendable ([though imperfect](https://benn.substack.com/p/who-is-the-community?s=w)) progress in welcoming more diverse members into its ranks. That’s a form of winning, but, if we build a cultural hierarchy that’s organized by technical talent, we won’t rewrite the sexist rules that govern the game. So here’s to [counting off some new rules](https://www.youtube.com/watch?v=k2qgadSvNyU), and paying analysts more.


---


[^1]: I would’ve preferred they go with the turducken approach, and called this datalsciengineer.

[^2]: So deep that [people can win Nobel prizes](https://www.nobelprize.org/prizes/economic-sciences/2021/summary/) for devoting their lives to studying one aspect of it.

[^3]: To be clear, this isn’t an indictment of the Analytics Engineering Club, which appears to cover the major topics it needs to cover. It’s a measure of the relatively short distance from analyst to analytics engineer.

[^4]: For context, according to [Glassdoor](https://www.glassdoor.com/Salaries/index.htm) and [Comparably](https://www.comparably.com/), data analysts in the Bay Area make an average of about $100,000 a year, compared to $110,000 for analytics engineers.

[^5]: Put another way, if we want to claim that analytics engineers produce more valuable work than analysts, we have to actually make that claim. What work do the two produce, and why is the former’s more valuable?

[^6]: Spend an afternoon on Hacker News, and you can’t help but wonder how many engineers assume nobody can do their jobs, but they can do everyone else’s.

[^7]: When recruiters design hiring programs, they think about how outreach sequences, interview panels, and closing processes all interact. When marketers run campaigns, they think about the relationship between branding, segmentation, product offerings, and marketing content. When sales reps work accounts, they balance complex political dynamics across champions, decision makers, budget holders, and deal approvers. Self-proclaimed systems thinkers aren’t unique because they think in systems; they’re unique because they think they’re smarter than everyone else for doing so.

================================================================================

# All your database are belong to us

*The machines are coming for our jobs, and…they might actually help? Plus, free advice for Steve Kerr and Ime Udoka. *

---

![All Your Base Are Belong To Us has turned 20 - The Verge](https://substackcdn.com/image/fetch/$s_!JT6m!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa027b6e5-257d-4d9e-8d20-8fb7f0cb316d_1400x788.jpeg)

Name a robot. 

Seriously, take a moment, and think of a robot. But not just any robot—pick the robot that you think everyone else would choose if they were asked the same question. Before you read on, write it down, for the culture:

[Take the survey!](https://docs.google.com/forms/d/e/1FAIpQLScS2AGYR-p0JYU35eD_vDfsGrktErDrP1OnjBmWQq1hjZDhaA/viewform)

> While we’re waiting for the webinar poll to finish (and to put some space between the test and the answer key), let’s take a brief, uh, timeout to talk about the NBA Finals.
> It’s a sequence that happens in nearly playoff game. The home team goes on a run. There's a massive, [career-defining block](https://www.youtube.com/watch?v=OnFWhYHvoWQ)[^1] on one end of the court; the crowd goes wild. The block leads to a three on the other end; the crowd gets louder. On the next possession, a turnover, an outlet pass, a fast break, a booming dunk; pandemonium. 
> To stop the run, the coach of the away team takes three disgusted steps onto the court, snaps off a timeout, and wheels back to his huddle, glaring at his assistants. Mark Jackson hits us with [a dumb catchphrase](https://www.youtube.com/watch?v=xVm41b5jImU), and all of us watching on TV are unceremoniously dumped into a State Farm commercial.
> As a fan on the couch, the timeout, which ejects me from a delirious arena into a [cringy sales pitch for crypto](https://www.ispot.tv/ad/b5F2/ftx-stephen-curry-is-not-a-crypto-expert-featuring-stephen-curry), kills *my* excitement. But does it kill the home team's momentum? Are these timeouts, which coaches commonly take, actually useful?
> Six years of [play-by-play data](https://www.kaggle.com/datasets/schmadam97/nba-playbyplay-data-20182019) says they aren’t. 
> From 2015 to 2021, there were about 20,000 runs in the NBA, where a run is defined as the home team scoring at least eight of the last ten points in an uninterrupted stretch of play (e.g., no end-of-quarter breaks, no other timeouts, etc).
> In 5,000 cases, the away team took a timeout, after which they scored an average of 5.16 points over the next ten points in the game. Though this seems positive—they broke the run!—most runs actually break themselves. In the 15,000 instances in which the away team didn’t take a timeout, they scored an average of 5.13 points over the next ten game points.
> Moreover, timeouts have no effect at all if the run happens slowly. Of the 20,000 runs, about 12,000 took more than two minutes to develop. For those runs, the away team performed slightly better when they *didn’t* take a timeout. This is summarized in the table below, which shows the average number of points scored by the away team after a run by the home team.
> Anyway, back to robots.

When I was asked to name a robot, my answer was WALL-E. If I had been asked to list a few more, I would’ve said [HAL](https://en.wikipedia.org/wiki/HAL_9000), R2-D2 and C-3PO, and whatever [those things are](https://www.youtube.com/watch?v=uhND7Mvp3f4) that Boston Dynamics builds, which were clearly created by someone who was a little too obsessed with *MechCommander* as a teenager.

I'm told that these are pretty typical answers—for us olds.[^2] If you ask a [youth](https://www.youtube.com/watch?v=K6qGwmXZtsE) the same question, nearly all of them will give the same appalling answer: Alexa. 

As should be obvious to anyone with a modicum of sense, Alexa is not a robot. It does not have lightbulbs for eyes; it doesn't speak to us in foreign yet relatable beeps; it doesn't even have a real body. Alexa is no more of a robot than autocorrect, Google search, or my Spotify Discover playlist.[^3] 

But, if I’m more honest with myself than I care to be, these things *could* be robots. They don’t look like people, or do the things that we human beings do. But, to go full high school term paper for a sentence,[^4] [Webster defines robots](https://www.merriam-webster.com/dictionary/robot) as “devices that automatically perform complicated, often repetitive tasks.” That fits, if it must. Though I’ll never call Alexa a robot, I can at least concede that our lives are being taken over by the machines, even if they don’t look like the ones the movies of my childhood anticipated.  

The same, I’m starting to think, will inevitably be true of the data industry. 

# Putting the artificial in artificial intelligence

I’ve long been skeptical of robots’ ability to perform the tasks of data professionals. Despite their hype, nearly all the tools that add automation to analysis—be it augmented analytics, AI-powered insight discovery, anomaly detection and alerting, or NLP querying—feel underwhelming. [Augmented analytics](https://www.tableau.com/learn/articles/augmented-analytics) tools, which market themselves as needle detectors for our giant haystacks of data, find mostly useless correlations, some spurious ones, and the occasional meaningful one. Alerts from anomaly detection services quickly become car alarms in a crowded parking lot: annoying false positives we learn to ignore, and wait for someone else to turn off. And NLP interfaces encourage us to ask questions about precise subjects in imprecise language, and hope that some black box built by three twenty-something YC founders with eighteen months of experience at Palantir trained a model that makes the same nuanced assumptions about what “weekly run rate by segment” means that I am. 

Moreover, machine learning is often a structurally inappropriate solution for a lot of the problems that analysts want to solve. Your standard business question—for example, why are customer retention rates down, and what do we do about it—is deeply affected by lots of exogenous and qualitative factors. It relies on very few observations, like a couple dozen customers churning across a customer base in the hundreds. And, as both [Randy Au](https://counting.substack.com/p/accidentally-trapping-ourselves-with) and [Sean Taylor](https://notes.causal.engineering/archive/locally-optimal/) called out in posts this week, decision makers don’t care about “technical” statistical significance; they want to see real, meaningful effects. To paraphrase Sean paraphrasing Garrett van Ryzin, when business leaders see an impact that matters, they don’t need statistics to know it.

In this light, today’s data robots aren’t much help. They’re oblivious to external forces; they confound themselves on small datasets; they can’t easily distinguish between statistical significance and colloquial significance.[^5] Even [the academics are unimpressed](https://arxiv.org/abs/2008.13060): “The auto-insight tools we reviewed often provide relatively simple facts...Some visualization researchers feel that the auto-insights generated by existing tools do not align with the conceptualization of human insights being deep and complex.”

This is why analysts ([should](https://benn.substack.com/p/the-technical-pay-gap)) get paid. They have to account for unaccountable factors. They have to draw concrete conclusions from uncertain trends. They have to know which statistically insignificant differences matter, and which statistically significant ones don’t. This requires an intuition and creativity that today’s robots don’t have. Boston Dynamics [may be able to kill me](https://www.youtube.com/watch?v=chPanW0QWhA), but they can’t replace me.

Or I used to think that. Now, I’m not so sure. 

# Putting the art in artificial intelligence 

In dismissing the potential of AI in analytics, I’m falling into the same trap that I did with Alexa. I’m assuming that if we’re going to be conquered (or helped) by some robot army, it’ll look and act the same as I do—not physically, perhaps, but procedurally. It would alert me of the same concerns I worry about, answer the same questions I’m trying to answer, or produce the same output that I’m trying to produce. The problems it solves, in other words, would be familiar to me today. 

Intellectually, it’s easy to see the flaw in this way of thinking—most big technological advances *change* problems as much as they solve them[^6]—but it’s hard not to be constrained by it. To anticipate what something like AI might do to our lives, we have to look beyond the curve of the horizon, and imagine worlds we can’t yet see. As a technological cynic and general curmudgeon,[^7] I’m not cut out for that kind of thinking.

Fortunately, Sean Taylor is. In the [same post](https://notes.causal.engineering/archive/locally-optimal/) as I mentioned earlier, Sean asked a provoking question: Could product managers use [DALL-E 2](https://openai.com/dall-e-2/), OpenAI’s rather remarkable image generating technology, to create dozens of new ideas for products to test? Could the tool’s seeming creativity serve as a substitute for our own? Is it possible that—ironically—giant, complicated regression machines are actually better at solving creative problems than they are at finding anomalous regressions?[^8] 

And could we do the same thing for analysis? In addition to producing an image or product proposal, an AI could generate reports and decks of business problems and metrics that attempt to explain them. While most of them might not make sense, there might be some revolutionary nuggets, like the “alien” chess strategies that [emerged from Alpha Zero](https://www.technologyreview.com/2017/12/08/147199/alpha-zeros-alien-chess-shows-the-power-and-the-peculiarity-of-ai/).[^9] 

The broader point is that this approach—use AI as a [creative partner](https://twitter.com/chrisalbon/status/1532474821140836352) rather than a calculator for trudging through a bunch of repetitive math problems—is almost entirely different from how the industry has traditionally thought of applying it to analytics. This opens up a number of possibilities I’d never considered. To offer a few wild ideas:

An AI could ask questions rather than try to answer them. It reads the conversations people have about a business, and examines the charts that describe it. Then it asks dozens of questions, like a VC doing some kind of deranged diligence. Surely, a few of those questions would be, as Sean suggested, just weird enough to investigate.

An AI could offer suggestions for how to re-architect DAGs. If you use something like dbt for long enough, it eventually becomes a multi-generational ruin, where new cities get layered on top of old, until none of the streets quite line up. An AI could provide a series of redesigned maps, like an unpredictable urban planner suggesting optimal bus routes for connecting neighborhoods. Some may be ridiculous. Some might be good ideas. 

An AI could parse SQL queries and semantic models, and attempt to explain them [in plain English](https://www.jasper.ai/). Most AI-enabled tools go the other way, trying to turn loose descriptions of business problems into code. The opposite might be better: Turn code into accessible explanations of business concepts. Data teams are often asked questions—what exactly is a lead? How do we define weekly active users?—that are easily answerable if you could read SQL, Python, or LookML. An AI could do this for us—and if the explanation doesn’t make sense, people could just ask for another version. 

Would any of these ideas actually be useful? Maybe. Are they even feasible to build? Doubtful. Will they come to pass? Almost certainly not—whatever I think the future will look like is surely wrong. The robots I can imagine today, and even the problems I can imagine them solving, probably aren’t the ones we’ll get. But, [for better](https://www.aboutamazon.com/news/devices/alexa-helped-save-my-life) or [for worse](https://www.theguardian.com/technology/2018/feb/14/amazon-alexa-ad-avoids-ban-after-viewer-complaint-ordered-cat-food), I now believe it’s inevitable that we’ll get something.  


---


[^1]: For Splitter, not [LeBron](https://www.youtube.com/watch?v=-zd62MxKXp8).

[^2]: I heard about this question from the criminally-underfollowed [Nan Yu](https://twitter.com/thenanyu) and [Belinda Preno](http://www.belindapreno.com/).

[^3]: Speaking of appalling, how many Taylor Swift covers do you think I to discover, Spotify? C’mon…as if I haven’t already listened to them on YouTube, the incognito window to my Spotify Wrapped.

[^4]: This is now how I connect with the youth, I guess. How do you do, fellow kids?

[^5]: In fairness to augmented analytics tools, I do think they can be useful if they’re applied to the right problems. While they aren’t suitable for figuring out why retention rates are down, they can be very useful when applied to large datasets where each record is a self-contained, independent(ish) trial. If you were to run a bunch of insight discovery algorithms over a highly dimensional table of every point-of-sale purchase at McDonald’s, you’d probably [find something interesting](https://hbswk.hbs.edu/item/clay-christensens-milkshake-marketing). The bad news is that companies only have one or two datasets like that; the good news is that, if they do have them, they’re really valuable.

[^6]: To add to my cliché term paper, “Henry Ford once said if he’d asked people what they wanted…”

[^7]: Some people have laser eyes in their profile pictures; I’m more of a coal-for-eyes, [Larry David](https://www.youtube.com/watch?v=BH5-rSxilxo) kind of guy.

[^8]: [Robots never were good at statistics.](https://www.youtube.com/watch?v=uYX-NSZMqt0)

[^9]: Of course, sometimes this approach produces [dangerous videos for children](https://www.theverge.com/culture/2017/11/21/16685874/kids-youtube-video-elsagate-creepiness-psychology). You can never tell with these AIs.

================================================================================

# Microsoft, Google, and the original purple people

*And, of course, Pokémon.*

---

![](https://substackcdn.com/image/fetch/$s_!VMM5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F52d0a67f-aecd-4e33-afce-9a85697a4bae_1600x705.png)
*[what ](https://www.youtube.com/clip/Ugkxa0oZQVWT2j0IEdN0iLEAeWA48wOahUb1)*

The first [purple people](https://www.getdbt.com/blog/we-the-purple-people/) I cared about were the purple Pokémon.

When I was in fifth grade, I had two hobbies: baseball, and Pokémon cards. On Tuesday nights, I'd play Little League; on Saturday mornings, it was Pokémon League. 

In the latter case, every weekend, one of my best friends[^1] and I would get driven to a nearby Books-A-Million to play the [Pokémon card game](https://en.wikipedia.org/wiki/Pok%C3%A9mon_Trading_Card_Game) against a few dozen other regulars. After a couple hours of matches—each game is a one-on-one battle in which the two players use customized decks of collectable cards—we’d report our results to the league organizers, walk across the parking lot, eat all we could eat at an all-you-can-eat CiCi’s Pizza, and get picked up to go home, to drink sodas and watch baseball.

Because good cards were hard to come by, we built our decks with whatever cards we could get. Typically, this meant using your first great card as a centerpiece, and then assembling a complementary cast around it from trades with other kids,[^2] or from lucky draws from packs bought with your allowance. My friend had a [Charizard](https://www.pokellector.com/card/Charizard-Base-Set-BS-4), a fire-themed Pokémon, so he built a fire deck. I got a [Japanese Mew](https://www.trollandtoad.com/pokemon/fossil-japanese-/mew-japanese-no-151-holo-rare-fossil-/1095435) in one of the first packs I opened, so I developed a strategy centered around the purple psychic Pokémon.[^3] 

Every once in a while, though, you’d run into a kid who had everything. With an unlimited collection of cards to draw from, they’d stuff their deck with a mismatched jumble of the most powerful Pokémon in the game. They hit you with an onslaught of raw force—[Ninetales](https://www.pokellector.com/card/Ninetales-Base-Set-2-B2-13), then [Zapdos](https://www.pokellector.com/card/Zapdos-Base-Set-2-B2-20), then [Hitmonlee](https://www.pokellector.com/card/Hitmonlee-Legendary-Collection-LC-13)—but their strategy was somewhere between inscrutable and incoherent.

In the data industry, Google is this kid.

Most data vendors compete like my friend and I: They find their one edge, and do everything they can to exploit it as much as possible. In more concrete terms, companies build features that pair well with their initial strength, integrate with a few important adjacencies, and try to define new product categories—ELT! Data observability! Data activation!—that put their offering at the center. The strategies don’t always work, just as I sometimes ended up with a lineup of feeble [Gastlys](https://www.pokellector.com/card/Gastly-Base-Set-2-B2-75) getting nuked by an army of [Electabuzzes](https://www.pokellector.com/card/Electabuzz-Base-Set-2-B2-24). The game we’re playing, though, is usually clear enough.

Google, by contrast, has built or acquired a very long list of impressive tools and technologies in the space. To name but a few: BigQuery is one of the [fastest and most scalable](https://datamonkeysite.com/2022/01/07/benchmark-snowflake-bigquery-singlestore-and-databricks-using-tpc-h-sf10/) databases on the market; [Looker](https://cloud.google.com/looker) is a leading BI tool, and LookML, if removed from Looker, is [the original metrics layer](https://benn.substack.com/p/bi-is-dead?s=w) of the modern data stack. Google Analytics is the [most widely used](https://w3techs.com/technologies/overview/traffic_analysis) web analytics product in the world. Google [bought Dataform](https://cloud.google.com/blog/products/data-analytics/welcoming-dataform-to-bigquery), a dbt-inspired transformation tool, and [Alooma](https://www.alooma.com/blog/alooma-plans-to-join-google-cloud), an early Fivetran and Stitch competitor. They offer [Colab](https://research.google.com/colaboratory/) for developing in notebooks; [Data Studio](https://datastudio.google.com/u/0/) for visualization; [Optimize](https://optimize.google.com/optimize/home/#/accounts) for A/B testing; [Data Catalog](https://cloud.google.com/data-catalog) for data cataloging; [Dataprep](https://cloud.google.com/dataprep) for data prep; and a whole host of [modeling](https://benn.substack.com/p/has-sql-gone-too-far?s=w#:~:text=The%20second%20tool%20exploring%20this%20idea%20is%20Malloy%2C%20an%20open%20source%20project%20led%20by%20LookML%20creator%20Lloyd%20Tabb.), [orchestration](https://cloud.google.com/composer), [AI](https://cloud.google.com/products#section-3), and [compute](https://cloud.google.com/bigquery/docs/bi-engine-intro) services. And none of these hold a candle to their crown jewel: Google Sheets, the only product on the market that can truly threaten Excel’s thirty-year reign as the [most dominant data product](https://benn.substack.com/p/the-next-billion-programmers?s=w) in the world.[^4] 

As far as data technologies go, it’s an embarrassment of riches. But like that of the kid with the Pokémon deck of death, Google’s strategy is much harder to discern.[^5] Though many of its products are popular, Google—and the data community’s chattering class, which isn’t representative of the market, but is perhaps representative of its attention—tends to discuss each of them separately. We [benchmark BigQuery](https://www.fivetran.com/blog/warehouse-benchmark), debate the [future of Looker](https://jpmonteiro.substack.com/p/is-looker-dead?s=r), get excited [about AlloyDB](https://roundup.getdbt.com/p/avoiding-traps?r=3dh9c&s=r&utm_campaign=post_selection&utm_medium=web#:~:text=In%20other%20database%20news%2C%20Google%20Cloud%20just%20launched%20a%20new%20database), and complain about [Google Analytics](https://twitter.com/bennstancil/status/1403003254489993217). But, for all its tall trees, there’s little discussed or revealed about the forest. 

Which strikes me as a little eerie. Google has the products, technology, and capital to dominate this industry. Why aren’t they? Are they still figuring out how to make all of their pieces fit together? Have they already, and we just haven’t been hit with it yet? Are they a collector hoping to make money on each card, and they’re playing an altogether different game than the rest of us?

Let’s make some guesses. [I’m feeling lucky.](https://www.google.com/)

# If it ain’t broke…

There are two obvious potential strategies. The first is to build a bunch of tools that make a lot of money on their own. Just as there’s no unifying vision about product synergies in [Berkshire Hathaway’s portfolio](https://www.berkshirehathaway.com/subs/sublinks.html) of Geico, a railway line, Dairy Queen, and the *Roanoke Times*, there doesn’t have to be some grand plan for how [Dataflow](https://cloud.google.com/dataflow) and [Spanner](https://cloud.google.com/spanner) work together. The story may be much simpler than that: Google wants to use their bottomless bank account and singular technical expertise to build better products, each winning on their own merits, than the rest of us can.[^6] 

That seems possible—and almost inevitable, given that organizational challenges at metropolis-sized companies like Google make some degree of product independence necessary. Still, Google's acquisitions, which include smaller strategic startups, clearly represent more than an effort to buy new revenue streams. So I’m skeptical that this explains everything Google is doing. 

The second possible strategy is that Google isn’t trying to build a suite of data products; they’re trying to sell lucrative, high-margin compute. To them, all of their data offerings—pipelines, BI tools, catalogs, marketing dashboards, everything—are glossy veneers on top of BigQuery and [Google Compute Engine](https://cloud.google.com/compute). There's no reason to integrate Alooma with Colab because…who cares about selling Colab? Both tools are hooks to drive people into a handful of major infrastructure services. You don’t cross-sell from one loss leader to another. 

Last fall, Erik Bernhardsson [made a compelling case](https://erikbern.com/2021/11/30/storm-in-the-stratosphere-how-the-cloud-will-be-reshuffled.html) for cloud vendors to take this approach. Major cloud providers may be better off selling commoditized compute services than duking it out in noisy, competitive, and turbulent SaaS and software markets. Most of these SaaS vendors rely on AWS, GCP, and Azure anyway; if you’re one of the cloud providers, collect your tithe and let everyone else do the hard work on top.

Google’s strategy could be similar. Google’s data products may not be meant to win the market, but to seed it. When better BI tools, data pipelines, or data catalogs come along, Google will happily yield to them, so long as they’re spinning the meter on BigQuery.

If Google sales reps are paid to cross-sell other services—which I imagine they are—and if BigQuery is indeed the revenue center of Google’s data offering—which I’m guessing it is—funneling everyone into a couple central services is probably Google’s *de facto* strategy in the field. So long as reps are hitting sales targets and departments are meeting revenue goals, Alphabet’s shareholders don’t need a grand vision from Google Cloud. Just, as Erik said, don’t rock the boat. 

Still, this seems like a local maximum, and I can’t help but think that there’s a bigger prize out there. 

# The trillion dollar buyer

A few weeks ago, I wrote that the data industry [has something to learn](https://benn.substack.com/p/case-for-consolidation) from the success of Microsoft’s bundled products. Many consumers, I said, would prefer to buy neatly packaged tools from a single seller, even if those products aren’t as good as specialized versions you could buy from individual vendors. Modularity, in other words, often isn’t as valuable as convenience. 

I stand by this point—[the buying experience is the product experience](https://twitter.com/josh_wills/status/1522625422449528832). If we have to buy eight data tools to build a stack, the buying experience is the sum of all eight sales processes; the cumulative annoyances a buyer feels is, *at its very best*, equal to the worst one. Microsoft demonstrates that these frustrations can be exploited.

As some [people pointed out](https://benn.substack.com/p/case-for-consolidation/comment/6467198?s=w), however, the argument is incomplete. Microsoft sells to IT, not data teams or end users of data products. Microsoft isn’t dominant because people value integration and convenience more than a product’s quality and capabilities; it’s dominant because its buyers care about [price](https://twitter.com/skamille/status/1523051189268475905) and [feature checkboxes](https://benn.substack.com/p/case-for-consolidation/comment/6537471?s=w). 

This reveals a vulnerability for Microsoft—and a huge opportunity for Google. There are roughly five companies that can credibility build and bundle infrastructure and applications into a complete data stack: Microsoft, Google, Amazon, Oracle, and Salesforce. Amazon sells to developers and engineers. Salesforce champions lines of business. Microsoft and Oracle win with IT. Google, it seems, hasn’t established itself yet. 

There’s an obvious place for them to focus: Data organizations. These teams aren’t Amazon’s engineers; they aren’t Salesforce’s business units; and they definitely aren’t Microsoft’s and Oracle’s IT teams. They are, as Anna Filippova memorably christened them last summer, the [purple people](https://www.getdbt.com/blog/we-the-purple-people/) in the middle: “[H]umans with a deep understanding of business context in a particular domain are called red people; [those with] technical expertise are called blue people…Purple people are the people in between—they have a little bit of both that enables them to translate between red and blue.”[^7] 

I’d argue that Microsoft’s enterprise business grew to its size in part because it sold to IT, the original purple people. Though IT organizations weren’t huge, their position as a corporate hub gave them enormously outsized budgets. As my prior post’s critics called out, this is now an anachronistic buyer for data products—but the appeal of selling to a centralized service organization, and the budgets they command, remains. Someone just has to offer it to them. Today, Google’s the only company that can.

What would that specifically look like? There are a variety of product updates that Google could make to turn their loose assortment of products into a [modern data experience](https://benn.substack.com/p/the-modern-data-experience). Pull LookML out as a separate metrics layer, with public APIs for third-party vendors. Scrap Looker’s visualization product and replace it with Data Studio. Embed the same visualizations in Colab. Make Colab an entry point into various ML services. Put Sheets directly on top of BigQuery; make LookML’s metrics accessible in Sheets;[^8] back the whole thing with BI Engine. Dispatch metadata from across the system into Data Catalog. Build a bridge from Google Analytics to Data Studio, to BigQuery’s SQL client, to Colab, and to Sheets. Glue it all together, because in the multifaceted, multimodal, multiplayer world of enterprise data, [it’s the glue that matters the most](https://benn.substack.com/p/work-like-an-analyst?s=w).

More than any product integration, though, Google’s opportunity comes from clearly defining their buyer. Microsoft did in the 1990s and 2000s with IT. Amazon did it in the 2010s with engineers. The 2020s, [we’re told](https://www.youtube.com/watch?v=q1nERFM9brA&t=3454s), are the decade that data becomes the next trillion dollar market. If I were Google, holding the hand it holds, I’d be awfully tempted to try to take it.[^9]

***Update, June 12:** I messed this piece up. While I stand by the points it makes, I told the wrong story with them. This is an abbreviated version of what I should've said:*

# Google is wasting all the good cards

The Pokémon League kid with all the good cards didn't win very often. Even though he had better individual cards than everyone else, his deck was too disorganized to use them. In most games, he lost with a bunch of mismatched energy cards in his hand, and an unevolved Charmeleon on the board. 

Google, it seems, sells its data tools in the same way. When we went [database shopping a few years ago](https://benn.substack.com/p/the-end-of-big-data?s=w#:~:text=Eventually%2C%20after%20a%20failed%20attempt%20to%20migrate%20to%20Athena%20and%20Spectrum%2C%20we%20made%20the%20decision%20to%20go%20shopping.), Google’s sales pitch was as simple as Snowflake’s—but in the wrong way. Early in our evaluation, we asked our Google rep why we should choose BigQuery. We were told that it’d be good enough for us because “it’s good enough for Google.”

As a piece of technology, I don’t doubt that’s true, for BigQuery and most of GCP’s other data products. But we weren’t shopping for horsepower, or pure clock speed. We were looking for a product that was easy to use; for a product that would work well with the rest of our stack; for helpful and engaged customer support; for a product* experience.* We weren’t going to use BigQuery to process [5.6 billion searches a day](https://blog.hubspot.com/marketing/google-search-statistics); we were going to use it for dashboards and a daily pipeline from Marketo. BigQuery’s top-end power would be squandered on us, like the unused Charizard in the kid’s folded hand. 

If I had to guess—again, from the outside—this problem has two origins. First, Google’s culture has long emphasized technology over marketing, which encourages a “if we build it, they will come” approach to software distribution. Second, when there’s pressure to grow the business—when execs say that this technology is great, but how do we make money from it?—the easy strategy is, as Erik identified to drive more compute. Google’s roadmap, then, is pulled by engineers building technology “good enough for Google” on one side, and sales people looking to upsell BigQuery and Google Compute Engine compute on the other. Nobody, it seems, is fighting for a cohesive user experience. 

And that, I think, is a huge miss. As [Gwen Windflower points out](https://twitter.com/gwenwindflower/status/1535317818584989696), analytics engineering—and, I’d argue, other adjacent roles that Google might sell data products to—is an extremely attractive field for people who want to work with a like-minded community to wire up open source tools and powerful compute platforms. But for [analytics engineering to go mainstream](https://twitter.com/gwenwindflower/status/1535626720497238018),[^10] it has to start attracting more data “nine-to-fivers:” The types of folks who care as much about supporting their colleagues with good data as today’s analytics engineers, but neither care about how their tools are made nor want to spend their personal lives talking about it on Twitter, in community forums, or on, god forbid, Substack.

For these people, their adoption criteria are different than the current set of early adopters. Running their own open source software is either enough of a headache or outright technical barrier to make them look for a proprietary solution. And buying one package instead of ten tools is both easier to do, and more likely to help them avoid a fight with IT and procurement that isn’t worth having. In the obnoxious parlance of corporate technobabble, the juice of the current modern data stack isn’t worth the squeeze. 

That’s Google’s opportunity. Take inspiration from what’s serving today’s data community, and make it accessible, seamless, and easy to buy.  Stop creating a mismatched stack of overpowered cards; design a cohesive deck of integrated ones. Sell the entire deck, ready to play, right out of the box. 

Google has the technology to build it, and the capital to buy it. What’s less clear is if they have the vision to imagine it.


---


[^1]: Who, it must be said, eventually moved on from Pokémon but not baseball, found something he loved doing, willed his way into the elite echelons of that thing, and now has a job that is [much cooler than yours](https://twitter.com/JohnDeMarsico/status/1413216138931081221), all while remaining one of the very best people in the world.

[^2]: There were always rumors floating around Books-A-Million about who was buying and who was selling. A Moltres is on the market! Someone is willing to give away the farm for a Blastoise! Forget labor markets or healthcare markets; I want some economists telling me what’s going on in *these* markets.

[^3]: And it was a dope strategy. I loaded the deck with [Mr. Mimes](https://www.pokellector.com/card/Mr-Mime-Base-Set-2-B2-27) and [Chanseys](https://www.pokellector.com/card/Chansey-Base-Set-2-B2-3). I’d slow play the opening turns (using [Mewtwo’s](https://www.pokellector.com/card/Mewtwo-Base-Set-BS-10) *Barrier* attack to stall if I could), which would buy me enough time to get an evolved [Alakazam](https://www.pokellector.com/card/Alakazam-Base-Set-BS-1) on the board. Then, I’d put a bunch of Chanseys on my bench, and attack with Mr. Mime. Mr. Mime’s *Invisible Wall* power protected him from taking heavy damage, and Alakazam’s *Damage Swap* power let me move the little damage he took onto my high-HP Chanseys. This made it nearly impossible to knock Mr. Mime out, creating a slow war of attrition that bled my opponent dry while Mr. Mime’s *Meditate* attack, which compounds over time, wore them down. Eat your heart out, Napoleon.

[^4]: Imagine your product being so widely used that its bugs are [documented on Wikipedia](https://en.wikipedia.org/wiki/Microsoft_Excel#Quirks).

[^5]: From a distance at least; I have no inside knowledge of what goes on [in the plex](https://www.amazon.com/Plex-Google-Thinks-Works-Shapes/dp/1416596585).

[^6]: Sooner or later, [Frank Slootman](https://benn.substack.com/p/the-data-app-store#footnote-1-50157390) [Thomas Kurian](https://en.wikipedia.org/wiki/Thomas_Kurian) comes for us all.

[^7]: I’m slightly misquoting Anna here, because I’m too much of Scrooge to include the emojis. Bah humbug.

[^8]: Google [teased this one](https://cloud.google.com/blog/products/data-analytics/lookers-universal-semantic-model) already.

[^9]: Or, you know, catch ‘em all.

[^10]: I’ll leave it to the reader to decide if this is a good or bad thing.

================================================================================

# iSnowflake

*It’s not the App Store. It’s the iPhone.*

---

![](https://substackcdn.com/image/fetch/$s_!N2zy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6c6cfe20-d4ab-4130-8d13-682f8fcd665a_640x356.png)
*The apps are in the computer. *

The trip to Las Vegas—for [Snowflake Summit](https://www.snowflake.com/summit/), the first data Megaconference[^1] since 2019—got off to an inauspicious start. My Uber to the airport cost a fortune, and the driver spent most of the trip complaining about, as he put it, “the flu.” When we took off, the Nasdaq was down 3.2 percent. When we landed—after five hours of searching for smooth air, rumbling over the Great Lakes like a Greyhound hydroplaning across a gravel road—the [Nasdaq was down 4.7 percent](https://www.reuters.com/business/nasdaq-futures-tumble-3-aggressive-rate-hike-bets-2022-06-13/). The taxi driver from the airport said no tourists were in town because gas prices are so high. 

On the opening night of the conference, I made a couple of slow laps around the vendor hall at [Caesar’s Forum](https://caesarsforum.com/).[^2] The room was full of glittering booths, eager salespeople, escalating lures for attention—swag, then a magician, then a raffle for a trip to Europe, then a [ski simulator](https://skytechsport.com/)—and, if we’re honest about it, dozens of now [massively overvalued](https://pitchbook.com/news/articles/market-volatility-startup-valuations-venture-capital) data startups. Though entirely incidental, I couldn’t help but think that hosting such an extravagant celebration of the data industry, [this week](https://www.wsj.com/articles/global-stocks-markets-dow-update-06-16-2022-11655364753?mod=hp_lead_pos1) of all weeks, at the conference center of a hotel that’s a *giant replica of Rome* felt a little on the nose. Like Las Vegas itself, the event felt like was an excuse to forget about what was happening around us, and to pretend we were somewhere else. 

The content of the conference, I assumed, wouldn’t change this impression. Snowflake execs in blazers, jeans, and sneakers would announce a predictable set of database improvements. They’d tell us Snowflake is now bigger, faster, cheaper, and more secure. They’d demo new integrations, new partnerships, and new features. They’d tell us how excited they were to be here; how hard their teams have been working; how this was all for us, the customer. They’d trot out a few of those customers, who would also tell us how excited they were. One would win an award for customer of the year. We would learn best practices. 

It would be boring—though in fairness, [boring makes money](https://benn.substack.com/p/the-end-of-big-data)—but we’d all pretend to be excited anyway. We’d mingle in clubs while wearing lanyards with our names on them. And then we’d go home, forgetting most of what we learned and who we met. What was going to happen in Vegas, I figured, would stay in Vegas.[^3] 

It didn’t quite happen this way. 

To be sure, we made plenty of the scheduled stops. We had lots of [sponsored](https://twitter.com/AtlanHQ/status/1536799142713823233) [fun](https://twitter.com/Alation/status/1537101840810053632). Save one passing remark about how Snowflake isn’t lowering its hiring targets, the collapsing tech market was roundly ignored. Snowflake announced that it’s now [bigger](https://twitter.com/SnowflakeDB/status/1536751876829433856), [faster](https://twitter.com/SnowflakeDB/status/1536760496522612737), more [cost-conscious](https://twitter.com/SnowflakeDB/status/1536761434998075392), and more [secure](https://twitter.com/SnowflakeDB/status/1536754791040241664). And the keynote closed with a nifty “[one more thing](https://twitter.com/SnowflakeDB/status/1536777325848633344).” 

But amid the predictable spectacle, something genuinely big happened too—something with parallels to Apple that go beyond mimicking the Jobsian reveal. It was largely missed by the audience, though, because Snowflake whiffed on the announcement.[^4] 

# The anatomy of a data app

What’s a data app?

As best I can tell, the most common definition is a dashboard with interactive widgets. A sales forecasting report that lets you tweak assumptions about sales cycles and win rates is a data app; a tabbed set of charts and tables that shows how a customer has recently interacted with a product is a data app; an A/B testing dashboard that computes all of the relevant results of a chosen experiment is a data app. 

In all of these cases—and in the example galleries of data app providers like [Streamlit](https://streamlit.io/gallery) and [Hex](https://hex.tech/gallery/)—data apps are overwhelmingly tools for consumption. If we were to draw diagrams of where apps are in the data stack, they’d sit squarely on top of the warehouse. In this way, they aren’t fundamentally different from classic BI tools; they just present data in more narrow, purpose-built ways. 

This rough architecture has become implicit in the way we talk about data apps. Over the last eighteen months, a number of people have gotten excited about their potential, and, intentionally or not, we’ve all described them in this way:

Bucky Moore, on the [future of cloud data services](https://www.kleinerperkins.com/perspectives/a-2020-perspective/): “The logical next step is to use this foundation to build full-featured applications that both read and write to the warehouse.”

Patrick Chase, on the [data warehouse becoming the new backend](https://pchase.substack.com/p/thenewbackend): “It makes sense for apps to read and write to their customer’s data warehouse instead of their own database.”

Martin Casado, on the [future of the data industry](https://www.youtube.com/watch?v=q1nERFM9brA&t=3458s): “All apps are just going to be reimplemented on top of the data layer.”

You can imagine the technical diagram underneath all of these predictions: The data warehouse sits at the back, data apps at the front, and there’s an arrow representing a few nice APIs in between. 

I had this same picture in mind after Snowflake acquired Streamlit, a tool for creating this type of data app, earlier this year. [The deal made sense](https://benn.substack.com/p/the-data-app-store), I thought, because, with a few tweaks, Streamlit could become “a framework for interacting with Snowflake” to build data apps. With a few more tweaks, it could also be “a marketplace for apps that Snowflake stands behind.” 

This week, Snowflake announced that [they’re building exactly this](https://www.snowflake.com/blog/introducing-snowflake-native-application-framework/). According to the announcement, they’re launching a “native application framework” for developing apps, and a marketplace for selling and distributing them. 

Snowflake’s announcements framed these apps in the same way that Bucky, Patrick, Martin, and I did: They’re tools that sit on top of the warehouse. [The launch post](https://www.snowflake.com/blog/introducing-snowflake-native-application-framework/)[^5] shows a diagram of apps, on top of a database, with arrows in between them. The same post lists a few examples of data apps, and most of them, like “cost analytics for cloud platforms” and “financial transaction analytics,” sound little different than a dashboard. And in the keynote announcing the app framework and marketplace, Snowflake leaned heavily on Streamlit, suggesting that data apps are synonymous with Streamlit apps.

I think this is wrong. I don’t think Snowflake is building what this implies they’re building. Data apps are actually much more than blinged-out dashboards that sit on top of a warehouse. They’re also programs that run *in* a data warehouse.

# *In* the computer

Later during the conference, I was talking with a couple of Mode folks[^6] about a data privacy and protection product that automatically masks personally identifiable information in Snowflake. They asked if Mode, which runs queries against Snowflake, could ever integrate with this tool. Could we connect Mode to it, so that email addresses would be hidden in query results in Mode? 

My initial thought was, sure, maybe. If the privacy product sat between Mode and Snowflake, it could intercept queries from Mode, do whatever magic it does, and send back masked results. Or we could connect to the tool via an API, and it’d give us some special query to run that would return concealed data. 

But then it occurred to me—what if the privacy tool was a data app that ran *inside* Snowflake? What if Mode doesn’t even need to know that the tool exists, and we just send normal queries, as we always do? When they get to Snowflake, they’re executed according to logic defined by Snowflake’s native primitives *and* the custom apps that people have installed in Snowflake. What if apps aren’t simple widgets for consumption, but are foundational programs that fundamentally change how Snowflake operates?

This framing opens up a tremendous amount of potential for what data apps could do. ML tools like [Continual](https://continual.ai/)? A suite of Python-based stored procedures that run directly in Snowflake. A custom logging framework, like Segment or Snowplow, for how people are using your warehouse? A package that gets installed in Snowflake, and creates log tables directly. dbt packages, dbt metrics, native Jinja, a dbt scheduler, the entirety of dbt itself? All apps. 

And like dbt, these apps could “just work” with everything else in Snowflake. One of the keys to dbt’s success is that it silently slid under every other tool in the stack. Nobody had to build an integration to dbt; you got it for free, via the tables it created in the warehouse.

The same would be true for the apps that run inside of Snowflake. A SQL-based ML package would be accessible via every BI tool or within dbt, with no work from either. A governance management service would apply its rules to every query run in Snowflake. A load-balancing app could automatically distribute jobs to the right warehouses to maximize speed at the lowest cost. 

In this telling, Streamlit doesn’t become a framework for building apps; it becomes a platform-focused language like [Swift](https://developer.apple.com/swift/).[^7] And to extend the analogy, Snowflake isn’t just an app store for buying widgets; it’s the entire iPhone. App developers don’t play in a limited sandbox; they can write custom programs that can take full advantage of the system’s hardware and native software. 

Moreover, like an iPhone, Snowflake could automatically manage things like app permissions. A reverse ETL app would be granted permission to send data outside of Snowflake; an ML app might keep data inside Snowflake, but be allowed to send metadata back to a SaaS service so that people could configure it; a logging app could be prevented from communicating with anything outside of Snowflake itself. 

In addition to giving customers more control, this would dramatically alter the economics of data app development. If buyers can find apps in a store, and security teams can simply decide what permissions they’re comfortable granting without doing formal diligence, small teams could profitably develop and distribute apps. Installing a data app would be like downloading a mobile app: Put in a credit card, check a few permission boxes, and you’re ready to go. 

Of course, even if Snowflake built all this, lots of things could go wrong. They could struggle to attract app developers—but Snowflake’s customer base is definitely big enough to entice some initial entrants, especially if development costs are reasonably low. The mobile app analogy could be flawed, because there are two mobile operating systems and dozens of databases—but given its growth rate, I suspect Snowflake is rapidly gaining market share. And Snowflake’s app store could become yet another graveyard of marginally useful widgets, like those that exist in everything from [Sharepoint](https://appsource.microsoft.com/en-us/marketplace/apps?product=sharepoint) to [Slack](https://mode.slack.com/apps)[^8]—but if you can run apps inside Snowflake rather than just on top of it, it can be a platform for building anything you want to do with your data. This offers a far wider range of valuable possibilities than app stores that are essentially extension libraries for SaaS products.[^9] 

However high the risk is for Snowflake, I believe the reward is even higher. Running apps inside of a database could redefine what a database is as much as iPhones redefined what cell phones were. If momentum builds in the ecosystem, and what you can do with Snowflake expands at the pace of what the community can develop, other database vendors will have no choice but to chase it. As the first mover on a premier product, Snowflake will be the industry’s iOS—the platform every developer wants to build for first.

# Cambrian explosion, part III

At the start of the conference, one of Snowflake’s executives said that this moment didn’t represent the end of Snowflake’s journey, but the end of the beginning. My initial reaction was to roll my eyes, wonder what cliché someone would drop next,[^10] and think that, if this conference marks the end of anything, it’s the passing of the market’s bull run and the reversal of the industry’s [“Cambrian explosion” of new data tools and startups](https://www.getdbt.com/blog/future-of-the-modern-data-stack/). Snowflake Summit wasn’t a graduation; it was the last party in Rome.

After hearing more about what Snowflake is going to build—or, more accurately, what I think they’re going to build, even if they haven’t quite said it themselves—I’m changing my mind. Snowflake could be on the cusp of changing what a database is, what data apps are, how they get built and sold, and what we can do with both of them. They could be building a platform that stokes the industry once more, and leads to another explosion of ideas and products. Rome isn’t falling; it’s simply evolving. 

What happens in Vegas, it turns out, can also be meaningful. 


---


[^1]: It’s like a [megachurch](https://en.wikipedia.org/wiki/Megachurch): The preachers are paid salesmen, and the congregation is thinking about lunch.

[^2]: And you had to walk slow, lest you stumble on the alarmingly squishy carpet.

[^3]: Speaking of things happening in Vegas, according to Snowflake, about ten thousand people attended the conference. These are tech people, so many of them are rich. Some, I suspect, like to gamble. Of those who did, some people made money, and some lost money. Of all the people who lost money gambling, *somebody lost the most money.* How much do we think this person lost?

[^4]: Or, they just didn’t want to talk about it yet. I should probably give the company making a billion dollars and growing at 100 percent a year the benefit of the doubt.

[^5]: I’m not saying that it’s suspicious that this annoucement links to the [exact moment](https://www.youtube.com/watch?v=q1nERFM9brA&t=3458s) in Martin’s talk at *Future Data* that [I linked to](https://benn.substack.com/p/the-data-app-store#footnote-3:~:text=remake%20all%20of%20today%E2%80%99s%20SaaS%20apps%20on%20top%20of%20the%20data%20layer) in the post about Streamlit, but I’m not *not* saying that.

[^6]: In case it’s not obvious, [I am a Mode folk](https://www.linkedin.com/in/benn-stancil/).

[^7]: Admittedly, I have no idea if this is technically possible for Snowflake to build.

[^8]: You could argue that Slack apps are a key part of Slack, and I wouldn’t disagree. However, I don’t know many companies of any reasonable size whose primary product is a Slack app.

[^9]: In other words, apps in SaaS services can only be as valuable as the service. Apps on a data platform are far more open-ended, and have a much higher ceiling.

[^10]: “I know it’s hot here, but it’s a dry heat.”

================================================================================

# Disaster

*Read something else today.*

---

![](https://substackcdn.com/image/fetch/$s_!ttZg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F00fce861-4f29-4db3-80ca-fdb08ec01fb9_1024x584.png)
*This man is in charge, for the rest of his life.*

I had something else to talk about this morning. It was the usual silliness—something about the curious irony of analytics engineering, and a few jokes about Excel and people in San Francisco.

Today, all of the sudden, [isn't the day](https://www.nytimes.com/live/2022/06/24/us/roe-wade-abortion-supreme-court) to tell those jokes. In what is fast becoming its [new tradition](https://benn.substack.com/p/tilt-and-tilted), the Supreme Court decided again to impose its deranged will on an [unapproving populace](https://news.gallup.com/poll/1576/abortion.aspx), stripping people of [the rights they want](https://www.wsj.com/articles/upholding-roe-v-wade-is-supported-by-most-americans-wsj-poll-finds-11654162200) (to say nothing of what the rights they’re owed), transparently [inventing legal rationales](https://twitter.com/lib_crusher/status/1539999857611485184) along the way, all while its most vile member—a man with such a feeble commitment to his oath of office law that [he clearly entertained](https://www.nytimes.com/2022/06/15/us/trump-emails-eastman-chesebro-jan-6.html) not only rejecting the apparent public opinion of the people, but the voted, counted, and certified [will of the electorate](https://www.nytimes.com/2022/05/20/us/politics/ginni-thomas-election-trump.html)—teased that [more is to come](https://twitter.com/Taniel/status/1540341232081174528).  The arc of the moral universe is long, and it bends toward whatever loathsome destination six unelected and unaccountable [politicians](https://twitter.com/bennstancil/status/1521501078281408512) [want it to](https://twitter.com/Kate_Riga24/status/1540356238164348931).

Next week, we can return to having jovial fights about our comfortable industry. But on this Friday, I don't have much to say, other than it's a disastrous day, created by six disastrous people, confirmed by a [disastrous idiot](https://www.nbcnews.com/politics/congress/sen-collins-completely-inconsistent-gorsuch-kavanaugh-support-overturn-rcna27099), and empowered by what has become a [disastrous institution](https://www.whitehouse.gov/wp-content/uploads/2021/06/Bowie-SCOTUS-Testimony.pdf). To those of you who showed up looking for cranky heckling and a goofier affair, I appreciate you, truly. But today, [read something else](https://www.newyorker.com/magazine/2022/07/04/we-are-not-going-back-to-the-time-before-roe-we-are-going-somewhere-worse).