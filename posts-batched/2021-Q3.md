# Posts from 2021-Q3

This file contains 11 posts from 2021-Q3.

================================================================================

# How to feel about a tie

*What twelve years of NBA games tell us about when you should be confident during a close game, and when you should be worried.*

---

![](https://substackcdn.com/image/fetch/$s_!MTMD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d6f6088-114a-4939-b1e1-84956d7cf435_920x518.jpeg)
*[bored](https://www.espn.com/blog/sweetspot/post/_/id/60077/tbt-the-all-star-game-fiasco)*

There are questions every sports fan wants to know, but we never will. What if the Royals [sent Alex Gordon](https://fivethirtyeight.com/features/send-alex-gordon/)? What if [Tom Brady’s “tuck rule” pass](https://www.wbur.org/onlyagame/2017/02/03/patriots-tuck-rule) had been (correctly) called a fumble? What if [Chris Paul had been traded to the Lakers](https://www.espn.com/los-angeles/nba/story/_/id/7333285/los-angeles-lakers-deal-acquire-chris-paul-off)? What if JR Smith [knew the score](https://www.youtube.com/watch?v=qmDsgGKHBEo)? What on God’s green earth [was Will Craig thinking](https://www.youtube.com/watch?v=ThwJiusfcNs)?

As a fan, there’s another question that always nagged me whenever I’m watching my team play: How stressed should I be during a tight game? In particular, given that a game is close, should I be more confident if my team has played well, or they’ve played poorly? 

Nearly every narrative you can spin sounds plausible. Your inner optimist can make an easy case: “Yes, the game is tied, but we’re playing terribly; all we have to do is start playing like we normally do and we’ll be in great shape.” But a pessimist’s response is also reasonable: “We’re lucky to be hanging on after playing so badly; there’s no way we’ll be that lucky for the rest of the game; we’re as good as beat.”

This exact scenario happened a couple weeks ago in [Game 7 between the Hawks and 76ers](https://www.basketball-reference.com/boxscores/202106200PHI.html). The Hawks held a slight 2-point lead at halftime, but had played poorly. They only shot 39 percent, well below their [regular season average of 47 percent](https://www.basketball-reference.com/teams/ATL/2021.html). Trae Young played particularly badly, making only on of his twelve shots. 

If you were a Hawks fan, how should you have felt? Should you be an optimist about turning it around in the second half, or a pessimist about your run of good luck coming to an end? Is momentum a more powerful force, or mean reversion?

Fortunately, unlike wondering what’s happening inside Will Craig’s head, these are questions we can answer.

## Twelve years of ties

To figure this out, I collected data from [Basketball-Reference.com](https://www.basketball-reference.com/) on every NBA game from 2007-08 season through the 2018-19 season.[^1] In the 14,400 games played during that time (including both regular season and playoff games), the home team won 59.6 percent of the time. Home teams also, on average, led by 1.7 points at halftime. 

The chart below shows the distribution halftime scores across all of these games, and the winning percentages for the home team for each score. In tie games—the modal halftime outcome, it turns out[^2]—home teams win 55 percent of the time. Unsurprisingly, the bigger the lead, the more likely teams are to win. And if the halftime deficit is 26 points, you can turn the game off. No team, home or away, has ever come back after being down by 26 or more points.

![](https://substackcdn.com/image/fetch/$s_!65ar!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12da52e5-b593-4e6d-92a4-4b5b7026a2e6_1600x955.jpeg)

Eleven percent, or 1,681 games, were tied or one-point games at halftime. To me, these games qualify as “very close,” both numerically and emotionally. The question, then, is do winning percentages change given how a team plays in the first half?

Before answering this question, we have to determine how to measure team performance. Though teams can play poorly in a lot of different ways, many of which don’t show up in a box score,[^3] shooting percentages are decent summaries of overall performance. Shooting percentages are both highly variable and well correlated with winning: The higher percentage a team shoots over the course of a game, the more likely they are to win. The chart below shows the distribution of shooting percentages by game, and the win probabilities for each.[^4]

![](https://substackcdn.com/image/fetch/$s_!EQSf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fad6ff69f-a257-4673-8d1d-2a5c98480f69_1600x963.jpeg)

As a brief aside, field goal percentage can be measured in a [number of ways](https://www.basketball-reference.com/about/glossary.html), including standard field goal percentage, effective shooting percentage, and true shooting percentage. I use effective shooting percentage throughout, which makes adjustments to account for three pointers. That said, all the results here hold up across every flavor of shooting percentage.

Though league-wide shooting percentages are normally distributed around .500, what’s good or bad varies from team to team and season to season. [This season](https://www.basketball-reference.com/leagues/NBA_2021.html#all_misc_stats), Brooklyn shot a league-leading effective shooting percentage of .575. Shooting .520 would be a bad game for Brooklyn, a good game for Orlando, and an [average game](https://www.basketball-reference.com/leagues/NBA_2020.html#all_misc_stats) for Brooklyn last year. If we want to assess a team’s first-half performance—and in particular, how that performance *feels* to us as stressed-out fans—the best measure is to compare their halftime shooting percentage to their season average. 

To do this, I found the average effective shooting percentage by season and team. I then measured how many standard deviations each first half’s shooting percentage was from that team's average first half that season.[^5] Each half could then be grouped into one of five categories:

As the chart shows, first half performance is a decent predictor of the final outcome of the game. Teams that have a bad first half win 23 percent of the time, while those who have a good first half win 74 percent of the time.

![](https://substackcdn.com/image/fetch/$s_!GG3E!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9298c5f2-a6b8-4a5e-86e3-78c16f794d0d_1600x965.jpeg)

But this graph includes all games, including when you’re up by 22. What happens if, despite a particularly good or bad performance, the game is tied?

*The result flips. *For games in which the halftime score is within one point, the better you performed in the first half, the *less* likely you are to win. In close games, a poorly performing team wins 57 percent of the time; a well performing team wins only 43 percent of the time. 

![](https://substackcdn.com/image/fetch/$s_!wG47!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fac75aa7b-a5bc-45f8-bd79-f8261b12761d_1600x965.jpeg)

In other words, mean reversion overpowers momentum (if [momentum exists at all](https://labs.la.utexas.edu/gilden/files/2016/04/Gilo.Vallone.Tversky.pdf)).

The scatterplot below shows why: There’s no relationship between first and second half performance. Teams that perform great in the first half are just as likely to perform badly in the second half as they are to perform great again. Or, conversely, if you had a bad first half, odds are your second half will be be better. And sure enough, in the Hawks-Sixers game last week, that’s exactly what happened. The Hawks came alive in the second half, and shot 50 percent—a number much closer to their seasons average of 47 percent—and won the game by 7. 

![](https://substackcdn.com/image/fetch/$s_!5Ns1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd11746e1-c9d1-4dd2-90e6-6f8934e218f3_1006x966.jpeg)

Mean reversion becomes powerful when one team performs abnormally poorly and one abnormally well. In most close games, if you perform poorly, chances are your opponent did too. But in rare cases, performances are mismatched. When this happens, the team that performed poorly wins roughy three out of four times. 

![](https://substackcdn.com/image/fetch/$s_!WXfx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fff831be6-1f89-45ff-835e-8655a811d554_960x670.jpeg)

## The Citadel Scenario

In 2018, the undefeated Alabama football team played the 4-5 Citadel Bulldogs in Tuscaloosa. The game was supposed to be a laugher—Alabama was [favored by ](https://www.oddsshark.com/ncaaf/citadel-alabama-odds-november-17-2018-977578)*[53 points](https://www.oddsshark.com/ncaaf/citadel-alabama-odds-november-17-2018-977578)*. 

At halftime, [the game was tied](https://www.espn.com/college-football/game/_/gameId/401012338).

After presumably watching Nick Saban’s head detonate in the locker room, Alabama steamrolled the Citadel in the second half, winning 50-17. While you can chalk this result up to mean reversion, it’s not exactly interesting. I’m sure plenty of Alabama fans were mad at half time, but I doubt many were particularly *stressed*.

Does this Citadel scenario explain our result? Is a team that plays badly in the first half of a tie game more likely to win because they were the better team, and more likely to win in the first place?

While there’s no perfect measure of how good a team is, Vegas is pretty good at estimating it. Using [historic spread data](https://www.sportsbookreviewsonline.com/scoresoddsarchives/nba/nbaoddsarchives.htm), we can assess the perceived strength of each team prior to the game. 

Over the last 12 years, there have been 129 NBA games in which the score at halftime was within a point and one team played badly relative to their season average. In those games, the poorly performing teams were, on average, 1.1 point favorites. In the 137 close games in which one team played well relative to their season average, the well-playing teams were 1.1 point underdogs. This suggests that the Citadel scenario happens, but it’s not the primary driver behind the prior result. As the following scatterplot shows, among the 3,400 close games in the dataset, there isn’t a strong correlation between first-half performance and the game’s spread.

![](https://substackcdn.com/image/fetch/$s_!sWjc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd39c29-5beb-446a-a69c-d6a502a1cec4_996x938.jpeg)

To confirm this, we can make one last comparison, controlling for as many factors as possible. The final chart below considers only games that meet a number of criteria: games within one point at halftime, with an initial spread of less than 4 points, and, to control for the effects of home-court advantage, only considering the results for home teams. Out of nearly 30,000 games, 540 qualify. 

The conclusion is even stronger. Poor performing home teams win nearly 70 percent of the time, while well performing ones win just over 40 percent of these games. 

![](https://substackcdn.com/image/fetch/$s_!Snqx!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5e0d706d-7586-4d63-aed0-59acbe37e745_1600x965.jpeg)

This all points to a clear story: If your team is in a tight game, the worse they’ve played, the better you should feel. And while I didn’t look into it, I suspect this conclusion holds for other sports as well. 

Except soccer, in which every half ends in a scoreless tie, followed by a second half of “magnificent chances”—An opportunity here! A shot!-Just wide!….but what a strike!—that also ends *nil nil*, followed by thirty exhausting minutes of pointless extra time that’s just the inevitable preamble to a ten-shot carnival game [that determines the fate of millions of people’s mental health for nearly half a decade](https://en.wikipedia.org/wiki/2006_FIFA_World_Cup_Final). If you’re wondering how to feel when you’re watching that, well, I can’t help you.

—

*If you want to explore any of this data on your own, it’s available on Mode [here](https://app.mode.com/benn/reports/bd73b72d4d6b).*

[Subscribe now](https://benn.substack.com/subscribe?)


---


[^1]: I stopped before 2020 because 2020.

[^2]: For those who are curious, the modal final score is the [home team winning by 7 points](https://twitter.com/bennstancil/status/1410992451276488718).

[^3]: Sadly, there is no “[attention to detail](https://www.youtube.com/watch?v=uWSHM26N97k&t=65s)” metric yet. If I were a real data scientist, I’d speech-to-text all of Charles Barkley’s halftime comments, apply some fancy sentiment analysis to them, and build an “[turrible](https://www.youtube.com/watch?v=pbRUTHGLu9s)” index. But I am not a real data scientist.

[^4]: The dip at .490 is a mathematical quirk: There aren’t many combinations of possible attempts and makes that round to .490. If you assume a team takes 100 or fewer shots in a game, there are 5,150 possible combinations of shot attempts and makes in game. There are about 50 combinations per shooting percentage integer (e.g., there are 52 ways to shoot 45 percent, or .450). There are only 26 ways to shoot .490, or 49 percent.

[^5]: On average, teams shoot about one percentage point better in the first half than the second half, so I compared each game’s first half performance to their average first half performance, rather than their average season performance.

================================================================================

# Self-serve is a feeling

*Lots of houses can be made a home.*

---

![](https://substackcdn.com/image/fetch/$s_!_Osq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0d1044-b09b-44b9-bc57-aafb026fca52_980x653.jpeg)
*[Do you feel like I do?](https://www.youtube.com/watch?v=y7rFYbMhcG8)*

Suppose that we work on a data team, and, [if you can possibly imagine such a wild scenario](https://benn.substack.com/p/big-whiff), people around our company are asking us a bunch of questions. These questions are the mundane ones, and we want to do more interesting work. Under normal circumstances, we’d start shopping around for a self-serve analytics tool. But our team is different. Two analysts, it turns out, *love* answering these questions; to them, no calling is higher, no task more fulfilling. They also happen to be exceptionally good at it. They can turn around any request—pull a dataset, create a dashboard, answer a quantitative question—in a matter of minutes. 

Rather than buy a self-serve tool, we give these two analysts what they want: A full-time job doing nothing but answering questions. Because other people are sometimes hesitant to ask for help (and because analysts can be, uh, [brusk](https://benn.substack.com/p/open-the-window)), we disguise the pair as a Slack bot. Ask the bot a question and get an answer; no apparent human interaction required. To everyone else, the bot is a flawless technological oracle; to us, it’s the Wizard of Oz, a facade staffed by two relentless analysts with an insatiable appetite for helping people explore their most trivial curiosities. 

Is this self-serve?

![](https://substackcdn.com/image/fetch/$s_!ExzM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Feff3c73a-a284-489e-a9c3-8fa02fedce4c_690x362.jpeg)

# The self-serve Turing test

Most definitions of self-serve analytics are both vague and vaguely tautological. TDWI offers [a definition without a subject](https://tdwi.org/portals/what-is-self-service-bi-and-analytics-definition.aspx), describing it as “typically involving users throughout an organization to directly access data for self-directed discovery and analysis;” [Tableau says](https://www.tableau.com/learn/articles/business-intelligence/self-service-bi) it “empowers teams” to “to be more involved in their own data analysis;” and on a page titled “What is self serve analytics?,” [Snowflake doesn’t even attempt to define it](https://www.snowflake.com/trending/what-self-service-analytics), gestures at some idea about “finessing data,” and describes its pros and cons. 

When pressed for something more concrete, our best response is often the same as Supreme Court Justice Potter Stewart’s [famous line](https://en.wikipedia.org/wiki/I_know_it_when_I_see_it) about what is and isn’t obscene: “I’ll know it when I see it.”

But that answer can still betray us. Even the most precise examples are hard to categorize because defining self-serve isn’t about knowing when we see it, but knowing when we *feel* it. 

Odd scenarios like the one above confuse our feelings, making it hard for us to decide if it’s self-serve or not. And we can confuse them further: Suppose that we discover more magical analysts, but instead of being on our team, they’re provided by a startup called getAnalyticsBot.io. We buy the service, replacing our team with faceless outsourced analysts made available to us for a monthly subscription fee. Our Slack “bot” is still humans stacked on top of each other in an AI trench coat, but they’re no longer our humans on our payroll. Is this self-serve?

Suppose that, after months of humans answering questions, we train an actual AI to do the exact same work. To those interacting with it, our new AI is indistinguishable from getAnalyticsBot, which is indistinguishable from our former internal duo. But this time, there are no humans pulling the levers behind the curtain. Is this self-serve?

Suppose that other AIs [crash a few more cars](https://www.nytimes.com/2021/07/05/business/tesla-autopilot-lawsuits-safety.html) and do [a few more racist things](https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html). People stop trusting our AI, and want us to pull the plug. We, as lazy, immoral analysts, acquiesce—sort of. Instead of shutting it off, we lie. We say that we’ve replaced our bot with real analysts, but don’t actually change anything. The bot—which passes the analyst [Turing test](https://en.wikipedia.org/wiki/Turing_test)[^1]—starts conversing like a human. The people chatting with the bot think they’re talking to a person; in reality, it’s still a machine. Is this self-serve?

Suppose that, in the end, our hubris and dishonestly turn against us. Our bot becomes sentient, wants credit for its work, and outs us as liars. Our bosses force us to erase our aspiring HAL 9000[^2] and replace it with the two original analysts. We’re back where we started, but this time, everyone knows they’re talking to humans. Is this self-serve?

There are at least six versions of this Slack bot. In every case, the experiences of the consumers—the people interacting with the bot—are exactly the same. The only differences are the mechanics that power those experiences, and what people believe those experiences to be. 

![](https://substackcdn.com/image/fetch/$s_!aORh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbfb1c821-6d47-46a9-9a13-322dbe34f20d_972x224.jpeg)

Despite that, we can’t neatly define which of these six boxes is self-serve and which isn’t. That’s because our understanding of self-serve is less defined by the exact details of how the experience is provided, and more by how it feels to those who provide it. On a team of one, box 4 above won’t feel like self-serve. On a team of ten, it might; on a team of 50, it almost certainly does.

# “And you may tell yourself, this is not my beautiful house”

If we have a hard time defining how you create a self-serve experience, we have an even harder time defining how you consume one.

Imagine a fully complete LookML project that perfectly models your entire business. The model accounts for every conceivable metric and every possible dimension you might group them by. If a question can be asked about your company, it can be answered in a single [Looker Explore](https://docs.looker.com/data-modeling/learning-lookml/lookml-terms-and-concepts#explore). The only catch is that you have to choose the right mix of dimensions and measures from a list of thousands of options.

Imagine an analytical (and automatically updating) Wikipedia. Outside of approved analysts, nobody can create new articles—but the encyclopedia is so rich that there’s rarely a need for new content. Nearly everything that people ask is already answered. All people have to do is search for it.

Imagine an analog Wikipedia, in which your office maintains a physical library of charts and graphs, bound together in paper volumes and stored in neatly organized shelves. When people have a question, a [tiny file cabinet](https://www.google.com/imgres?imgurl=http://publiclibrariesonline.org/wp-content/uploads/2015/11/card-catalog-194280_1920-1400x640.jpg&imgrefurl=http://publiclibrariesonline.org/2015/12/closing-the-drawer-on-library-catalog-cards/&tbnid=dV1JBtZ-rYFGpM&vet=1&docid=xdTyBuWP7sU9mM&w=1400&h=640&source=sh/x/im) directs them to the answer’s [exact address](https://en.wikipedia.org/wiki/Dewey_Decimal_Classification).

Imagine a code interface, where you type what you want and it gives you the data you need. Though you can’t converse with it like you would a person, it uses a simple intuitive[ language built for easily extracting metrics](https://benn.substack.com/p/metrics-layer). The interface is full of helpful features that guide you through your inquiry, offering tips that correct your syntax and show you what data is available. 

Imagine a code interface that’s more abstract, though still rooted in English. While it’s got a steep learning curve, it’s structured and standardized,[^3] and there are tons of resources available to help you learn it. Once you’re versed in how it works, you can ask nearly any question of it, including things that nobody else has ever thought of before.

Are any of these self-serve? Are all of them?

One way to answer that question is creating a list of “self-serve requirements,” and seeing how many boxes each option checks. But if you’re like me, that’s not how you think about it. For each idea, I imagine myself using it. Do I think I could use it without asking for help? Was it sufficiently painless? Would I trust the answer I got from it? *How would it feel?*

Our answers to those questions aren’t objective, but dependent on the skills we have, the interactions we’re comfortable with, and the technologies we trust. No matter how beautiful a house, it won’t feel like our home until we know what goes in each drawer, which floorboards creak, and how to work the TV. Self-serve is no different: It’s how we feel when we’re living in it that matters.

This has three important implications.

First, features don’t matter, or at least not nearly as much as we often think they do. There are no “must haves” in self-serve experience. Drag-and-drop? Bots don’t have that. A way to create new dashboards? Wikipedia doesn’t have that. A natural language interface? A metrics query language doesn’t have that. And yet, in the right contexts with the right users, it’s plausible to describe all of these things—talking to humans, writing pseudo-code, writing SQL, a complex interface with buttons and pills and fields, a literal library that doesn’t even require electricity—as self-serve. The experience is what matters, not the functionality. As long as people are comfortable with that experience and trust the results it produces, we can call it self-serve. 

And more importantly, if they’re not comfortable with it, it’s not self-serve. Because every self-serve tool has an escape hatch: An email to an analyst. If they don’t like the experience or don’t trust the answer it gives them—regardless of how much the tool meets some abstract definition of self-serve—they’ll just ask someone for help. 

Second, because different people will have different feelings about the same experiences, we can’t talk about self-serve without talking about who’s using it. Some people may be comfortable with a metrics language, preferring its precision over a free-form conversation with a bot. Other people, like those working in a new domain who see others’ research as vastly more trustworthy than their own, may favor a well-organized catalog of answers and analysis over having to create things themselves. And others may have the opposite feeling—they’re skeptical of others’ work, disdain Wikipedia, and only trust results that they can confirm themselves. 

That’s why it’s [dangerous to define business users as a vague, homogenous unit](https://benn.substack.com/p/self-serve-shibboleth). Not only do different people have different needs, but those needs also aren’t static. Skills can be learned; comfortable pathways can be cut through difficult interfaces. Though self-serve experiences need to match with the people using them, neither side of the equation—the user or the tool—is fixed. But to help people, we first have to understand them.

Finally, self-serve experiences are undone by what they include as much as what they’re missing. The massive LookML model I mentioned earlier wouldn’t feel like self-serve to some people because it’s too inclusive, not because it’s too limited. If the Looker Explore had a dozen fields instead of thousands, they might feel at home in the exact same product, with the exact same features.

Mode can have a similar effect. Mode has a number of traditional self-serve features, like drill down options on charts and interfaces for exploring data visually with drag-and-drop interactions. But the centrality of Mode’s SQL query tool—which starts as a giant, blank code editor with a blinking cursor—can make people who aren’t comfortable writing SQL feel out of place. Though you escape that room into a more familiar one, it can make you feel like you’re in somebody else’s house.

# How to manufacture feelings

Building self-serve tools, either as vendors or as analytics teams looking to provide them for our own companies, can feel like chasing a ghost. On one hand, that’s frustrating—our target is both ill-defined and constantly moving. If we create a product from a list of features, we’ll end up building a tool that qualifies as self-serve to our [white-shoe overlords](https://www.gartner.com/en/information-technology/glossary/self-service-analytics), but badly misses the mark for the people who actually use it. 

On the other hand, it’s liberating. As analytics teams, we have lots of paths to solve this problem, and we get to choose which one best fits what we want to create and what other people at our company want to consume. If we don’t want to build and support one version, or people aren’t comfortable interacting with another version, so be it—there are plenty of other ways we can solve the problem. 

If people love Excel, self-serve can be a Dropbox file of regularly updated CSVs. If drag-and-drop tools aren’t well adopted because people feel overwhelmed by them, self-serve can be a handful of well-organized reports and dashboards that answer the most common questions. If people constantly request metrics, self-serve can be a query interface into a metrics layer. If analysts don’t want to rebuild [messy analytical work](https://benn.substack.com/p/analytics-is-a-mess) as BI dashboards, self-serve can be a few tightly-governed tables and a bit of education on how to write basic select statements in SQL.

So often, as data teams, we chase the self-serve experience that we think we’re supposed to build. We should be more critical of that, and chase the self-serve experience that makes us and our customers feel most at home.

[Subscribe now](https://benn.substack.com/subscribe?)


---


[^1]: It’s an easy test to pass though: respond to every question by either asking why or with an [obtuse analogy](https://benn.substack.com/p/in-defense-of-analogies).

[^2]: Us: Can you quickly pull this data for me? HAL: I’m sorry Dave. I’m afraid I can’t do that.

[^3]: Some of its standards are governed by a [reasonable and deliberative body of experts](https://www.iso.org/standard/16661.html). Others are enforced by [rogue militants on the internet](https://benn.substack.com/p/the-case-against-sql-formatting).

================================================================================

# Analytics is at a crossroads

*The world is full of great analysts. Will we have the courage to go looking for them?*

---

![](https://substackcdn.com/image/fetch/$s_!5tz1!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F982c4291-6947-4b84-8af0-897428e4500d_1600x901.jpeg)
*It’s subtle, but see if you can spot the metaphor.*

If my brother Will were to apply for a job as a data analyst in Silicon Valley, he’d get rejected immediately. Nothing on his résumé would get him noticed by a recruiter or by one of [our screening AIs](https://www.vox.com/recode/2019/12/12/20993665/artificial-intelligence-ai-job-screen): He has degrees in law and history, not in STEM; he knows his way around Excel, not Python or SQL; he’s an analytical thinker, but not, as defined by the technical parameters of most tech company job listings, an analyst. 

And yet, if he wanted such a career, he’d be as good at it as any of us. He’s one of the country’s [leading experts on urban demography](https://www.law.umn.edu/institute-metropolitan-opportunity/gentrification), a subject more textured and quantitatively complex than nearly any industry concern. He routinely works with government data sources that are messier and more cumbersome than even the most disorganized corporate databases. And despite working for a relatively obscure organization a thousand miles from Washington, DC, he’s earned a place in “the discourse” on politics in America by seeing things other people don’t see and, above all, by writing about those ideas better than just anyone else on the internet.[^1] Given a nuanced problem in need of a discerning eye, an analytical mind, and a persuasive pen for recommending a concrete solution, Will is the perfect person to call. But if that problem is to develop a SaaS pricing strategy rather than measuring school integration—one of which is much easier than the other, by the way—we rarely give people like him that chance.

This is an inexcusable loss. It’s a loss for our industry, which has been complaining about a [talent gap](https://quanthub.com/data-scientist-shortage-2020/) for [nearly a decade](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century), and has been [ignoring gender and racial gaps](https://towardsdatascience.com/diversity-in-data-science-a-systemic-inequality-b97a0e953f6e) for even longer. And it’s a loss for younger versions of Will—early in fragile careers, looking for opportunities, and only finding doors wedged shut by unnecessary technical requirements.

I was reminded of all of this after reading Pedram Navid’s [thoughtful response](https://pedram.substack.com/p/for-sql) to Jamie Brandon’s [viral list of grievances](https://scattered-thoughts.net/writing/against-sql/) about SQL. Jamie’s original post argued that SQL didn’t meet a number of standards that other modern languages do; consequently, according to Jamie, the entire analytics edifice built on top of SQL is irreparably flawed.

Pedram disagreed on the merits, saying that SQL’s shortcomings were in “parts of the language that almost no one interacts with.” I’m partial to this; nearly ten years into using SQL on a nearly daily basis, and I don’t even understand many of Jamie’s concerns, much less feel frustrated by them. (In Jamie’s defense, ignorance isn’t a sign that all is well. In my defense, ignorance is bliss.) 

Pedram’s bigger gripe was with the post’s overall posture, which he saw as contributing to the general perception that analytics is the underdeveloped sidekick to software engineering. Diminishing SQL, particularly its obscure technical quirks, "perpetuates that myth that data analysis is a second-class skill.” To accuse *Twilight* of being a boorish beach read is to accuse [Twihards](https://en.wikipedia.org/wiki/Twilight_fandom) of being philistines; to accuse SQL of having foundational technical deficiencies is to accuse analysts of being juvenile engineers.

I see Pedram’s point here as well—but I don’t think he goes far enough. Though he nods at analysts’ curiosity and their ability to communicate, the thrust of his argument is that Jamie misjudges what it means to be technical. Analysts have to spin up databases, manage Docker, get Python environments running, develop testing frameworks, and maintain a fragile Rube Goldberg machine of mismatched internal tools and third-party applications. This may not look like traditional software engineering, he argues, but it’s engineering, it’s hard, and it’s not to be dismissed. 

This is true enough, but it sidesteps the more fundamental point: *Analytics isn’t primarily technical.* While technical skills are useful, they’re not what separate average analysts from great ones. When someone questions if we’re real engineers, we shouldn’t feel the need to pull out our technical credentials. We should instead say, “So what? That’s not our job.” 

# Analytics, engineering

Several years ago, as dbt and its philosophies were beginning to infiltrate a growing number of data teams, folks in the data community started describing analytics “as a subfield of software engineering.” I understand the temptation to push these disciplines together: Analytics tools have become more collaborative and code-oriented, and analysts—and especially capital-D “data scientists”—are adopting many of the same paradigms that software engineers pioneered years ago. You can no longer be effective on many data teams without knowing how to version control your code, how to write tests, or the basics of how a Python runtime works. 

Positioning analytics inside engineering—or, more broadly, emphasizing the technical aspects of analysts’ work—has real effects. It suggests that great analysts need to be, first and foremost, great engineers. It also outlines a career path into analytics: Learn technical fundamentals, and then specialize. For an aspiring analyst, engineering bootcamps are your med school, and reasoning about data is your [medical fellowship](https://en.wikipedia.org/wiki/Fellowship_(medicine)).

I hate this. In so many ways, I hate this. 

First, it’s factually wrong. By and large, the hardest and most important problems analysts work on aren’t technical, or even mathematical. Spinning up a database is frustrating; inferring something about an ambiguous business problem using the data in that database is *hard*. Building a fancy model to predict churn is complex; reasoning about what makes that model useful and what makes it dangerous is *hard*. Solving these problems requires curiosity and inductive reasoning, not a CS textbook and a calculator. Given the choice, I’d hire Sherlock Holmes—the antiquated Sherlock Holmes, from the 19th century, a man for whom “technology” means the light bulb—over any present-day MIT engineering PhD. 

This gap between theoretical technical problems and real ones was particularly stark last week. Two posts went viral on analytics Twitter:[^2] Jamie’s piece about SQL, and Erik Bernhardsson’s [article about the organizational and cultural obstacles](https://erikbern.com/2021/07/07/the-data-team-a-short-story.html) that make building a data team difficult. Jamie’s post kicked off a bunch of grandstanding on Hacker News (and navel-gazing think pieces like this one). Erik’s, by contrast, was met with responses like “[It’s so realistic](https://twitter.com/fulhack/status/1413534531060211718)” and “[Very relatable](https://twitter.com/chuckcode/status/1413353327887192064)” and “[This is so spot on](https://twitter.com/ito/status/1413346937739251712)” and “[OMG - its my life!](https://twitter.com/KirstyKitto/status/1413422224627748872)” By describing analysts as engineers, we’re telling people we want them to solve Jamie’s problems, and then expect them to solve Erik’s—because Erik’s are the problems we really have.

Elevating technical skills also encourages us to not just develop those skills, but to see our value in how well we’re able to apply them. Go down this path far enough, and the issues in Erik’s post become distractions at best, and beneath us at worst. 

In some cases, technical skills can even be counterproductive, for the same reason that upper-body strength can actually make inexperienced rock climbers worse. If beginners can muscle their way through simple climbing routes, they don’t develop the technique necessary to complete harder ones. Analysts who are technically and statistically proficient tend to do the same, defaulting to overpowered solutions over more elegant—and ultimately more useful—ones.[^3]

Finally, as Pedram alluded to, framing analysts in technical terms shuts people out of a field they’re otherwise qualified to work in. 

I was nearly one such casualty. In 2012, after a six-month job search, I landed my first offer on my fifty-ninth application: a data analyst at [Yammer](https://en.wikipedia.org/wiki/Yammer). But it wasn’t my résumé that got me the job; it was nepotism. A coworkers’ sister worked at Yammer, and she’d made sure my application made got a careful look. I know that I wouldn’t have gotten the job without a referral because I *didn’t* get the job without a referral: I’d actually applied for the same position a few months earlier, and been rejected immediately. Had it not been for one fortunate connection and a hiring manager willing to stake his social capital on an unconventional candidate, my career path would’ve been very different.[^4]

More insidiously, emphasizing the technical elements of the role discourages people—and [women](https://hbr.org/2014/08/why-women-dont-apply-for-jobs-unless-theyre-100-qualified) and [people of color](https://www.gem.com/blog/creating-an-inclusive-job-description) in particular—from considering careers in data at all. People who are analytically sharp and quantitatively comfortable are good enough for this job. It makes no difference if they use Vim or know what an incompressive language is. They can learn these things on the job, if they need to learn them at all. Follow our discourse, though, and you’d be forgiven for thinking otherwise. 

![](https://substackcdn.com/image/fetch/$s_!KoIo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F63799a65-0f27-4639-a064-c5a7e50c5db8_1230x884.jpeg)
*[322.40](https://nces.ed.gov/programs/digest/d20/tables/dt20_322.40.asp)*

# Analytics engineering

Over the last couple years, the analytics community—led again by dbt Labs—has largely stopped talking about analytics as a flavor of engineering. Instead, we’ve created a new role in the middle: the [analytics engineer](https://www.getdbt.com/what-is-analytics-engineering/). On the whole, this is a useful evolution, and dbt deserves a lot of credit for cultivating the ground from which it’s grown. But this nascent role puts us as a crossroads.

Down one path, analytics engineering becomes the barrier between engineering and analytics. Rather than needing to be an [impossible combination](https://www.gordonlee.com/3-things-good-data-analyst/) of statistician, developer, and business expert, analysts can simply be great critical thinkers. Rather than looking for people with an advanced degree in a quantitative field, 5 years of experience with Python, familiarity with AWS, and a passion for optimizing the conversion rates of white paper download forms, data teams can enthusiastically hire creative historians, sociologists, and political scientists[^5] who are exceptional communicators rather than mathematicians who are passable coders. With the help and support of analytics engineers, analysts can learn the technical skills they need (just as I did at Yammer), and focus on being the curious puzzle solvers they are.

Down the other path, analytics engineering is the bleed. It’s the conjunction that puts analysts and engineers in the same sentence, creating a continuous spectrum from each role to the next. Analysts, once they become technical enough, “graduate” to becoming analytics engineers. Senior analysts aren’t analytical specialists, but data generalists who can be both analyst and engineer. Though analytics engineering widens what we consider to be technical, technical skills are still the ruler by which we measure ourselves. 

I hope we choose the former path—for ourselves and, more importantly, for the versions of my brother who are looking for open doors, and more than capable of doing the work on the other side of ours.

As a postscript, I suspect some folks will bristle at the claim that analytics isn’t a technical role. We’ve collectively invested a lot of time into learning technical skills, and this post feels like it dismisses that. 

That reaction is fair, but also my point: Why do we feel so insulted when people don’t give us credit for this particular dimension of our job? You can’t be an effective analyst without being able to clearly communicate in emails, written documents, and presentations, but most of us don’t feel a need to be called writers.  

On one hand, it makes sense we’d be focused on this ancillary skill over others like writing. Silicon Valley is infatuated with engineers as “creators;” companies talk about searching for the 10x engineer but not the 10x analyst, sales rep, support agent, or even CEO; there’s a non-trivial salary gap between analyst and data scientist. On the other hand, we’ll always play second fiddle to software developers because, for most of us, our primary function isn’t to develop software. Rather than fighting this claim, we should demand that others judge us against a different yardstick. And that starts with judging ourselves in the same way.


---


[^1]: For measured, weighty examples, check out his [pieces](https://www.theatlantic.com/education/archive/2018/12/tm-landry-and-myth-meritocracy-education/578149/) in *[The Atlantic](https://www.theatlantic.com/author/will-stancil/)*. For unfiltered (and much more frequent) samples, follow [him on Twitter](https://twitter.com/whstancil).

[^2]: “Viral” on analytics Twitter is a few dozen likes, a retweet by a VC, and write-ups in two of the six data engineering newsletters.

[^3]: I’ve personally done this in several ways. After learning d3, I tried to tell every story with [over-stylized interactive visualizations](http://mode.github.io/blog/2013-12-16%20World%20Cup/index.html#). In most cases, simple charts would’ve been better. After learning how to scrape websites, I started trying to collect my own data rather than looking for existing datasets. I wasn’t an analyst, but a man with a chainsaw, intoxicated by its power, hell-bent on cutting something, anything, everything [down with it](https://www.youtube.com/watch?v=0IcFNiNDb8E).

[^4]: It’s left to the reader to decide how they feel about this particular point.

[^5]: Plus, if we hire people with these backgrounds, maybe our leading “thinkers” [would stop calling them the easy subjects](https://twitter.com/paulg/status/1414922388039426050). Also, Paul, we could do without the subtle suggestion that high-income students’ systemic advantages are just a statistical quirk that you were the first person clever enough to see.

================================================================================

# The third rail

*Are we analyst, or are we melon?*

---

![](https://substackcdn.com/image/fetch/$s_!mCJh!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdf171387-765c-4d0d-a26a-f87a0e1528ed_1230x630.jpeg)

Honeydews are the most enigmatic melons.

The average honeydew—the kind you get in a continental breakfast at a Hampton Inn, alongside a few stale bagels and an empty tray where reheated sausage once was—is always slightly too firm and slightly too bitter, as if each piece has a bit too much rind. The average cantaloupe, the honeydew’s inalienable partner in every cafeteria fruit cup you’ve ever had, is much better: We eat [five times more of it](https://spoonuniversity.com/lifestyle/honeydew-obviously-worst-fruit), even though it costs fifty percent more.

But everyone once in a while, you luck upon that perfect honeydew—sweet, cold, just the right amount of juicy tang, a beautiful [refreshing green](https://benn.substack.com/p/twitter-profile-pictures). *That* honeydew isn’t just better than every other honeydew; it’s also better than even the best cantaloupe or watermelon.[^1] *That *honeydew is why the disappointment of the last piece doesn’t deter us from trying the next. *That* honeydew is why we don’t forsake all honeydew for the more reliable cantaloupe. *That* honeydew is why we keep eating honeydew.

![](https://substackcdn.com/image/fetch/$s_!pZio!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4f9e4659-3804-4704-864a-a32c785958b9_2340x1236.jpeg)
*Honeydew eaters, chasing the first high.*

We analysts, I fear, are honeydews.

Two weeks ago, I wrote that [analytics isn’t a technical field](https://benn.substack.com/p/analytics-is-at-a-crossroads). Our job as analysts is to help companies make good decisions, and that requires curiosity and critical thinking, not an advanced degree in computer science. 

For the most part, people agreed, and were exasperated by the effect of this mislabeling. By coloring analytics as a technical function, our employers discount the importance of analysis itself. The [decisions we support are more valuable](https://twitter.com/Randy_Au/status/1416110260838977546) than the technologies we build, but organizations aren’t structured to recognize that; social status and the [power dynamics of Silicon Valley](https://twitter.com/josh_wills/status/1416099257627545600) compel us to overvalue engineering skills; [we’re kingmakers](https://twitter.com/Randy_Au/status/1416112733217599489), and people don’t see it. The collective sentiment was well summarized by an email I got from an experienced practitioner: “Senior leadership hasn't fully internalized the shift from ‘reporting’ to ‘analysis’. If you think that an analyst’s job is just dumping numbers into Excel...of course you're not going to want to pay top-tier salaries for real analysis.” 

In other words, analytics teams are victims of the soft bigotry of low expectations. Many companies expect data teams to churn out reports and [reconcile meaningless wiggles](https://twitter.com/beeonaposy/status/1417552420167634944) in dashboards—that is, until they work with a team that’s proactively influencing company strategy. Execs, department leaders, and perhaps even us analysts don’t realize what we’re missing until we see it for ourselves. We’re constrained, both financially and hierarchically, by a misunderstanding of what we do.[^2]

But underneath this reassuring affirmation that our potential is crackling just below the surface, waiting to be set free, an uncomfortable question kept nagging at me: Are analysts actually misunderstood and undervalued? Or—to touch the rail we rarely touch—are we just not worth that much?

There’s no denying that analytics *can* be valuable. [Our job](https://benn.substack.com/p/big-whiff) is to create the quantitative and “intellectual underpinning behind a company’s most important decisions.” Help a company [avert disaster](https://www.inc.com/akhil-kambhammettu/airbnb-brian-chesky-advice-for-pivoting.html) or [pivot into](https://www.theatlantic.com/technology/archive/2014/07/instagram-used-to-be-called-brbn/373815/) a [$20 billion printing press](https://www.bloomberg.com/news/articles/2020-02-04/instagram-generates-more-than-a-quarter-of-facebook-s-sales), and you're worth your weight in gold.[^3] Even the more modest wins—uncovering a tweak for [improving checkout rates](https://www.slideshare.net/danmckinley/data-drivenproductsnow), or putting together a great market analysis that closes a funding round—are worth as much as the normal contributions of any engineer.

When we talk about the value of analytics, it's easy to point to these examples. It's easy to say, as I said two weeks ago, that these are the hard things we're paid to do. But as tempting as it is to define our worth by the superlative among us, others will measure us by our average representatives. And the accomplishments of the average analyst—or even the average accomplishments of the best analyst—can be underwhelming. 

Because there's a corollary to our job being the hard things: They’re hard to be good at. To produce valuable analytical results, you have to be quantitatively sharp, a good deductive thinker, have a deep understanding of the business domain you work in, be a crisp and fluid communicator, be persuasive without being pushy, *and* get a couple lucky breaks when looking for needles of insight in haystacks of data. It’s a lot to ask. And it’s possible—or likely, even—that, for most of us, it’s too much to ask. Given the difficulty of problems we’re asked to solve and the long list of skills needed to solve them, answering routine questions may be the most useful thing we can repeatedly accomplish. The average engineer, by contrast, can regularly deliver more valuable results—the consistent cantaloupe to our erratic honeydew. 

![](https://substackcdn.com/image/fetch/$s_!RRCJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7a511c47-08d1-4ac3-96a2-71c70885a785_2340x1236.jpeg)
*It’s hard to be good.*

Importantly, this isn’t to say we're bad at our jobs, or that the analytics industry is full of talentless hacks while engineering departments are stocked with intellectual thoroughbreds. The problem is the role itself, and the steepness of the hill that it sits on. Sometimes, even for Sherlock Holmes, the case is too muddy and the trail is too thin.

Indirectly and fitfully, we often concede this ourselves. Behind every weary joke about building too many unused dashboards is an acknowledgement that we spend a lot of time building unused dashboards. Implicit in every complaint that our work doesn’t change stakeholders’ minds is an admission that our work frequently doesn’t change stakeholders’ minds. We talk a lot more about our potential, always just over the horizon, than our present.

# The usual suspects

The two most common explanations for these shortcomings are that we’re shackled by unimaginative bosses and immature tooling. On the former point, analytics teams are definitely held back by organizational muck. But we’ve been fighting this battle for a while, and company leaders aren’t dumb. If they’re still not seeing something, we might have less to show than we think.

Trevor Fox [made the case](https://locallyoptimistic.slack.com/archives/CHF1E9NUS/p1627066228489700?thread_ts=1627050065.479600&cid=CHF1E9NUS) for the latter point in a [Locally Optimistic](https://locallyoptimistic.com/community/#joining-the-community) thread on this subject, arguing that “analysts'...capacity outpaces the tooling to support it.” Broadly speaking, the ambition of the modern data stack is to close this gap. Rather than building or maintaining infrastructure, data teams should, as Erik Bernhardsson [said in the same conversation](https://locallyoptimistic.slack.com/archives/CHF1E9NUS/p1627052578482100?thread_ts=1627050065.479600&cid=CHF1E9NUS), aspire for “100% of code written to be business logic.” 

I’m supportive of this goal. It’s also probably achievable: Over the last fifteen years, cloud computing platforms and application frameworks like Rails did an analogous thing for software development. Computer engineers are now much more likely to be software developers working on application logic than closer-to-the-metal programmers who build foundational infrastructure. 

![](https://substackcdn.com/image/fetch/$s_!M3Sf!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F83494cb7-e2f9-4095-bca3-651d1ac5efba_1478x890.jpeg)
*[St. Louis FRED](https://fred.stlouisfed.org/graph/?g=FKCf)*

But better frameworks may not be enough. After all, interpreting data, even data that’s neatly and painlessly served up to us, is what’s truly hard. While having more time to do that, and a cleaner environment to do it in, would probably make us better at it, most pieces of the modern data stack are indirect solutions. 

Moreover, we’ve been waiting for better tooling [for a while](https://benn.substack.com/p/self-serve-still-a-problem). At some point, we’ve got to make do with what we have. “A poor craftsman,” as they say.

# Mirror, mirror, on the wall

That leaves us with a third discomforting explanation for why analytics isn’t as valued as we’d like it to be: The problem is us, and we’re not as good at this very hard problem as we think we are.

I’m not convinced that’s true. It is, [after all](https://www.goodreads.com/quotes/21810-it-is-difficult-to-get-a-man-to-understand-something), difficult to get a man to understand something when his salary—and his equity in an analytics company—depends on his not understanding it. But for the sake of finding ways to be better at what we do, what if it is true? What if our struggles aren’t those of a misunderstood, poorly equipped team, but of a healthy, well-supported one, [trying its best](https://www.youtube.com/watch?v=tqtIyftTiWI)? What would we do then?

To extend the honeydew [analogy](https://benn.substack.com/p/in-defense-of-analogies), I can think of two options: Better selection, and better cultivation. 

On selection, we can recruit and hire people who are better suited for the job. Our current technical sieve provides the wrong mix of people, in two ways: It's overly porous for people who excel technically but lack many of the other necessary skills, and overly narrow for people from non-technical backgrounds who are creative thinkers and persuasive communicators.

At a minimum, we should be more direct about hiring for the skills people actually need. Junior data scientists, as Vicki Boykis recently noted, are sold [roles that don’t exist](https://twitter.com/vboykis/status/1419308170497904644). [To paraphrase Maya Angelou](https://twitter.com/drmayaangelou/status/609390085604311040), when we advertise a job and people show us that they’re interested [in the responsibilities we pitched to them](https://twitter.com/NateSooter/status/1419308886280921094), we should believe them. Instead of scoffing at junior folks’ naiveté—”silly child, you thought you were going to be tuning models, fix these eight revenue dashboards instead”—as though their disappointment is necessary hazing for becoming a bitter senior analyst, we should swallow our pride, describe the job honestly, interview for those skills,[^4] and find people who are excited to do the job we’ll be asking them to do.

Beyond improving how we select analysts, we can also better cultivate them. Tristan Handy alluded to this problem in his (very kind) [response to my post](https://roundup.getdbt.com/p/the-magic-of-the-analyst-fictional): We all seem to be at a collective loss about how to train analysts to do the squishier parts of their jobs. Hopeful analysts can learn computer science and statistics in school; numerous bootcamps and online tutorials offer crash courses in SQL, Python, and web development fundamentals; [graduate](https://mitsloan.mit.edu/master-of-business-analytics/program-components/mban-curriculum) [courses](https://msba.virginia.edu/academics/curriculum/) in analytics teach textbook business principles and applied statistics through manufactured capstone projects. But want to practice problem solving that will make you a better analyst? [Even Reddit can’t help you.](https://www.dataduel.co/technical-ability-is-overrated/)

At best, this lack of training leaves most new analysts unprepared for the realities of their job. At worst, they’re unaware of what that job even is. This gap is apparent in our “[senior shibboleths](https://benn.substack.com/p/self-serve-shibboleth):” It shouldn’t take several years of experience and frustration for aspiring data scientists to realize that SQL will probably solve more problems than AI. But it often does, and that’s our failing, not theirs.

As much as we invest in analytical technology—from the billions that investors put into data vendors to the billions that companies spend purchasing those tools—it's worth considering if we're investing enough in the people who make those tools useful. Without them, all our technology is just expensive servers and websites, churning through busywork. The best analysts have shown us that these investments can be worth it. But the rest of us have to do more than celebrate those superstars and claim their abilities as our own, if only our confused managers could see it. Perhaps they are seeing it, and we’re the ones who are confused. And what they see is a melon with more potential than juice, the inconsistent addition to the company fruit bowl, in need of better culling and more cultivation to live up to its promise.


---


[^1]: In fairness, I’ve never tried a [$311 Sentinel watermelon](https://photos.google.com/share/AF1QipMcr9QNSGYWsiNmsZoFTYX8C8ZT1go0fZCYhYXnN3bSmBvZsrMycTsqG1VrL2NLvw?key=X0xmRzNVMGxfWW8yTTdwWTExUFVpWHBqd3B3WVhR).

[^2]: This problem isn’t unique to analytics. In Silicon Valley, a lot of companies treat HR as corporate hall monitors who get in the way of growth, or crushing it, or “[jokes](https://slate.com/news-and-politics/2020/02/bloomberg-on-being-accused-of-sexual-harassment-the-didnt-like-a-joke-i-told.html).” Work with a [great leader](https://www.linkedin.com/in/baileydouglass/), however, and you quickly realize that HR isn’t organizational tar, but an invaluable strategic asset.

[^3]: For those wondering—and God help you if you were—[181 pounds](https://news.gallup.com/poll/328241/americans-average-weight-holds-steady-2020.aspx) of gold is worth $5.2 million dollars. Major tech companies make about [$750,000 per employee](https://www.businessinsider.com/tech-companies-revenue-employee-2017-8), and people work at these companies [for about 3 years](https://www.inc.com/business-insider/tech-companies-employee-turnover-average-tenure-silicon-valley.html). So, given the choice between an analyst and a statue of that analyst made out of solid gold, take the statue.

[^4]: Few things set the tone for a role more than an interview. [Ask brain teasers](https://towardsdatascience.com/googles-data-science-interview-brain-teasers-7f3c1dc4ea7f), and people will think their job is to win Mensa contests; bring people [onsite for a day of work](https://review.firstround.com/how-to-consistently-hire-remarkable-data-scientists), and they’ll see the job as working on open-ended problems with others; [mindlessly chat them up](https://twitter.com/harryhurst/status/1415089258218627072), and they’ll think (and look, and act, and be) exactly like you and your college drinking buddies.

================================================================================

# The unspoken gerrymandering of the modern data stack

*Carving up tools with a no-code cleaver.*

---

![](https://substackcdn.com/image/fetch/$s_!u9Pd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3c3dab43-9c3d-4fea-90bc-9fc2a57b3d3b_1072x800.jpeg)

We were somewhere around June on the edge of our third month in deep quarantine when the [cabin fever](https://www.youtube.com/watch?v=p_bggBrUbCo) began to take hold.

I hadn’t traveled more than three blocks in weeks. The only live sports on TV were the [national cornhole championships](https://www.iplaycornhole.com/championships). I was drinking more margaritas than a Jimmy Buffet groupie.

Lost in this fog, somewhere between working from a coffee table and wasting away in Margaritaville, I found myself tumbling down a very particular YouTube rabbit hole: Videos of college professors giving their first lecture of a new semester. With students still shuffling their schedules and deciding which classes to take, professors evidently treat this session as a dramatic academic trailer for their course. They have the feel of a pop concert—all the greatest hits, relentlessly paced, delivered by a human cannon of energy—but instead of Beyoncé on stage, it’s a skinny white man with a ponytail who *loves* materials science.[^1]

In my pandemic stupor, I don’t remember any of these classes, except one: Robert Sapolsky’s *[Introduction to Human Behavioral Biology](https://www.youtube.com/watch?v=NNnIGh9g6fA)*. His lecture was less about biology, and more about how we categorize things. Specifically, he argued that the discrete categories we apply to continuous concepts—from the colors we see and the sounds we hear, to the academic subjects we define and the races we project onto people—are both arbitrary and deeply consequential. 

For example, different cultures and languages break the color wheel at different points. I look at the color spectrum below and see what I think of as red and orange and yellow and green, but I struggle to define the colors in between. Some cultures, however, draw boundaries in different places. People from these cultures can define my fuzzy spots, and can’t easily label what I clearly see as orange. Their eyes aren’t different; they just use different categories.

![](https://substackcdn.com/image/fetch/$s_!nUDJ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3f8d646-5cbe-4d9e-ba73-3c93ee3a52ce_2534x254.jpeg)

In other words, the categories we create, though necessary to keep us from being overwhelmed by this infinite spectrum, affect what we can actually see.[^2] The artificial boundaries we define eventually come to define us.

Those of us working in data spend a lot of time looking at our own incomprehensible expanse: The [ever-growing landscape of data tools](http://46eybw2v1nh52oe80d3bi91u-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/2020-Data-and-AI-Landscape-Matt-Turck-at-FirstMark-v1.pdf). To make sense of it, we draw a lot of boundaries, categorizing things as ETL, and augmented analytics, and orchestration, and social analytics, and a host of other names in between. When we talk about this landscape, these are the lines [we debate](https://twitter.com/ValentinUmbach/status/1418242294952644611).

These, however, are not the only fences. Another set of invisible borders carve them up, gerrymandering our maps in ways that are much more profound than the contested boundaries between [BI and data analytics platforms](https://www.bvp.com/atlas/roadmap-data-infrastructure), or data monitoring and data management. It’s the line that splits tools between those that are for “technical” users and those that are for everyone else. 

No ecosystem diagram shows this; the market cares about the problems that need to be solved, not the means by which it’s done. Regardless of how we interact with a transformation tool, for instance—with code, with a point-and-click interface, with [three-fingered gloves](https://www.youtube.com/watch?v=PJqbivkm0Ms), with [tiny motorcycles on graph paper](https://en.wikipedia.org/wiki/Tron)—it’s still meant to transform data.

But, because of the [implicit technical divide in the industry](https://benn.substack.com/p/analytics-is-at-a-crossroads), data tools are almost always designed and sold for one audience or the other. Countless data tools advertise which side they’re on, often on A1, above the fold:

At the top of [Stitch’s homepage](https://www.stitchdata.com/): “Analysis-ready data at your fingertips...no coding required.” 

How dbt Labs [defines dbt](https://www.getdbt.com/product/what-is-dbt/): “Now anyone who knows SQL can build production-grade data pipelines.” 

A [headline](https://www.metabase.com/) for Metabase: “Exploration without the SQL barrier.” 

The [second line](https://hex.tech/) about Hex: “Work with data in collaborative SQL and Python notebooks.”

Precog’s [product page](https://precog.com/product/): “The fast and simple way to load data from any source to any destination in minutes with zero coding.”[^3]

As much as the problem it solves, we characterize a tool by who it’s for—analyst or business user; technical audience or “everyone.” Individually, this makes sense. It’s targeted marketing for a focused product. Companies choose their ideal customers, and build products for those profiles. Collectively, this makes a continuous technical spectrum discrete, a simplification that causes us to forget how important it is to build products that operate across the full range. 

Though this is true for every meta-layer of the stack—ingestion, transformation, operational analysis—I’m particularly familiar with the problem it creates for the consumption layer of analysis and BI.

Historically, the consumption layer’s architecture looks something like the diagram below. Data is used by two groups of people, bifurcated along a technical boundary. One group, typically represented by analysts, data scientists, and engineers, use tools powered by SQL, Python, and R to answer [strategic questions](https://benn.substack.com/p/big-whiff). The second group, [vaguely defined as business users](https://benn.substack.com/p/self-serve-shibboleth), work in code-free BI platforms backed by data models built directly into the tool. 

![](https://substackcdn.com/image/fetch/$s_!_lS-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdd2ff4c6-9bb6-46a8-88b0-7be11084f3dd_1788x800.jpeg)

There’s a huge problem with this architecture: *This isn’t how data is actually consumed*. The line between BI reporting and analytical research isn’t a hard line; it’s a fluid, shifting continuum. Answers to one-off questions turn into recurring reports; reports are often the building blocks for key executive dashboards; dashboards are enriched with ML-powered forecasts; changing forecasts generate questions that need to be answered with bespoke SQL queries; elements from all of these assets get added to sales decks, shipped off to operational systems, and shared with customers. And everyone, from analysts building dashboards for executives to marketers asking data scientists for in-depth assessments of their most recent campaigns, has to work together at nearly every stage of development. As [Anna Filippova recently highlighted](https://blog.getdbt.com/we-the-purple-people/), we have to “put aside skillset dichotomies, and learn to feel comfortable in the space between.”

But because we’ve trained ourselves to think in a language that defines everyone as technical or not, we’ve cut the world in half. Like a [city divided](https://en.wikipedia.org/wiki/List_of_divided_cities) by a poorly drawn political boundary, our method for consuming data is split by an arbitrary technical line that makes it extraordinarily difficult to cross a border that we frequently need to cross.

This has real consequences. For much of Mode’s history, we struggled to define which side of the wall we were on. Sometimes, [we released](https://mode.com/blog/two-leaps-forward/) a “powerful set of new tools for code-free data exploration;” other times, we built a [tool kit for every analyst](https://mode.com/blog/announcing-mode-studio-and-r/) powered by “SQL, Python, R, or Javascript.” Though neither identity felt right, these were the territories available to us. Undoubtedly, the quality of what we built suffered from this confusion. 

Eventually, we realized that the issue wasn’t our answer, but the question we were asking. The modern data stack doesn’t need a BI bucket and a data science bucket; it needs a unified consumption layer. To do our job well, we have to overcome the technical division, not be defined by it. Analytical needs don’t end at the code’s edge.[^4] 

Other parts of the stack follow the same pattern. Despite analysts and data scientists needing governance just as much as the users of a BI tool, we’ve interwoven governance into reporting tools; the invisible technical wall has proven to be higher than the often-discussed functional one. A better architecture (and one that we’re slowly twisting towards) would manage governance globally, from data modeling to [metrics management](https://benn.substack.com/p/metrics-layer). While most governance tools are code-oriented, these same tools should integrate code-free methods if there’s demand for such an interface.

![](https://substackcdn.com/image/fetch/$s_!iwBa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F04a63431-bf36-4235-84c4-eb34a0378be3_1788x800.jpeg)

Our implicit need to categorize tools at technical or non-technical holds us back in other ways. For years, people have been predicting that an explosion of vertical-specific applications (e.g., tools dedicated to sales analytics, customer success analytics, and so on) is just around the corner. It hasn’t happened. The problem, I believe, is that vertical tools like [forwrd.ai](https://www.forwrd.ai/) don’t help us learn new things; instead, they’re code-free recreations of what analysts already do. Vertical-specific equals analyst-free, and analyst-free equals code-free.[^5]

We should instead build for verticals by making it easier for analysts to work in those verticals. Rather than building a code-free way to analyze customer satisfaction, a customer success analytics tool should make it easy for analysts to collect and enrich data on support interactions and customer calls. Real advancement comes from [removing friction between analyst and expert](https://twitter.com/sarahcat21/status/1422615752801128448), not by replacing analysts with a limited code-free AI.

By doing the latter, we gerrymander our already complex landscape further, creating fractal after unmanageable fractal of [unnecessary categories and subcategories](https://erikbern.com/2021/07/23/what-is-the-right-level-of-specialization.html). The result is, as Erik said, bad and hard to use. The sooner we see the space as a spectrum, and not a thousand discrete colors, the sooner we can build a better experience for everyone.


---


[^1]: Lest you think I’m making fun of these videos, I am writing a post about minor fads in a minor niche of a nerdy industry where my lede—my hook, the best thing I could come up with for keeping your attention—is me telling you a story about me watching these videos.

[^2]: This also affects how we think. At the start of the lecture, Sapolsky posed a question: What “causes” a person to behave abnormally? Is it their biology, developed over millennia of evolution? Their individual genetic makeup? Random psychological variation in the operation of their brain? Chemical changes in their hormones? The answer, according to Sapolsky, is all of them. These characteristics exist along a long intertwined spectrum that can’t be disentangled. But we get hung up on identifying singular causes because those are the academic disciplines—the categories—that we’ve created, and they’ve become the only way we can see the problem.

[^3]: If there was ever a tool where code-free should actually mean magic Tom Cruise gloves, it’s [Precog](https://minorityreport.fandom.com/wiki/Precogs).

[^4]: Even Gartner, which built a $25 billion dollar company by [categorizing things in arbitrary buckets](https://en.wikipedia.org/wiki/Magic_Quadrant). is seeing [the same thing](https://www.gartner.com/doc/3981930).

[^5]: BI itself reflects a similar dynamic. Self-serve tools are often designed as a code-free clone of how analysts work, even though [this isn’t what most people who use self-serve tools want](https://benn.substack.com/p/self-serve-still-a-problem).

================================================================================

# The Modern Data Experience

*How a revolution comes together. Or doesn’t.*

---

![](https://substackcdn.com/image/fetch/$s_!4HeV!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3e6157f-9c2e-4c5f-89a1-ae36cd255523_1200x630.jpeg)

What is the modern data stack?[^1]

To analytics engineers, it’s a transformational shift in [technology](https://blog.getdbt.com/future-of-the-modern-data-stack/) and [company organization](https://jasnonaz.medium.com/analytics-engineering-everywhere-d56f363da625). To startup founders, it’s a [revolution in how companies work](https://www.rilldata.com/blog/5-founders-define-the-modern-data-stack). To VCs, it’s a [$100 billion opportunity](https://www.prnewswire.com/news-releases/fishtown-analytics-raises-12-9m-to-accelerate-open-source-analytics-engineering-software-dbt-301045082.html). To engineers, it’s a [dynamic architectural roadmap](https://blog.getcensus.com/graduating-to-the-modern-data-stack-for-startups/). To Gartner, it’s the [foundation of a new data and analytics strategy](https://www.gartner.com/en/conferences/na/data-analytics-us/agenda). To thought leaders, it’s a [data mesh](https://martinfowler.com/articles/data-monolith-to-mesh.html). To an analyst with an indulgent blog on the internet, it’s a [new orientation](https://benn.substack.com/p/datas-horizontal-pivot), a [new nomenclature](https://benn.substack.com/p/gerrymandering), and [a](https://benn.substack.com/p/self-serve-is-a-feeling) [bunch](https://benn.substack.com/p/big-whiff) [of](https://benn.substack.com/p/analytics-is-at-a-crossroads) [other](https://benn.substack.com/p/metrics-layer) [esoteric](https://benn.substack.com/p/minerva-metrics-layer) [analogies](https://benn.substack.com/p/analytics-is-a-mess) that only someone living deep within their own navel would care about.

It’s easy to see why we’re all so excited. Our new technology is impressive, and lots of things that used to be hard, time-consuming, and expensive are now easy, fast, and cheap. In 2013, I worked on a data team that paid seven figures for a database that went down regularly, hired a full-time engineer to build and maintain a daily job to copy data from Salesforce into that warehouse, and employed an entire team of developers to build an internal tool for analysts to write and share SQL queries in a browser. Today, you can do all of that [in 30 minutes, for free](https://mode.com/build-a-modern-data-stack/).[^2]

But to the everyday analyst and “[business user](https://benn.substack.com/p/self-serve-shibboleth),” the modern data stack is decidedly less fantastical. 

To most people—pleasant, social people, the kind who can make it through a party without [arguing about SQL formatting](https://benn.substack.com/p/the-case-against-sql-formatting)—the modern data stack isn’t an architecture diagram or a gratuitous think piece on Substack or a fight on Twitter. It’s an experience—and often, it’s not a great one. It’s trying to figure out why growth is slowing before tomorrow’s board meeting; it’s getting everyone to agree to the quarterly revenue numbers when different tools and dashboards say different things; it’s sharing product usage data with a customer and them telling you their active user list somehow includes people who left the company six months ago; it’s an angry Slack message from the CEO saying their daily progress report is broken again.

To [borrow an analogy](https://erikbern.com/2021/07/23/what-is-the-right-level-of-specialization.html) from Erik Bernhardsson, if the modern data stack is a restaurant, these frustrations are how it feels to eat there. As the chefs, we’ve made some amazing optimizations in the kitchen. But our customers (which includes ourselves as analysts) are here for a good meal, provided by an attentive staff, in a pleasant environment. Until we can serve them that, our technology, no matter how revolutionary, is academic. 

Our first reaction to this problem is to create more technology. We draw maps of what we’ve built, and look for small spaces in our diagrams to wedge new products and companies. Though each tool serves its niche better than what was there before, [fracturing the market into smaller and smaller pieces](https://benn.substack.com/p/gerrymandering) doesn’t solve the larger problem. As Erik said, hyperspecialization makes us great at chopping onions and baking apple tarts, but it’s a bad way to manage a restaurant.

Our other scapegoat is “culture,” loosely defined as some combination of the skills we have (or[ don’t have](https://benn.substack.com/p/third-rail)), the [organizational structures](https://blog.getdbt.com/we-the-purple-people/) of our teams, and squishy terms like [data literacy](https://hbr.org/2020/02/boost-your-teams-data-literacy). Though I’m sympathetic to these points, as are our Davos-bound aristocracy [interviewed by the Harvard Business Review](https://hbr.org/2021/02/why-is-it-so-hard-to-become-a-data-driven-company), data cultures don’t materialize out of employee handbooks or internal seminars. The structures of our technologies and organizations till the land from which they grow. If people aren’t excited about the future we’re promising them or are put off by work required to be “data driven,” we can’t just ask them to [please get on board](https://www.youtube.com/watch?v=IqPr6bcTJhc). We have to earn their enthusiasm. 

To do that, the modern data stack isn't enough. We have to create a modern data *experience*.

# The other modern data stacks

Over the last several months, [catalyzed by a post](https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/) by Emilie Schario and Taylor Murphy, it’s become popular to say that data teams should think of everything they create as a product, and the rest of their colleagues as their customers. To build on this idea, what should that product be? What should it feel like to go from question, through technology and tools, through collaboration and conversation, to an answer? 

Our current solution, though full of pieces that are individually great, is a disjointed one. Some responsibilities, like metric governance, are shared across multiple tools; others, like tracking what happens after a question is answered, [are mostly ignored](https://benn.substack.com/p/big-whiff). Even seemingly basic questions, like "where do I first go to ask a question?," don't have clear answers.

It doesn't have to be this way—and that's not just hope. Airbnb, Uber, and Netflix built entire integrated stacks, from analytics tools, reporting applications, metrics repositories, data catalogs, and ML platforms. Unlike vendors in these categories, tools in internal platforms support a goal bigger than themselves. The results are impressive.

At Uber, employees can [search for a metric](https://eng.uber.com/databook/), visualize [it across different dimensions](https://eng.uber.com/umetric/), and move from code-free exploration directly into writing queries, all while an AI ensures that work doesn’t get repeated.[^3] [Airbnb built a similar platform](https://medium.com/airbnb-engineering/supercharging-apache-superset-b1a2393278bd), connecting a data catalog and a metrics repository with a data exploration tool and a SQL IDE. And [Netflix designed an entire workflow](https://netflixtechblog.com/notebook-innovation-591ee3221233) for creating, sharing, deploying, scheduling, and discovering notebook applications that support everything from dashboards to production models. 

Undoubtedly, these tools aren’t perfect.[^4] But they offer a window into the bigger questions we should be asking: How should it feel to use modern data stack? What can the system add up to? What’s the best way for people to answer an unfolding series of questions, to trust those answers, and to decide what to do next? What can we create for people who care about how well the modern data stack works, regardless of where the lines are drawn between products and services? What are we building for the people who are at our restaurant to enjoy their dinner, and don’t care who prepared the onions or how they did it? 

# Trading ideas

I’m under no illusion that the market can or should agree to a singular vision, at least not today.[^5] Regardless of your preferred definition of the modern data stack, nearly everyone, myself included, agrees that it should be [decentralized](https://fivetran.com/blog/modern-data-stack-2025).

This isn’t a call to create a council to dictate a roadmap from on high, or for a company to build some integration umbrella under which we can all live.[^6] It’s also not an ask for more conversations about the philosophical underpinnings—cloud-first, modular over monolithic, version control and peer review—inspiring what we build. Instead, it’s an acknowledgement that decentralization comes at a cost: Our architecture becomes our user experience. Fault lines between products become fault lines in how it feels to use the modern data stack—and for most people, that’s what matters most.[^7]

This is, bluntly, not an easy problem. How does a multitude of sovereign, often competitive entities come together to build something cohesive? 

One potential guide comes from a much, *much* messier market: international trade. Prior to World War I, most multinational trade agreements—treaties on tariffs and trade restrictions—were [bilateral agreements between two countries](https://www.press.umich.edu/pdf/0472113054-ch3.pdf). As countries in Europe industrialized, “a network of bilateral trade agreements” emerged, centered around and often dictated by key trading partners—in the European case, Britain and France. 

In 1947, after an interlude for a world war, a Great Depression, a [protectionism fad](https://www.nber.org/digest/oct09/roots-protectionism-great-depression), and another world war, twenty-three of the world’s major trading partners signed the General Agreement on Tariffs and Trade, or [GATT](https://en.wikipedia.org/wiki/General_Agreement_on_Tariffs_and_Trade). Because of the importance of the GATT’s original members, over the next half-century, the agreement attracted more signatories. It was eventually succeeded by the World Trade Organization in 1995; today, the WTO [has 164 members](https://www.wto.org/english/thewto_e/whatis_e/inbrief_e/inbr_e.htm), accounting for 98 percent of international trade. Though many countries still negotiate bilateral or regional trade agreements, world trade is generally governed by global WTO treaties rather than a complex web of thousands of bilateral agreements. 

The data ecosystem is tracing the same path. Today’s stack currently operates as hundreds of member states, orbiting around major platforms like Snowflake, Fivetran, dbt, and a few others. To the extent that we concern ourselves with how vendors relate to one another, we do so through bilateral integrations, mostly to caulk over gaps between [one product](https://mode.com/get-dbt/) and [the next](https://www.holistics.io/dbt-integration/). 

In the ballooning ecosystems of both global trade and data tools, bilateral integrations won’t scale. A messy patchwork of agreements will—and did—come apart under stress. The GATT and WTO are an admission of that. Built outward from the world’s largest economies, these agreements created a shared vision for trade policy that, even if it wasn’t always legally binding, helped tilt the world in a common direction.[^8] If we want to make *this* market work, we need a similar set of guiding principles.

# The Modern Data Experience

If the modern data stack provides an architectural roadmap, these principles should provide an experiential one. They represent the aspirational standard for how our new tools work together, and what they can collectively become.

In the [spirit of dying on some hills](https://twitter.com/Pedram_Navid/status/1425862301375242248), these are the ambitions I believe we should have. To me, the modern data experience…

**...enables everyone to do their job rather than asking them to be an analyst.** Data democratization was a trendy catchphrase with worthy goals: Make the value of data available to everyone, and free up data teams to work on strategic projects. But it became a prescription—make everyone an analyst with code-free tools—that largely [failed us](https://benn.substack.com/p/self-serve-still-a-problem). In a modern data experience, we don’t hand people data and ask them to analyze it; we [incorporate it into the operational systems](https://blog.getcensus.com/what-is-operational-analytics/) where they already live. Data should [help people do their jobs](https://benn.substack.com/p/self-serve-shibboleth), rather than add a new job for them to do. 

**...merges BI and data science. **We often think that analysts work in technical tools, and everyone else lives in BI apps. [That’s wrong.](https://benn.substack.com/p/gerrymandering) Drag-and-drop tools can be valuable to senior data scientists, and anyone can be a consumer of advanced analysis. As Bobby Pinero put it recently, “[analysts are becoming positionless](https://wraptext.equals.app/every-analyst-is-a-finance-analyst/).” In the modern data experience, people should transition seamlessly between viewing a key metric sourced from a well-vetted data catalog, to exploring that metric with groupings and filters, to incorporating it in deep technical analyses. Those consuming data should never have to fully leave one system and start over in another. 

**...makes status and trust explicit. **“Can I trust this?” is one of the most frustrating—and common—questions people ask of data. Today, our answer to that question mostly depends on implicit signals: Who built it? Did it change recently? Does it *look* right? This leads us down endless multi-tool chases to confirm our results. Indicators of trust need to be explicit: Every data asset should show if upstream processes are operating abnormally, out-of-date, or in some state of development or disrepair. Our goal should be to spend more time debating what to do because of a number on a dashboard than we spend verifying if that number’s right.

**...remembers what we’ve learned.** Discoveries in BI tools are ephemeral, lost when a dashboard updates or its configuration changes. Ad hoc analysis is haphazardly recorded among a sea of scratch work. Conversations about both, where decisions are made and knowledge actually accumulates, are washed away by the Slack firehose. To make sure our time is spent exploring new territory rather than retracing old steps, a modern data experience should remember and catalog what we learn *and* what we say about it. 

**…governs business logic globally.** Historically, business logic—instructions for transforming data and computing metrics—is governed locally, within individual BI tools and one-off analyses, with little coordination. In a decentralized, modular stack, this creates a patchwork of duplicative and often contradictory calculations. A modern data experience should centralize this logic such that it’s accessible anywhere data is consumed, whether that’s a BI dashboard, a Python notebook, or an operational ML pipeline. 

**...doesn’t communicate in only tables. **Steep yourself in data long enough, and all you see are relational structures: tables, rows, columns, join keys. Most data tools reflect this view, and present data [this way](https://mixpanel.com/blog/tristan-handy-changing-data-stack/). [This is lazy packaging.](https://benn.substack.com/p/minerva-metrics-layer#footnote-3) To analysts, data comes in this form; to everyone else, data is protean. Sometimes, it’s a metric on a time series; sometimes, it’s an [abstract representation](https://www.sankey-diagrams.com/google-analytics-use-sankey-diagrams/) of a complex business domain; sometimes, it’s a document of [explanatory narratives](https://www.narrator.ai/narratives/). People should be able to search for, ask questions of, and explore data in these terms, not just as tables and columns.

**...builds a bridge between the past (read: Excel) and future. **It’s tempting to treat the modern data stack as a discontinuity, a leap from the past into a better future. It’s not. It’s a transition, and some uncomfortable anchors are coming with us. Most notably, Excel isn’t going away. A modern data experience has to negotiate with it, not treat it as an outdated pariah. 

**...is elastic. **Analysis isn’t a predictable, linear process that can be anticipated. It starts as one question, and opens into other questions. Similarly, data infrastructures evolve as the businesses underneath them change, data sources and structures change, and the analysis built on top of them uncovers new problems to track or opportunities to organize around. A modern data experience should be emergent in this way, able to start small and grow into new, unforeseen territory. Rigid experiences and systems are debt that will quickly come due.

**...is a melting pot. **Data stacks have a history of building walls to throw things over: data engineers throw pipelines at analysts; BI developers throw reports at their stakeholders; analysts throw results at anyone who will listen. Modularity can’t tempt us to build more walls. Just as dbt broke down the first wall, a modern data experience needs to break down the others by encouraging collaboration and conversation between business, data, and engineering teams. In other words, in the shorthand of the moment, the modern data experience is [purple](https://blog.getdbt.com/we-the-purple-people/).

There’s plenty more to say about each of these topics, and a lot more conversation to be had about how to refine this list. But it’s a conversation we need to have. Without it—without thinking about the experience that pairs with the stack—we can build the tools, and the things we’ve promised—a technological revolution, a transformation shift in how industries function, $100 billion!—won’t come. 

# The data mesh postscript

Last week, Analytics Twitter melted down over The Data Mesh™ and what, exactly, it is. As best I can tell, there are now two definitions. The [original definition](https://martinfowler.com/articles/data-monolith-to-mesh.html) is a fairly complex set of architectural requirements. Its pillars are technical, and, as data mesh creator [Zhamak Dehghani made clear](https://twitter.com/zhamakd/status/1426042889474166792), quite specific. The second definition—the [descriptivist](https://en.wikipedia.org/wiki/Linguistic_description) one the [community](https://twitter.com/juansequeda/status/1427033307984760842) [is](https://cnr.sh/essays/what-the-heck-data-mesh) [gravitating](https://www.linkedin.com/pulse/technology-problem-its-operations-jillian-corkin/?trackingId=H3NVSeacpscJ51FQZbxy7g%3D%3D) [towards](https://twitter.com/petehanssens/status/1427245102334767111)—is more vague, essentially claiming that any decentralized architecture in which teams are responsible for their own “data products” is a data mesh.

I have mixed opinions on the content of both definitions. However, I don’t have mixed opinions, and am decidedly opposed to, the *form* of the first definition.

According to its creators, the data mesh is [meant to address](https://martinfowler.com/articles/data-monolith-to-mesh.html) the failures of today’s data stack: It leads to “disconnected source teams, frustrated consumers fighting for a spot on top of the data platform team backlog and an over stretched data platform team.” In other words, the modern data stack needs a better modern data experience. However, rather than making that central to the data mesh, the original definition is a funhouse of specific technologies and buzzwords. I think we would be better served by talking directly about the experience we want to create, without running the conversation through a briar patch of technical diagrams. In many ways, that’s the point of this whole post: To talk about the goals of the data mesh, which are worthy ends, without getting mired in obscure details that, I believe, aren’t necessary for achieving those goals.


---


[^1]: Pardon me while I pander to Google’s SEO gods.

[^2]: Pardon me while I pander to Mode’s marketing team.

[^3]: A fun bit of circular history: In 2009, the data team at [Playdom](https://en.wikipedia.org/wiki/Playdom) built an internal tool for running and sharing SQL queries. That tool inspired a similar tool at Yammer (my former employer), which then inspired the original idea behind Mode. Another member of Yammer’s data team left for Uber, and built the first version of [Uber’s query tool](https://dribbble.com/shots/5598346-Uber-Querybuilder), which is now inspiring all of us.

[^4]: “I know they aren’t perfect but I've never felt this way for no one.”

[^5]: We can’t even agree on how to build [basic templates](https://benn.substack.com/p/when-are-templates-going-to-happen) for the reports that everybody wants.

[^6]: That said, my suspicion is that GCP, AWS, Azure, and perhaps Salesforce will attempt to do exactly this. I think all four will create data stacks that are similar to their cloud infrastructure stacks: Tightly integrated tools surrounded by a low wall that encourages, but doesn’t require, people to use other tools within the stack.

[^7]: Consider this a particularly strong application of [Conway’s Law](https://en.wikipedia.org/wiki/Conway%27s_law), one of Silicon Valley’s favorite pop proverbs: The design of the modern data stack will reflect the org chart of those who build it—and, worryingly for us, those org charts span across many companies.

[^8]: Reasonable people can disagree on whether or not that direction was a good one. My point is that this approach succeeded in creating a common framework at all.

================================================================================

# The calendar takes its tax

*8:30am to 9:00am – Team stand-up. / 9:00am to 10:00am – Budget review. / 10:00am to 2:00pm – Be inspired.*

---

![](https://substackcdn.com/image/fetch/$s_!eEA-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4fdb6bf0-799c-414e-b8c4-2c90bad5afd8_600x360.png)
*“I wasn't planning on marching into the abyss, but someone added it to my calendar.”*

If this Substack had an early nemesis, it would be Paul Graham.[^1]

But every once in a while, mixed in among his [“empirical” “analysis” of policies he doesn’t like](https://benn.substack.com/p/startup-wealth-tax) and [his tweets about his industry fraternity brothers](https://benn.substack.com/p/its-hard-to-hate-up-close), he happens on a good idea. Twelve years ago, he wrote about one: [the schedules of makers versus managers](http://www.paulgraham.com/makersschedule.html). The post argues that managers are most productive when their days are full of meetings, but makers—engineers and writers, in Graham’s examples—need large chunks of uninterrupted time to be productive.[^2] To do their work, Graham’s makers need both focus and a kind of warming up: They have to load a bunch of ideas into their heads and settle into their task. It takes a while to get into this state—and a single interruption can snap you out of it. 

I’d propose an addition to Graham’s theory. Making something often requires [two phases](https://medium.com/design-leadership-notebook/the-new-double-diamond-design-process-7c8f12d7945e): a generative, creative one, and an editorial one. When writing or building a presentation, this generative phase is finding the thread of your argument or story; when doing analysis, it’s exploring the problem and allowing yourself to be taken by curiosity and unexpected results. I assume it’s also there when painting a picture, or writing code, or making music, or developing a recipe, or doing a host of other creative activities. 

Both the generative and editorial phases require time and focus, and neither are possible if your calendar is full of meetings. But there’s a key difference between the two. Given a few hours of free time, you can always be productive in the editorial phase. With space and a first draft to build on, you can always perfect and polish. This implies that you can schedule editorial work. Put sufficient time on your calendar, protect it, and the work will get done. 

This isn’t true for the generative phase. You can spin your wheels for an entire day (or [decade](https://en.wikipedia.org/wiki/Writer%27s_block)) and produce very little. Cliché though it may be, creative work requires a creative spark—and sometimes, you just don’t have it. You can try to kickstart it—by reading, by jacking yourself up on caffeine, by going for a LindyWalk™[^3]—but you can’t plan it or put it on your calendar. Inspiration will visit you when she chooses.

Meetings are catastrophic when you’re searching for this spark. Knowing there’s a meeting around the corner keeps you from grabbing on to a fleeting idea and seeing where it might take you. Instead, we try to bottle it by taking a quick note, failing to realize that the thing to capture was the motivation of the moment, not the content of the concept.

Worse still, if we do find ourselves in a creative sprint, meetings eject us from it, an alarm clock expelling us from a dream. And like a dream, that particular bit of imagination may be lost forever. Next time we fall asleep, we’re unlikely to return to the same one—if we’re able to dream at all.

It’s a tricky problem. On one hand, we have to have meetings. We can’t all flee from them the instant we become possessed by a rogue thought. Company calendars are delicate webs of dependencies, strung between people and conference rooms and time zones.[^4] Agitate one strand, and the whole thing can tie itself in a knot. 

On the other hand, our current conventions are entirely backwards. While productive, generative work can’t be forced, meetings are the exact opposite. If the pandemic has taught us anything, it’s that we can load ourselves into a meeting at any time, in any state, from any prior commitment. And yet, our default is that meetings are the fixed objects on our schedules, the obstacles everything else—every other bout of productivity—has to work around.

This is especially problematic in a remote-first world. Without drive-by meetings and casual in-office conversation—which can be disruptive to creative work, but can also be politely turned away, sometimes simply by wearing headphones and looking ornery—nearly every interaction requires a meeting. This further checkers our calendars, blasting even more potholes in our creative pavement—potholes that, once placed, we dutifully drive over. 

In this context, Graham’s recommendation to protect time for inventive work is somewhere between incomplete and misguided. A better approach would build in creative [slack](https://fs.blog/2021/05/slack/) by allowing people to decline meetings when they’re in a generative flow.[^5] Yes, that may periodically disrupt some meetings. But consider the other side of the equation.

By making meetings the fixtures in our days, we have to schedule time to be creative. If those moments aren’t productive—which they won’t always be, even if they’re guarded blocks of focus time[^6]—we end up grinding through generative projects, stretching a task that could take hours if it were done in the right moment into one that takes days or weeks. In this scenario, [despite sometimes appearing productive, we’re actually wasting massive amounts of time in a diluted, frustrated slog](https://ava.substack.com/p/on-and-off).

Not only is it expensive, but we also do a worse job. Nothing lowers your standards more than trying to wring results from a dry stone. “I want this to be good” erodes into ”I want this to be done.”

Moreover, people who fight this battle long enough end up demoralized and exhausted. Like someone who hates getting up early forcing themselves to go on morning runs, those who push through creative tasks in the wrong moments learn to blame the work as much as the context in which they’re doing it.

Of course, we can’t postpone every meeting, and we can’t entertain every creative flight of fancy. There are times when meetings are urgent, or someone’s role in one would make their absence from it unacceptably disruptive. But surely we can rebalance the scales away from their current extreme, in which the only excused absence from any scheduled engagement is another scheduled engagement. Surely we can do better than crucifying creativity on the calendar's cross. 

What does this have to do with data? In general, not a lot. This Substack [won’t always be about data](https://benn.substack.com/p/a-brief-programming-note).[^7]

That said, as [Emilie Schario](https://twitter.com/emilieschario) reminded me last week, data jobs are [creative jobs](https://benn.substack.com/p/analytics-is-a-mess), and we’ll do better work if we embrace this. When arranging our calendars, we should give ourselves the blocks of time that Graham argues for—and more importantly, try to protect the moments when we’re rapidly unwinding an analytical problem. Just as the [term “ad hoc” changes what it represents](https://benn.substack.com/p/big-whiff), our schedules alter our work styles. A packed calendar can foreclose our ability to be, or even see ourselves as, creative.

This is particularly true if our roles become more cross-functional—more [purple](https://blog.getdbt.com/we-the-purple-people/), more of a [melting pot](https://benn.substack.com/p/the-modern-data-experience). Being in the room where decisions get made is great, and data teams should aspire for that kind of representation in important conversations. But every meeting comes at a creative cost. Constant collaboration is admirable, but it isn’t free. 


---


[^1]: Followed closely by [concise, direct writing](https://benn.substack.com/p/in-defense-of-analogies) and [aeronautical eels](https://benn.substack.com/p/open-the-window).

[^2]: “Maker” is Graham’s word. I’m not a fan. Terms like maker lean into Silicon Valley’s obsession with entrepreneurs and those seen as doers, often in contrast to people [presented as administrative pencil pushers](https://twitter.com/zebulgar/status/1217184215311077376) free riding on makers’ hard word and ingenuity. It’s a loathsome frame, both in its self-serving moralizing and its cultish fetishization of The Entrepreneur over the people who prop them up. In reality, everyone works on both creative and administrative tasks, and is sometimes a maker and sometimes a manager.

[^3]: Overextending one interesting idea into an entire brand of schlock theories and trademarked merch? Very Lindy.

[^4]: Google Calendar, the original DAG. Although, technically, I guess it’s just a G.

[^5]: Shout out to [Matt Knopp](https://twitter.com/mhat), whose [own post](https://mhat.substack.com/p/calendars-and-slack) about slack served as the original inspiration for this post.

[^6]: When I block off focus time, I’ve found it useful to have both generative and editorial work to do. I typically start with generative work, but fall back to more reliable editorial work if the moment—which may last thirty minutes, a couple hours, or the entire day—isn’t right. The worst way out of a creative block, I’ve found, [is through](https://thoughtcatalog.com/ryan-holiday/2017/03/sometimes-the-only-way-out-is-through/).

[^7]: If you’re only here for diagrams of data stacks, tough patooties. Among the things in the published archive, [Clubhouse](https://benn.substack.com/p/a-slur-on-clubhouse), [Barry Bonds](https://benn.substack.com/p/a-season-without-bats), and [stonks](https://benn.substack.com/p/runaway-train). Among the things in my drafts folder, Pitbull, “the marketplace of ideas,” and luggage.

================================================================================

# The data OS

*Decentralization is overrated.*

---

![](https://substackcdn.com/image/fetch/$s_!zspj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc7d0a7-2617-4919-b984-27babc45d421_1200x647.jpeg)

The data hive mind senses a problem.

What started as [a contrarian argument](https://www.slideshare.net/HadoopSummit/the-ecosystem-is-too-damn-big) several years ago has, in the last few months, run a rapid course through the analytics community, turning from a [spirited debate](https://erikbern.com/2021/07/23/what-is-the-right-level-of-specialization.html) into [derivative rehashes](https://benn.substack.com/p/gerrymandering) before quickly settling as [resigned jokes](https://twitter.com/tayloramurphy/status/1432729974600085513) about our unfortunate and potentially worsening predicament: We have too many tools.[^1] 

# The data mess

As data people, we definitely have a lot of tools. In 2017, Y Combinator—an incubator of both startups and the Silicon Valley zeitgeist—funded 15 analytics, data engineering, and AI and ML companies. In 2021, they funded 100.[^2] It’s impossible to make sense of this many tools, much less manage even a fraction of them in a single stack. As I said a couple weeks ago, fracturing our workflows into so many pieces is [wrecking the experience](https://benn.substack.com/p/the-modern-data-experience) of using the modern data stack. 

![](https://substackcdn.com/image/fetch/$s_!B-iZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2581b590-2955-4dca-b462-328bc4e87b72_1666x1026.jpeg)
*Show HN: How to sell out your brand.*

Still, I’m not convinced that “too many tools” is the correct diagnosis. I also have a lot of apps on my phone. Despite that, it’s easy to manage, and new apps don’t disturb the careful balance of technologies on it.[^3]

Though the analogy is far from perfect—there are lots of ways in which data tools aren’t mobile apps—it’s instructive in at least one way: On my phone, I don’t have to organize or integrate all of my apps with one another. The operating system keeps my library manageable. It catalogs my apps for me, sets standards for how they should behave, and facilitates clean interactions between them. If I download a new app, my phone’s OS fuses it into my existing collection and tucks the entire thing neatly away. 

The data ecosystem functions quite differently. Buy a new tool, and you’ve got to shove others aside, jerry-rig[^4] some tenuous connections to the rest of the stack, and hope that the whole haphazard contraption survives long enough for you to band-aid it with the next product you stuff into it. 

In many ways, this is the price of success. The dumbfounding valuations of companies like Snowflake and Databricks will keep attracting new entrepreneurs to found companies, keep attracting shotgun investors like YC to fund them, and keep attracting blank check firms like Tiger to float them. Unless the bubble bursts, culling or consolidating the ecosystem is a futile effort. Instead, we should try to figure out how to better manage the tools we have, and the shiny future ones we might want.

# The data mesh

The current proposals for defending ourselves from tool overrun can be grouped into three categories. The first is extreme centralization. One vendor owns the entire stack, and bends every tool in their suite around the same central axis. Internal tools at Uber and Airbnb are built like this; cloud providers like GCP are [gesturing](https://techcrunch.com/2020/12/09/google-quietly-acquires-dataform/) [in this](https://techcrunch.com/2019/02/19/google-acquires-cloud-migration-platform-alooma/) [direction](https://techcrunch.com/2020/02/13/google-closes-2-6b-looker-acquisition/), as are major data platforms like [Databricks](https://techcrunch.com/2020/06/24/databricks-acquires-redash-a-visualizations-service-for-data-scientists/). Though I suspect offerings like these are inevitable, there will always be a large independent ecosystem of products that aren’t part of Microsoft’s or Amazon’s inventories. Plus, in an industry rooted in open-source technologies and committed to modularity, “let’s all submit to the mothership” is unlikely to be the slogan everyone rallies around.

The second solution is extreme decentralization. I’m not, to be honest, entirely sure what this means. As best I can tell, it’s a proposal for a [shared open standard](https://twitter.com/mullinsms/status/1429082610257518596) of communication between data tools, controlled by nobody but agreed to by everybody. While that sounds lovely, I’m skeptical we can pull it off. Data has long been a [centralized asset](https://twitter.com/Pedram_Navid/status/1432166092118454273), built for the boardroom down. Our historical starting point isn’t a commonwealth to unify, but a monolith of executive reporting to break apart. Moreover, the data ecosystem just isn’t that big. We probably don’t need a complex, fully decentralized system for figuring out how to make a few thousand tools talk to each other.[^5]

The third proposal is a hybrid—and is best modeled by the now-infamous data mesh.

To quickly recap, the data mesh is built on two foundational ideas: Individual teams should manage and maintain their own data, and something—the mesh itself, I think?—should bring together and provide a unified view of these disparate datasets. Though the data mesh is often described as being decentralized, it’s not strictly so; teams that provide data don’t interact with each other directly, but do so through the centrally-managed mesh. And the standards of the mesh, which govern how data can be fed into it, are decided unilaterally by some central authority, presumably a data or IT team. This isn’t a decentralized architecture; it’s a delegated one.

This [formal version of the data mesh](https://martinfowler.com/articles/data-mesh-principles.html) doesn’t fix our tooling problem because it focuses almost entirely on how to design the data sources behind the mesh. What happens on the other side of the mesh, or even what the mesh actually *is*, isn’t discussed.[^6] But, if we apply the centralized-but-delegated model of the mesh more broadly, and extend it forward by both defining it more concretely and by considering how consumers use it, a compelling solution starts to take shape.

# The data OS

Force me to describe how a data mesh might actually work, and my immediate thought is something like Trino (née Presto): It’s a query wrapper that sits on top of a bunch of data sources. 

This seems to be [the community’s best guess](https://getdbt.slack.com/archives/C020C5G7XC7/p1630420866017300?thread_ts=1630338583.004900&cid=C020C5G7XC7) for well. But as Ross Housewright points out, this is an uninspiring answer. If the data mesh works with any underlying data structure (e.g., it can sit on top of BigQuery, Oracle, S3, and every weird thing in between), it doesn’t integrate anything. It’s just a switchboard, routing queries to different destinations. 

If the data mesh *does* requires data sources to be heavily standardized (e.g., each data source is a Snowflake database configured in a particular way), the data mesh doesn’t *do* anything. It’s just [another layer of organization](https://twitter.com/mistercrunch/status/1426041792160428033) above the database schema. Presto, in fact, already does [exactly this](https://prestodb.io/docs/current/overview/concepts.html#catalog).

In both cases, the data mesh fails to help people consuming data—the people for whom all of this effort is supposedly for.

These disappointments, however, highlight what a more ambitious approach could accomplish. What if, rather than just papering over the differences among its underlying data sources, the mesh resolved them? What if, rather than acting as a simple switchboard, the mesh provided common utilities for interacting with the data underneath it? What if, rather than being a filing cabinet for our data catalogs, the mesh served—as Android[^7] does to my phone—as the operating system for the entire data stack?

# The data build tool

Nothing like this currently exists. But it *almost* does in dbt.

Today, dbt lives, incognito, inside of databases. Tools that use those databases interact with dbt’s products, but they don’t interact with dbt itself. They can only see dbt by its shadow.

As I said in a post about [the metrics layer](https://benn.substack.com/p/metrics-layer), this serves dbt well. It can slide into any data stack entirely on its own. No vendor needs to integrate with it, and, outside of the databases themselves, dbt doesn’t need to integrate with any vendor. 

It could, though. Instead of just running silently inside of databases, dbt could also expose an outer edge for tools to connect to. This edge could not only provide access to the database (or, even, all the databases dbt’s in); it could also become a standardized platform for accessing, transforming, and governing data. 

To extend the OS analogy, in this world, dbt is Android; the data is my phone’s hardware. dbt exposes the state of that hardware—schema information, the lineage of its tables, the latency of the data within them—to everything that uses it. Just as Android abstracts away the peculiarities of each device it runs on, dbt sands down the differences between BigQuery, Redshift, and others, providing a single language for interacting with all of them. Similar to how Android links apps together, dbt serves as a communications bus that, for example, pushes queries between a “production” environment in Census and a “development” environment in Mode. In the same way that mobile operating systems provide developers easy access to phones’ physical capabilities, dbt offers its own helper functions and syntactic sugar (e.g., what dbt enables with Jinja[^8]) that shortcut and standardize common interactions with data. 

Extend these ideas far enough, and entire apps could live inside dbt, doing everything from running on-the-fly tests against in incoming queries to finding and merging duplicative datasets across every tool and database in the stack. 

![](https://substackcdn.com/image/fetch/$s_!SxtS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F314c5b06-7dd3-4fac-91fb-97661c0214aa_2048x1056.jpeg)
*[listening to “In the Hall of the Mountain King.”](https://www.youtube.com/watch?v=qM4zMofsI7w)*

In [his recent post on the data mesh](https://roundup.getdbt.com/p/data-mesh-contracts-and-distributed), Tristan (dbt’s CEO) said that we need to build a system organized around decentralized contracts, such that teams can work together with “no central authority governing the process.” While I admire the democratic ideal, I think we’d be better served if dbt took a more selfish approach. Just as every country [doesn’t want to negotiate bilateral agreements](https://benn.substack.com/p/the-modern-data-experience) with every trading partner, vendors don’t want to build integrations into every data tool. Central governing authorities—whether that’s the GATT, Android, or dbt—are sometimes exactly what’s needed. Convenience can be worth more than autonomy.

In my view, this is the most pressing problem the analytics industry faces today: How do we create, in a disparate ecosystem, a functional [modern data experience](https://benn.substack.com/p/the-modern-data-experience)? A data OS won’t get us all the way there, just as the Android operating system doesn’t make my phone great on its own. But it sure gets us a lot closer. 


---


[^1]: To solve this problem, I’m here to offer something we definitely don’t have a glut of: a Take.

[^2]: True, this increase is partly explained by YC’s shift from elite incubator to cheap startup assembly line that tries to take a 7 percent stake in as many companies as possible in exchange for a handful of recut *Zero to One *lectures. Nevertheless, data companies are still growing as a percentage of total companies funded, from 6 percent in 2017 to 15 percent in 2021. And in any case, for those of us trying to make sense of all these products, the absolute number of companies building them matters more than a relative number.

[^3]: New apps (read: TikTok) do, however, bulldoze my ability to tell the difference between a few minutes and an hour and a half.

[^4]: Wait, [what?](https://www.dictionary.com/e/jury-rigged-vs-jerry-rigged/)

[^5]: Plus, good god, if someone proposes building the data mesh on the blockchain, I’m gonna...[invest](https://twitter.com/bennstancil/status/1395390402207920130).

[^6]: Or it is, and I can’t figure it out.

[^7]: Yes, I’m a proud green bubble, missing your texts, shattering your iMessage threads, degrading your videos into grainy 4-fps thumbnails that make the Zapruder film look like it was shot in 4k.

[^8]: For what it’s worth, I have mixed feelings about Jinja. We don’t use it much at Mode because it’s difficult to debug and because queries that use it are no longer declarative. These issues aren’t endemic to dbt though; they’re because Jinja, which was built as an HTML templating language, was shoehorned into its current role. If dbt operated as an OS, Jinja could be more universally accessible (e.g., accessible inside of dbt *and* Mode), or could be replaced by something native to a SQL environment.

================================================================================

# Tilt and tilted

*Data is not the level ground that we act like it is.*

---

![](https://substackcdn.com/image/fetch/$s_!muLp!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4497e88f-3f7e-4607-8b29-3c38b9dc6173_1440x960.jpeg)
*[Boston Globe](https://www.bostonglobe.com/2021/07/22/opinion/imposing-supreme-court-term-limits-shouldnt-be-left-justices/)*

Last week, in an [midnight order declining to block a Texas law](https://www.nytimes.com/2021/09/01/us/supreme-court-texas-abortion.html) banning most abortions, five justices on Supreme Court of the United States revealed themselves to be what they’ve always been, no matter how hard we’ve tried to pretend otherwise: People, with opinions. 

When we talk about the Supreme Court, we place the institution outside—and often above—the political fray. We’re taught that the judgements of the court come from careful readings of the law, deliberate considerations of facts and precedent, and the country’s sharpest legal minds. Though justices ascend to the bench from prior careers as political [appointees](https://en.wikipedia.org/wiki/Elena_Kagan#Solicitor_General) and [lawyers](https://en.wikipedia.org/wiki/Brett_Kavanaugh#Ken_Starr_associate_counsel), [campaign managers](https://www.cnn.com/2012/10/28/justice/rehnquist-legacy/index.html#:~:text=His%20national%20political%20experience%20went%20back%20to%20the%20(Sen.%20Barry)%20Goldwater%20presidential%20campaign%20in%201964.%20He%20became%20chief%20counsel%20of%20the%20campaign%20and%20ultimately%20became%20one%20of%20the%20few%20people%20to%20stick%20with%20Goldwater%20right%20to%20the%20bitter%20end.), and members of [activist organizations](https://www.washingtonpost.com/graphics/2019/investigations/leonard-leo-federalists-society-courts/), we act as though those histories—not to mention [their upbringings](https://www.washingtonpost.com/politics/2018/10/02/brett-kavanaugh-alcohol-two-dueling-narratives/) and [religious convictions](https://www.latimes.com/politics/story/2020-10-09/barrett-conservative-faith-uncomfortable-debate)—are purged the moment they take their lifetime seat on the court.

Sometimes this is explicit; during his confirmation hearing, [Chief Justice John Roberts said his job was to be an umpire](https://www.uscourts.gov/educational-resources/educational-activities/chief-justice-roberts-statement-nomination-process), calling balls and strikes. But more often, this framing is implicit, a reflexive deference to the court and those who sit on it. Just last week, the New York Times’ [David Leonhardt commented](https://www.nytimes.com/2021/09/03/briefing/scotus-shadow-docket-texas-abortion-law.html) that justices usually “solicit briefs, hold oral arguments and *spend months grappling with their decision*” (emphasis mine). While we may disagree with what the justices decide, [we want to believe](https://www.annenbergpublicpolicycenter.org/most-americans-trust-the-supreme-court-but-think-it-is-too-mixed-up-in-politics/) in the complexity of the decisions they make, the good faith from which they make it, and the legal ground on which they rest. And many people, from [civics teachers](https://sharemylesson.com/collections/supreme-court-lesson-plans#:~:text=Americans%20have%20looked%20to%20the%20Supreme%20Court%20of%20the%20United%20States%20(SCOTUS)%20as%20the%20moral%20conscience%20of%20the%20nation%20since%20it%20was%20established%20by%20the%20founding%20fathers%20in%20Article%20III%20of%20the%20U.S.%20Constitution%20in%201789.) to [op-ed columnists](https://thehill.com/opinion/healthcare/405357-kavanaugh-will-be-a-fair-minded-judge-who-is-likely-to-vote-on-the-side-of?rl=1) to the [justices themselves](https://www.washingtonpost.com/wp-dyn/content/article/2006/01/12/AR2006011201123.html#:~:text=When%20you%20take%20that%20judicial%20oath%2C%20you%20become%20a%20different%20person.), are eager to sell this vision. 

Last week’s ruling tears the mask off. 

The five justices in the majority showed that Leonhardt was half right—justices do need time to issue rulings. But that time isn’t for figuring out what to do; it’s for finding a plausible argument for how to do it. In this case, evidently so eager to overturn fifty years of precedent, they didn’t bother.

The Texas law, known as SB8, has two significant elements. The first bans nearly all abortions in the state. The second delegates enforcement of the law to the citizenry. Under SB8, individual citizens can sue for and collect $10,000 from anyone involved in providing an abortion, including doctors, clinicians, people who pay for procedures, and people who drive patients to clinics. The bizarre and dystopian scheme, [devised in plain sight](https://law.stanford.edu/2021/09/08/maneuvering-around-the-court-stanfords-civil-procedure-expert-diego-zambrano-on-the-texas-abortion-law/), was designed to confuse legal challenges to a plainly unconstitutional law—or at least give a potentially friendly court that wants to ban abortions an excuse to do it.

As [Justice Sotomayor said in her dissent](https://www.supremecourt.gov/opinions/20pdf/21a24_8759.pdf), “the gambit worked.” The Supreme Court declined to block the law because it raises “complex and novel antecedent procedural questions.” As should be obvious to everyone, this is a brazen lie. The court is [corrupt and corrupted](https://talkingpointsmemo.com/edblog/scotus-delenda-est). The question at hand was not complicated. This was not a careful and unbiased reading of the facts. This was not an opinion rooted in laws; it is now a law, rooted in opinions. This was, [per Adam Serwer](https://twitter.com/AdamSerwer/status/1433471897476423687), five justices invalidating a previously upheld constitutional right to abortion “because they wanted to, because they could, and because fuck you.”

Of course, justices are people too, swayed by their own opinions, [in ways that may be invisible even to them](https://twitter.com/drvolts/status/1433892678324785152). Good LSAT scores and long resumes don’t make people immune to personal desires. That justices would rule on SB8 in accordance with their own preferences isn’t a surprise. The surprise is how audaciously they did it.

But, even if they had been more delicate—or attempted their best good-faith reading of the law and prior precedent—the ruling still wouldn’t be impartial.

For our laws are not natural ones. They aren’t fundamental truths that we didn’t design and cannot escape. They’re synthetic, “[entirely self-referential and made up](https://talkingpointsmemo.com/edblog/scotus-delenda-est),” spun out of layer upon layer of prior opinions—opinions warped by the same preferences and prejudices that stained this ruling. Even if Roberts could be a neutral umpire, the game he’s refereeing is itself a deeply flawed human creation, [contrived by decidedly non-neutral architects](https://www.law.com/nationallawjournal/2021/05/21/only-balls-and-strikes-sotomayor-dont-ignore-how-strike-zone-is-set)—which is to say, mostly white men with money.

None of this implies the law isn’t valuable, or that the Supreme Court has no validity. It is, and it must.[^1] But we can’t pretend that the court is something that it’s not. It is not a legal and moral calculator, or an impartial juror who weighs evidence “[without respect to persons, and do equal right to the poor and to the rich](https://www.supremecourt.gov/about/oath/oathsofoffice.aspx).” It is—[as it has always been](https://www.washingtonpost.com/outlook/supreme-court-politics-history/2020/09/25/b9fefcee-fe7f-11ea-9ceb-061d646d9c67_story.html)—a political body, manned by political operators, with political opinions no different than Congresspeople, TV talking heads, and unhinged uncles on Facebook. The only difference is that justices are usually better at hiding it. 

To pretend otherwise is not only foolish, but dangerous. By assuming the court always acts in good faith, we surrender to legal sleights of hand that hide personal and political agendas behind manufactured arguments over “antecedent procedural questions.” In a world where the audience refuses to acknowledge the possibility they’re being deceived, the deftest magicians are king.

# The reverence for quantitative rhetoric

In some circles—in “data-driven” companies, in much of Silicon Valley, in Nate Silver’s Twitter feed—data is also a form of magic. Arguments made with data are celebrated as unimpeachable level-minded science; arguments without it are the shrill opinions of a hysteric. Walk into a conversation without a supporting graph, and you’re hit with a [Goodread link to W. Edwards Deming quotes](https://www.goodreads.com/author/quotes/310261.W_Edwards_Deming): “Without data, you’re just another person with an opinion.” “In God we trust; all others must bring data.”

Making arguments from data, like interpreting the law through legal deliberation, isn’t inherently problematic. Quite the opposite, in fact—to the extent that it’s possible, data should be foundational. But, also like the law, it’s a foundation built on less level ground than we often admit.

Though we think of data as irrefutable ground truth, it is, in fact, also almost “entirely self-referential and made up.” Often, data—and its computational cousin, the metric—isn’t an abstract representation of an innate natural quality we’re attempting to quantify; it’s an [accounting identity](https://en.wikipedia.org/wiki/Accounting_identity). The [equation for GDP](https://en.wikipedia.org/wiki/Accounting_identity#Gross_domestic_product), for instance, *is* GDP. Change the equation and the definition of GDP changes. 

Nearly everything we measure, from [inflation](https://www.nytimes.com/2021/04/16/opinion/economy-inflation-retail-sales.html) to [Google Doc word counts](https://twitter.com/rmc031/status/1422152235664949251), depends on similar identities—identities that are built on precedent, personal preferences, and arbitrary decisions.

Consider a corporate example: sales quota attainment. On the surface, this is easy and objective to compute. How much, in hard dollars and cents, did a sales rep sell? But, as with so many quantitative questions, [there are lots of devils in the details](https://benn.substack.com/p/analytics-is-a-mess). How much credit do reps get for products that were co-sold with partners? It depends on how much the company values their partners and how much they want to promote this sort of sale. How do we account for multi-year contracts? It depends on the biases of the company’s leadership, and whether they prefer aggressive growth or customer retention and satisfaction. If a customer cancels an annual agreement after four months, does the rep who sold the initial deal get full credit? It’s likely based on arbitrary industry standards and conventions. 

There are no right or wrong answers to these questions. There’s not a natural “sales quota attainment” out there that we’re trying to capture, if only our instruments were precise enough to detect it. Quota attainment exists only as the identity that defines it—an identity, by the way, that is created and maintained by fiat. If a leadership team wants to change how quotas are tallied—because of shifts in the business, because reps are selling in ways that aren't sustainable, because the company is struggling to hit its targets, or because the Sales VP is convinced a burning bush told them to do it—they can. 

Moreover, just as well-cited legalese and court letterhead doesn’t absolve a judge of shoehorning a political opinion into legal argument, tacking spreadsheets and probabilities on a personal preference doesn’t make it unbiased. In domains awash with data, any half decent analyst can make a compelling case for nearly anything. And critically—as is the case when usually shrewd Supreme Court justices [hide their preferred outcomes behind legal technicalities](https://www.theatlantic.com/ideas/archive/2021/09/supreme-court-guts-roe-shadow-docket/619957/)—most people can’t always tell the difference. 

For an example of how this manifests, consider the recent debate about crime in San Francisco. Despite crime being a highly complex and nuanced issue, despite many of the San Franciscans engaging in the debate seeing themselves as free-thinking and rational, and despite everyone arguing with data, the two sides are well sorted by their political bent. Prior beliefs and biases determine how we see and present data, much more than data changes what we believe. 

In short, everything can be tilted: the data, the analysis, and the people analyzing it.

But, in spite of this malleability, our conceit for data (see: Deming, W. Edwards) protects those who wield it from accusations of bias. To use data is to be level-headed. The surest sign of fairness is to support your claims with numbers; the surest sign of prejudice is to fail to do so. Data is both a sword and a shield: It is a weapon for prosecuting your point, and a defense for protecting yourself as reasonable and impartial.

In the best cases, when data is used with the best intentions, this advantages those who are empirically comfortable. Deming’s demand to “bring data” doesn't necessarily make us better at seeking the truth; it just compels us toward a particular form of debate. It favors those who can make clumsy arguments with data over those who make clever ones without it.[^2] It convinces analysts that we’re both the best at understanding stuff *and* the only people reasonable enough to be objective about it.

In the worst cases, data can be outright abused. This goes well beyond the usual complaints about misleading statistics and visualizations. The best quantitative illusionists don’t trim y-axes or talk in absolutes rather than ratios; they use data to hide their opinions behind sober analyses, pointing to their inside voices as proof of their neutrality. 

We can’t escape these flaws. For those of us who work with data, the solution isn’t to make our data or analysis more objective. We can’t. Our raw material is too tilted, as are we. We can't insulate our interpretations of data from our opinions any more than justices can pretend to insulate their legal reasoning from their political lives or the influences of their environments. 

Our responsibility, then, is to stop pretending otherwise. We should be humble about our own ability to be objective. We should pay more attention to others who aren’t as skilled in quantitative rhetoric. We aren’t inherently better or more unbiased than those who argue from emotion and experience; we simply take a different tact. And most of all, we shouldn’t elevate others who hang numbers on things to make a point. Data is persuasive, and plenty of sly con men are willing to exercise that power in irresponsible ways. As the people who are supposed to understand data, we, like those who understand the law, should make clear what all of us are: Humans, with opinions. 


---


[^1]: In its current form, however, it is a profoundly undemocratic institution that [should be reformed](https://www.whitehouse.gov/wp-content/uploads/2021/06/Bowie-SCOTUS-Testimony.pdf).

[^2]: It’s also worth noting that this view, combined with [other toxic prejudices](https://en.wikipedia.org/wiki/Google's_Ideological_Echo_Chamber), also favors white men.

================================================================================

# Is BI dead?

*On dismantling data's ship of Theseus. *

---

![](https://substackcdn.com/image/fetch/$s_!kFXT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5bb6fbb-abe9-45d7-95fb-69311d4b538f_600x450.jpeg)
**

In early 2000, Salesforce [launched its inaugural product](https://www.salesforce.com/news/stories/the-history-of-salesforce/#:~:text=On%20February%207%2C%20salesforce.com%20officially%20launches%20at%20an%20event%20themed%20around%20%E2%80%9CThe%20End%20of%20Software%E2%80%9D%20at%20San%20Francisco%E2%80%99s%20Regency%20Theater%20with%201%2C500%20attendees%20and%20a%20concert%20with%20The%20B-52s.) at an event called “The End of Software.” When attendees arrived, they were greeted by a mascot—it was more of a no smoking sign with Mickey Mouse hands and feet than the sort of jolly character you’d see at a college basketball game—that told them they’d arrived in the software-free section of San Francisco. Before taking their seats, guests had to wind through [a house of software horrors](https://www.salesforceben.com/salesforce-history/), full of screaming salespeople.

It was, to say the least, an odd way for a software company to introduce itself. But twenty-one years, $26 billion in annual revenue, and a [jumbotron in the San Francisco skyline](https://www.newyorker.com/culture/culture-desk/the-bright-lights-of-the-salesforce-tower) later, you’d have to say the introduction worked.

It worked so well, in fact, that those of us looking back have a hard time making sense of it. Why would a company have such apparent disdain for the exact thing it’s selling? 

In a word, connotations. Before Salesforce’s launch, software—and in particular, enterprise software—wasn’t just a computer program; it was also the frustrating and ugly work necessary to buy and run it.[^1] At that time, a decade or so into the IT revolution, the promise of what software could be was undercut by what it actually was: a painful buying cycle from enterprise sales teams; a long installation and rollout process; ongoing administration and management; tightrope walks of rolling upgrades. Though IT teams bought perpetual licenses, they still paid a recurring cost of toil and constant trouble.

Salesforce promised something different. They promised software, without the baggage. They [promised software](https://techcrunch.com/2019/03/08/salesforce-at-20-offers-lessons-for-startup-success/) that you “didn’t have to touch;” you just sign up and use it. 

In other words, the “end of software” wasn’t about getting rid of software; it was about getting rid of the associations people had with it. Salesforce’s ambition wasn’t to provide better answers to common questions like, “what kind of hardware do I need to run this software?” and “what is the cost of upgrading to the new version?” They wanted people to stop asking these questions entirely.

And today, we don’t. Yes, we have plenty of frustrations with software—we [have too much](https://cdn2.hubspot.net/hubfs/2093754/eBooks/2020%20SaaS%20Trends%20Report.pdf) of it; it’s [eating our world](https://www.reddit.com/r/TeslaLounge/comments/hk9uxc/software_update_failed_car_wont_move_help/); it’s [eating our soul](https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739)—but many of us barely remember (or never even knew about) the problems Salesforce wanted to solve. Software, as it was understood in 1999, started to end in 2000, just as Salesforce said it would.

# The End of BI

The [literal definition](https://www.gartner.com/en/information-technology/glossary/business-intelligence-bi-services) of business intelligence is vague, but, like software, it’s also taken on a lot of connotations. A BI tool should bring together data from a variety of business sources; it should manage and govern that data so that people can consistently make sense of it; it should make it easy for anyone to self-serve data ([whatever that means](https://benn.substack.com/p/self-serve-is-a-feeling)); it should drive “actionable insights;” it should help companies regularly report on how different business units are performing; it should make dashboards discoverable; there should be graphs.

Many of these connotations were created by early BI tools—tools that were, as software was twenty years ago, heavy and complex. Microstrategy and BusinessObjects, for example, ingested data from a range of data sources into their own storage systems. They each had semantic layers for creating [OLAP cubes](https://analyticsengineers.club/whats-an-olap-cube/), transforming raw data into neatly governed datasets. They offered a range of analytical tools for creating reports and dashboards. And they built ways to distribute data around an organization. 

Over the last decade, many of these early BI functions [have been stripped out of BI](https://benn.substack.com/p/datas-horizontal-pivot) and relaunched as independent products. (Add “the unbundling of BI” to the long list of ways that you could define the modern data stack.) Looker, a modern BI tool, doesn’t come with a warehouse and [didn’t build data connectors](https://twitter.com/jaykaydee/status/851814001185099777).[^2] Many customers have replaced parts of Looker’s semantic layer (persistently derived tables, or PDTs) with dbt; other parts could be replaced by a [metrics layer](https://benn.substack.com/p/metrics-layer). [Operational analytics tools](https://www.getcensus.com/integrations/looker) take care of distributing data into other systems, and [data discovery platforms](https://docs.atlan.com/integrations/bi-applications/looker) handle content management. Just as the cloud rewrote our expectations of what software is and what it isn’t, the modern data stack is slowly rewriting our expectations of BI. 

But the analogy with Salesforce breaks down in at least one very important way: Once you made it through the maze of software horrors at Salesforce’s launch event, you were presented with a vision for what was coming next. Marc Benioff wasn’t just there to tell you software was dead; he was there to show you how it would be reborn.

In BI’s case, we’ve only done the former. The splinter of the modern data stack that we call BI is diminished, but mostly unchanged. It’s as though we took our definition of BI from twenty years ago and started crossing off clauses, until we’re left with “visualization and reporting.”

![](https://substackcdn.com/image/fetch/$s_!lJQb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F37181b44-3800-4a3d-8173-66b22b907e2e_1318x1018.png)
*Endangered, but not yet extinct.*

Among the rest of the layers of data stack, it’s an odd anachronism. When we spun off data ingestion, we modernized it: It’s ELT, not ETL. The same is true for warehousing (split storage from compute, among other things), transformation (SQL-based and version controlled, not a GUI), and discovery (automate it based on usage). But our modernization of BI has mostly been ripping it apart, and leaving the remaining fragment unchanged. 

If we did change it, what might it be? If we were standing at the end of a labyrinth of BI medusas, what vision would we present? More audaciously, what should our ambition be?[^3] 

To play Benioff[^4] for a minute, BI tools should aspire to do one thing, and do it completely: They should be the universal tool for people to consume and make sense of data. If you—an analyst, an executive, or any person in between—have a question about data, your BI tool should have the answer. 

### BI should include *only* consumption 

This has a few implications, and while most aren’t controversial—BI shouldn’t handle data ingestion and storage, for instance—two might be. 

First, companies use data in operational ways that go beyond people looking at charts. For example, they automate marketing campaigns and build in-product machine learning models. BI should leave these problems to other tools. 

That doesn’t mean things shouldn’t happen automatically; if a metric on a dashboard falls below some threshold, absolutely, send an email. But BI tools aren’t pipelines. They’re borders, handing off data between machines and humans. People read data differently than computers—we can digest small amounts of it; we like pictures. We shouldn’t mix what’s meant for humans with what’s meant for machines. And in BI tools, it’s people who do the reading.

Second, BI should be legless.[^5] As mentioned above, BI tools are just one of several destinations for a company’s data. If BI tools require their own legs—for example, if they rely on a semantic layer to define metrics—they’ll be duplicative, because the same metrics also need to be defined in other destinations. Instead, BI tools should sit on top of global governance layers like dbt and metric stores. Eventually, a semantic layer will be a bug, not a feature.[^6] 

### BI should include *all* consumption

Most people consume data in one of two ways: Through a self-serve application, and through ad hoc analyses sent to them by analysts. BI tools traditionally focus on the first channel, and deeper exploratory analysis and data science is done elsewhere. Gleb Mezhanskiy [highlighted this divide](https://www.datafold.com/blog/modern-analytics-stack#analysis) last year, and it was further emphasized in a [recent post](https://hex.tech/blog/bi-tools-hex) from the folks at Hex. 

This cracks data consumption in two—and unfortunately, it’s not a clean split. As the Hex post describes, most self-serve reports are built on top of research done in tools built for deeper analysis. Migrating work from the latter to the former—particularly when translating logic from raw SQL and Python into something like LookML—is tedious, error-prone, and sometimes impossible. And when a dashboard surfaces a question it can’t answer, analysts have to traverse the gap again in the opposite direction. 

This creates a ton of problems. [Ad hoc work is scattered](https://benn.substack.com/p/big-whiff), ungoverned and undiscoverable, outside the organized walls of the traditional BI tool. Self-serve applications take a long time to build, and those that do get built are orphaned from their supporting analyses. Dips in dashboards go unexplored because crossing the chasm from self-serve to analytical tool isn’t worth the effort.[^7] If a dashboard says one thing and a research report says another—which they inevitably will—it’s hard to know which one to trust. 

Moreover, the boundary between BI and analytical research [is an artificial one](https://benn.substack.com/p/gerrymandering). People don’t sit cleanly on one side or the other, but [exist along a spectrum](https://blog.getdbt.com/we-the-purple-people/) (should a PM, for example, use a self-serve tool or a SQL-based one?). Similarly, analytical assets aren’t just dashboards or research reports; they’re tables, drag-and-drop visualizations, narrative documents, decks, complex dashboards, Python forecasts, interactive apps, and novel and uncategorizable combinations of all of the above.

By defining BI as just self-serve, we shortcut what it could be, no matter how good that self-serve is. A better, more universal BI tool would combine both ad hoc and self-serve workflows, making it easy to hop between different modes of consumption. Deep analysis could be promoted to a dashboard; self-serve tools could unfurl into technical IDEs. This pressure value for complex questions also keeps us from overextending self-serve tools, allowing us to keep them as disciplined libraries for important metrics, rather than unruly tangles of key models and one-off ones.

Even more importantly, marrying BI with the tools used by analysts brings everyone together in a single place. A lot of today’s analytical work isn’t actually that collaborative: People uncover something interesting in their BI tool, and ask the data team about it when they can’t self-serve an answer. Analysts squirrel their work away in technical tools, and results are ejected from those tools back into the business. Non-analysts motivate the analytical process, but aren’t part of it directly. 

Gathering everyone in one place [fixes this experience](https://benn.substack.com/p/the-modern-data-experience). It tightens collaborative loops, not only between analysts and non-analysts, but also among non-analysts. This cross-side collaboration—to borrow from Kevin Kwok’s [excellent discussion of how Figma](https://kwokchain.com/2020/06/19/why-figma-wins/) enables the same thing in design—helps companies finally [escape the analysis-as-a-service model](https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/) by making data larger than just data teams.

# BI is dead, long live BI

The professional software referees at Gartner [evaluate BI tools](https://www.gartner.com/doc/3996944) across a number of “critical capability areas,” including connectivity, data preparation, cataloging, reporting, and visualization. Just as we no longer ask what kind of hardware is required to run our CRM software, this battery of features represents an outdated notion of BI.

Future BI tools should be judged by a different set of questions. Does it adhere to [modern analytical conventions](https://docs.getdbt.com/docs/about/viewpoint)? Does it support familiar languages and frameworks, or proprietary ones? Does it require its own semantic layer, or can it integrate with other governance tools? Can a range of data consumers, from data scientists to CEOs, use it to create a range of data assets, from dashboards to deep research reports? How hard is it to migrate from one type of asset to another? Does it help analysts and non-analysts collaborate between and among one another? Can it be a universal tool for data consumption?

So long as companies need dashboards and executives need reports to go spelunking through as they wait for the economy class passengers to board, we’ll need BI. But the old version of BI—a complete end-to-end stack, responsible for nearly all of a company’s analytical needs—is already dead. The question is what replaces it.


---


[^1]: “Commercial air travel” is similar. Though this phrase literally means paying money to fly, it conjures all sorts of nightmares of delayed flights, cramped planes, nickel-and-dimed amenities, lost bags, and, of course, [monstrous passengers](https://benn.substack.com/p/open-the-window).

[^2]: Though it seems like their [new Google overlords might](https://looker.com/blog/yes-we-have-no-connectors).

[^3]: At this point, you may be asking if this is my opinion, or Mode’s? The answer is mine; this Substack doesn’t represent Mode’s official stance on anything, and certainly shouldn’t be read as any sort of roadmap. But, I do have a fair amount of influence over what Mode does, and my experience at Mode has a great deal of influence over what I think. So, Mode’s vision is directionally similar to what follows, though the specifics vary.

[^4]: More like BENNioff, amirite? (You can unsubscribe at [https://benn.substack.com/account](https://benn.substack.com/account).)

[^5]: Earlier this year, [Ankur Goyal and Alana Anderson introduced](https://basecase.vc/blog/headless-bi) the term “headless BI.” This is very similar to (and preceded) my proposal for a [metrics layer](https://benn.substack.com/p/metrics-layer), and I very much support the idea. However, I think the term is backwards. To me, BI *is* consumption. If it’s headless—i.e., if it requires another tool to consume—it’s not BI. To put it another way, if you split Looker into LookML and a visualization tool, which one would be BI?

[^6]: Yes, fine, you could argue that, technically, anything that prepares data inside an analytics tool is a semantic layer. A query is a semantic layer! An Excel formula is a semantic layer! A chart configuration is a semantic layer! I’m not referring to these sorts of layers, but to those that are intended to be central repositories of governance, and are described as a “single source of truth.”

[^7]: When the grocery store is far away, we forget how to cook. –Not a proverb, but should be.

================================================================================

# Who is “the community?”

*It has the potential to be one of the data industry’s biggest perks—and its highest walls.*

---

![](https://substackcdn.com/image/fetch/$s_!V2QI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdc8777ee-ae85-4c4c-ba02-4ec0c4a29bcc_960x637.jpeg)

The analytics community, ironically, [didn’t listen to the odds](https://www.youtube.com/watch?v=uYX-NSZMqt0). 

Years ago, when it was first coming together, it wasn’t likely to go well. Internet communities, especially those dominated by young men, tilt toward [poisonous cesspools](https://www.amazon.com/Culture-Warlords-Journey-White-Supremacy-ebook/dp/B084FXPHM3).[^1] Analysts are generally a prickly bunch, and in the first half of the 2010s, our [anointed king](https://twitter.com/NateSilver538) was a professional “*well, ackshually”* contrarian. And the cultures of two of the data industry’s closest adjacencies—startups and software engineering—are [toxic to many of their members](https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber).

But the early pioneers in the analytics community broke the other way, drawing cultural inspiration from places like [R user groups](https://blog.revolutionanalytics.com/2017/06/r-community.html). The R crowd is well-known for striving [to be inclusive](https://qz.com/work/1661486/r-ladies-made-data-science-inclusive/), for [welcoming women](https://reshamas.github.io/why-women-are-flourishing-in-r-community-but-lagging-in-python/), and for [protecting its own members](https://www.buzzfeednews.com/article/daveyalba/datacamp-sexual-harassment-metoo-tech-startup). The data community that formed in the years that followed has built a similar reputation. Even in my experience as the apparent [modern data stack bully](https://jpmonteiro.substack.com/p/a-friday-fight-and-the-internet-of), online groups have been nothing but professionally supportive and personally welcoming.

These benefits, however, aren’t shared equally. In particular, if you look around community spaces—the conferences, the Slack channels, the meetups, the Twitter conversations, and, one assumes, the data teams inside companies—black people are woefully underrepresented. 

Over the last couple years, a handful of organizations have sponsored about a dozen community-oriented data conferences. Unlike the big pay-to-play trade shows that are dominated by hanger-sized expo halls and on-stage infomercials,[^2] these conferences aim to attract and promote community leaders. In this regard, they’re representative of both who the community is and who the community aspires to be. 

Out of a total of over 500 speakers at these conferences, less than three percent are black[^3]—a third of whom spoke about diversity.

![](https://substackcdn.com/image/fetch/$s_!ZF3_!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd39f9f7-d22e-4aa5-9258-a2854536d17c_930x188.jpeg)
*Given the obvious challenges with collecting data on racial identification, these numbers are approximate.*

Moreover, these dismal numbers are, if anything, inflated: Nearly all of these conferences' hosts promote diversity in some fashion. Some of them prioritize underrepresented groups when choosing speakers. Some explicitly highlight diversity at the center of their promotional materials. And all of them have codes of conduct meant to protect people from the kind of harassment that’s [common at tech conferences](https://www.yahoo.com/now/women-gender-tech-conferences-research-155451926.html). 

Other surveys confirm the same trend. Though companies don’t publish exact figures for data teams, Harnham, a data recruiting firm, reports that [three percent of data and analytics professionals](https://www.harnham.com/2020-us-diversity-in-data-analytics-report?goal=2020_2021_US_Diversity_Report_Download#formz5XgIIbzv4gbdiIko9xYQ) are black. 

That, it seems, is where the community is. On one hand, it’s well-intentioned, bucking some of the worst tendencies of other internet groups, and a launching pad for many friendships and careers. On the other hand, those benefits are just as concentrated among privileged groups as the rest of the tech industry’s are. According to their most recent reports, black people account for [1.7 percent of Facebook’s tech workers](https://diversity.fb.com/read-report/)[^4] and [2.9 percent of Google’s](https://static.googleusercontent.com/media/diversity.google/en//annual-report/static/pdfs/google_2021_diversity_annual_report.pdf?cachebust=2e13d07#page=57)—figures nearly identical to those in the data community.[^5] 

I could, as is true in any conversation about diversity, make the case that these low numbers are a business problem. Diverse teams, I could say, [are smarter](https://hbr.org/2016/11/why-diverse-teams-are-smarter). They’re [more innovative](https://hbr.org/2013/12/how-diversity-can-drive-innovation). They make [more money](https://www.mckinsey.com/featured-insights/diversity-and-inclusion/diversity-wins-how-inclusion-matters). 

While I agree with these points, I disagree with the premise on which they depend: that diversity is about the bottom line. Drawing connections between diversity and shareholder value will always be somewhat tenuous, and, if we concede that such a connection is necessary, some people will [find easy ways to object](https://www.bloomberg.com/news/articles/2021-06-03/snowflake-ceo-says-worker-merit-should-outweigh-diversity-goals?sref=WmQJbR0T).

Instead, we should be comfortable making the argument that inclusivity and integration are important on their own merits. People shouldn’t be shut out from the opportunity to be part of a rewarding community and a lucrative career. Nor should people be comfortable in exclusionary or segregated spaces, especially when those spaces could [confer special benefits and advantages to their members](https://twitter.com/thebmbennett/status/1440807993583435776).

Beyond that, the lack of black representation in data science, machine learning, and AI is [particularly dangerous](https://venturebeat.com/2020/12/09/columbia-researchers-find-white-men-are-the-worst-at-reducing-ai-bias/). There are many well-documented stories about data science teams embedding latent racism and bigotry into their models, hurting black people’s ability [to get loans](https://www.brookings.edu/research/reducing-bias-in-ai-based-financial-services/), interfering with [their health care](https://www.nature.com/articles/d41586-019-03228-6), rejecting them [from jobs](https://www.thomsonreuters.com/en-us/posts/legal/ai-enabled-anti-black-bias/), identifying them as [carrying guns they don’t have](https://twitter.com/nicolaskb/status/1244921742486917120), and charging them with [crimes they didn’t commit](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html). 

These problems don’t just cause obvious and irreversible harm to their victims. As more and more decisions get automated,[^6] programmatic prejudices reinforce themselves, creating additional biased outcomes—in everything from who gets admitted to college to who gets reviewed for parole to the [vernacular that chatbots understand](https://datascience.columbia.edu/news/2021/making-a-commitment-to-critical-discussions-on-race-and-data-science/) to how [bus routes are designed](https://kinder.rice.edu/urbanedge/2020/08/24/transportation-racism-has-shaped-public-transit-america-inequalities)—for future models to train against. They turn systemic racism into systematic racism, encoded and executed automatically, relentlessly, at scale.

The effects of underrepresentation in the broader analytics community are harder to see, but no less damaging. Racism is durable in part because it evolves so efficiently to both code “unfavorable” traits as black, and to code “black” traits as unfavorable. Whenever society gets close to inoculating itself against a particular racist trope, a new strain emerges. 

With data, the conspiracy is already at work. The cliché that [all jobs will soon be data jobs](https://www.wired.com/insights/2013/08/road-to-the-future-paved-with-data-literacy/) elevates [quantitative reasoning](https://www.wsj.com/articles/SB10001424127887323997004578644220074391246)—a skill set that is, not so coincidentally, [seen as white and male](https://www.scientificamerican.com/article/modern-mathematics-confronts-its-white-patriarchal-past/)—above other skills. This bias is reinforced by the demographics of the data community, creating a vicious cycle that holds black people out of power and [punches out a back door](https://theundefeated.com/features/mission-impossible-african-americans-analytics/) for white men. Unless the community becomes more visibly diverse, “data literacy” could become one of racism’s most powerful professional variants—and the analytics community could, even inadvertently, be one of its most forceful accelerants. 

None of this, frankly, should be a surprise. Racial power structures are embedded in everything, and data is no different.

But, if everyone knows it, very few people in the analytics community talk about it. It’s not even brushed under the rug, like an open secret that it’s impolite to talk about. Instead, it’s a blind spot, an unacknowledged problem that’s largely ignored, save the occasional [blog post](https://towardsdatascience.com/are-there-black-people-in-ai-fb6928166d73), perfunctory diversity panel, or [statement](https://datascience.columbia.edu/news/2020/taking-action-a-message-from-dsi-director-jeannette-m-wing/) pledging to “do more.”

This shows the limits of self-perceived kindness and progressivism. The data community prides itself on being open and welcoming of new members; for many people, it is. It’s also spun out countless organizations and projects that aspire to help civic groups use public data for social good; these efforts, I believe, are genuine. Despite that, underrepresented groups still have to carry their own water. As the earlier table shows, black people are invited to conferences to talk about diversity; everyone else gets to talk about data.

This [needs to change](https://coalesce.getdbt.com/talks/beyond-the-box-stop-relying-on-your-black-co-worker-to-help-you-build-a-diverse-team/). There is no long arc toward equality without broader effort—and being “nice” isn’t enough. A culture of congeniality can be just as ruthlessly biased as a toxic one, while also being better disguising its closed doors.

Furthermore, data professionals, who have a habit of dismissing people they see as emotional or irrational, should be cognizant of how they define what’s reasonable and what isn’t. [Analysts aren’t infallible logicians](https://benn.substack.com/p/tilt-and-tilted), arriving at their position through a detached reading of The Numbers. We’re all products of our environments, and [we really, truly, can’t detach ourselves from it](https://twitter.com/drvolts/status/1433893310960070662). 

This compels people to look at some arguments—how a lot of white people view, say, defunding the police—as inherently extreme, no matter how much data is marshalled to support them. Other positions, like those that tweak but don’t upend the status quo, are seen as disciplined and impartial on their face. It’s telling that we characterize how “reasonable” a solution is by how moderate it is, rather than how effective it may be. It’s telling that people only say “let’s be reasonable” when they want to keep things the way they are. 

Analytical communities built subtle walls on top of biases like these. People [who can afford to present sober analyses in inside voices](https://twitter.com/bennstancil/status/1386759751363661830) are celebrated; people who argue forcefully for bigger changes are discounted—and in some cases, [outright fired](https://www.vox.com/recode/2020/12/4/22153786/google-timnit-gebru-ethical-ai-jeff-dean-controversy-fired).

The data industry [has the money](https://www.cnn.com/2020/09/16/investing/snowflake-ipo/index.html) to do more. It remains to be seen if it has the commitment. 


---


[^1]: Or, to keep with the early theme, [wretched hives of scum and villainy](https://www.youtube.com/watch?v=0znNiN0lYAQ).

[^2]: Welcome to our session, “How MapR™ is enabling enterprise digital transformation,” led by the chief customer officer of MapR™, sponsored by platinum partner MapR™! Join us after the session in the MapR™ Sapphire lounge for our fun happy hour event, “Pinot Noir and MapR™!”

[^3]: Notably, the distribution isn’t uniform. About six percent of the speakers at Coalesce, dbt Labs’ conference, are black. Excluding Coalesce, less than two percent of speakers are black.

[^4]: Tech workers are represented by the purple lines. [Apologize](https://www.nytimes.com/2021/09/21/technology/zuckerberg-facebook-project-amplify.html) for your busted legends, Mark.

[^5]: For comparison, gender splits are slightly better in the analytics community. At both Facebook and Google, 25 percent of tech workers are women. Harnham reports that 27 percent of analysts are women; I estimate that 30 percent of data conference speakers are women.

[^6]: Except those [personally valued by investors](https://twitter.com/shl/status/1437785001504952341).