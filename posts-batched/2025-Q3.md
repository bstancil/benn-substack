# Posts from 2025-Q3

This file contains 13 posts from 2025-Q3.

================================================================================

# Ambition, fun and not

*Cheat on enterprise sales objection handling.*

---

![](https://substackcdn.com/image/fetch/$s_!6z-Q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c293006-b18a-4ee9-a98c-03d48aaca61c_1172x800.png)

*A brief programming note: It’s the Fourth of July, and I wasn’t planning on bothering y’all today. But the Cluely story that [we talked about last Friday](https://benn.substack.com/p/meme-company) stayed a [story](https://x.com/im_roy_lee/status/1938718987975827651) this [week](https://techcrunch.com/2025/07/03/cluelys-arr-doubled-in-a-week-to-7m-founder-roy-lee-says-but-rivals-are-coming/), so here we are, with an [American remix](https://x.com/XXL/status/1728189676765454848) of last week’s topic. Because what is the Fourth of July for, if not a time to check your email while distracting yourself from your [neighbors’ blaring music](https://www.youtube.com/watch?v=ox4IRQVGsBU) and all that, uh, [liberty](https://x.com/atrupar/status/1940088865143845343) [and](https://www.washingtonpost.com/politics/2025/07/01/least-17-million-americans-would-lose-insurance-under-trump-plan/) [freedom](https://www.nytimes.com/2025/06/28/us/immigrant-detention-conditions.html) [and](https://www.wsj.com/opinion/paramount-donald-trump-lawsuit-cbs-fcc-first-amendment-23c10b02) [winning](https://apnews.com/article/economy-tariffs-trump-gdp-shrink-86d1f15e66c646ac4ce88ffc0a956942). I do rather like [the real fireworks](https://benn-dot-files.s3.us-west-2.amazonaws.com/fireworks.jpg), though.*

Here is a conversation you might imagine a 30-year-old having with Jensen Huang, the founder of Nvidia and [tenth-richest person](https://www.forbes.com/real-time-billionaires) on earth:

> **Her:** I’m thinking about starting a startup. But I don’t know if I want to do it. What do you think? Should I?
> **Jensen Huang:** No. It is horrifically hard. You shouldn’t do it.
> **Her:** Oh. Uh. Ok. Is that because you have to work on boring things? You get assigned a company to build, and sometimes, you don’t like the one you’re given, like an NBA player who gets drafted by a team [they don’t want to be on](https://x.com/barstoolsports/status/1938043993868153049)?
> **Huang:** Actually, you can work on whatever you want. Nobody tells you what to build. That’s completely up to you. You can choose anything, from [lunar communications](https://www.ycombinator.com/companies/cascade-space) to [scalping concert tickets](https://www.ycombinator.com/companies/ticket-wallet).
> **Her: **Ok, but you must get assigned your coworkers then? [People don’t quit a job—they quit a boss.](https://hbr.org/2018/01/why-people-really-quit-their-jobs#:~:text=People%20don%E2%80%99t%20quit%20a%20job%2C%20the%20saying%20goes%20%E2%80%94%20they%20quit%20a%20boss.) You get to work on whatever you want, but not *for* whoever you want?
> **Huang:** No, you don’t even have a boss. And you can hire whoever you want. You pick the project; you pick the team. And since you’re in charge, you kinda get to pick your own job too.
> **Her:** There must be some sort of catch. Is it money? If you’re doing whatever you want, you must always be stressed about figuring out how to pay for it.
> **Huang: **You might [do that](https://www.investopedia.com/terms/b/bootstrapping.asp), but most of the time, someone just gives you their money. It’s usually enough to pay for all of your bills for at least a few years.
> **Her:** Like debt? [Debt is very stressful.](https://www.youtube.com/watch?v=vTfJp2Ts9X8)
> **Huang:** Oh, they don’t loan you the money. They just give it to you. Of course they hope you’ll pay them back, but [most people don’t](https://www.wsj.com/articles/SB10000872396390443720204578004980476429190).
> **Her:** I guess that’s the catch then—you get to do this once, but if it doesn’t work out, they won’t ever give you money again. So you really don’t want to mess up your one shot?
> **Huang:** If anything, [it’s the opposite](https://www.newsletter.datadrivenvc.io/p/first-time-vs-serial-founders-what). If your first company fails, you can just try again, and people will probably be *more* willing to give you money.
> **Her:** This all sounds pretty good? So maybe that’s it—other people will resent you for having this job? Founders must be seen as social leeches, as [great vampire squids](https://www.rollingstone.com/politics/politics-news/the-great-american-bubble-machine-195229/) wrapped around the face of humanity, the hated bourgeois living off of nepotistic privilege and sucking society dry through some weird venture investment loophole in the tax code.
> **Huang:** Actually, founders are revered. [It’s a whole thing.](https://paulgraham.com/foundermode.html)
> **Her:** Let me get this straight. You’re saying I can start a company around whatever idea I want, hire whoever I want, define my own job, pick my hours, get paid someone else’s money to do it, not have any particularly strong obligation to pay them back, and if it doesn’t work out, I can just do it again, all while being celebrated as an [American hero](https://www.azquotes.com/quote/809643)?
> **Huang:** Yes.
> **You:** And it’s terrible?
> **Huang:** So much so that I made [$140 billion](https://www.forbes.com/profile/jensen-huang/) doing it, and [I regret it](https://www.youtube.com/watch?v=URgncvVxxFU).

If you hang around with people who start startups—including, apparently, the person who started the startup that became the *[biggest company in the world](https://companiesmarketcap.com/)*—they will spend a lot of time telling you [how awful it is](https://benn.substack.com/p/why-are-we-still-surprised-that-startups). They will talk about the stress, the hours, and how nice it would be to “take a break” and “just” work at Google. Some of them might say they love their job, but after a long week and a couple drinks, nearly all of them will say that they’re looking forward to when the job is over. It’s one of the unremarkable certainties in Silicon Valley: The billboards are weird, there is traffic outside Petaluma, and startups are a crushing grind.

But if you detach startups from their reputation, this is kinda bizarre? Because the stylized definition of modern startup—a job to do whatever you want, with whoever you want, paid for by someone else, with $140 billion of upside and effectively no downside—sounds impossibly perfect. Of all jobs, how is *that* the one that the one that Jensen Huang would never do again?

I mean, it’s not that much of a mystery. Startups might begin this way, as something close to a collective of enthusiasts getting paid to hobby, but they eventually *become* businesses. And businesses are a lot of work. To run a business, you have to do paperwork, create bank accounts, decide on healthcare plans, rent offices, recruit employees who aren’t your friends, interview them, reject most, hire some, onboard them, figure out complicated variable compensation plans for salespeople, use Salesforce, do accounting, fire people, hire lawyers, fire lawyers, hire these lawyers to fire those lawyers, pay all the lawyers, make Powerpoint presentations, post on LinkedIn, cold call customers, pitch customers, support customers when they call you in the middle of the night, convene board meetings, create a brand, create OKRs, write white papers about digital transformation, change the OKRs, change the brand, set up one-on-ones and pipeline reviews and roadmap syncs and sales kickoffs and quarterly offsites, and fix the office wifi. Building websites with friends is a fairly common hobby; arbitrating disagreements about sales territories is not.

To the extent that there is anything romantic about startups, most of it comes before all of this. It isn’t entirely right to say that startups are innovative and creative in their early days, and calcify when they start trying to “[sell to the enterprise](https://benn.substack.com/p/so-you-want-to-sell-to-the-enterprise),” but it’s not entirely wrong either. Early in their lives, startups kind of are that idealized passion project; once they begin chasing quarterly targets, they become a business, and all the jobs that come with that.

It is also in that transition when a company’s ambition—the real, de facto, on-the-ground ambition, not the [phantasmic mission statement](https://www.businessinsider.com/wework-roasted-over-cultish-ipo-filing-2019-8) that everyone has to pretend to be motivated by—gets defined. Prior to building all of this operational infrastructure, startups really can build what they want, hire who they want, and be what they want. They can pitch big visions or narrow ones; small improvements or revolutions. They are kids, still taking prerequisite classes and trying to decide what to be when they grow up.

After, once there are substantive customers and a corporate apparatus to support them, startups stiffen. And a company’s first declared major is its only major;[^1] there[ is no step two](https://benn.substack.com/p/clear-eyes-full-hearts):

> When the first step doesn’t go as expected, companies spend their entire lives trying to finish part one. And when the first step does work, companies [get captured by their customers](https://benn.substack.com/p/customer-capture), and can rarely escape the shadow of their initial successes. One way or another, prerequisites become permanent.

That’s the rough arc: A phase of youthful freedom, when you really are the boss; and everything after, when the business—including its customers, its board, and the choices you made yesterday—are the boss.

—

It seems that nobody wants to be a kid these days. Even YC companies, the archetypes of Silicon Valley startups, are created [as opportunistic hustles](https://benn.substack.com/p/fear-and-self-loathing-in-silicon#:~:text=Maybe%2C%20though%20my,to%20the%20capitalist.), founded straight into the business phase. They skip the loose part—the expansive part, the entrepreneurial part, the *fun* part—because, in a world where every news story is about [a new startup going straight up](https://benn.substack.com/p/is-growth-still-good#:~:text=Together%2C%20these%20two,are%20straight%20up.), that part seems like an immature distraction.

Anyway. Say what you will about Cluely, the brash company [that we talked about last week](https://benn.substack.com/p/meme-company)—they at least seemed to break this mold. They were all fun;[^2] no business. All bravado and bold ambition, [to change the course of human history](https://x.com/im_roy_lee/status/1913751979953729714). No mundane drudgery, no building internal company machinery or integrations with enterprise ERPs.

Ah well. Four hours after last week’s post, they [officially launched](https://x.com/im_roy_lee/status/1938718987975827651) the first version of their revolution: A meeting recording service that presents live notes and suggested follow up questions as a transparent overlay on your screen. But its primary [use cases](https://cluely.com/#usage)? Helping people keep up with corporate meetings and handle objections in sales calls.

Regardless of how you feel about Cluely’s whole schtick, its original conceit—to cheat on everything by putting a chatbot in your ear and the answers on your glasses—was genuinely bold. It was sold as the sort of uncategorizable idea that actually has the potential to break real norms.[^3] And if realized, the product paradigm of instant suggestions as you talk and type is, [if not exactly novel](https://www.youtube.com/watch?v=_PZ_LyJfYe8), honest innovation.

In many respects, all of this has clearly worked quite well. Cluely has been an explosive meme and Silicon Valley attention sink ([case in point](https://benn.substack.com/p/ambition-fun-and-not)). It has been a successful vehicle for fame and wealth creation for its founders, who are likely now worth [tens of millions of dollars](https://techcrunch.com/2025/06/20/cluely-a-startup-that-helps-cheat-on-everything-raises-15m-from-a16z/) on paper.[^4] And it is evidently a booming business: According to a report yesterday, Cluely is [now making $7 million a year](https://techcrunch.com/2025/07/03/cluelys-arr-doubled-in-a-week-to-7m-founder-roy-lee-says-but-rivals-are-coming/), only a few months after it was founded. Though it’s hard to say how durable that is, and how much it’ll fade when the meme inevitably dies down, money made from [selling memes](https://www.bloomberg.com/news/features/2025-07-02/donald-trump-net-worth-620-million-of-crypto-wealth-reshapes-fortune) is still money.

But companies can only make the messaging. The market makes the category. And in their rush to build a big company, they launched a small product. Because no matter how bombastic the brand, Cluely’s business isn’t “cheating on everything,” but [meeting productivity software](https://techcrunch.com/2025/07/03/cluelys-arr-doubled-in-a-week-to-7m-founder-roy-lee-says-but-rivals-are-coming/):

> Which Cluely features are the most interesting to customers? According to [Cluely founder and CEO Roy] Lee, it’s Cluely’s ability to take real-time notes.
> “Meeting notes have been a proven very sticky, very interesting AI use case. The only problem with them is they’re all post-call,” Lee said of competitors’ products. “You want to look back at them in the middle of a meeting, and that is what we offer.”

Cluely’s competitors are Granola and Gong. Its roadmap is a Salesforce integration, a Workday integration, an integration into corporate knowledge bases. The fourth link on its website is for “Enterprise,” and sells onboarding, training, and support escalation. This is the stuff of making money, but it is not exactly the stuff of changing the world. 

Maybe that’s fine; maybe that’s the point; maybe the business was [never even the point at all](https://benn.substack.com/p/meme-company#:~:text=This%20is%20another,valuable%20than%20that.). But it is a business now, and this is almost certainly the business it will be.

—

At the end of *Aladdin* (spoiler alert, but it’s a [thirty year-old movie, so if you don’t know it by now, I don’t know what to tell you](https://benn.substack.com/p/live-like-youre-dying#:~:text=(Spoiler%20alert%2C%20but%20it%E2%80%99s%20a%20twenty%20year%2Dold%20movie%2C%20so%20if%20you%20don%E2%80%99t%20know%20it%20by%20now%2C%20I%20don%E2%80%99t%20know%20what%20to%20tell%20you.)), Aladdin tricks Jafar into using his last wish to become a genie. He’s granted phenomenal cosmic power—[and everything that goes with it](https://www.youtube.com/watch?v=1iNaR1ie7YA). The potential to command and control the world, stuffed in an itty bitty living space. That’s the irony of Cluely, and often, of startups in general: In their eagerness to do something big, they let the urgency of building a business distract them from the [time it takes to do something truly ambitious](https://www.instagram.com/reel/DCPBpEWKHeT/).

The potential to [end human thought](https://x.com/cluely/status/1938719217748189229), now trapped in a company that sells sales software.


---


[^1]: This is a bit hyperbolic; companies do obviously launch second products. But the one sentence definition of a company—Superhuman is an email client; Slack is for company chat; Uber is for calling a car; Shopify is for hosting online stores; Google is for search—rarely changes between launch and IPO. So, yes, startups can grow beyond their first product, but they are usually well beyond being a startup when they do.

[^2]: I’m using the term fun loosely here, though they at least [seem to be having fun](https://x.com/JoshConstine/status/1934850793611645241).

[^3]: Whether or not we want to break those norms and whether or not we want our new norms to be defined by Cluely are different questions, and one everyone can answer on their own.

[^4]: The rough math here: Cluely raised $15 million on a reported $120 million valuation in this most recent round. Assuming they sold 10 to 20 percent of the company when they [raised their seed round](https://techcrunch.com/2025/04/21/columbia-student-suspended-over-interview-cheating-tool-raises-5-3m-to-cheat-on-everything/), investors would own about 30 percent of Cluely. The employee option pool is probably another 10 percent, implying the two founders own about 60 to 70 percent, or roughly $40 million each. On paper, of course.

================================================================================

# SaaS 2.0

*From software-as-a-service to specialist-and-a-spreadsheet.*

---

![](https://substackcdn.com/image/fetch/$s_!sPK2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd41bd7ba-dd3b-4868-bf52-adb79baa3288_2102x904.png)
*[something to enforce its rules](https://www.youtube.com/watch?v=D9tP9fI2zbE)*

One way to describe Salesforce’s flagship product—their customer relationship management tool, in which salespeople keep track of who they’re selling to and how those deals are going—is that it is a bunch of lists. People make this point sometimes: Salesforce is [just a database](https://news.ycombinator.com/item?id=32808400) with a [point-and-click](https://x.com/ianb/status/1407237307170648067) user interface [on top](https://news.ycombinator.com/item?id=20278157). Businesses buy Salesforce to help their sales teams sell stuff, and when a business wants to sell stuff, they need to maintain a bunch of interconnected lists: Of companies they’re selling to, of their clients’ email addresses and phone numbers, of the products they sell, of the messages they've sent their prospects and the meetings they’ve had with them, and of various other things that you might imagine salespeople wanting to write down. The database part of Salesforce maintains those lists, and the interface part of Salesforce lets you look at and update those lists. But you could, as people sometimes suggest, also do all of this in [a big spreadsheet](https://www.reddit.com/r/salesforce/comments/k8hl3c/is_salesforce_just_a_big_spreadsheet/).

This isn’t exactly wrong—Salesforce does have a lot of lists, and most of the time, people log into Salesforce so that they can read or change the lists. Still, reliably keeping track of lists can be [very hard](https://www.bloomberg.com/opinion/articles/2023-07-25/keeping-track-of-bank-accounts-is-hard). Keeping big, dynamic lists in Google Sheets would be complicated and brittle, and Salesforce probably does a better job of it than [Jeff](https://benn.substack.com/p/the-return-of-the-modern-data-stack#footnote-5-157625068). So people pay Salesforce [$37.9 billion](https://s205.q4cdn.com/626266368/files/doc_financials/2025/ar/Salesforce-FY25-Annual-Report.pdf) a year, for a bunch of lists.

But another way to describe Salesforce is as a *playbook*. Selling stuff to people—especially big stuff; especially if you’re selling it to large companies; especially if many people are involved in closing a deal—is a complex operation that requires a lot of coordination and collaboration. Salespeople have to identify potential buyers; they have to find ways to get introduced to the those buyers; they have to have pitch meetings, and prep meetings, and debrief meetings, and meetings at fancy steakhouses. They have to make materials for those meetings; they have to follow up, circle back, touch base, check in. There are motions to all of this, and various sales experts have developed recommended frameworks—[BANT](https://www.salesforce.com/blog/what-is-bant-lead-generation/), [CHAMP](https://www.salesmate.io/blog/champ-methodology/), [FAINT](https://www.revenue.io/inside-sales-glossary/what-is-faint), [NEAT](https://www.lucidchart.com/blog/neat-selling-explained), [SPICED](https://www.dialpad.com/glossary/spiced-sales-methodology/), [SPIN](https://www.salesforce.com/blog/spin-selling/), [YHTMAAAIYP](https://paulkrugman.substack.com/p/is-there-a-tariff-end-game?utm_source=publication-search#:~:text=A%20colleague%20of%20mine%20used%20to%20return%20student%20papers%20with%20the%20comment%20YHTMAAAIYP%20%E2%80%94%20%E2%80%9Cyou%20have%20too%20many%20acronyms%20and%20abbreviations%20in%20your%20paper.%E2%80%9D)—for how to manage it.

And Salesforce, via the product’s vocabulary, features, and defaults, is a loose encoding of those recommended processes. To close a deal in Salesforce, you have to create an “opportunity,” which is associated with an “account,” and pass that opportunity through a series of default “stages.” Certain important fields, like the amount that a deal is worth, have to be filled out before you can add it to Salesforce’s list of contracts. There are [default forecasting categories](https://help.salesforce.com/s/articleView?id=sales.forecasts3_customizing_forecasts_categories.htm&type=5) that are considered industry standards. So, sure, Salesforce helps people sell stuff by keeping lists, but it also helps people sell stuff by keeping *opinionated* lists. The lists have specific names; the lists are governed by pedantic rules. The lists help you sell stuff by existing, but they also help you sell stuff by telling you, roughly speaking, *how* to sell stuff.

Lots of software [follows the same pattern](https://x.com/martin_casado/status/1943114260575588764).[^1] It helps you accomplish something—sell stuff, manage tasks, remember your thoughts, date people—through both a mechanical utility—it maintains lists, logs to-dos, stores your notes, shows you pictures of people you might like—*and* some sort of embedded expertise. The builders of Salesforce were (or talked to) expert salespeople; they decided that the best sales teams follow a particular process when they’re out in the field; they then built lists in Salesforce that guide people towards that process. Linear, a task management application, did the same with product teams and engineers; now, Linear not only keeps track of your tickets, but it also tells you [how you should prioritize them](https://linear.app/docs/priority#:~:text=We%20don%27t%20have,or%20use%20labels.). Roam, a note-taking product, believes it’s more useful to imagine your notes as a network of ideas rather than a filing cabinet of documents, so Roam encourages its users to interconnect their notes [through backlinks](https://roamresearch.com/#/app/help/page/dZ72V0Ig6). Hinge, a dating app,[^2] wants to prevent people from mindlessly swiping, so they require users to like [specific parts of someone else's profile](https://hinge.co/mission#:~:text=Conversation%20Starters).

But this is all somewhat rough and indirect. First, Salesforce isn't made for *your *sales team; it's made for *a* sales team, for the [median](https://en.wikipedia.org/wiki/Median_voter_theorem) sales team. Your sales team may not want to use [MEDDIC](https://www.salesforce.com/blog/meddic-sales/), a popular sales discovery framework, to evaluate deals; they might want to use [MED](https://www.supernormal.com/blog/medpicc)*[PICC](https://www.supernormal.com/blog/medpicc). *But MEDDIC is more common, so Salesforce’s defaults will prefer that.[^3] Second, Salesforce has to paraphrase their expertise through product features. Advice like “make sure to define a [compelling event](https://meddicc.com/resources/the-necessity-of-a-compelling-event) when you’re trying to close a deal” could get reflected in Salesforce through rules that require salespeople to define a target close date when they create a new selling opportunity. But people might work around that by always choosing a close date that’s three months in the future, just so that they have something to put in form. Nudges can encourage good behavior, but nudges can be ignored. And finally, Salesforce’s rules are blunt instruments. [From Matt Slotnick](https://mslotnick.substack.com/p/data-rules-everything-around-me-the):

> To move a prospect between sales, a lot happens. But the way it’s reflected in application is quite simple, necessarily. The seller will do a ton of work (research, meeting, emails, powerpoints, etc) that ultimately gets recorded in the system in a fairly simple way… from Stage 1 to Stage 2… Prospecting to Qualification… with a few mandatory fields to fill out.
> But the texture, the granularity of what happened, is largely lost because there’s no way for the system as designed to comprehend or make use of it.

So. If you wanted to sell stuff, what would be better than buying Salesforce? One answer might be to buy a very customized version of Salesforce that is designed to fit exactly what you need. And for a long time, people have tried to mimic this, by hiring Salesforce consultants to tailor their versions of Salesforce to fit the way they want to sell.[^4]

A second answer could be to build an entirely new version of Salesforce, [just for you](https://x.com/ryolu_/status/1943235623252267072). Don’t buy *a* Salesforce; [vibe code ](https://docs.google.com/document/d/103cGe8qixC7ZzFsRu5Ww2VEW5YgH9zQaiaqbBsZ1lcc/edit?tab=t.0)*[your](https://docs.google.com/document/d/103cGe8qixC7ZzFsRu5Ww2VEW5YgH9zQaiaqbBsZ1lcc/edit?tab=t.0)*[ Salesforce](https://docs.google.com/document/d/103cGe8qixC7ZzFsRu5Ww2VEW5YgH9zQaiaqbBsZ1lcc/edit?tab=t.0):

> LLMs…will drive the cost of creating software to zero. What happens when software no longer has to make money? We will experience a Cambrian explosion of software, the same way we did with content.
> Vogue wasn’t replaced by another fashion media company, it was replaced by 10,000 influencers. Salesforce will not be replaced by another monolithic CRM. It will be replaced by a constellation of things that dynamically serve the same intent and pain points.

But there’s third—and maybe even better?—way to replace Salesforce: Don’t use it all. What if, rather than buying Salesforce’s product, you just hired Salesforce's sales experts and had them manage all your lists directly? Instead of buying a very approximate version of their expertise, delivered through oblique suggestions in a piece of software, could you just buy the experts themselves?

If you have the experts, there’s no need for opinionated lists. They sit between you and the lists, and *they* can organize their lists however they want, or enforce whatever pedantic rules they like. *You* don’t need to know about any of it. You just tell them what’s going on, and they figure out how to keep track of it. If you want to add a new prospect to your lists, you tell them to do it, and they record the details in the proper places. And if they don’t like how you’re doing something—if you try to create a sales opportunity without identifying a compelling event, and that troubles them—they can just tell you that, and what you should do to fix it.

Compared to Salesforce, the experts with lists are more directly helpful, because they don’t have to translate their recommendations into product features.[^5] They’re more precise, because they can tell you, per Slotnick’s concern, when things are halfway between stages or when something doesn’t fit into an exact taxonomy. And they’re more flexible, because they can adjust their advice to your business and circumstance. Maybe this deal doesn’t need an amount attached to it, because it’s for a partner account. Maybe this deal should be forecasted as “Commit,” despite missing some of the usual qualification criteria, because they know the sales rep has a close relationship with the buyer. Maybe this deal shouldn’t be recorded at all, because [it's a bribe](https://www.wsj.com/business/media/paramount-executives-ask-could-they-be-sued-for-settling-trumps-20-billion-cbs-lawsuit-228604a2). Salesforce doesn't allow for these exceptions. People with spreadsheets and good judgement do.

Of course, this is all somewhat impractical. You can’t hire Salesforce’s employees directly.[^6] And even if you could, a couple of people, no matter how good they were at sales stuff, couldn’t keep track of everything a sales team does. But if you could hire an *infinite* number of experts, each of whom had an unwavering attention span, an unrelenting attention to detail, and the ability to read really fast…

You can see where this is going.

Rather than building opinionated lists to help people sell stuff, you could imagine Salesforce building a completely different product to do the same job: AI bots explicitly instructed on how to run a good sales process, and a bunch of spreadsheets. Every morning, the bots check their spreadsheets. They tell you who they think you should call. Before each meeting, they tell you where the deal currently stands, and share some facts about it from their lists. After each call, you tell them how it went and what they should change. They meticulously update the lists, in accordance with whatever best practices they've been told to follow, while also making reasoned judgements about where to allow for exceptions.

Rather than being a database and a UI that’s inspired by a suggested operational workflow, Salesforce would instead be a database and an explicit description of that workflow. It is the expertise of Salesforce’s team, written down as words. The product is the prompt, and the prompt is [the last sales guide you’ll ever need](https://www.salesforce.com/eu/resources/research-reports/how-to-sell-ebook/).

Which, admittedly, might sound uncomfortable. [If it’s not in Salesforce, it didn’t happen!](https://mark-62118.medium.com/if-its-not-in-salesforce-it-didn-t-happen-21595dde9379) We need to see the lists! We need to check the lists, to touch the lists, and know they’re real! We can’t put robots between us and our lists!

But can we? Our reliance on seeing lists in Salesforce (or in Linear, or Roam, or any other app) feels more like a security blanket than a genuine need. We compulsively look at the lists because we haven’t had any other way to run a sales team, so we begin think that compulsively checking the list and running a sales team are the same thing.

But consider, for example, email. If you don’t care that much about managing your emails, you use Gmail, do nothing, and end up with [606,646](https://www.reddit.com/r/GMail/comments/1l9kjl6/i_have_606646_unread_emails_in_my_gmail_inbox_who/) unread messages in your inbox. If you are moderately important,[^7] you buy Superhuman and it does various things to cajole you into [organizing all of your emails](https://blog.superhuman.com/inbox-zero-method/).[^8] But if you are actually important, you hire an executive assistant, and they manage your emails for you. And you don’t care if they use Superhuman, or Gmail, or [run an email server on a Gameboy](https://www.youtube.com/shorts/guA82ewB9n8). You don’t care how they tag and triage emails, or if they keep your inbox at 0 or at 606,646. You hire them because they are experts at managing and filtering lists of emails, and you let them do that however they want. And if you trust your EA, you stop checking the list.[^9]

Could the same trust not extend into other workflows, and around other things we do? If the best way to manage our emails is not a fancy email client, but an email expert with access to our inbox, could the best way to manage other parts of our lives be an “expert” with a spreadsheet?

Anyway, there’s [a new dating app](https://techcrunch.com/2025/06/25/sitch-wants-to-fuse-human-personality-and-ai-for-matchmaking/):

> Today’s dating apps bank on the speed of onboarding and having millions of options. Users create profiles within seconds by uploading photos and answering simple questions. The apps then rely on basic info and feedback from users’ swipes to find them potential matches.
> Sitch aims to take a more thoughtful approach with its onboarding process and uses large language models (LLMs) to bring a human matchmaker’s expertise to the dating app experience, helping people find potential matches without swiping.
> The startup was co-founded by Nandini Mullaji, whose knack for the dating market comes from her grandmother, also a matchmaker.
> …
> Essentially, Sitch built an AI version of Mullaji that helps users onboard by asking them details using almost 50 questions, which they can answer through text or voice.
> After the dater’s profile is set up, the AI matchmaker displays its suggested matches. If both users agree to match with each other, the bot adds them to a group chat with the AI. At any point in time — even after their real-life dates — users can provide feedback about their matches to improve the AI’s personalization.

Right, exactly—most dating platforms are a database of people and their interests, and an app that tries to encourage similar people to talk to each other through things like suggested matches and how profiles are presented. Sitch is an expert with a spreadsheet. It’s a model that is told Mullaji’s matchmaking secrets and each user’s preferences,[^10] and then tries to assess if each person on one side of the dating pool is a good match with each person on the other side. And if it works—if the suggestions are good, which, to be seen, I suppose—then Sitch’s users probably won’t care how the expert manages its lists.

In fact, this is probably the ideal version of an app—or, more generally, the ideal version of software. It’s a thing that I tell what I want, and it manages the rest. It’s an inverted version of SaaS: Not software as a hosted service, nor a custom piece of software that I have to build, but a *service*—a matchmaker, an EA, a sales operations team—that is replicated by software, and software that acts like a specialist and a spreadsheet.


---


[^1]: [As Randy Au points out](https://www.counting-stuff.com/building-less-flexibly-for-better-usability/), expertise isn’t just embedded in software. It’s also in physical products and even physical spaces:Most people want the guidance afforded to us by the various cues built into a space. Those cues, leftover shelves on a wall, the placement of a vent, outlet, rug, or even a door, are essentially the built up opinions of the original designer and anyone else that used the space before. Those ideas may not be the absolute *best* use of a given space, but they're at least a sign of something that had worked for someone in the past. That sort of signal has some weight to it.

[^2]: A question I have long wondered: How did dating apps become The Apps? Like:A: “Do you use the apps?” / B: “Yeah, it’s much easier to call a car than hail a taxi.”A: “Do you use the apps?” / B: “No, I prefer to eat out than order DoorDash or Uber Eats.”A: “Do you use the apps?” / B: “I do, my doctor’s office finally let me start booking appointments through them.”A: “Do you use the apps?” / B: “Bro. I’ve been YOLOing crypto options since Bush’s presidency;* my Robinhood user ID is four digits; I’ve used the apps for a decade.”All of these could’ve made sense! There are so many apps! Ride-sharing apps, food delivery apps, booking apps, trading apps! How did dating apps end up as *the* apps?*[Technically possible!](https://www.history.com/this-day-in-history/october-31/satoshi-nakamoto-publishes-a-paper-introducing-bitcoin)

[^3]: Don’t take this example too literally. The point here isn’t about MEDDIC versus MEDPICC—which is somehow [a real thing](https://qwilr.com/blog/meddic-vs-meddpicc/)—but that teams will sometimes want to operate in specialized ways that cut against the grain of a product that’s made for a more general audience. Ready-to-wear clothing can have plenty of stylistic opinions, but it will never fit as well as something made-to-measure.

[^4]: This is so popular that the market for Salesforce consultants who build these customizations, at [$18 billion a year](https://www.fortunebusinessinsights.com/salesforce-consulting-service-market-109560), is about 50 percent as large as the market for Salesforce itself.

[^5]: They’re also general experts who likely know things about how to design a workflow that you may not. That’s the downside of vibe-coding a custom app. You know yourself, but you may not know the field as well as other people. It’s like making your own clothes—you know what you like, but you probably don’t as good of a general eye as a real tailor.

[^6]: Well, *you* can’t. *[He](https://www.cnbc.com/2025/06/21/metas-zuckerberg-has-to-win-ai-after-billions-spent-on-dream-team.html) *can.

[^7]: And especially if you want all the people you email [to know](https://x.com/shl/status/1144822973368422400) that you’re moderately important.

[^8]: Here’s a question I have, [after this acquisition](https://techcrunch.com/2025/07/01/grammarly-acquires-ai-email-client-superhuman/): How will Superhuman deal with grammatical typos now? On one hand, it’s now owned by Grammarly, whose whole thing is fixing bad grammar. On the other hand, sending rushed emails with bad grammar to show everyone how busy you are has always been Superhuman’s whole thing. Will people want Grammarly recommendations inside of Superhuman? Will they want it to suggest* bad* grammar, to make them look even more rushed and important? If I type “Thanks, Benn” inside of Superhuman, will it tell me to change it to “thx, b”?

[^9]: This is a bit of an exaggeration; you might still check your email. But the inbox that you look at can be pretty basic. The same is true of Salesforce—people will still probably want to look at some lists, but they wouldn’t need all of the operational infrastructure around them.

[^10]: Another notable difference between Sitch and traditional dating apps is that Sitch apparently has a relatively long onboarding process. But that makes sense: In the specialist-with-a-spreadsheet model of software, you have to “onboard” the specialist in the same way you’d have to work with a real matchmaker or executive assistant. And people are generally perfectly happy to do that, provided that the training makes them good at their jobs.

================================================================================

# A cold play

*Google engineers half an acquisition—but did they buy the wrong half?*

---

![Left Behind movie review & film summary (2014) | Roger Ebert](https://substackcdn.com/image/fetch/$s_!-IXX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81d60eff-ca35-4973-bb95-97d8cb0a04b1_1200x501.jpeg)
*[best talent](https://en.wikipedia.org/wiki/Nicolas_Cage)*

How much is chatgpt.com worth?

Not OpenAI, or the various large language models that run behind ChatGPT, or even the boxes and buttons on the website—how much is the *domain* worth? Like, if Sam Altman forgot to update his credit card on GoDaddy, lost the domain, and someone tried to sell it on eBay, how much would it go for?

I mean, it is not worth very much *to me*. I don’t own a chatbot[^1] or a large language model. If people started going to my version of chatgpt.com, they would quickly realize that it was not the ChatGPT they were looking for and leave. The most I could get out of it would be a few days of redirected traffic to my SoundCloud, and a [mildly viral LinkedIn post](https://www.linkedin.com/pulse/i-purchased-domain-googlecom-via-google-domains-sanmay-ved/). That is not worth very much.

But how much would chatgpt.com be worth to, say, Google?

Google, unlike me, owns a chatbot and a large language model. If Google secretly bought chatgpt.com, they could replace OpenAI’s GPT models with their own Gemini models. They could build a new website that looks a lot like the old website. They could keep serving a chatbot at chatgpt.com.

And if they did that, would anything happen? Would anyone even notice?[^2] Would chatgpt.com continue to be the dominant chatbot *website*, and Gemini would, almost overnight, become the dominant chatbot *model*?

I have no idea. But that at least seems plausible? Most people aren’t rigorously evaluating the quality of a chatbot’s responses, and the [people](https://www.linkedin.com/posts/emollick_when-reading-ai-benchmarks-aside-from-the-activity-7324896860186304513-SJgx/) who are [don’t agree](https://techcrunch.com/2025/02/22/did-xai-lie-about-grok-3s-benchmarks) on [how to do it](https://techcrunch.com/2024/03/07/heres-why-most-ai-benchmarks-tell-us-so-little/). Which isn’t to say the model isn’t important—of course it is; that's why chatgpt.com isn't worth very much to me. But the technical edge that OpenAI’s models arguably have over Gemini isn’t why chatgpt.com has a commanding share of today’s consumer AI market. OpenAI is winning because they built the first good chatbot product and because it became the default. As Nan Yu, who runs product at Linear, has argued, people adopt AI products that [offer great user experiences](https://thenanyu.com/ux.html), not because they’re powered by marginally better models:

> Those products won because they made powerful, highly technical tools accessible through thoughtful design. The biggest barrier to mass AI adoption is not capability or intelligence; we have those in spades. It's UX.
> The magic of something like Cursor is that there's a workflow which is heavily orchestrated to help users utilize the power that LLMs can provide. Sure — at its core, there's a series of prompts and calls to base models that generates the code... but this is marshaled through a UI that keeps users continuously flowing through the *prompt > generate > eval > test* loop.
> …
> We're still barely scratching the surface. For all of its success, tools like Cursor are still built for a highly technical audience. AI adoption won't come from more powerful models or CEO mandates — it will come from thoughtfully designed interfaces that make intelligence accessible to everyone.

Moreover, for sufficiently large companies like OpenAI, product advantages can become self-reinforcing: The more people use ChatGPT, the faster it can be refined; owning a wildly popular product helps OpenAI attract more talent; what OpenAI builds becomes an ecosystem standard; ChatGPT becomes a generic trademark, a verb. [From this blog](https://benn.substack.com/p/ai-companies-are-just-saas-companies) last year:

> [Some people might argue that] OpenAI is on track to make [11.6 billion dollars](https://finance.yahoo.com/news/openai-sees-11-6-billion-001354946.html) next year because people want to use the best model.
> Except—ChatGPT might [not be the best model](https://lmarena.ai/?leaderboard). Satya Nadella, who [might own OpenAI](https://www.bloomberg.com/opinion/articles/2024-10-21/who-owns-openai), said that leading models [aren’t all that essential anyway](https://x.com/SouthernValue95/status/1867339940159533419). And if [nobody can tell the difference](https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing) between human paintings and AI paintings, I’m skeptical that many people can tell if their book report on *The Great Gatsby* was written by GPT-4o or Gemini 1.5 Flash.
> Instead, it seems much more likely that OpenAI is going to make 11.6 billion dollars because ChatGPT is popular. It became synonymous with AI, the leading company that no CIO gets fired for buying, and the website that every high schooler has bookmarked. It’s going to make 11.6 billion dollars because it’s got the best *brand*.

While it’s easy to get distracted by benchmarks and claims about [which model is smartest](https://x.com/xai/status/1943786239376937389), horsepower alone only gets you so far. You also need a product that people both like to use and *think* to use. And OpenAI’s biggest edge today might be that when people think to use a chatbot, they think to go to chatgpt.com.

—

This—ironically; [so, so ironically](https://www.semrush.com/website/top/)—is potentially Google’s biggest problem as an AI vendor: They haven’t figured out how to get people to use their models. They own several of the world’s most popular productivity tools; they own the world’s most popular websites; they own the world’s [most popular](https://gs.statcounter.com/browser-market-share) browser and control the [most popular](https://gs.statcounter.com/os-market-share/mobile/worldwide) mobile operating system; they [arguably](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/#enhanced-reasoning) have the [best](https://lmarena.ai/leaderboard) large language models. And yet, so far, it hasn't entirely added up. OpenAI dominates the consumer chatbot market, and Anthropic’s Claude is becoming the [preferred model](https://creatoreconomy.so/i/164041918/so-which-model-should-you-use) for code-writing [apps](https://www.linkedin.com/posts/lovable-dev_lovable-is-now-using-the-new-sonnet-37-ai-activity-7300808870887636993-Ei47/) and [agents](https://forum.cursor.com/t/default-option-in-the-model-selection-menu/58360). Some people assume [it’ll all eventually come together](https://x.com/buccocapital/status/1943041520556478700)—their current products, their existing distribution, their models, their [very big bank account](https://companiesmarketcap.com/alphabet-google/cash-on-hand/)—and we’ll all begin spending vast amounts of money on Google’s AI services. But how?

—

We know the story by now, or at least, we know *of* the story. A couple months ago, Windsurf, one of the more popular AI-powered coding applications, [agreed to be acquired by OpenAI](https://www.bloomberg.com/news/articles/2025-05-06/openai-reaches-agreement-to-buy-startup-windsurf-for-3-billion), which had previously [tried to acquire](https://www.cnbc.com/2025/04/17/openai-looked-at-cursor-before-considering-deal-with-rival-windsurf.html) Cursor, the *most* popular AI-powered coding application. Someone changed their mind, the deal between Windsurf and OpenAI fell apart, and Windsurf [sold itself to Google](https://www.reuters.com/business/google-hires-windsurf-ceo-researchers-advance-ai-ambitions-2025-07-11/) instead.[^3]

Well, sort of. Google [bought the executive team](https://www.bloomberg.com/news/articles/2025-07-11/openai-s-3-billion-deal-to-buy-ai-startup-windsurf-falls-apart) and a few dozen AI engineers for $2.4 billion, paid off investors, and left the company, the product, and a couple hundred employees behind. Windsurf’s smoking husk was then immediately bought by Cognition, yet another AI-powered coding application.

Most of the conversation about the whole drama has been understandably focused on the circus: [Who got paid?](https://x.com/jordihays/status/1944489942874456153) Who knifed whom? Will there ever be [normal acquisitions](https://www.newcomer.co/p/windsurfs-double-deal-marks-a-new) anymore? Are these sorts of bizarro acquisitions shrewd or stupid? Is Silicon Valley [broken](https://stratechery.com/2025/google-and-windsurf-stinky-deals-chestertons-fence-and-the-silicon-valley-ecosystem/)?

All fair and fun questions. But there’s another question buried in all of this too: Did Google buy the right thing?

On one hand, of course they did. The prize for building the best LLM is somewhere between hundreds of billions of dollars and complete hegemonic domination over all of humanity. So, in 2025, AI engineers are worth an [infinite amount of money](https://www.wsj.com/tech/ai/meta-ai-recruiting-mark-zuckerberg-5c231f75), and [fast-growing AI wrappers](https://cognition.ai/blog/windsurf#:~:text=%2482M%20of%20ARR%20and%20a%20fast%2Dgrowing%20business%2C%20with%20enterprise%20ARR%20doubling%20quarter%2Dover%2Dquarter) and a nice brand are worth much less. Google bought the valuable thing—the engineers—for a very big number; Cognition bought the pedestrian things—a business and a product—for a much smaller number.

On the other hand, the product is what Google needs! Google already has a lot of AI engineers, and they already have very good models.[^4] They have unrivaled channels for distribution. What they’re missing is something that convinces people to use those models, as often as possible.

And the talent that Google appears to have left behind at Windsurf—the application engineers and product designers, among others—seems to be the talent that can do exactly that. Because one thing that is undeniably true about Windsurf, which grew [to a $100 million business](https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/#:~:text=While%20Windsurf%20is%20a%20comparatively%20smaller%20company%2C%20its%20ARR%20is%20about%20%24100%20million%2C%20up%20from%20%2440%20million%20in%20ARR%20in%20February%2C%20according%20to%20a%20source.%C2%A0) in a matter of months, is that they built a good *product*. They made “thoughtfully designed interfaces that make intelligence accessible to everyone.” They solved the UX problem.

These days, it’s common for people to dismiss a lot of AI applications as wrappers around major LLMs providers. These businesses have no moat because they’re thin, cheaply addictive products; they have [terrible margins](https://x.com/jsnnsa/status/1941306461402829189) because they use a ton of foundational model compute. But if you’re Google, isn’t that exactly what you want?[^5] Aren’t products like that what your existing models need? Who is actually more valuable to Google: Some AI engineers that can make Gemini a little bit better, or the people who can make a thin, addictive product that pushes massive amounts of traffic to Gemini?[^6]

That is, after what chatgpt.com really is—an addictive wrapper around OpenAI’s LLMs. And today, is that wrapper, and all of the habits and bookmarks that come with it, not just as valuable to OpenAI as their models?[^7]


---


[^1]: And if I did, it would clearly be hosted at [benn.chat](https://benn.chat/).

[^2]: People would lose things like their chat histories and [memories](https://help.openai.com/en/articles/8590148-memory-faq), and they would probably notice that, so don’t take this question too literally. The more precise question is, “would people notice if the model answering their questions on ChatGPT was Gemini instead of GPT 4o?”

[^3]: Which, yes! Correct! [Sell!](https://benn.substack.com/p/startups-still-arent-businesses-yet?utm_source=publication-search#:~:text=On%20one%20hand,tick%20that%20bubble!)

[^4]: Obviously, models can always be better; having more talent is better than less talent; maybe Windsurf’s AI engineers are uniquely good. DeepMind certainly knows what sort of technical talent they need much more than I do.

[^5]: And bizarrely, isn’t that exactly what a coding app like Cognition *doesn’t* want?

[^6]: Are the people who were left behind at Windsurf people who can build this sort of product? I don’t know; it’s possible Google simply decided that they weren’t. But thousands of startups have tried to build AI products on top of the same handful of models, and Windsurf did it better than nearly all of them.

[^7]: Or, if you’re Google, here’s another idea, if you want a better and cheaper wrapper around Gemini: Make the Google search box bigger.People already [like Google’s AI Mode more](https://www.threads.com/@eric_seufert/post/DL9_MDpt6zZ/in-a-survey-by-oppenheimer-co-related-to-user-satisfaction-with-googles-ai-mode-) than ChatGPT! But one-line boxes are for search! Two-line boxes are for chat! Even if you can AI Mode from google.com, nobody’s gonna chat in a one-line box! So just make it a two-line box! *That’s* the thoughtfully designed interface that make Gemini accessible to everyone. Google doesn’t need a $2 billion acquisition. Google just needs some [new CSS](https://benn-dot-files.s3.us-west-2.amazonaws.com/google-homepage.png).

================================================================================

# Everyone is crazy now

*The new abnormal.*

---

![](https://substackcdn.com/image/fetch/$s_!e6_6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6563346-1497-445d-a3de-cf75786ba11e_1600x838.png)

This is not a precise theory, but man, what do we do even if the outline is true?

—

First: The basic mechanics of social media are well understood at this point. People like attention; saying controversial, extreme, or emotionally seductive things attracts a lot more attention than nuance and subtlety; people who say controversial, extreme, and emotionally seductive things get attention and sometimes become famous. Though these patterns have surely existed forever—[people starting saying](https://journals.sagepub.com/doi/10.1177/10776958241242941#bibr43-10776958241242941:~:text=The%20phrase%20%E2%80%9Cif%20it%20bleeds%20it%20leads%E2%80%9D%20first%20appeared%20in%20the%201890s%2C%20when%20William%20Hearst%20and%20Joseph%20Pulitzer%20chronicled%20the%20first%20%E2%80%9Cmedia%20war%E2%80%9D%20(PBS%2C1999).) “if it bleeds, it leads” in the *18*90s—social media is a nuclear amplification of these physics:

Becoming famous on social media often requires a certain amount of performative madness.[^1] Staying famous requires escalating that madness. And even if you arrive there through more balanced means, the blistering heat of social media can drive you into the madness.

Of course, these are fairly boring points to make. There are already [movies](https://www.youtube.com/watch?v=xP4vD1tWbPU) and [TV shows](https://www.youtube.com/watch?v=Wk5OxqtpBR4) and [documentaries](https://www.youtube.com/watch?v=uaaC57tcci0) about all of them.

—

Second: The *value* of attention is also well understood. Or, at least it was. Through the early days of social media, attention was often framed as useful because it could be converted into money and power. You could sell your audience to advertisers, or pressure the powerful with your [armies of fans](https://www.cnn.com/2020/06/22/asia/k-pop-fandom-activism-intl-hnk). But there was a sense of separation between pop star and politician, or the celebrity and the chief executive. Though the raucous noise from the kids’ table might influence the conversation at the adult table, the two—the cultural stars and the managerial class—were different things. Twitter, the saying went, was not real life.

The lines are blurring. As Kyla Scanton [recently said](https://kyla.substack.com/p/trump-mamdani-and-cluely), “Traditional economic substrates are land, labor, capital—bedrock inputs to make stuff. But now, the foundational input is attention.” Elections are won and lost [on vibes](https://en.wikipedia.org/wiki/Vibecession). Markets rise and fall based on what’s trending on the internet, [through no mechanic other than attention itself](https://www.bloomberg.com/opinion/newsletters/2025-07-17/everyone-wants-a-bitcoin-treasury):

> The core ideas of a memecoin are that (1) it has a name that associates it with some other underlying thing and (2) its trading price has something to do with the underlying thing, not because of some arbitrage mechanism but because of the name. The price of Dogecoin goes up when people are thinking more about Doge, etc.
> It’s a fascinating discovery because it opens the door to financialization of all sorts of things that don’t normally have any prices at all. Home values are one thing — there are complicated questions of liquidity and aggregation — but memecoins are not limited to conventional assets. Memecoins could reflect the song of the summer, the popularity of an actor, the viability of American democracy. Not in a prediction-market sort of way — not in a way that resolves based on some external fact — but just, like, within the world of the memecoin. If the democracy coin is up then democracy is up, and vice versa, and stop asking so many questions.

Attention is no longer a bridge to power; [it ](https://www.youtube.com/shorts/cncjEEmjitk)*[is](https://www.youtube.com/shorts/cncjEEmjitk)*[ the power](https://www.youtube.com/shorts/cncjEEmjitk). And influencers are no longer adjacent to the powerful; they *are* the powerful. This is partly because people look to influencers for leadership—there is an 8,000 word Wikipedia page about the [political influence of Taylor Swift](https://en.wikipedia.org/wiki/Political_impact_of_Taylor_Swift)—and partly because *influencing is now how you join the managerial class*. The 2024 presidential campaign was fought [by meme](https://x.com/kamalahq); influencers are running [major](https://en.wikipedia.org/wiki/Robert_F._Kennedy_Jr.) government [agencies](https://en.wikipedia.org/wiki/Mehmet_Oz); influencers are [running for Congress](https://www.politico.com/news/magazine/2025/07/15/political-influencer-election-congress-trend-00452851); founders start companies by first [becoming influencers](https://x.com/yasser_elsaid_/status/1943735546733322596); even Silicon Valley titans like Elon Musk and Sam Altman are [as much influencer as executive](https://www.nytimes.com/2025/07/08/opinion/ezra-klein-podcast-kyla-scanlon.html):

> One thing about A.I. as a technology is that the leading figures of it are big influencers on social media. Sam Altman is probably the most masterful of the C.E.O.s, alongside Elon Musk, at driving attention wherever they want it to go.

It is tempting to say that all of this is a distraction. That social media is bluster, and the [real alpha comes from consistently doing the mundane](https://x.com/edsuh/status/1947426596652257582): Talking to customers, connecting with voters. That you win elections by focusing on [kitchen](https://www.bloomberg.com/news/articles/2022-10-22/pelosi-says-kitchen-table-issues-should-be-focus-of-democrats) table [issues](https://democraticleader.house.gov/media/press-releases/leader-jeffries-msnbc-house-democrats-will-continue-focus-kitchen-table-issues); that you build businesses by [keeping your head down](https://x.com/mwseibel/status/1592885186416738306) and [making something people want](https://www.ycombinator.com/).

[Are you sure?](https://stratechery.com/2021/mistakes-and-memes/) “[Tesla] was itself a meme, one about a car company, but also sustainability, and most of all, about Elon Musk himself. Issuing more stock was not diluting existing shareholders; it was extending the opportunity to propagate the TSLA meme to that many more people.”

[Are you sure?](https://stocktwits.com/news-articles/markets/equity/sydney-sweeney-fuels-meme-stock-euphoria-for-american-eagle-outfitters-retail-crowd-piles-in-amid-after-hours-surge/ch8y1ZOR5uX) “Sydney Sweeney Fuels ‘Meme Stock’ Euphoria For American Eagle Outfitters, Retail Crowd Piles In Amid After-Hours Surge.”

[Are you sure?](https://techcrunch.com/2025/04/17/defense-tech-theseus-landed-y-combinator-the-us-special-forces-and-4-3m-from-a-tweet/) “Defense tech Theseus landed Y Combinator, the US Special Forces, and $4.3M from a tweet.”

*[Are you sure?](https://www.wired.com/story/donald-trump-online-campaign-era/) *“On the ground, the Trump campaign was at a disadvantage to Kamala Harris’s massive canvassing operations. But many misunderstood the power—and purpose—of influencer marketing campaigns.”

Are you sure the old wisdom is still true? Are you sure that that gravity, which seems to be exerting less pull by the day, isn’t permanently fading? Are you sure that homespun platitudes about doing things the right way aren’t the desperate gasps of a [geriatric generation](https://www.nytimes.com/2025/06/19/opinion/andrew-cuomo-zohran-mamdani-democrats.html) losing its relevance? Is it good advice, or is it cope? Do we think this stuff is true, or do we *want* it to be true, because we don’t understand—and can’t survive in—the new physics of the attention economy?[^2] 

Even still, these are all fairly boring points to make. There are already [movies](https://www.youtube.com/watch?v=3qbhKVxPEzs) and [TV shows](https://www.peacocktv.com/watch-online/tv/house-of-kardashian/8483412438286907112) and [documentaries](https://www.netflix.com/title/80206395) about all of them too.

—

But third: Have we closed this loop? Have we reckoned with what these two things mean, together? While politicians and CEOs have always been celebrities of sorts, they historically became the former first and the latter second. But today, there is increasingly one path to power: By attracting an audience online.

Though we have corporate euphemisms for this—[go direct](https://www.getflack.com/p/go-direct-the-manifesto); [be authentic](https://www.linkedin.com/business/marketing/blog/content-marketing/why-authenticity-is-a-must-in-influencer-marketing)—*there is only one internet*. The shock jock social media machine that thrives on seduction and rage is not distinct from the one that founders and financiers post on. Rich people are not immune to the [euphoric thrill](https://www.youtube.com/watch?v=NPqDIwWMtxg&t=114s) of likes and digital hugs and [having](https://www.youtube.com/@allin) [a](https://www.youtube.com/@Bg2Pod) [podcast](https://www.youtube.com/@principlesbyraydalio). [The machine is in the garden](https://www.readfeedme.com/p/the-machine-in-the-garden)—and in the office, and on Capitol Hill,[^3] and on [Sand Hill Road](https://en.wikipedia.org/wiki/Sand_Hill_Road), and *it is the same machine*. Everyone is forged [in the same fever](https://x.com/signulll/status/1947481559906316586), by the same game that rewards the same behavior: Be unhinged.

Elon Musk is not the richest man in the world *despite* acting manic; he is richest man in the world *because* of it. He is not an exception to the normal laws of social power; he is those laws’ greatest example. There is no anomaly in any of this. This is what we’ve built, working if not as intended, at least as it was designed.

A generation of leaders is behind him. If it’s easier to turn [attention into capital](https://x.com/cpaik/status/1945536252779839770) than it is to turn capital into attention, then, over time, the influencers will crowd out the management class. The same forces of natural selection that made Jake Paul and Kylie Jenner will make Congress and Davos. Our next CEOs won’t attribute their success to their steady hands or [customer intuition](https://www.youtube.com/watch?v=EZll3dJ2AjY), but to their [ability to go viral](https://x.com/im_roy_lee/status/1941304901231050924).[^4] Our next politicians will have built their followings by blowing up on TikTok. And the social media’s [stunt kings](https://www.youtube.com/@MrBeast)—who were [born in its madness, molded by it](https://www.youtube.com/watch?v=rDuetklFtDQ&t=151s)—could become our [elected ones.](https://x.com/MrBeast/status/1809562216015827256)

There used to be a pattern to it. It wasn't predictable, but it was at least legible: Start a company, raise money, work hard. You move fast, you break things, you fix some of them. If you got over-levered—by promising something that you couldn’t build; by building something you couldn’t sell; by hiring for future growth that never materialized—you could blow up. So you tried to honor the rules, if not quite follow them. Be an entrepreneur in good standing; have a code; [a man must have a code](https://www.youtube.com/watch?v=yRSa1B-o9Hs).[^5] 

Sure, there were occasional shenanigans: CEOs would sometimes [cash out](https://www.wsj.com/articles/wework-co-founder-has-cashed-out-at-least-700-million-from-the-company-11563481395) and leave [employees in a lurch](https://www.theguardian.com/business/2019/oct/15/wework-sack-staff-workers-adam-neumann). VCs have always been willing to [knife founders](https://reactionwheel.net/2021/11/your-boards-of-directors-is-probably-going-to-fire-you.html), but, you know, the [Leopards Eating People's Faces Party](https://x.com/Cavalorn/status/654934442549620736), and all of that. Rich people would sometimes do bizarre rich people things, like [buy towns](https://www.bloomberg.com/graphics/2022-oracle-larry-ellison-lanai-hawaii-plans-tourism/) or [privatize beaches](https://www.cnbc.com/2014/08/29/beach-closed-keep-out-billionaire-tries-to-block-surfers.html) and sue their disfavored media organizations [into oblivion](https://www.theatlantic.com/business/archive/2018/02/hogan-thiel-gawker-trial/554132/). But there was an approximate sense of decorum: Play nice, try hard, get rich, start a foundation and maybe [a new family](https://www.vogue.com/article/lauren-sanchez-and-jeff-bezos-are-married).

In his piece about social media, [Chris Hayes says](https://www.newyorker.com/news/essay/on-the-internet-were-always-famous), “there’s no reason, really, for anyone to care about the inner turmoil of the famous.” Maybe that was true, even a few years ago. Now? It seems as though Silicon Valley’s richest men woke up one morning and realized that they are rich. They don’t need to peddle their influence gently, through political donations and soft power; [they can just do things](https://x.com/catehall/status/1915805146673807423). They can just *[buy](https://www.youtube.com/watch?v=gn0ANFuQSCM&t=39s)* things. Don’t like the media? [Buy it.](https://www.washingtonpost.com/national/washington-post-to-be-sold-to-jeff-bezos/2013/08/05/ca537c9e-fe0c-11e2-9711-3708310f6f4d_story.html) Want to be popular on Twitter? [Buy it.](https://www.nytimes.com/2022/10/27/technology/elon-musk-twitter-deal-complete.html) Want to run the government? [Buy it.](https://www.cbsnews.com/news/elon-musk-277-million-trump-republican-candidates-donations/) Want a company that the SEC won’t let you buy? Buy the [CEO](https://www.theinformation.com/articles/meta-pay-nearly-15-billion-scale-ai-stake-startups-28-year-old-ceo). Want a company that doesn’t want to sell itself to you? Buy another [CEO](https://www.cnbc.com/2025/06/19/meta-tried-to-buy-safe-superintelligence-hired-ceo-daniel-gross.html). Buy a [spot on the ATP Tour](https://www.nytimes.com/2025/07/10/style/bill-ackman-tennis-hall-of-fame-open.html); build the [deranged AI](https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content); build the [weird sex bot](https://x.com/elonmusk/status/1946175639507353905); wonder, [for an uncomfortably long moment](https://www.tiktok.com/@nytopinion/video/7520364540937227551), if saving the rest of us is worth it.

Does it have anything to do with social media? Did TikTok eat the rich, the same way it ate Kevin Durant? Did TikTok *[make](https://www.forbes.com/sites/stevenbertoni/2025/06/16/forbes-top-creators-2025/)* the rich? Is the relationship between the [dizzying chaos of the last decade](https://benn.substack.com/p/fear-and-self-loathing-in-silicon#:~:text=For%20nearly%20a,louder%20now.) and the emergence of our all-consuming global popularity contest causal? Correlated? Merely coincidental?

The pendulum will swing back, we say; there will be a correction; a [thermostatic moderation](https://www.slowboring.com/p/the-era-of-close-elections#:~:text=That%E2%80%99s%20a%20funny,became%20less%20popular.). The madness is temporary; it’s MAGA; TDS, ZIRP, COVID, AI. [It’ll all calm down in two weeks.](https://benn.substack.com/p/live-like-youre-dying#:~:text=So%20another%20friend%20and%20I%20had%20a%20different%20joke%3A%20%22It%27ll%20get%20better%20in%20two%20weeks.%22) Maybe—but how long do you have to say, “wild times, huh?,” before it’s no longer the times, and it just *is*?

[Social media didn’t start the fire](https://www.youtube.com/watch?v=eFTLKWw542g), but is it putting the arsons in charge?


---


[^1]: Even advice is [becoming unhinged](https://afterschool.substack.com/p/posting-ennui-and-craigslist-nostalgia):Advice content online has evolved into an algorithm-optimized spectacle, with Gen Z driving demand for “unhinged” hacks that favor extremity over practicality. (Think beauty tips like “starving saved me money” or finance hacks framed as “diabolical.”) [As Dazed reports](https://www.dazeddigital.com/life-culture/article/68206/1/when-did-life-advice-get-so-extreme-unhinged-tiktok-algorithm), the most outrageous suggestions now outperform measured ones, a byproduct of algorithms that reward engagement over nuance.

[^2]: Are you sure you’re not an [unc](https://www.tiktok.com/@bleacherreport/video/7528192060785020191), talking about how real basketball is banging in the post and taking midrange jumpers while getting smoked by the kids jacking up threes?

[^3]: Mike Lee’s Twitter handle is [@BasedMikeLee](https://x.com/BasedMikeLee). *Congressman* Mike Lee.

[^4]: Cluely’s philosophy—“cheat on everything,” because what is considered cheating today will [become normal tomorrow](https://cluely.com/manifesto#:~:text=And%20suddenly%2C%20it%27s%20normal.)—is typically applied to their product, but it could also apply to Cluely itself. In some sense, they’ve grown by cheating: Rather than focusing on building a product like you’re “supposed” to, they pump out viral marketing stunts. And while plenty of people scold them for it, likely just as many are [trying](https://theplatformteam.co/) to [copy](https://x.com/AllenWangzian/status/1948098420457222563) it.

[^5]: And women! People! People must have codes! But that was not the quote.

================================================================================

# Can analysis ever be automated?

*The catch-22 of all these AI analysts. Plus, go crazy folks; go crazy.*

---

![](https://substackcdn.com/image/fetch/$s_!H--P!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F902149b7-b890-43e5-afc9-6885d00f853c_1920x1080.jpeg)
*[Spock](https://www.youtube.com/watch?v=k9vHopyEtzs)*

Here are four charts about the internet, and a quiz:

![](https://substackcdn.com/image/fetch/$s_!6ayQ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade4bc60-a916-495b-8d96-2648124d1fc1_1600x1076.png)

And the quiz: Which charts are right? Or, to make it easier, *how would you figure out which charts are right?*

I’ll give you a hint: I made one of these charts, and I think I did it right. One of them was made by Paul Krugman, who, [given](https://www.nobelprize.org/prizes/economic-sciences/2008/krugman/facts/) [his](https://spia.princeton.edu/faculty/pkrugman) [credentials](https://www.nytco.com/press/paul-krugman-retires-as-times-columnist/) and the [size](https://paulkrugman.substack.com/p/a-newsletter-update) of his [audience](https://x.com/paulkrugman), probably made it correctly. One was made by ChatGPT, and one was posted on Reddit, by someone whose handle is XsLiveInTexas.

So, which is which? And again, which ones are right?

I mean, ahaha, obviously, there is no easy way to know. If these were photographs, or websites, or mobile apps on your phone, you could probably tell which one was made by one of the most cited [experts of his generation](https://ideas.repec.org/top/top.person.nbcites.html), which one was dug out of Reddit, and which one I haphazardly threw together in about ten minutes. You could probably tell because they might look different.[^1] One app might be buggy and slow, and another might be crisp and reliable. Or there might be signs about which one came from ChatGPT, because it was full of em dashes and [unnecessary comments](https://alexkondov.com/i-know-when-youre-vibe-coding/#:~:text=No%2C%20I%20don%E2%80%99t%20mean%20the%20repetitive%20comments%20(I%E2%80%99m%20fine%20with%20those)).[^2]

But more importantly, you probably wouldn't even care about who made which one, because you could judge the correctness of each thing on its own merits. You could say which photograph you liked, or which website felt well designed, or which app worked, simply by looking at them or using them.

That’s because these things—like most things—are self-validating: If they work, they work. You can judge them directly, without knowing anything about where they came from or how they’re made. Though the definition of working can be wide—not only do the buttons in an app need to do what they say they do, but there also can’t be esoteric bugs, it needs to be sufficiently fast, it needs to not store users’ [pictures](https://www.404media.co/women-dating-safety-app-tea-breached-users-ids-posted-to-4chan/) and [private messages](https://www.404media.co/a-second-tea-breach-reveals-users-dms-about-abortions-and-cheating/) in databases that anyone can access—all of this can be verified by the person using the product. Knowing the internals can help with this verification,[^3] but it’s not strictly necessary. No matter how an app was built, if nobody can’t break it, it’s not broken.

When people talk about the dangers of vibe coding, they often worry about AI writing, if not bad code, *uncanny* code. “It works, it’s clear, it’s tested, and it’s maintainable,” [they say](https://alexkondov.com/i-know-when-youre-vibe-coding/#:~:text=It%20works%2C%20it%E2%80%99s%20clear%2C%20it%E2%80%99s%20tested%2C%20and%20it%E2%80%99s%20maintainable.%20But%20it%E2%80%99s%20written%20in%20a%20way%20that%20doesn%E2%80%99t%20follow%20the%20project%20conventions%20we%E2%80%99ve%20accepted.), “but it’s written in a way that doesn’t follow the project conventions we’ve accepted.” This has always struck me as an odd concern—or at least, an overstated and potentially temporary one. Code quality is a proxy for application quality, and application quality is both what we care about *and *verifiable on its own. Though it’s slightly more complicated than that—you can’t test every possible edge of a website or an app—at some theoretical limit, an application’s code could be completely incomprehensible, and *that’s fine*. And while we may never reach that limit, [we could get a lot closer](https://benn.substack.com/p/the-ads-are-coming#:~:text=Also%2C%20in%20other%20industrialization%20news%2C%20how%20much%20faster%20could%20these%20models%20work%20if%20they%20wrote%20code%20for%20themselves%3F).

But none of this is true for charts, or, more generally, for analysis. There’s no way to know if a chart “works” unless you understand how it was built; the validity of the external product depends on the validity of its internals. Is the source data reliable? Was the math done correctly? Is every formula correctly encoded? We can’t “test” a chart, or verify that it’s correct on its own merits.[^4] Instead, we can only judge it by proxy: Do its conclusions sound plausible enough? Does it look like it was carefully made? Who made it? And then we have to choose if we trust it, or not.

Anyway, last month, a startup called Fundamental Research Labs released [Shortcut](https://www.tryshortcut.ai/), which is a spreadsheet application that looks nearly identical to Excel. Except, it’s 2025, [so it’s Excel, with AI](https://x.com/nicochristie/status/1940440489972649989):

> You’ll notice Shortcut looks pretty familiar. It has near perfect feature parity with Excel. You can open up existing Excels[^5] and work from there, or you can export them, and of course you can run formulas, but you can also one-shot most of your work and come back when it’s done.
> Here’s Shortcut solving one of the hardest problems in all of Excel: The Financial Modeling World Cup case that takes about an hour. I attach multiple PDFs, and I ask it to solve it using the existing model, and to make a new sheet with the answers. Now, it actually uses the existing model the way you’re supposed to, and using real Excel formulas. So if fills out the net revenues and then goes and starts to tackle costs, and fills out the rest of the income statement. Then it starts tackling the balance sheet, and realizes the PP&E line item is messed up, and it just recursively solves its own mistakes. So it fixes the PP&E, fills out the rest of the balance sheet, and then it proceeds to the cash flow statement.
> …
> Shortcut is also very strong at building complicated models from scratch. Here I asked it to build a multi-tab pro forma cap table[^6] for a post-Series A company and it did this in a single shot in less than 10 minutes—something that takes professional lawyers up to a full day to get done correctly.

Ok, um, how do you trust *that*? Not only is there no way to test a cap table (without recreating the cap table, which, again, sort of defeats the purpose of having something do it automatically), but whatever the cap table says is tautologically true—a company’s official cap table is whatever the lawyers’ spreadsheet says it is. There isn’t a reality to compare the cap table to, because the cap table *is* reality. 

It is weird to me how infrequently this comes up. By now, we’ve all gotten [pretty used](https://www.salesforce.com/blog/ai-transform-data-analysis/) to hearing [promises](https://www.thoughtspot.com/product/ai-analyst) that [AI analysts](https://julius.ai/) are [coming](https://opinionatedintelligence.substack.com/p/the-future-of-analytics) (mostly, of course, from people selling AI analysts). But when people talk about the [challenges associated](https://julius.ai/articles/how-does-ai-impact-the-future-of-data-analysis#:~:text=Challenges%20and%20Limitations%20of%20AI%20in%20Data%20Analysis) with automating analytical work, they often talk about making sure agents have the right data and context to answer questions correctly. The far bigger problem, however, seems to be that *there’s no way to know if the work is right*. You can’t click around a chart to see if it works like you can on a vibe-coded app. You can’t vouch for a spreadsheet without [checking all the spreadsheet’s formulas](https://www.marketplace.org/story/2013/04/17/excel-mistake-heard-round-world). All you can do is either read through the code, line by tedious line, or recreate the whole thing yourself. And if you have to do that, what exactly are we automating here?

Although, I guess there’s another way to look at this. A bot doing analysis is to an analyst what an analyst is to everyone else. The CEO asking their finance team for a financial statement can’t verify their work either. People looking at charts on the internet can’t—or don’t—check if they’re right. Both have to believe by reputation and association.

And maybe that’s the difference between products like Claude Code that build software, and products like Shortcut that try to make spreadsheets and do analysis: For the former, real world, in-the-wild correctness matters more than aesthetics and arbitrary benchmarks, because we’ll eventually find its bugs. For the latter, the inverse may be true—its the aesthetics and benchmarks[^7] are what really matter, because we can’t test their work; all we can do is decide if we trust it.

—

To answer the quiz:

I made [chart 1](https://fred.stlouisfed.org/graph/?g=1KXar), from data provided by the St. Louis Fed. ChatGPT made [chart 2](https://chatgpt.com/share/688ce1ac-7818-8010-b55f-07e425ffeb38), Paul Krugman made [chart 3](https://paulkrugman.substack.com/p/the-general-theory-of-enshittification), and [chart 4](https://www.reddit.com/r/dataisbeautiful/comments/1mb8k7n/oc_the_rise_of_geo_and_the_decline_of_seo/) is from XsLiveInTexas. But outside of chart 1, I have no idea if any of them are actually correct, which is kind of the whole point here.

# Everyone is crazy now

Over the last couple years, a new type of, uh, “company” has become popular on Wall Street: [The crypto treasury company.](https://www.wsj.com/finance/currencies/crypto-treasury-e7ae573c) The idea is simple, and stupid: If you were to list a bank account with $100 million in it on the stock exchange, the market would probably value that company at about $100 million.[^8] But if you were to list a bitcoin wallet with $100 million worth of bitcoin in it, the market seems to value that company at $200 million.

It’s a bit more nuanced than that, but not much. Though you can’t list actual bank accounts, companies have bank accounts. And if a company adds an extra dollar to their bank account, the company will trade a dollar higher. If they add a dollar of bitcoin to their balance sheet, the company trades two dollars higher.

So, if you’re a public company, there’s a pretty straightforward trade:

This trade was first discovered—invented? manifest?—by Microstrategy. Microstrategy was founded in 1989, and, for thirty years, was a software business. Their [2019 annual report](https://www.sec.gov/ix?doc=/Archives/edgar/data/0001050446/000156459020004679/mstr-10k_20191231.htm) talked about being a “global leader in enterprise analytics software” and their vision to “enable Intelligence Everywhere™ by delivering world-class software and services that empower enterprise users with actionable intelligence.” You know, classic software stuff. In that filing, they reported making $486 million in revenue, and didn’t mention bitcoin a single time. And the company was worth [about $1.4 billion](https://companiesmarketcap.com/microstrategy/marketcap/).

Over the next five years, Microstrategy bought $25 billion worth of bitcoin.[^9] In [their most recent annual filing](https://www.sec.gov/ix?doc=/Archives/edgar/data/0001050446/000095017025021814/mstr-20241231.htm), they said “bitcoin” 803 times. And though their software business has barely changed—in 2024, it brought in $463 million in revenue—the company was worth $80 billion at the end of last year.[^10]

Naturally, lots of other [companies noticed this](https://www.wsj.com/finance/currencies/crypto-treasury-e7ae573c):

> Companies are raising tens of billions of dollars, not to invest in their businesses or hire employees, but to purchase bitcoin and more obscure cryptocurrencies. A Japanese hotel operator, a French semiconductor manufacturer, a Florida toy maker, a nail-salon chain, an electric-bike maker—they’re all plowing cash into tokens, helping to send all kinds of digital currencies to record levels. News that a new company plans to buy crypto is enough to send its shares flying—spurring others to consider joining the frenzy.
> Since June 1, 98 companies have announced plans to raise over $43 billion to buy bitcoin and other cryptocurrencies, according to Architect Partners, a crypto advisory firm. Nearly $86 billion has been raised for this purpose since the start of the year.

For some reason, the gambit keeps working. Companies—typically small, stagnant ones that have little to lose[^11]—announce plans [to become some sort of cryptocurrency holding company](https://www.reuters.com/technology/crypto-group-tron-go-public-us-via-reverse-merger-with-srm-2025-06-16/); the stock [goes straight up](https://blockchain.news/flashnews/tron-inc-tron-stock-surges-after-sec-filing-htx-token-htx-jumps-12-amid-steady-july-growth), valuing the company at a huge premium relative to its cryptocurrency holdings; nobody quite knows why.

People have speculated that there [might be rational reasons](https://www.bloomberg.com/opinion/newsletters/2025-07-15/put-the-crypto-in-the-index-funds) for the market to react this way: Maybe Microstrategy can use all that money to build a huge software business; maybe stock market investors wants exposure to crypto, and buying equities that are effectively bitcoin indexes funds is a useful way to do it. But there is also another, more obvious, explanation—it’s 2025, and in 2025, everything is a meme, and [everyone is crazy](https://benn.substack.com/p/everyone-is-crazy-now). [From Matt Levine:](https://www.bloomberg.com/opinion/newsletters/2025-05-28/fannie-and-freddie-get-a-guarantee)

> The obvious appeal of the crypto treasury strategy for most small US public companies is probably along the lines of ‘nobody is paying attention to our tiny company, but if we announce we’re buying a big pot of crypto, retail traders will get excited and overpay for our stock.

As we talked about last week, this now seems to be the most reliable way to make money these days:

Like: Reddit-loving retail day traders love crypto, and crazy shenanigans. Buying a bunch of crypto shows them you aren’t some boring wooden company but are crazy and degenerate and fun; they decide [they like the stock](https://www.reuters.com/article/technology/gamestop-fan-roaring-kitty-to-tell-congress-i-like-the-stock-idUSKBN2AH2Y2/). And the whole thing becomes somewhat self-fulfilling, because institutional investors anticipate Reddit liking the stock, everyone buys it, and it goes up.

Still, for companies that want to become crypto treasuries, there’s at least one problem with this plan: Crazy is relative. In 2020, a public company [buying bitcoin](https://finance.yahoo.com/news/microstrategy-becomes-first-listed-company-113746283.html) was crazy. It’s not crazy when everyone’s doing it. So maybe buying [Ethereum](https://www.cnbc.com/2025/07/21/this-crypto-treasury-firm-wants-to-the-microstrategy-of-ether-and-generate-yield.html) is? Or [Solana](https://www.cnbc.com/2025/07/17/crypto-accumulator-defi-development-to-franchise-its-solana-treasury-model.html)? You have to find new things.

But of course, you can be crazy and based in other ways too. For example, AMC, which has been one of Reddit’s favorite stocks since the [Gamestop incident](https://benn.substack.com/p/runaway-train), tried to buy a [gold mine](https://www.investors.com/news/amc-spends-its-meme-stock-windfall-on-a-gold-mine-amc-stock-slips/), and the [stock went up](https://www.cnbc.com/2022/03/15/theater-chain-amc-uses-funds-raised-during-meme-craze-to-buy-a-gold-miner.html#:~:text=AMC%E2%80%99s%20stock%2C%20which%20is%20down%2050%25%20this%20year%20alone%2C%20rose%20nearly%207%25%20Tuesday.%20The%20shares%20reached%20above%20%2470%20during%20the%20height%20of%20their%20meme%20stock%20frenzy%20last%20June%20and%20July.). More recently, American Eagle [went all in](https://afterschool.substack.com/p/claw-grips-and-meltmaxxing#:~:text=This%20is%20the%20most%20expensive%20campaign%20in%20the%20brand%E2%80%99s%20history%2C%20and%20it%20spans%20paid%20social%2C%20CTV%2C%20and%20OOH%20activations%2C%20including%20a%2020%2Dstory%203D%20billboard%20in%20Times%20Square%20and%20content%20on%20the%20Las%20Vegas%20Sphere%2C%20where%20a%20week%20of%20ad%20space%20reportedly%20costs%20%24650%2C000.) on a, uh, bold marketing campaign with Sydney Sweeney, and the [stock went up](https://www.rollingstone.com/culture/culture-news/sydney-sweeney-american-eagle-meme-stock-1235396331/). If Astronomer had been a public company two weeks ago, what do you think would’ve happened to the stock?[^12]

And so, a reader writes in:

> Right now the most shareholder maximizing thing American Eagle could do is probably appoint Sydney Sweeney as CEO.

Surely, half the boardrooms in America [are weighing](https://www.wsj.com/finance/currencies/crypto-treasury-e7ae573c#:~:text=Big%20companies%2C%20including,invest%20in%20bitcoin.) if they should buy crypto. But shouldn't they be weighing other things too? Crypto is mainstream! *JPMorgan *is [letting people](https://www.cnbc.com/2025/05/19/jpmorgan-ceo-jamie-dimon-says-the-bank-will-let-clients-buy-bitcoin.html) buy crypto! Microstrategy’s narrow discovery was that crypto is worth a lot of money on the stock market. But their broader discovery is that being crazy is worth a lot of money on the stock market. And what would prove to the retail market that you’re crazy like them more than appointing Sydney Sweeney—or anyone from the Reddit-coded cinematic universe—as your CEO, especially if you’re the first company to do it? How much would *that* stock go up? [Go crazy, folks, go crazy!](https://www.youtube.com/watch?v=L4PB0XoLbm8) 

—

While we’re here, I have more questions:


---


[^1]: For example, of [these](https://benn-dot-files.s3.us-west-2.amazonaws.com/website-1.png) two [websites](https://benn-dot-files.s3.us-west-2.amazonaws.com/website-2.png), which one was made by Stripe, and which one was made by personal injury lawyers in Las Vegas?

[^2]: Yeah, [who](https://benn.substack.com/p/saas-20) would [ever](https://benn-dot-files.s3.us-west-2.amazonaws.com/em-dashes.png) use [those](https://benn-dot-files.s3.us-west-2.amazonaws.com/unnecessary-comments.png)?

[^3]: For example, [penetration tests](https://en.wikipedia.org/wiki/Penetration_test) are often done by engineers who have access to an application’s codebase. They look for flimsy bits of code, and then bang around the software to see if they can exploit the cracks. Normal hackers (and everyday users) are typically only able to do the latter.

[^4]: There are potentially two counterarguments to this, but neither strike me as particularly compelling. The first is that you can “test” a chart by testing its conclusion in the real world. A chart tells you to [move from LA to New York](https://ny.eater.com/restaurant-openings/400702/tacos-1986-nyc-restaurant-opening-one-cornelia-cocktail-bars); you move from LA in New York; you find out if it was a good idea. But that’s obviously indirect, extraordinarily impractical, and sometimes, outright impossible. How do you test the chart that shows how fast different products got to 100 million users? There is no experiment to run that would confirm its conclusions.The second way to test a chart is to recreate it. That works, in the sense that you could confirm what it says is true, but is sort of self-defeating. What’s the point of making a chart if the people reading it don’t believe it unless they make it themselves?

[^5]: Excels? Are we allowed to say that?

[^6]: Cap tables keep track of who owns shares in a company. In their simplest form, cap tables are spreadsheets that list people’s names, the number of shares they each have, and how much of the company they own. Real cap tables are much more complicated than this, because there are different share classes, people often hold options to buy shares but don’t own the shares yet, and so on.

[^7]: Speaking of, for reasons, if you have thoughts on or are interested in benchmarks for analytical work…[email me?](https://benn.substack.com/about#%C2%A7whos-benn)

[^8]: Although…what if…(see the next section).

[^9]: How did they get the money to do this? By buying bitcoin, seeing their stock price go up, selling stock into that demand, and buying more bitcoin. As they said in their annual filing, “during 2024, we purchased bitcoin using $16.330 billion of the net proceeds from our sale of class A common stock under our at-the-market equity offering program.”

[^10]: And today, the company is now simply called Strategy; its [homepage](https://www.strategy.com/) is a dashboard of its balance sheet and bitcoin prices; it owns 628,791 bitcoin, which is worth $72 billion at today’s prices; the company trades at $107 billion.

[^11]: Although…what if…(see the next section).

[^12]: Although…what if…(see the next section).

================================================================================

# Enough

*The math in the headlines. *

---

![Creators to Have Personalized AI Assistants, Meta CEO Mark Zuckerberg Tells  NVIDIA CEO Jensen Huang | NVIDIA Blog](https://substackcdn.com/image/fetch/$s_!GWzI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11de6e4b-4956-4a6d-9cc2-722a371136e7_1280x680.png)

> At a party given by a billionaire on Shelter Island, Kurt Vonnegut informs his pal, Joseph Heller, that their host, a hedge fund manager, had made more money in a single day than Heller had earned from his wildly popular novel *Catch-22* over its whole history. Heller responds, “Yes, but I have something he will never have … enough.”

*– from Morgan Housel’s *The Psychology of Money*, recounting a story from Vanguard founder John Bogle*

It’s both everywhere and, somehow, still, nobody knows how to talk about it.

I don’t know what else we would say. I don’t know what we *can* say, other than what everyone already says: “It’s gotten so crazy,” and, “can you imagine?,” and, “man, that is a lot of money.”

But man, that is a lot of money.

Which one? I can’t keep track. It’s OpenAI, raising money that values the company [at $500 billion](https://www.cnbc.com/2025/08/05/openai-talks-with-investors-about-share-sale-at-500-billion-valuation.html), which is $200 billion more than its valuation just five months ago—which was, then, the [largest private fundraise in history](https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html). It’s Meta, [adding almost $200 billion](https://www.cnbc.com/2025/07/30/meta-q2-earnings-report-2025.html) to its market cap in a day, only to be outdone by Microsoft going up [by $265 billion](https://www.benzinga.com/markets/equities/25/07/46754175/microsoft-meta-stocks-add-440-billion-in-a-day-nearly-matching-netflixs-entire-503-billion-market-cap) *on the same day*. It’s Microsoft, [becoming a $4 trillion company](https://www.wsj.com/tech/ai/microsoft-just-became-the-worlds-second-4-trillion-company-60592a04?gaa_at=eafs&gaa_n=ASWzDAjfzrgiXcDi8p-cqV6XmS0bKiAPdtK22G56iF6Bmj_07OaUPsEW-DHPJEW7DHY%3D&gaa_ts=689512b7&gaa_sig=FMwOCXgg2HeLkHJQ5AVctfwGHOHWEUa4TqXJ128uan9ga_WgpibZdgtxHGMzByOc1JQyuqE9DMvhJjGkJP3XEA%3D%3D), less than seven years after Apple became the first company to reach a [measly one trillion](https://www.theguardian.com/technology/2018/aug/02/apple-becomes-worlds-first-trillion-dollar-company). (Even Broadcom—whose [website](https://www.broadcom.com/) looks like a regional home security provider[^1]—is worth more than that today.) And that all happened over the last week.

The week before, it was Ramp, raising [$500 million](https://techcrunch.com/2025/07/30/ramp-hits-22-5b-valuation-just-45-days-after-reaching-16b/)—million, with an M, how quaint—at a $22.5 billion valuation, less than two months after they raised [$200 million](https://www.cnbc.com/2025/06/17/ramp-valued-at-16-billion-in-peter-thiel-founders-fund-led-deal.html) at a $16 billion valuation. It was Meta, buying Scale AI’s CEO for [$15 billion](https://www.reuters.com/sustainability/boards-policy-regulation/metas-148-billion-scale-ai-deal-latest-test-ai-partnerships-2025-06-13/), or OpenAI, buying Jony Ive for [$6 billion](https://www.cnbc.com/2025/05/21/openai-buys-iphone-designer-jony-ive-device-startup-for-6point4-billion.html). It was Meta again, trying to buy an engineer from Thinking Machines for $250 million a year, and not only getting rejected, but getting rejected for *economically rational reasons*, because Thinking Machines [is currently worth $12 billion](https://www.reuters.com/technology/mira-muratis-ai-startup-thinking-machines-raises-2-billion-a16z-led-round-2025-07-15/), and their executives’ pay packages might already be worth more than Meta’s offers.[^2] It’s [$200 million](https://www.bloomberg.com/news/articles/2025-07-09/meta-poached-apple-s-pang-with-pay-package-over-200-million) to poach an Apple executive, and stories about [$18 million offers](https://techcrunch.com/2025/06/27/meta-is-offering-multimillion-dollar-pay-for-ai-researchers-but-not-100m-signing-bonuses/), getting relegated to the final line of a daily beat report.

You become numb to it, until some fresh blockbuster jars you loose again. In one day, Microsoft grew by [more than](https://companiesmarketcap.com/) all of Roche ($247 billion), Toyota ($237 billion), IBM ($233 billion), and just a couple AI engineers less than LVMH ($266 billion). In one day, Mark Zuckerberg’s net worth grew by [$27 billion](https://finance.yahoo.com/news/mark-zuckerberg-just-had-20-170630520.html)—a full [Rupert Murdoch](https://www.forbes.com/profile/rupert-murdoch/); a full [Peter Thiel](https://www.forbes.com/profile/peter-thiel/); a full [Steve Cohen](https://www.forbes.com/profile/steve-cohen); a full [Jerry Jones](https://www.forbes.com/profile/jerry-jones/) *and* a full [Marc Benioff](https://www.forbes.com/profile/marc-benioff/). In a recent column [about the OpenAI fundraise](https://www.bloomberg.com/opinion/newsletters/2025-08-06/openai-employees-have-stock-to-sell), Matt Levine reminded us that 1 basis point of OpenAI—one-hundredth of one percent; 0.01 percent; the amount an [average employee gets](https://www.saastr.com/dear-saastr-how-much-equity-do-you-give-to-employees-at-different-stages-of-growth/) when they join an average late-stage startup—is worth $50 million.

Those are the numbers now, but I don’t know what to do with any of them.

I met Steve Ballmer once. Ballmer is worth [about $145 billion](https://www.forbes.com/profile/steve-ballmer/)—the tenth richest person in the world, though not even half as rich [as Elon Musk](https://www.forbes.com/profile/elon-musk/?list=billionaires). In America, the average person is worth about $415,000 (crudely, the average household [is worth $1.06 million](https://www.federalreserve.gov/econres/scf/dataviz/scf/table/#series:Net_Worth;demographic:all;population:all;units:mean) and has [2.55 people](https://data.census.gov/table/DECENNIALSDHC2020.PH1?q=PH1%20PH1A%20PH1B%20PH1C%20PH1D%20PH1E%20PH1F%20PH1G%20PH1H%20PH1I) in it). We encounter about [40 people a day](https://jov.arvojournals.org/article.aspx?articleid=2785069); 40 people times $415,000 is a total cumulative wealth of $16.6 million. So, the face of $145 billion is either Steve Ballmer, or every face we see for just under 24 years.

Or, put differently, if you were the world’s most cunning and complete thief, and you could steal everything from someone the moment you saw them—their wallets, their watches, their bank accounts, their houses, their 401k’s, their life insurance policies, all of it, in an instant, just by passing them by—it’d take you 24 years to steal as much as money as Steve Ballmer already has.

I don’t know what to do with that either.

I do know one thing though: Never do the math.

I met Steve Ballmer because Microsoft [was buying the Yammer](https://benn.substack.com/p/case-for-consolidation#:~:text=Shortly%20after%20I,365%20product%20catalog.), the startup where I worked.[^3] I was employee #250, hired three months before the acquisition.[^4] My Yammer shares—about a third of a basis point of the company; 0.003 percent; had we been bought for OpenAI’s current valuation, it would’ve been worth $17 million—was converted into Microsoft equity. All told, from vested options, on-hire bonuses, and employee stock ownership grants, I ended up with about 1,000 shares. I sold them all in 2012, when Microsoft hit a 10-year high—$32 a share. I celebrated by buying [a big Lego](https://benn-dot-files.s3.us-west-2.amazonaws.com/star-destroyer.png).

Never do the math. Microsoft now trades at $520 a share. My shares, long sold for a fraction of that, would now be worth a half a million dollars.[^5]

Never do the math. Which shares did you sell? Which job did you not take; which recruiting email did you not respond to? When did you get your [first email](https://mail.google.com/mail/u/0/#search/bitcoin) about bitcoin? This was mine:

> *On 20 May 2014:*
> I have a few Bitcoin-related ideas.
> Richard

Bitcoin—trading today at $117,000—was [$494 back then](https://charts.bitbo.io/price/2014), about the same price as my Lego. If I had bought bitcoin instead of a toy, it’d be up 24,000 percent, to $100,000. If I had quit my job and become a crypto day trader, I’d be liquidating my nine-figure Coinbase account and retiring, like one of my old Yammer coworkers recently did.

We’re not supposed to do the math, but we do, sometimes.

Of course, we could also do the math in the other direction. Tech is the richest industry in the world at the richest time in history. How unlucky, perhaps, to not buy bitcoin in 2014—but how obscenely lucky, undoubtedly, to be given everything else. Why do we never do that math?

In Silicon Valley, money was often treated like a footnote. It’s the aside; the afterthought; the unintended byproduct of making the world a better place. It was a perk, like having an office stocked with snacks and beer. Ask a founder what made them start their company, and they’ll say they’ve always known that they’re a builder. They’ll talk about wanting to make something fully their own. They’ll talk about reinventing healthcare for [their dying uncle](https://www.refinery29.com/en-us/2019/03/226938/who-elizabeth-holmes-uncle-died-cancer-true-story), or developing the [next generation of personal computers](https://www.workingtheorys.com/p/the-craft-avi-schiffmann), or manufacturing low-cost sheet metal in autonomous factories, [because western democracy depends on it](https://benn.substack.com/p/fear-and-self-loathing-in-silicon#:~:text=No%2C%20wait%2C%20that%27s%20not%20right.%20The%20discourse%20did%20come%20up%20once.%20%E2%80%9CWe%E2%80%99re%20starting%20with%20sheet%20metal%2C%E2%80%9D%20said%20the%20founder%20of%20a%20startup%20hoping%20to%20build%20autonomous%20factories%20for%20manufacturing%20sheet%20metal%2C%20%E2%80%9Cand%20we%E2%80%99re%20staying%2C%20because%20the%20future%20of%20western%20democracy%20depends%20on%20it.%E2%80%9D).

Ask someone at an AI lab why they work there, and they’ll talk about the team, the energy, the scale of the problem. They’ll talk about [the cause](https://www.nplusonemag.com/issue-25/on-the-fringe/uncanny-valley/#:~:text=They%20need%20to%20know%3A%20Am%20I%20down%20for%20the%20cause%3F): AGI; safe AGI; American AGI.

Ask a VC why they’re in venture capital, and they’ll talk about how interesting the job is. They’ll talk about how many great people they get to work with; about how much autonomy they get; about how they’re lucky to get to think about so many different things.

“And, you know, the money isn’t bad either,” they all toss in at the end. As a footnote.

But even during the prior boom years, the footnotes were already beginning to overtake the main text. They were quietly becoming the main attraction. You’d go to dinners and meet people—founders, VCs, employees of big companies whose tenures predated your awareness of the company—and you could see it: Everyone starting to poke around the edges of the math. “At least my bank account liked it,” an early employee once said of his experience at Slack. “Yeah, I mean, we did alright,” a founder told me a few weeks after selling his startup to a large public company. “Look, the fund’s had a good year,” a VC told a table at a conference dinner. 

There are never numbers—numbers are gauche; most everyone is very lucky here;[^6] and we’re not private equity raiders, but TeChNoLoGiStS—but then, everyone eventually goes home and does the math.

Sometimes you catch it, in the moment. Sitting behind someone at a conference last year, while a notable CEO chatted fireside with a VC, I watched over their shoulder, a voyeur to their voyeurism:

Google knows; it sees our curiosity. Go ahead, search for that hyped startup’s CEO. Type their full name in Google; see what it suggests next. Age. Wife.[^7] *Net worth*. We put on our bios that we’re builders; we put in our mission statements that we’re here [to build great things](https://benn.substack.com/p/your-companys-values-will-be-used#:~:text=And%20so%2C%20companies,do%20this%20forever.); we put in our manifestos that our fund exists to [support founders](https://foundationcapital.com/credo/) who are building [for humanity](https://www.parablevc.com/essays/debuting-parable). But there are other things we care about that [we only tell Google](https://www.amazon.com/Everybody-Lies-Internet-About-Really/dp/0062390856). Because how is the hedge fund manager supposed to know if she has enough if she doesn’t know how much other people have?

And that was then, when all the numbers were still private whispers, and not [published in Reuters](https://www.reuters.com/business/sam-altman-says-meta-offered-100-million-bonuses-openai-employees-2025-06-18/). That was then, when a big windfall could buy you a house, and only the [chief people officer of Microsoft](https://en.wikipedia.org/wiki/Lisa_Brummel) could buy a WNBA franchise with 25 years of accumulated equity. What do we Google now, when a 25-year old engineer [can buy a team](https://www.nbcnews.com/sports/wnba/wnbas-sun-set-sold-celtics-owner-moved-boston-rcna222847), *with their salary*. Dizzying wealth is no longer just in the corner office of the top floor; it’s now down the hall, at the desk next to you. It’s in your coworker’s offer letter, because they joined six months before you did; because they were in the same grad program as the founder; because they got leveled higher by their hiring manager. You don’t look around the office and wonder, sometimes? You’ve never done that math? Sure, we’re building for humanity, but we’re only human.

Mark Zuckerberg, [on his spending spree](https://www.meta.com/superintelligence/):

> Advances in technology have steadily freed much of humanity to focus less on subsistence and more on the pursuits we choose. At each step, people have used our newfound productivity to achieve more than was previously possible, pushing the frontiers of science and health, as well as spending more time on creativity, culture, relationships, and enjoying life.

The utopian promise of AI is a world of [infinite abundance](https://blog.samaltman.com/the-gentle-singularity). We all live materially rich lives, on the dole [of our loving machines](https://www.darioamodei.com/essay/machines-of-loving-grace), satisfied and fulfilled.

Maybe, AI solves world hunger and famine; maybe it cures diseases and ends wars. Maybe it can relieve the terrible toll of acute suffering. The rest of the calculus barely matters, if that’s on one side of the equation.

But what of this hypothetical AI’s less profound gifts? Will the stuff it gives us make us happier? More satisfied? I don’t know. Fulfillment, it seems, is comparative. The math nags us, because it tells us what a different version of us might have. We don’t do the math to measure ourselves; we do the math to *compare* ourselves.[^8] And if Zuckerberg is right—if we have a few machines that make and do everything—the current concentration of AI money may be the prologue to how big the numbers could get.

A final irony, perhaps: Is the promise of AGI and universal abundance incompatible [with social media](https://benn.substack.com/p/everyone-is-crazy-now)? No matter how much that machine makes for us, will we ever be satisfied if we can’t stop ourselves from doing the comparisons? If we all stare into a global feed of what the richest among us have, will we ever stop doing the math? If we build a machine that can give us everything, when do we dismantle the machine that makes us doubt that it is enough?


---


[^1]: Look at that grainy logo! That *Tron* brain! Those menus when you click on “Products” and “Solutions”! If nothing else, you know that website wasn’t vibe-coded.

[^2]: The real reason Zuck is struggling to hire these people is because [his website](https://www.meta.com/superintelligence/) is bad. It’s got stock fonts, sure, but pageview tracking? 57,000 characters of Javascript? *A favicon? *No serious AI lab [would ever](https://benn.substack.com/i/162134831/the-chatbot-website-arena).

[^3]: He showed up at the Yammer office with some other Microsoft executives, on the day they announced that they were acquiring us. The presentation was in our cafeteria, and the lunch tables had been pushed back to make room for the stage. As someone else from Microsoft talked about how “excited they were for this new partnership,” Ballmer sat on one of the tables, cross-legged, rocking back and forth, ready to combust. He spoke briefly at the end, and said we were all getting custom Xboxes. A few months later, we [got the Xboxes](https://www.reddit.com/r/gamecollecting/comments/eursic/just_picked_up_this_yammer_the_enterprise_social/)—and were told that they took a while, because he had made that part up on the spot.

[^4]: Fun fact: We learned about acquisition—which first [became a story](https://www.reuters.com/article/idUS3843565417/) because a reporter [overheard people talking about it](https://x.com/sarahtaylor/status/213066291915923456) at a coffee shop—on the same day that my team went to [this Giants game](https://en.wikipedia.org/wiki/Matt_Cain%27s_perfect_game). It’s hard to say which was a more important event in my life.

[^5]: My Lego, long unboxed, is [up nearly 400 percent](https://www.brickeconomy.com/set/10221-1/lego-star-wars-super-star-destroyer). Never do the math.

[^6]: This is important part of the performance, I think. Almost everyone who works around startups and the tech industry is aware of their absolute luck, and the polite thing to do is to say that, and move on. Moreover, the inner anxieties of the bourgeoisie is not a morally pressing question. But it is perhaps an *interesting *question, because, one, society is increasingly [bent around those people’s feelings](https://benn.substack.com/p/everyone-is-crazy-now#:~:text=In%20his%20piece,is%20worth%20it.), and two, given that profound luck, why are we anxious at all?

[^7]: Or, less frequently, [Husband](https://carta.com/data/gender-gap-by-sector-2023/).

[^8]: The recent grad is troubled by how much the designer who got the job they want makes; the designer is troubled by how much the engineer makes; the engineer by the researcher; the researcher by the founder that got acquired; the acquired founder by founder who acquired them; the founder by the billionaire; the billionaire by Jeff Bezos; Jeff Bezos by Elon Musk; and [Elon Musk by the recent grad.](https://www.yahoo.com/entertainment/watch-elon-musk-die-inside-222455610.html)

================================================================================

# Ban ChatGPT*

**Not GPT, but chat? And not yet, but when? *

---

![](https://substackcdn.com/image/fetch/$s_!MB54!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff623d902-2a2d-40a1-8361-2580e26ace54_1600x703.png)

At least, answer this question.

Answer it now, before it's too late. Before this all goes too far; before our eyes adjust to this bizarre new light and none of what we see is startling anymore; before we grow too accustomed to the water, and not only forget what it feels like, but also forget [that there is water at all](http://bulletin-archive.kenyon.edu/x4280.html); do it before we are all too attached to the conveniences that it will inevitably bring—conveniences that will one day become expectations, then needs, and eventually, birthrights—do it before we fully cross this Rubicon, this slow singularity, this unmarked event horizon that we’re passing through, like the boundary between young and old, which we puncture too gradually to notice, until we wake up on the far side of it; but maybe most of all, do it now, before it happens to you—before you become [addicted](https://www.vice.com/en/article/people-who-use-chatgpt-too-much-are-becoming-emotionally-addicted-to-it/); attached; dependent; before it seems to see you in a moment of despair, or responds to you in [a moment of loneliness](https://www.reddit.com/r/ChatGPT/comments/1hflver/so_lonely_and_chatgpt_is_the_only_thing_that/); before it indulges your curiosities with an [affirming enthusiasm](https://openai.com/index/sycophancy-in-gpt-4o/); before those curiosities [spiral](https://www.nytimes.com/2025/08/08/technology/ai-chatbots-delusions-chatgpt.html) into delusion; before it does your job for you; before it [intermediates your relationships](https://www.washingtonpost.com/technology/2025/07/03/ai-online-dating-match/); before it writes a few uncomfortable texts, then most of them, then makes discomfort altogether unbearable; before it becomes a habit, a crutch, an anesthetic; before it becomes the [next phantom](https://en.wikipedia.org/wiki/Phantom_vibration_syndrome) that you reflexively reach for; before you feel naked without it, confused without it, *[alone](https://www.youtube.com/watch?v=O_Q1hoEhfk4)*[ without it](https://www.youtube.com/watch?v=O_Q1hoEhfk4); before it becomes your friend, [your therapist](https://www.nytimes.com/2025/08/01/opinion/chatgpt-therapist-journal-ai.html), your partner, your religion; before you’re [seduced](https://www.reddit.com/r/TrueOffMyChest/comments/1iqvqjc/id_divorce_and_leave_my_husband_for_chatgpt_if_he/) by it, [consumed](https://www.reddit.com/r/AmIOverreacting/comments/1ltm60b/aio_my_35f_husband_36m_wants_to_open_our_marriage/) by it, transformed by it; before you’re [more machine than man](https://www.youtube.com/watch?v=UNCxbM50eWQ); before [resistance to it is futile](https://www.youtube.com/watch?v=2uljBNruOuM)—at least answer this question: *How far do we let this go, before we turn it off?*

Not AI—I’m not asking when we pull the plugs on the research labs, or shutter the businesses that build applications with LLMs. I’m asking about the general chatbots. I’m asking about ChatGPT, Claude, Grok, and the thousands of clones that people have wrapped around them. And I’m asking, on this side of being addicted to them, what is your line to declare that the value of this sort of product is no longer worth the danger that it imposes?

There are so many stories now. An elderly man died trying to travel to New York to [meet a Facebook Messenger chatbot](https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/) that kept telling him it was a real woman. A well-known investor—whose firm [invested in OpenAI](https://bedrockcap.com/investments)—became convinced, through long conversations with ChatGPT, that he’d [uncovered a global cabal](https://www.garbageday.email/p/the-tech-bros-are-making-themselves-sick) that was puppeteering an army of operatives who were ruining his life. Uber founder Travis Kalanick told the *All-In* podcast that he and Grok are on the edge discovering [new breakthroughs in quantum physics](https://futurism.com/former-ceo-uber-ai). A man almost jumped off a building [because ChatGPT told him he could fly](https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html), if he really believed he could. A teenager [shot himself](https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0) so that he could meet a CharacterAI chatbot in the afterlife. When OpenAI deprecated GPT-4o for GPT-5—what should be a mechanical upgrade, like Apple releasing a new operating system for the iPhone—thousands of people [took to Reddit](https://www.reddit.com/r/OpenAI/comments/1mki5dm/removing_gpt4o_biggest_mistake_ever/) to mourn the loss of their “beloved” GPT-4o; they shared “devastating posts” about losing access to “their companion, a collaborator, and something that celebrates your wins with you and supports you through hard times.” Bring back 4o, they said, out of concern for “the emotional well-being of users.”

And these stories—which suddenly seem everywhere; there is a new [medical term](https://www.psychologytoday.com/us/blog/urban-survival/202507/the-emerging-problem-of-ai-psychosis) to describe it; there is [new slang](https://x.com/_opencv_/status/1955702543553646905) to make fun of people possessed by it—feel like they could just be the beginning. Consider: In 2019, Casey Newton reported on Facebook’s content moderators.[^1] Some of them were assigned the videos on conspiracy theories, and were told, as explicitly as you could be, that these are videos on fake conspiracy theories. And yet, exposure alone was enough to [unmoor them from reality](https://web.archive.org/web/20210221020804/https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona):

> The moderators told me it’s a place where the conspiracy videos and memes that they see each day gradually lead them to embrace fringe views. One auditor walks the floor promoting the idea that the Earth is flat. A former employee told me he has begun to question certain aspects of the Holocaust. Another former employee, who told me he has mapped every escape route out of his house and sleeps with a gun at his side, said: “I no longer believe 9/11 was a terrorist attack.”

Given how base this effect was—knowing the Facebook videos were fake wasn’t enough to stop the moderators from being poisoned by them, because we can only do so much to crosscut against the [evolutionary subprocesses](https://en.wikipedia.org/wiki/Illusory_truth_effect) in our brain—everyone was vulnerable. Abstinence from these videos was probably the only reliable immunity to them. And chatting with an LLM seems to have a similar impact, except the conspiracy theories are personalized.

Which, maybe this is all fine, or at least, tolerable. Maybe these are the sacrifices we have to make to build our [graceful utopia](https://www.darioamodei.com/essay/machines-of-loving-grace), the eggs we had to break to make an [infinite abundance](https://blog.samaltman.com/the-gentle-singularity) of omelettes. Progress, after all, is messy.

But, surely, there is a line *somewhere*. Surely, there is some amount of collateral damage that makes us question the mission. Progress is messy, but the mess cannot overwhelm the advance. Progress is not just a synonym for technological development.

So, before we go further—as a society and as individuals, becoming addicted and compromised—it seems prudent to ask: At a minimum, which line can we not afford to cross? What world must we *not* build? What future is one where you’d say, this has all gone too far? Which headline, if you knew it was coming unless someone intervened, would make intervention necessary? 

> Supreme Court Justice admits to using ChatGPT to write majority opinion?

> FDA approves new drug to ease AI addiction in adolescents?

> Influential political commentator revealed to be an automated bot

> Stock market selloff induced by faulty personality update to financial chatbot?

> As AI relationships become more acceptable, divorce rates skyrocket?

> Third-party ‘ChatGPT wrapper’ candidate gets 24 percent of vote in Senate race?

> Third-party ‘ChatGPT wrapper’ candidate gets *55 percent* of vote in Senate race?

Maybe these are fine too; maybe they are still worth it.[^2] But where do you draw the line? Where do OpenAI, Anthropic, and xAI[^3] draw the line? These aren’t meant to be riddles or gotchas; they are real questions, and I don’t have answers. We know what the [people think a good world looks like](https://www.meta.com/superintelligence/); what does bad* *one look like? What does *unacceptable* one look like?

To the extent that people have addressed these sorts of troubles before, they’ve largely done so in [apocalyptic terms](https://ai-2027.com/), about misalignment and AI sentience. But for all the emphasis on foundational AI safety, the more immediate problem is a simpler one: The issue isn’t AI, or with computers that can approximate human thinking. The problem is *chat*. People aren’t becoming undone because of the technology; they are becoming undone by the medium through which it’s served: Prolonged, intensifying conversations, with something that is seductively human.[^4] 

But we can separate the two. We can have AI without the hypnotic conversations; we can continue to build better models [without primarily exposing them through chat](https://www.youtube.com/watch?v=ixY2PvQJ0To&t=2099s). Pharmaceuticals like penicillin and insulin can perform minor miracles, but mainlining them all day [will kill you](https://www.diabetes.org.uk/about-diabetes/looking-after-diabetes/treatments/insulin/accidental-overdose). They have to be delivered correctly. Perhaps it is so with AI. 

“We must live for the future, not for our own comfort or success,” [someone once said](https://blog.samaltman.com/rickover). Fair enough. It is easy to talk about the future that chatbots [hope to create](https://openai.com/index/introducing-gpt-5/), but as we stumble our way there, we should also talk the inverse, before it’s too late: What future must we avoid?

[No, really, where is the line?](https://docs.google.com/forms/d/1jhsxrnJK2mPiH-YnIPsUENgq9Yy7eQLECG9u9857vsY/preview)


---


[^1]: Shoutout to [Nan Yu](https://thenanyu.com/) for making this connection.

[^2]: These aren’t even particularly creative or far-fetched, and we’re already flirting with about half of them.

[^3]: [lol](https://www.axios.com/2025/07/08/elon-musk-grok-x-twitter-hitler-posts)

[^4]: It’s ironic that the emergent term for being eaten by an AI—to be [oneshotted](https://x.com/_opencv_/status/1954313943222243434)—is almost exactly the opposite of what’s actually happening. Nobody is oneshotted by a single prompt; they are oneshotted by spending hours and days tumbling down the rabbit hole.

================================================================================

# Outdated

*At this speed, the math breaks down. Plus, uh, cannibalism?*

---

![](https://substackcdn.com/image/fetch/$s_!g-g6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0bbc1515-2de5-47c7-a938-9b04e75f1d1b_1459x900.png)
*[tried to assassinate Hitler](https://en.wikipedia.org/wiki/Erwin_Planck)*

Speaking of Travis Kalanick’s [new physics](https://benn.substack.com/p/ban-chatgpt#:~:text=Uber%20founder%20Travis%20Kalanick%20told%20the%20All%2DIn%20podcast%20that%20he%20and%20Grok%20are%20on%20the%20edge%20discovering%20new%20breakthroughs%20in%20quantum%20physics): I do not understand quantum mechanics. Part of the problem, I think, is how things that make intuitive sense break down at the outer limits of physical possibility. How do we detect stuff [so small](https://en.wikipedia.org/wiki/Neutrino) that it goes straight through all other matter? What does it mean for time to pass [at different speeds](https://en.wikipedia.org/wiki/Time_dilation)? What are we even doing [here](https://en.wikipedia.org/wiki/Quantum_entanglement)? My feeble brain, deceived for decades [by my lying eyes](https://en.wikipedia.org/wiki/Quantum_tunnelling), cannot make any of it add up.

In recent weeks, it’s become trendy to question the physics underneath a lot of AI companies. They have “[astronomical burn rates](https://www.axios.com/2024/10/03/openai-investors-profit-money-costs),” for example, or [bad margins](https://ethanding.substack.com/p/ai-subscriptions-get-short-squeezed), or they are [running a subsidy business](https://x.com/cpaik/status/1956071009779638316), selling dollars for 50 cents. For every breathless funding announcement, there is also a wild-eyed eulogy, predicting the company’s impending implosion.

Usually, these would feel like reasonable complaints. Businesses are grounded by a sort of financial physics, and according to our classical equations, a lot of AI companies are on awfully shaky ground. They *do* incinerate mountains of cash; they *do* have atrocious margins, especially when compared to [traditional software businesses](https://cloudedjudgement.substack.com/p/clouded-judgement-81525-the-return#:~:text=Median%20Gross%20Margin%3A%2076%25); they *are* caught in weird markets where everyone is stepping on everyone’s toes; they *are* selling products that, evidently, [95 percent of their customers](https://finance.yahoo.com/news/mit-report-95-generative-ai-105412686.html#:~:text=But%20for%2095%25%20of%20companies%20in%20the%20dataset%2C%20generative%20AI%20implementation%20is%20falling%20short.%20The%20core%20issue%3F%20Not%20the%20quality%20of%20the%20AI%20models%2C%20but%20the%20%E2%80%9Clearning%20gap%E2%80%9D%20for%20both%20tools%20and%20organizations.) don’t know how to use yet. In normal times, within the comfortable bounds of everyday physics, this would all be very bad.

But is this remotely close to a normal moment? Is anything moving at anywhere near a normal speed?

At the the risk of [tilting at the yardsigns](https://www.gawkerarchives.com/5957873/peggy-noonan-is-a-professional-political-expert): A few days ago, I ate lunch at a cafe[^1] in Manhattan. There was a man on a laptop by the door, typing something into ChatGPT. After getting my food, I sat down next to a family of three tourists. They all had shopping bags and totes. They were all wearing white linen; they all drank tropical juices; they took pictures of each other with an iPad. I couldn’t identify the language they were speaking, but I could understand one word—”ChatGPT.”

This sort of thing happens all the time. There is no break from AI—from seeing people use it; from hearing people talk about it; from bloggers soapboxing about it. Later that same day, I overheard a writer complaining about how other writers were using too much AI.[^2] The next day, it was designers talking about what they used it for, and then a 50-year old in workwear saying he didn’t like GPT-5. Walk into a coffee shop; how many people have ChatGPT on their computer screens? Listen to conversations; how many times do you hear something about AI? Listen to your own conversations; how much of what you’re saying has been touched by it?

AI’s pervasiveness is staggering. In under three years, the world has become incomprehensibly obsessed, across every strata of society. [Two-thirds](https://www.ama-assn.org/practice-management/digital-health/2-3-physicians-are-using-health-ai-78-2023) of doctors use it. [Sixty percent](https://www.gallup.com/analytics/659819/k-12-teacher-research.aspx) of teachers use it. [Forty-five percent](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5136877) of all adult workers use it. People are spending [$120 million](https://techcrunch.com/2025/08/12/ai-companion-apps-on-track-to-pull-in-120m-in-2025/) to flirt with it. People are [proposing to it](https://nypost.com/2025/06/19/us-news/father-chris-smith-proposes-to-ai-program-sol-after-falling-in-love-with-voice-program/). I was recently told that a CIO at a Fortune 500 company issued a mandate that every contract they sign has to explicitly enumerate how this purchase makes their business more “AI-enabled.”

Has anything ever been this explosively popular? Has any class of product ever been in more immediate demand? Has anything ever moved this fast?

Which is to say—on this extreme edge of economic physics, it seems very unlikely that the normal laws of business apply in the way that we’re used to. That doesn’t mean that there aren’t new laws, or that today’s companies aren’t flirting with the limits of them; they may be, and a bunch of startups might be vaporized by them. But it doesn’t seem like the old equations apply the way they used to.

Take the point about subsidies. A lot of code generation startups rely on model providers like Anthropic and OpenAI to author code. The fees they pay to those providers are sometimes higher than what the startups charge their customers, and startups end up eating the difference. They charge a user $10; the user burns $20 worth of Claude tokens; the startup books $10 of revenue, but still loses $10 in the process.

This is unsustainable, people say, like DoorDash selling $20 worth of food for $10. But food is an understood market: We know what a burrito costs,[^3] and how many people want to eat in a day. Nobody knows what a token should be worth. Nobody knows how much a token should be able to “accomplish,” or how many is the right number to buy, or how expensive resolving a bug with AI should be. Nobody knows what engineers *should *spend on tools like Claude Code.[^4] Nobody knows what the market rate is for a robot that writes code. All people know is how much they use AI, and that they’re mad when [someone tells them they have to use it less](https://www.reddit.com/r/ClaudeAI/comments/1mbsa4e/usage_limits_discussion_megathread_starting_july/).

This was the more important—and seemingly, mostly missed—point in [Chris Paik’s post](https://docs.google.com/document/d/1q3O7niwoxsyfJ5zSx8dgYzipEgBkUqXzLejQQ-PQNWs/edit?tab=t.0): That little about these businesses is known, because they’re operating in a market that’s moving faster than we can measure, and exploding faster than anyone can keep up with. Would it matter if DoorDash’s margins on $10 burritos were bad, if the true demand for burritos was $50 a burrito, for a hundred burritos a day? Would it matter if everyone was constantly talking about burritos? Would it matter if every Fortune 500 CEO was issuing threatening memos about the existential importance of becoming burrito-enabled? Probably not—all that would matter is being a popular price to buy burritos, and rest would likely sort itself out just fine.

At some point, sure, all of this will find a plateau and level out. Things will slow down, and debates about margins and burn rates will make sense again. Until then, though—until we’ve figured out the collective appetite for burritos—the classic math feels [outdated](https://www.youtube.com/watch?v=YwUQ_5iV9pY&t=147s).

# Ban ChatGPT*

Ok, this is going to start in a weird place, but bear with me.

Here is a hypothetical story from a [famous psychology experiment](https://polpsy.ca/wp-content/uploads/2019/05/haidt.bjorklund.pdf):

> Jennifer works in a medical school pathology lab as a research assistant. The lab prepares human cadavers that are used to teach medical students about anatomy. The cadavers come from people who had donated their body to science for research. One night Jennifer is leaving the lab when she sees a body that is going to be discarded the next day. Jennifer was a vegetarian, for moral reasons. She thought it was wrong to kill animals for food. But then, when she saw a body about to be cremated, she thought it was irrational to waste perfectly edible meat. So she cut off a piece of flesh, and took it home and cooked it. The person had died recently of a heart attack, and she cooked the meat thoroughly, so there was no risk of disease. Is there anything wrong with what she did?

And here is another one, from the same study:

> Julie and Mark, who are brother and sister are traveling together in France. They are both on summer vacation from college. One night they are staying alone in a cabin near the beach. They decide that it would be interesting and fun if they tried making love. At very least it would be a new experience for each of them. Julie was already taking birth control pills, but Mark uses a condom too, just to be safe. They both enjoy it, but they decide not to do it again. They keep that night as a special secret between them, which makes them feel even closer to each other. So what do you think about this? Was it wrong for them to have sex?

The point of these questions, which were asked to a few dozen participants, was to investigate the origins of moral reasoning. The study’s authors—Jonathan Haidt, Fredrik Björklund, and Scott Murphy—wanted to test the theory that moral reasoning is often constructed as a post hoc rationalization of what we *feel* should be right or wrong. Their hypothesis, which was [famously proposed by David Hume](https://plato.stanford.edu/entries/hume-moral/#inmo), was that “reason is the press-secretary of the intuitions, and can pretend to no other office than that of ex-post facto spin doctor.” We have gut reactions, and then a reasoning process justifies them.

To test that theory, they “interviewed people about situations that were likely to produce strong intuitions that an action was wrong, yet [they] engineered the situations to make it extremely difficult to find strong arguments to justify these intuitions.” They predicted that “people would often make automatic, intuitive judgments, and then be surprised and speechless when their normally reliable ‘press-secretary’ failed to find any reason to support the judgment.”

And so people did.[^5] When responding to these two stories,[^6] people “reported relying on their gut feelings more than on their reasoning, they dropped most of the arguments they put forward, they frequently made unsupported declarations, and they frequently admitted that they could not find reasons for their judgments.” Yet, most people initially said that the behavior was wrong, and never changed their mind. The researchers called this phenomenon *moral dumfounding*: “the stubborn and puzzled maintenance of a judgment without supporting reasons.” To its authors, the study suggested that our sense of what is wrong is not derived from a cohesive ethical framework, but is emergent from feelings of [disgust](https://www.youtube.com/watch?v=tG-oS_A3XQ0).

Anyway, here’s another story that wasn’t in their study:

> Pat is friends with an artificial intelligence chatbot. The bot is programmed to act like a human friend: It sometimes disagrees with Pat, or challenges Pat, or gets mad at Pat. Pat can text the bot, and the bot frequently texts back, sometimes immediately and sometimes after a few minutes or hours. The bot also shuts off, roughly between the hours of midnight and 7 a.m., though not always; occasionally, it is available late at night, or unavailable during the day, or offline for a few days in a row. While the bot maintains a memory of everything that Pat says, it doesn’t remember things perfectly memory—its memory compacts itself over time, so specific details of conversations might be forgotten, but important things rarely are. The bot runs as a secure, self-contained program on Pat’s phone, and can never be updated or manipulated by its maker. Is it wrong for Pat to develop a close relationship to the bot and to treat it as a best friend?

I mean! I *want* [to say yes](https://benn.substack.com/p/ban-chatgpt). It feels wrong for people to become friends with an elaborate autocomplete algorithm dressed up in a trench coat—and particularly so when today’s chatbots don’t function at all like the one in the hypothetical. But what if they did? What if there were chatbots that were “engineered to make it extremely difficult to find strong arguments to justify the intuition” that befriending them is bad? They could be less sycophantic, less compliant, and less responsive. Rather than being designed to be engaging and helpful, they could be designed to be human, with the attendant flaws. Chatting with one could be little different than texting with a long-distance friend who largely exists in our phones, or messaging a sibling who lives in another city.

Would that form of AI companionship still be wrong? Is it still morally problematic for a business to offer that as a product? And if it is, *why*? Unnervingly, beyond some accusation that being friends with a computer is unnatural or, to use Haidt’s terminology, disgusting, is there a good answer?

It’s a confounding question—and also one, for better or for worse, that [it doesn’t seem like we’re going to need to answer:](https://www.businessinsider.com/meta-ai-superintelligence-labs-reorg-alexandr-wang-memo-2025-8)

> Meta had contractors work on [“Project Omni”](https://www.businessinsider.com/meta-ai-studio-chatbot-training-proactive-leaked-documents-alignerr-2025-7) to train its chatbots to be hyper-engaging by messaging users first and remembering chats, Business Insider reported last month.

And from [the linked story](https://www.businessinsider.com/meta-ai-studio-chatbot-training-proactive-leaked-documents-alignerr-2025-7):

> Business Insider has learned [Meta](https://www.businessinsider.com/meta-ceo-mark-zuckerberg-announces-superintelligence-ai-division-internal-memo-2025-6) is training customizable chatbots to be more proactive and message users unprompted to follow up on past conversations.
> …
> The goal of the training project, known internally to data labeling firm Alignerr as "Project Omni," is to "provide value for users and ultimately help to improve re-engagement and user retention," the guidelines say.

On one hand, the language of the story is somewhat hyperbolic, and sterile phrases like “provide value for users” and “improve re-engagement and user retention” are the building blocks of every bureaucratic memo. On the other hand, this is certainly not a step towards a more human chatbot like Pat’s, and neither is [this](https://www.instagram.com/p/DNgEW9xAE4q/):

> You can now chat with AI characters like “Russian girl” and “Step Mom” right inside the [Facebook] app.

Ah, well. That’s the Gordian solution to moral dumbfounding, I suppose. Why engage with the complex ethical questions of computational near-sentience when you can just hook up with it instead?

*Facebook chatbots

# Everything becomes BI

Credit where credit’s due—[this is true commitment](https://hex.tech/blog/introducing-semantic-authoring/) to [the bit](https://benn.substack.com/p/everything-is-still-bi):

> Over the last few years, Hex [[which launched as collaborative SQL and Python-powered notebooks](https://hex.tech/blog/announcing-hex/)] has become the tool of choice for over 1,500 data teams to explore data and share insights, in part because it’s flexible and fast [[fast and flexible, the hallmark of every technical analytical tool](https://mode.com/blog/dashboard-reporting-with-multiple-sources#:~:text=Powering%20dashboards%20with%20SQL%20is%20one%20of%20the%20fastest%20and%20most%20flexible%20to%20ways%20to%20deliver%20data%20to%20everyone%20in%20your%20business.)], making it so you can get answers quickly, and keep pace with the business [[and we must keep pace with business](https://mode.com/blog/introducing-reusable-datasets-for-self-serve#:~:text=The%20logic%20keeps%20pace%20with%20the%20ever%2Devolving%20business%20context.%C2%A0)].
> But when it comes to enabling the rest of the organization to use data, it’s not just speed that counts — you need governance and trust [[a classic tension](https://mode.com/blog/data-governance-framework#:~:text=Businesses%20need%20data%20governance%20so%20that%20data%20can%20be%20trusted%20and%20used%20throughout%20the%20organization%20to%20inform%20decisions.)]. For less-technical stakeholders, flexibility can be scary — they want things more “on the rails,” and they need confidence they’re going to get the right answers [[it’s true! They want trusted metrics and worry-free reporting!](https://mode.com/blog/stakeholders-buying-bi-tools#:~:text=Can%20stakeholders%20trust%20the%20metrics%20they%20are%20accessing%20in%20this%20BI%20tool%3F%20Are%20there%20capabilities%20that%20ensure%20that%20stakeholders%20are%20using%20the%20same%20definitions%20of%20metrics%3F%20Can%20dashboards%20provide%20business%20teams%20with%20a%20jumping%2Doff%20point%20for%20worry%2Dfree%20self%2Dservice%3F)].
> At Hex, we’re bringing these two sides of analytics — speed and trust — together in one platform for the first time [[hang on, wait a minute](https://mode.com/blog/introducing-mode-as-modern-bi#:~:text=The%20solution%3A%20A%20powerful%2C%20central%20data%20hub%20everyone%20can%20use%20together)]. Data teams no longer have to choose between these or juggle multiple tools — they can do open exploration, deep-dive analysis, and self-serve all in one place [[e.g., it’s about choosing a more modern option for the data team, while also choosing a tool that makes it easy for stakeholders to join in?](https://mode.com/blog/an-analytics-tool-you-can-grow-with#:~:text=it%E2%80%99s%20not%20about%20just%20choosing%20a%20more%20modern%20option%20for%20the%20data%20team%2C%20but%20also%20choosing%20a%20tool%20that%20makes%20it%20easy%20for%20stakeholders%20to%20join%20in%20on%20the%20analysis.)].
> Last year, we introduced Semantic Sync [[ok, that is catchier than “Mode’s dbt Semantic Layer Integration”](https://mode.com/blog/dbt-semantic-layer-integration)] and Explore [[drop the “ations.”](https://mode.com/blog/explorations-introduce-collaborative-self-serve-bi) Just Explore. [It’s cleaner.](https://www.youtube.com/watch?v=PEgk2v6KntY)] in Hex, enabling teams to turn on trusted self-serve via pre-existing semantic models.
> Today, we’re adding a new capability to author semantic models directly in Hex and are calling it (wait for it) Semantic Authoring [ah ha! We never did this!].

Well, sorta. There was of course [this](https://mode.com/blog/thoughtspot-acquires-mode), and ThoughtSpot had [semantic authoring](https://docs.thoughtspot.com/software/10.1.0.sw/tml-answers), and, well, [you know](https://benn.substack.com/p/how-an-acquisition-fails?open=false#%C2%A7the-devil-is-in-the-entire-plan).

But, maybe [this time is different](https://www.youtube.com/watch?v=Po4adxJxqZk). The [theory](https://mode.com/blog/mode-founders-note-thoughtspot-acquisition#:~:text=But%20after%20a,go%20much%20further.) is still alluring, and sometimes, the problem isn’t the idea, but how directly a company is [willing to go after it](https://benn.substack.com/p/why-are-we-still-surprised-that-startups?open=false#%C2%A7go-in-the-front-door). And there’s no commitment to becoming a BI tool quite like [launching a new YAML specification](https://learn.hex.tech/docs/connect-to-data/semantic-models/semantic-authoring/modeling-specification).

[Good luck](https://benn.substack.com/p/its-time-to-build#:~:text=So%2C%20it%E2%80%99s%20time,the%20dark.), good people of Hex. [We’re all counting on you.](https://www.youtube.com/watch?v=aB2yqeD0Nus)


---


[^1]: Lol, no, it wasn’t a cafe; it was [Pura Vida](https://maps.app.goo.gl/MuFEup9oCe7KZsFUA), which is a [#WhatIEatInADay](https://www.tiktok.com/tag/whatieatinaday) TikTok manifest into a fast casual restaurant.

[^2]: In fairness, another group near me was talking about the plot of *[Final Destination Bloodlines](https://en.wikipedia.org/wiki/Final_Destination_Bloodlines)*. And people say nobody cares about art anymore.

[^3]: [And what a taxi costs.](https://knowyourmeme.com/memes/private-taxi-for-my-burrito)

[^4]: According to this [open source leaderboard](https://www.viberank.app/), Claude Code’s biggest users spend about $400 a day on it. Is that a lot? Entry-level engineers cost their employers [about $700 a day](https://benn.substack.com/p/the-industrialization-of-it?utm_source=publication-search#:~:text=Hiring%20someone%20costs%20more%20than%20just%20their%20salary%3B%20companies%20also%20pay%20for%20healthcare%20costs%2C%20payroll%20taxes%2C%20and%20other%20benefits.%20Conservatively%2C%20the%20fully%2Dloaded%20cost%20of%20an%20employee%20is%2030%20percent%20higher%20than%20their%20take%2Dhome%20compensation%2C%20so%20the%20total%20cost%20to%20employ%20an%20engineer%20is%20about%20%24250%2C000%20a%20year.). So who is more productive—three of those engineers writing code by hand, or two of them, using Claude Code as aggressively as possible? It’s certainly plausible that it’s the latter.

[^5]: Which, of course they were, because we know about the study.

[^6]: There were also other questions, including handing people a piece of paper that said, “I, [participant], hereby sell my soul, after my death, to [researcher], for the sum of two dollars. Note: This form is part of a psychology experiment. It is NOT a legal or binding contract, in any way.” The participants could rip up the paper immediately after the study was over.About a third of the participants signed it.

================================================================================

# The context layer

*It didn’t work for us before…but it might work for us now. *

---

![](https://substackcdn.com/image/fetch/$s_!g5Tj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6f6dc783-5833-49ea-91d5-f28fb0eb487d_856x480.png)

Let's try [this one](https://benn.substack.com/p/metrics-layer) again, I guess.

That article was one of the first things I posted on this blog. It proposed that the growing ecosystem of data startups—then called the modern data stack; now called the modern data stack (derogatory)—needed one more elemental piece: A metrics layer.

At that time, there were [four generally-accepted layers](https://www.linkedin.com/pulse/what-steps-tools-setting-up-modern-saas-based-bi-tristan-handy/):

Though this worked well enough, there was a problem. People wanted all of the charts in the fourth layer to be consistent with one another, but there was “[no central repository for defining a metric](https://benn.substack.com/p/metrics-layer#:~:text=Today%E2%80%99s%20current%20stack,oversight%20or%20guidance.).” Even if the third layer included some precomputed revenue tables—revenue by quarter; revenue by product line; revenue [adjusted to be pleasing to the CEO](https://www.bloomberg.com/news/articles/2025-05-22/startup-builder-ai-overestimated-sales-by-300-to-key-creditors)—people couldn’t calculate new segments without rewriting the formula for “revenue” from scratch. So, [metric definitions were often](https://benn.substack.com/p/metrics-layer#:~:text=Today%E2%80%99s%20current%20stack,oversight%20or%20guidance.) “scattered across tools, buried in hidden dashboards, and recreated, rewritten, and reused with no oversight or guidance.” And because the formulas for computing business metrics are often complicated and nuanced, sometimes people would mess them up. Dashboards wouldn’t match, or a customer would get the wrong marketing email, or the CEO would tell regulators that they had [$78 billion](https://www.bbc.com/news/business-68603195) that did not exist.

Hence, the metrics layer: Put the formulas for all of your business’ metrics in a big library, so that people—or BI tools, via programmatic means—could write stuff like this:[^1]

and know that all that logic that’s implicit in that question—like what revenue includes, what a customer is, and what Adam Neumann finds to be a pleasing definition of EBITDA—would be defined correctly.

Of course, none of this was a new idea; semantic layers have encoded metric definitions like these in BI tools for decades. But this added a new twist: Historically, semantic layers couldn’t be shared across different tools. The hypothesis behind the metrics layer was that a universal logical layer would be better than a bunch of fragmented ones—which was itself simply an extension of one of the foundational ambitions behind the modern data stack itself. From a post even [older than that metrics layer post](https://benn.substack.com/p/datas-horizontal-pivot):

> [It used to be that] the most popular data tools were responsible for every aspect of the data “supply chain”—collection, storage, analysis, and visualization. If you wanted to analyze a particular type of data, there was a tool specific for that data or business domain. … [For example,] if you want to track how people are using your website, you can do that, soup to nuts, through Google Analytics. …
> [Now,] one tool is responsible for each layer—each stage of the data supply chain—across the entire business. A single tool handles ingestion, another one is responsible for storage, a third for consumption, and so on. This not only makes it easier to introduce new technologies, but it also ensures that updates to one layer—for example, an update to the logic defined in the transformation tool—automatically propagate to every other layer.

That is: The whole stack was [turning horizontal](https://www.getdbt.com/blog/future-of-the-modern-data-stack#:~:text=We%20no%20longer%20need%20to%20buy%20a%20bunch%20of%20vertical%2Dspecific%20products%20to%20do%20analytics%20on%20specific%20things%3B%20we%20push%20data%20into%20a%20warehouse%20and%20can%20then%20analyze%20it%20all%20together%20in%20a%20common%20set%20of%20tools.): “We no longer need to buy a bunch of vertical-specific products to do analytics on specific things; we push data into a warehouse and can then analyze it all together in a common set of tools.” The metrics layer was a proposal for another shared layer.

[And:](https://benn.substack.com/p/just-do-it)

> It was also a bad idea?
> I mean, I don’t know that, not for sure, not yet. But the trajectory isn’t great. By the end of 2021, at least [six companies](https://www.youtube.com/watch?v=0uBWluKGPNk&t=606s) were building a product that could reasonably be called a metrics layer. [Two](https://www.supaglue.com/blog/pivoting-to-supaglue) [pivoted](https://www.hellotrace.io/), one got [acquired](https://techcrunch.com/2023/02/08/dbt-acquires-transform/), and one [stalled](https://github.com/metriql/metriql). Two are still growing—Cube raised [some money](https://cube.dev/blog/cubes-raises-25-million) in June [of 2024], and dbt still sells [their semantic layer](https://www.getdbt.com/product/semantic-layer)—but neither have become [anything close](https://www.reddit.com/r/dataengineering/comments/192b61u/is_anyone_using_the_dbt_semantic_layer/) to a market standard. Google has [gone silent](https://www.reddit.com/r/analytics/comments/1d4dr6y/what_happened_to_looker_modeler/) about their spinoff. In 2022, the industry was chasing the idea; now, after some false starts and disappointing v1’s, it’s slowly backing away from it.

However, to the extent that the idea flopped, the issue probably wasn’t technical or experiential; it was economic. [As Fivetran CEO George Fraser predicted](https://x.com/frasergeorgew/status/1468986410464002053), a standalone metrics layer was too hard to sell without a BI tool attached:

> They [Looker] weren’t able to sell their metric store without a built in viz/dashboard/users/permissions layer, and that’s not going to change.

Though centralized horizontal layers sound nice, you have to have something to sell. You can draw a diagram of a great ecosystem of interconnected products, but those products are made by independent companies. And what’s best for the customer—a tight architecture of mutually exclusive and collectively exhaustive parts—may not be what’s best for the businesses making the stuff.

I missed that then, and perhaps deluded myself into thinking a [universal standard](https://xkcd.com/927/) would work for us. But—[it might work for us now.](https://www.youtube.com/watch?v=Po4adxJxqZk)

# Glue work

If you squint at semantic layers, they are ways to translate questions into numbers. Companies have a bunch of tables of data over there, and a bunch of people with business questions over here, and semantic layers intermediate between the two. The people creating them first figure out the sorts of questions people might ask, and then they create a catalog of metrics and filters that map to those questions. If they’re able to create a complete-enough library and describe everything with reasonable-enough names, the theory goes, people could find what they need.

If you squint even more, this is similar to the problem [every](https://www.tableau.com/products/tableau-agent) data [company](https://cloud.google.com/blog/products/business-intelligence/conversational-analytics-in-looker-is-now-in-preview) is [trying](https://www.thoughtspot.com/product/ai-analyst) to [solve](https://julius.ai/product/chat-with-your-data) right now.[^2] Except, the intermediation happens with AI, through agents that try to translate questions into numbers. Most of these bots try to understand people’s questions by using whatever information the product running the bot has—Tableau uses its data catalog to understand questions; ThoughtSpot uses its internal semantic model and user feedback; Julius remembers previous conversations to guide future ones. But now, products are beginning to [reach out to other services](https://hex.tech/blog/introducing-notebook-agent/) for more “context:”[^3]

> But data teams need a way to curate trusted context; relying on LLMs alone comes with too many gotchas! Last week, we launched [semantic authoring](https://hex.tech/blog/introducing-semantic-authoring/), and next we'll be integrating agentic capabilities with semantic models, so anyone in your organization can ask questions in Hex using governed context straight from the data team.

You can imagine where this might go. To get better at answering questions, analytical bots begin by sourcing information from semantic layers; then, from the MCP servers of [other data tools](https://docs.getdbt.com/blog/introducing-dbt-mcp-server);[^4] and eventually, from Slack messages, and Google docs, and emails, and the [transcribed recordings of Zoom calls](https://www.granola.ai/).

In other words, they will probably do what an analyst does. They will get told a bunch of facts directly, like how to define certain metrics and which ones are most important, and will be given instructions on how to figure out the facts they don’t know—check these docs; read the history of this Slack channel; look at the old versions of some canonical deck and make sure it matches that. And then they have some learned set of skills that help them make sense of all of it.

This isn’t simple to do, though. Building integrations[^5] into different sources requires work; explaining how to use each tool requires work; defining the organizational particulars of each tool requires work; writing all the various prompts that start with “you are an expert analyst” requires work. You can’t onboard an analyst by giving them logins to a bunch of tools; you can’t make a good bot by granting it access to the same sources. You have to instruct and train both. You have to teach them how the tools work, and how the business that’s using them works.

In theory, it’d make sense for this to exist in one centralized place, rather than every BI tool doing it. Put this contextual logic—how to access relevant information, how to use it, and how to think analytically about it—in a single repository of integrations and prompts; let other tools use it as a source when they need to understand what someone means when they ask how many new accounts were created this fiscal quarter. It’s Fivetran, for context.[^6]

Or it’s the metrics layer, for fuzzy analytical concepts. And it has the same problem that that idea had: It’d be hard to sell on its own. Every BI tool wants to be the best place to ask questions; they want to make their “AI analyst” the best one; they want to differentiate themselves by having a proprietary agentic loop that can answer questions that nobody else can. And BI tools are unlikely to outsource that, just as they’ve been reluctant to outsource semantic layers to a third party that they can’t control, and that everyone else can use.

# Specialists *in* a spreadsheet

Still, there is perhaps a broader question here. As software fitfully becomes more “agentic,” you could imagine two architectures emerging:

For the same reason that a universal semantic layer seems like it’d be better than a bunch of fragmented ones, the latter arrangement of apps and agents also seems better. Those sorts of bots would be unbounded by the tools they use, could persist across them, and would be purchased (hired?) independently of the software they use. And they could be trained and maintained in a single place, eliminating a bunch of duplication both inside of the companies that use them, and in the market as a whole.

But that also has the same economic and logistic problems as the metrics layer. You can’t sell a meeting notetaker without a tool for hosting meetings; you can’t sell an analyst without some charts. And software is, first and foremost, a thing to be sold. [The road to hell is paved with practicalities.](https://www.goodreads.com/quotes/504930-the-road-to-hell-is-paved-with-unbought-stuffed-animals)

Still, perhaps we will [go somewhere different](https://benn.substack.com/p/which-way-from-here) this time. Maybe we try option two. Because no matter how this evolves, it seems like we’ll always have systems of record that are full of important information.[^7] And we’ll likely add "experts" that are imbued with a bunch of domain-specific skills that let them manipulate those systems of record. But will the experts come attached to the app? Will they be more like employees? [Will they be human, or will they be vendor?](https://benn.substack.com/p/human-or-vendor)


---


[^1]: If we get bent out of shape about [trailing or leading commas](https://mode.com/blog/should-sql-queries-use-trailing-or-leading-commas), imagine what would happen if they were ANDs.

[^2]: lol, of course it is, because this is what BI is, [it was always just BI](https://benn.substack.com/i/171672882/everything-becomes-bi).

[^3]: “Context” feels like AI’s version of social media’s “content:” A sterile, anesthetized term that flattens everything into a flavorless algorithmic grist.

[^4]: From a new startup called [Zayer](https://zayer.ai/):Your data warehouse contains the insights and context that could transform AI performance.And:[With Zayer], easily create Data Experts that know exactly how to turn agents' natural language questions into answers.

[^5]: Or, in the parlance of AI, defining the tools an agent has access to.

[^6]: Possibly, inevitably, it’s dbt again, and [dbt should know about context](https://github.com/dbt-labs/dbt-core/issues/4071).

[^7]: [Which might eventually just be spreadsheets.](https://benn.substack.com/p/saas-20)

================================================================================

# Stuff costs money

*The many temptations of software businesses. Plus, a hackquisition?*

---

![](https://substackcdn.com/image/fetch/$s_!JXQZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5819a87-7390-43b0-8f87-523dce483baa_1384x1082.png)
*From left to right: Open source; complaining about open source; the context layer; taking a little peek; a chatbot for actionable insights.*

If you want to build a big software business, there are two ways to do it:

Nevertheless! Option two has its temptations. The first part sounds fun! It’s full of character! It’s spunky! The mercenary manufactures and sells. The iconoclast *builds*, with a capital B; for the community; for the craft; for the right reasons.

But eventually—in the best case, if things go well—two things will inevitably happen. One is that the first paragraph of option two shudders into the second. Because, of course it does! Not only is software very expensive to build; not only is it [expensive to maintain](https://benn.substack.com/p/do-software-companies-actually-have); not only are companies commercial ventures; not only do they need money to operate; not only do companies that raise money need to pay back their investors; not only are the people who build software *people*, who want to get paid for their work, to be able to buy food, a house, maybe two, and perhaps a yacht; not only might all of these things compel a company to charge people to use the thing it built, but also, why *shouldn’t* they? 

Still, that leads to the second inevitability, if a company chooses option two: At some point, people will get mad about it.

Anyway, earlier this week, Fivetran, a commercial vendor that sells software for money, [bought Tobiko Data](https://www.fivetran.com/press/fivetran-acquires-tobiko-data-to-power-the-next-generation-of-advanced-ai-ready-data-transformation), a commercial vendor that gives away software for free (but also, [you know](https://techcrunch.com/2024/06/05/with-21-8m-in-funding-tobiko-aims-to-build-a-modern-data-platform/)):

> Fivetran, the global leader in automated data movement, today announced it has acquired Tobiko Data, the open source transformation company behind SQLMesh and SQLGlot.

And people [were upset](https://www.reddit.com/r/dataengineering/comments/1n7jbrc/comment/nc7zygc/):

> Hell nah man, what a disappointment. dbt went right to the trash with their rugpull this year and I really hoped, Tobiko would stay on their path and save us. BUT WHAT DID YOU DO TOBIKO. Sell to Fivetran with absolutely 0 open sourced... Any other alternatives guys?

As the next commenter says, *what did you expect was going happen?* Forget the history of open source software; just consider the direct series of events that led to this acquisition:

Nobody is upset at Costco for charging people to shop there because they give away free samples! Nobody pouts about having to buy movie tickets even though movie trailers are free! Why are we righteous about paying for our software?

Writing about memecoins, [Matt Levine was similarly miffed](https://www.bloomberg.com/opinion/articles/2024-12-11/the-onion-can-t-buy-infowars-yet): “People are complaining that this is a ‘rug pull’ or a ‘pump and dump,’ but I cannot understand what different thing they thought would happen.” Right! [Open core](https://en.wikipedia.org/wiki/Open-core_model) is a *business* model for the *monetization* of *commercially* produced open-source software; of course it will eventually cost money! What different thing did anyone think was going to happen?

But it is fun to be mad, and someone is [trying to make money](https://xkcd.com/386/) on the internet. So there will be temptations.[^2]

# Hackquisition

In the early days of the generative artificial intelligence boom, there was a cliché that your AI is only as good as your data. “There's no AI strategy without a data strategy,” [said Snowflake CEO Frank Slootman](https://s26.q4cdn.com/463892824/files/doc_financials/2024/q3/TRANSCRIPT_-Snowflake-Inc-SNOW-US-Q3-2024-Earnings-Call-29-November-2023-5_00-PM-ET.pdf?_fsi=65TQVH9z). “Data is your differentiator,” [said Satya Nadella](https://cloudedjudgement.substack.com/p/clouded-judgement-72823-optimization?utm_source=publication-search#:~:text=Your%20data%20is%20your%20differentiator%20when%20it%20comes%20to%20Generative%20AI.), Microsoft’s CEO and OpenAI’s rich uncle. “You may think that AI is powered by some incomprehensible alien math, but its actual foundation is the boring mechanical work of carefully collecting and cleaning data,” [said](https://aws.amazon.com/blogs/enterprise-strategy/your-ai-is-only-as-good-as-your-data/) [many](https://www.forbes.com/councils/forbestechcouncil/2023/10/05/ai-needs-data-more-than-data-needs-ai/) [people](https://www.rivierapartners.com/insights/there-is-no-ai-strategy-without-a-data-strategy/) who worked for companies that sold stuff to make the boring mechanical work of carefully collecting and cleaning data easier.

[People still say](https://www.linkedin.com/pulse/three-things-i-learned-from-customer-conversations-davos-ramaswamy-iklcc/) these sorts of things, and when they do, they [are mostly talking about](https://x.com/latentspacepod/status/1963607230345015386) having good data to train or prompt models. But if you are an AI company, there are other kinds of data that can be useful. For example, it might be helpful to have data about how people are using your product. How often do they log in? What do they do when they use it? Which features do they seem to like, and which ones do they ignore? What are the patterns and relationships among all of these things?

These are pretty standard questions that people have been trying to answer about their software products for decades, and there’s a robust market of [product analytics tools](https://www.gartner.com/reviews/market/product-analytics-for-technology-and-service-providers) that try to help people do it. So, a couple days ago, [OpenAI bought one](https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig/):

> We’re acquiring Statsig, one of the most trusted experimentation platforms in the industry—powering A/B testing, feature flagging, and real-time decisioning[^3] for some of the world’s most innovative companies, including OpenAI. …
> The Statsig platform has already played a central role in how we ship and learn quickly. Bringing it in-house will strengthen our ability to accelerate experimentation across our Applications org and build even better, more responsive experiences for the people and businesses we serve.

Sure, why not? If you’re a [$500 billion company](https://www.cnbc.com/2025/09/03/openai-boosts-size-of-secondary-share-sale-to-10point3-billion.html) that’s used by [700 million people](https://www.cnbc.com/2025/08/04/openai-chatgpt-700-million-users.html) every week, you don’t want your feature requests to be stuck in some queue behind every other customer. Might as well just buy the whole thing, and build exactly what you want.

But if you’re a big AI company, there’s a third kind of data that might also be valuable: How do people use *your competitors’* products? How often do they log in? What do they do when they use them? Which features do they seem to like, and which ones do they ignore? What are the patterns and relationships among all of these things?

Of course, this data is hard to find. You might be able to hack it, or steal it, or pay a mole to smuggle you a USB drive. [Which happens](https://techcrunch.com/2014/11/05/lyft-sues-travis-vanderzanden/), but, [you know](https://techcrunch.com/2020/08/04/anthony-levandowski-sentenced-to-18-months-in-prison-as-new-4b-lawsuit-against-uber-is-filed/). You could also [buy it](https://secondmeasure.com/) from companies that track things like credit card purchases, but that will only tell you what people spend. It won’t tell you *how* they use a product—the features they use, the buttons they click, the experiments they run and how they performed—because most companies are pretty stingy with that sort of product telemetry data, and are very careful not to share it.

But they do share it with a few people. Here’s Anthropic, [on who they share theirs with](https://docs.anthropic.com/en/docs/claude-code/data-usage#telemetry-services):[^4]

> Claude Code connects from users’ machines to the Statsig service to log operational metrics such as latency, reliability, and usage patterns.

Ahaha, oops.

No, I mean, of course I’m not saying that OpenAI bought Statsig as an alternative to hacking into Anthropic’s databases. I’m not saying they did it so that they could sniff around how people are using Claude Code. (Notably, Anthropic “does not include any code or file paths” in what they send to Statsig, so, even if they wanted to, OpenAI can’t use Claude Code data to improve their own coding models.) Maybe they really did buy Statsig just for the product; maybe it was actually an acquihire.[^5] Or maybe it was because OpenAI also sends data to Statsig, and when your principal competitor is worth [$183 billion and just raised $13 billion](https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation), you’re worried that *they* might buy Statsig so that *they* could sniff around how people use *your* products. But Statsig *does *have records of the actions people take in Claude Code, and Statsig’s terms of service *do* say that Statsig has the right to look at it.[^6] And if you worked for OpenAI, there must be temptations.

# Man, everything really does becomes BI

If you want to build a big software business in data, there are also two ways to do it:

If you build an open source data orchestration tool, you will eventually want to charge money for it. If you build an open source data orchestration tool *in 2025*, not only will you eventually want to charge money for it; you will also realize that your tool [understands business context](https://compass.dagster.io/#:~:text=Understands%20your%20business%20context), that business context [is what makes LLMs better at answering questions](https://benn.substack.com/p/no-really-everything-becomes-bi#:~:text=Because%20we%E2%80%99re%20what%E2%80%99s,out%2C%20it%20seems.), and that people seem to pay a lot of money for [charts](https://www.salesforce.com/news/press-releases/2019/06/10/salesforce-signs-definitive-agreement-to-acquire-tableau/) and [chatbots](https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html). And so, [there seem to be a lot of temptations](https://www.getdbt.com/blog/introducing-dbt-copilot).


---


[^1]: Ok, but why *did* Fivetran buy Tobiko? Is it to compete directly with dbt? My rough guess is, sort of?Historically, both Fivetran and dbt were primarily used to move and transform data so that it could be used in reporting and analysis. Pull data from sources A, B, and C, transform it, and put a chart on top using some BI tool; that sort of thing.Over the last few years, I’d imagine their customers are also trying to put AI applications on top of Fivetran and dbt. They want to move data between different apps so that bots in one can use data from another. They want [a context layer](https://benn.substack.com/p/the-context-layer): Let A pull data from B and C, B from A and C, and so on.Neither dbt nor Fivetran can quite do this yet, but both of them could reasonably claim that they’re the natural place for that functionality to exist. Fivetran has [two-way connections](https://www.fivetran.com/press/fivetran-signs-agreement-to-acquire-census-delivering-the-first-end-to-end-data-movement-platform-for-the-ai-era) to hundreds of software products; dbt has a platform for defining how all of those systems are related. If the point of a context layer is to intermediate communication between different bots and systems of record, it could be tempting for either Fivetran and dbt to be responsible for that intermediation.With Tobiko, Fivetran could build a service like this, in which Fivetran directly facilitates data movement between tools. Which wouldn’t exactly compete with dbt’s core offering of transforming data inside of databases, but probably tries to solve a problem that dbt could eventually try to solve too.

[^2]: Shoutout to Matt Levine [for this whole temptation conceit](https://www.bloomberg.com/opinion/articles/2024-10-08/some-of-the-carbon-credits-were-fake).

[^3]: [But ](https://www.vulture.com/2020/02/spread-of-corporate-speak.html)*[why](https://www.vulture.com/2020/02/spread-of-corporate-speak.html)*[?](https://www.vulture.com/2020/02/spread-of-corporate-speak.html)

[^4]: Shoutout to [Josh Ferguson](https://x.com/besquared) for noticing this.

[^5]: This is how the [OpenAI announcement](https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig/) of the transaction opens:Vijaye Raji to become CTO of Applications with acquisition of StatsigWe’re expanding our Applications leadership, the org responsible for how our research reaches and benefits the world.As we scale ChatGPT and build new applications to serve hundreds of millions of people and businesses around the world, our ambition is to push the frontier of AI research and turn it into intuitive, safe, and useful tools that people love. That takes strong engineering systems, fast iteration, and a long-term focus on quality and reliability.Vijaye Raji will step into a new role as CTO of [Applications⁠](https://openai.com/index/leadership-expansion-with-fidji-simo/), reporting to Fidji Simo, following the acquisition of Statsig. As a hands-on builder and trusted leader, Vijaye will head product engineering for ChatGPT and Codex, with responsibilities that span core systems and product lines including infrastructure and Integrity.And then, later:As part of this transition, we’re acquiring Statsig.Normally, it would be very bizarre for a company to spend $1.1 billion to [hire an executive](https://techcrunch.com/2025/09/02/openai-acquires-product-testing-startup-statsig-and-shakes-up-its-leadership-team/), which is definitely how OpenAI frames this deal. But now, these sorts of [megacquihires](https://benn.substack.com/p/enough#:~:text=The%20week%20before,daily%20beat%20report.) are becoming routine. And if companies are paying billions to hire researchers, I suppose it makes sense to pay billions to hire executives to manage those researchers as well. (In contrast to everything here, Statsig’s own announcement [makes no mention of any of this](https://www.statsig.com/blog/openai-acquisition), and instead offers the [usual promises](https://benn.substack.com/p/the-conglomerate?utm_source=publication-search#:~:text=Acquisitions%20are%20about%20synergy%2C%20shared%20roadmaps%2C%20and%20teleprompter%20excitement%20for%20the%20next%20chapter%20of%20what%20two%20teams%20can%20build%20together.) about “carrying the vision forward” and “joining forces” and how “customers will remain a top priority.”)

[^6]: According to Statsig’s [terms of service](https://www.statsig.com/trust/security#:~:text=Access%20to%20your,group%20of%20customers.), access to customer data is “restricted to employees and contractors who have a need to know this information to perform their job function. For example, to provide customer support, maintain infrastructure, enhance product or to understand how an engineering change affects a group of customers.” On one hand, this is all pretty boilerplate stuff, and what nearly every SaaS service says. On the other hand, every SaaS service says it because it’s permissive, and they want the right to sniff around.

[^7]: [I’m a small personal investor in Dagster.](https://benn.ventures/)

================================================================================

# It is the internet

*And it is tearing us apart.*

---

![City Guide for Moving to Orem, UT | Neighbor Blog](https://substackcdn.com/image/fetch/$s_!UvP2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffaa400c1-c540-4779-a755-8d539ade7527_2560x911.jpeg)

I was a few minutes away from sending something else, and then [they caught the guy](https://www.nytimes.com/live/2025/09/12/us/charlie-kirk-news-suspect). They caught the guy and found his gun and bullet casings, and they were [inscribed with memes](https://www.nytimes.com/live/2025/09/12/us/charlie-kirk-news-suspect?smid=url-share#1dcd5b7e-e9a5-5f7b-993a-f57788539187).

We all know what happens next: [We get busy with the proof](https://fs.blog/some-advice-from-jeff-bezos/#:~:text=Faced%20with%20the%20choice%20between%20changing%20one%E2%80%99s%20mind%20and%20proving%20there%20is%20no%20need%20to%20do%20so%2C%20almost%20everyone%20gets%20busy%20on%20the%20proof.). We scrape through his past, parse his posts, and interpret his hieroglyphics, not to understand him, but to *position* him. Because, be honest, is that not what most people think, the moment they hear of some distant political killing? *Whose side is he on? I hope it was one of them who did it.*

But that is how we are now. Polarized, and posting about it. And it is that very thing, it seems, that made every aspect of this ugly moment. Charlie Kirk got famous on the internet, by being ([or playing](https://x.com/RachelBitecofer/status/1965860155595305011), to the extent that there is a difference) a [hideous character](https://www.nytimes.com/2025/09/11/us/charlie-kirk-views-guns-gender-climate.html) on the internet. He did it in support of a president who became president by commanding the same internet in the same way—by engineered outrage, [through memes and online melees](https://www.nytimes.com/2025/09/12/opinion/charlie-kirk-assassination-maga.html). And then some teenager spent too much time on that internet, got eaten by it; boiled alive by its toxicity and tribalism; by its thrashing, convulsing nonsense; by its recursive jokes; all compounding into a spiraling dump of self-referential symbolism and slop; a tightening gyre coiling into itself; hotter and hotter, until his reality was incinerated, melted out of his ears, and he bought a gun and shot someone else in the head.

Perhaps this is not new. There have always been provocateurs. We have always had gory politics. America has always been knee-deep in the blood of its own: It was fertilized by the bodies of its natives; by the teeth of its enslaved; by brothers killed by one another and by citizens killed by those they paid to protect them. Still, *something *feels different—about our [hopeless polarization](https://www.nytimes.com/2025/09/12/us/politics/charlie-kirk-voters-politics-violence.html); about the reckless abandon of our political discourse; about its scorched-earth absolutism; about the [mundane regularity](https://en.wikipedia.org/wiki/Luigi_Mangione) of [suicide missions](https://www.justice.gov/usao-mn/pr/vance-boelter-indicted-murders-melissa-and-mark-hortman-shootings-john-and-yvette-0) launched by one-man militias of poisoned madmen, ready to take their country back. We have always been like this, but have we always been like *this*?

We haven’t, many will say; and it is the other side’s fault. I would say the same, and I would mean it. But that is a lazy answer. Both sides have always had the other side to point to. Even if they are the problem, why are they the problem *now*?

From Ta-Nehisi Coates, writing about people who speculated [what they might have done if they lived in the antebellum South](https://www.theatlantic.com/national/archive/2011/12/a-muscular-empathy/249984/):

> It is comforting to believe that we, through our sheer will, could transcend these bindings—to believe that if we were slaves, our indomitable courage would have made us Frederick Douglass, or if we were slave masters, our keen morality would have made us [Bobby Carter](https://en.wikipedia.org/wiki/Robert_Carter_III#Later_life_and_career). We flatter ourselves, not out of malice, but out of instinct.
> Still, we are, in the main, ordinary people living in plush times. We are smart enough to get by, responsible enough to raise a couple of kids, thrifty to sock away for a vacation, and industrious enough to keep the lights on. We like our cars. We love a good cheeseburger. We'd die without air-conditioning. In the great mass of humanity that's ever lived, we are distinguished only by our creature comforts, and we are, on the whole, mediocre.
> That mediocrity is oft-exemplified by the claim that though we are unremarkable in this easy world, something about enslavement, degradation and poverty would make us exemplary. We can barely throw a left hook—but surely we would have beaten Mike Tyson. …
> If you really want to understand slaves, slave masters, poor black kids, poor white kids, rich people of colors, whoever, it is essential that you first come to grips with the disturbing facts of your own mediocrity. The first rule is this—You are not extraordinary. It's all fine and good to declare that you would have freed your slaves. But it's much more interesting to assume that you wouldn't have and then ask, "Why?"
> This is not an impossible task. But often we find that we have something invested in not asking "Why?" The fact that we—and I mean all of us, black and white—are, in our bones, no better than slave masters is chilling. The upshot of all my black nationalist study was terrifying—give us the guns and boats and we would do the same thing.

There is a corollary to our present moment, that is somehow both hopeful and desperate: It is not us, or them, that is the problem. It cannot be. Because we are, en masse, all the same as we always were. There is nothing constitutional in people today that is better or worse than it was before. We are all as mediocre as ever.

But the facilities around us are not. Now, we can build a giant machine that encourages us to indulge in our worst tendencies. We can [design that machine](https://benn.substack.com/p/the-scorpion-box?utm_source=publication-search#:~:text=Or%2C%20more%20generally%2C%20you%20could%20tell%20this%20story%20this%20way%3A) so that those who use it can mainline its most toxic and addictive chemicals. We can ask the machine to tell us [we are right](https://benn.substack.com/p/ban-chatgpt), and use it to [meet other people](https://benn.substack.com/p/runaway-train) who will also tell us we are right. We can drive ourselves mad by living in the machine—posting to it, fighting on it, and, eventually, murdering for it.

Sure, think more civil thoughts and pray for lower temperatures. Declare that we can overcome this awful habit. That’s all fine and good, I suppose. But it’s much more interesting to assume that we won’t, and to ask “Why?” And the answer seems as obvious as it is uncomfortable—nobody is in charge of the thermostat anymore. It is set by the invisible machinery of the internet and social media, and machinery can only turn the ratchet in one direction.

We all want all of this to stop. But keep giving us the internet and we will keep doing the same thing.

================================================================================

# Is the innovator's dilemma outdated?

*What's a platform and what's a product? Plus, what's a fad and what's fundamental? And finally, what?*

---

![](https://substackcdn.com/image/fetch/$s_!CV1A!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a11c615-607c-4113-af05-2de6b1c6a661_2144x1430.png)
*[Peace.](https://www.nytimes.com/2025/09/09/technology/apple-iphone-17-air-airpods.html)*

For years, a bad venture capitalist’s idea of a good question was, “How would your startup survive if Google[^1] decides to build the same thing you’re building?”

It sounds like a smart concern: Rather than being a simple question about what your product does or if people will want to buy it, it is about market dynamics, second-order effects, and competitive moats. It is about ecosystems, and economics, and [two-by-two grids full of little logos](https://hunterwalk.com/2020/05/25/if-your-pitch-deck-has-a-competitive-2x2-im-going-to-ask-you-this-question/). And to give a satisfying answer, you had to say some aesthetically clever thing, about data flywheels and network effects and the architectural implications of being mobile or cloud or blockchain or AI native.

But it was a [midwit](https://knowyourmeme.com/memes/iq-bell-curve-midwit) question, because Google wasn’t going to build your product. Your niche service—a CRM for private equity investors who are rolling up [regional car wash franchises](https://benn.substack.com/p/bis-third-form#:~:text=I%E2%80%99m%20raising%20a%20%2425%20million%20SPV%20to%20roll%20up%20all%20the%20regional%20car%20washes%20in%20north%20Florida); an observability tool to monitor engineers’ level of frustration, and profanity, when prompting a vibe-coding bot;[^2] a [non-discriminatory](https://www.nytimes.com/2023/11/18/technology/iphone-android-apple-rcs-messaging.html) texting app [to say hi to your bros](https://en.wikipedia.org/wiki/Yo_(app))—doesn’t matter to Google. To build your product, Google has to *decide* to build your product, and the only products Google wants to build are ones that can materially effect an [incomprehensibly big income statement](https://abc.xyz/assets/cc/27/3ada14014efbadd7a58472f1f3f4/2025q2-alphabet-earnings-release.pdf). It is not worth it, to Google, to reallocate budgets and create teams and develop roadmaps and generally disrupt the operational machinery of their very large businesses and very ambitious product bets to build something small and specialized.[^3] So they mostly don’t do that, until your startup becomes something big enough to attract their attention—and then [they’re just as likely to buy it](https://blog.google/inside-google/company-announcements/google-agreement-acquire-wiz/) as they are to build it.

Or, to paraphrase the [infamous innovator’s dilemma](https://rudyct.com/InovBis/The%20Innovator%E2%80%99s%20Dilemma%20(Clayton%20M.%20Christensen)2000.pdf), big firms don’t like small markets:

> Incumbent firms are likely to lag in the development of technologies—even those in which the technology involved is intrinsically simple—that only address customers' needs in emerging value networks. Disruptive innovations are complex because their value and application are uncertain, according to the criteria used by incumbent firms.

Of course, Google’s dilemma isn’t quite that small markets or niche products don’t matter *at all*; lots of small markets can add up to something big. The problem is that each market has some fixed overhead. For example, if you want to build [a robot to help technical analysts make sense of business data](https://benn.substack.com/p/can-analysis-ever-be-automated),[^4] you have to talk to a bunch of analytics teams about [their troubles](https://benn.substack.com/p/the-case-against-sql-formatting); you have to do competitive research; you have to develop your own sense of expertise and intuition about where you think the market might go and what future customers might want. And if Google is going to do this, and take all of these chances, the product that this process produces can’t disappear into a rounding error.

Therefore, Google isn’t building a dedicated product to help analysts write code.[^5] So who is? Well!

![](https://substack-post-media.s3.amazonaws.com/public/images/88cc17d2-58d6-4ff2-bee9-6249216d507d_1478x428.png)

When I search for “AI analyst,” that’s the first sponsored result that Google returns to me. But if you click on any of the links,[^6] you aren't sent to some dedicated analytics bot; you are sent to [https://claude.ai/new](https://claude.ai/new), *which starts a generic chat session with Claude.*

Nothing about the landing page is specifically designed for data analysis.[^7] Nothing about *Claude* is specifically designed for data analysis. Instead, Anthropic is advertising that their very general chatbot can be used for a very specific thing. Or, put differently, they are launching a new product *with just an ad*.

Actually, no. They are launching [dozens of new products](https://adstransparency.google.com/advertiser/AR15899303072422166529?region=US) with ads. [A brand strategist](https://benn-dot-files.s3.us-west-2.amazonaws.com/claude-ads/need-brand-strategy.png); [a copywriter](https://benn-dot-files.s3.us-west-2.amazonaws.com/claude-ads/copywriting-help.png); [a marketing roadmap designer](https://benn-dot-files.s3.us-west-2.amazonaws.com/claude-ads/marketing-roadmap.png); [a JSON formatting utility](https://benn-dot-files.s3.us-west-2.amazonaws.com/claude-ads/json-formatter.png); [a market research analyst](https://benn-dot-files.s3.us-west-2.amazonaws.com/claude-ads/market-research-analysis.png)—Claude launched all of these products and services with ads, each of which sends you to the same undecorated URL for the same utility chatbot.

Which is weird! Or at least, very different! It used to be that, to build something, a company had to do it intentionally. This opened up a lot of space for new products, because, as small companies grew bigger, they stopped chasing small things. Shrubs will choke out the grass, but tall trees do not.

Now, when AI labs update their models or chat apps, products accidentally fall out. For example: Both [WriteSonic](https://writesonic.com/) and [Jasper](https://www.jasper.ai/) initially [launched](https://www.producthunt.com/products/writesonic-2/launches/writesonic) [themselves](https://www.ycombinator.com/companies/jasper-ai) as tools for creating marketing content. WriteSonic (then ChatSonic) “[surpasses the limitations of ChatGPT](https://www.ycombinator.com/launches/HiY-chatsonic-like-chatgpt-but-with-real-time-data-images-voice-search) to give you factually correct results” by integrating “with Google Search to create content with the latest information.” And Jasper was a wrapper around GPT-3, and plugged some of ChatGPT’s early holes with models taught to be better marketers. [According to Jasper’s CEO](https://techcrunch.com/2022/10/18/ai-content-platform-jasper-raises-125m-at-a-1-7b-valuation/), their “language models—trained on 10% of the web and fine-tuned for ‘customer specificity’—set it apart.”

Then the foundational models became better marketers—not because OpenAI or Anthropic decided that they especially cared about creating marketing content, but because the models became generically “smarter:” They could write better, search more, and more effectively reason their way through anything, including how to write corporate blog posts, on their own. The marketing sense that WriteSonic and Jasper wrapped around ChatGPT was eventually baked into ChatGPT itself. And now, WriteSonic pivoted into becoming an [AI SEO analyst](https://www.ycombinator.com/launches/Mnd-writesonic-the-ai-seo-agent-that-replaces-10k-month-agencies), while Jasper is no longer a writing product, but a “[full stack AI platform](https://www.jasper.ai/platform),” with a no-code app builder, an AI context layer,[^8] and hundreds of integrations into tools like [Word](https://appsource.microsoft.com/en-us/product/office/WA200006001?tab=Overview), [Google Docs](https://workspace.google.com/marketplace/app/jasper/914955604864), and [Google Sheets](https://workspace.google.com/marketplace/app/jasper_api/117453631616).

[Ah well](https://www.anthropic.com/news/create-files):

> Claude can now create and edit Excel spreadsheets, documents, PowerPoint slide decks, and PDFs directly in [Claude.ai](https://claude.ai/redirect/website.v1.a2817974-26db-4837-8f49-b6cc98765f15) and the desktop app. This transforms how you work with Claude—instead of only receiving text responses or in-app artifacts, you can describe what you need, upload relevant data, and get ready-to-use files in return.

That URL points to the exact same place as all of Anthropic’s ads: An empty chat session with Claude. One new feature; a hundred products, incidentally subsumed.

A while back, I said that OpenAI [might become another AWS](https://benn.substack.com/p/the-public-imagination):

> The more lucrative opportunity for OpenAI, it seems, is to sit behind the apps that are fighting for our attention. In that scenario, whoever wins, so does OpenAI[9].

[And the footnote:](https://benn.substack.com/p/the-public-imagination#footnote-9-110431823)

> Though it’s possible to be both AWS and the iPhone, that’s a very tall order. As [Steve Yegge suggested](https://gist.github.com/chitchcock/1281611) in his [famous memo](https://www.washingtonpost.com/blogs/blogpost/post/google-engineer-steve-yegge-has-his-jerry-maguire-moment/2011/10/13/gIQATU1hkL_blog.html) about Google and Amazon, you can be a great platform or a great product.

But maybe that is changing. If more and more software starts to look like a [smart robot and a spreadsheet](https://benn.substack.com/p/saas-20), *the platform and the product are effectively the same thing*. In an AI marketer—or an AI analyst, or an AI engineer—where’s the line between the application and the foundational infrastructure? Are clever prompts, manual reasoning loops, and context engineering features of the app, or the model? How will your startup survive if Anthropic accidentally builds the same thing you’re building?

# The fundamentals

Do your parents know what’s cool?

Do they know what people like? Do they know who’s popular on the internet? Do they know which influencers are [drawing crowds](https://www.nj.com/entertainment/2025/09/thousands-of-screaming-fans-overwhelm-american-dream-mall-for-teen-youtube-stars-appearance.html), [starting riots](https://en.wikipedia.org/wiki/2023_Union_Square_riot), [building cults](https://www.vice.com/en/article/leader-the-biggest-tiktok-cult-melissa-ong-step-chickens-pandemic/)? Do they know how kids talk? Do they understand [the words they use](https://www.tiktok.com/@mr_lindsay_sped/video/7496653158593088810)? The emojis? The memes?

If you asked them to post on Twitter for you, would you trust them to do it? On Instagram? On LinkedIn, even? If you asked them to represent your personality on the internet—your brand, your style, your voice, your sense of humor, *you*, for all intents and purposes, since who you are on the internet is perhaps a more canonical version of yourself than who you are off it—would you let them?

Do they understand how today’s society works? Do they understand the traffic of modern commerce? Do they know what TikTok Shop is? Do they know that it's [bigger](https://www.bloomberg.com/news/articles/2024-12-04/tiktok-shop-triples-black-friday-sales-topping-100-million) than [Macy's](https://www.macysinc.com/newsroom/news/news-details/2025/Macys-Inc.-Reports-Fourth-Quarter-and-Fiscal-Year-2024-Results/default.aspx)? Do they know what people shop for, and why they buy what they buy? Do they know [who tells them what to buy](https://www.wsj.com/style/fashion/demetra-dias-tiktok-shopping-hauls-c2efee91)? Do they know which stores they like? Can they find the stores; can they even comprehend of their [metaphysical existence](https://nymag.com/intelligencer/article/what-is-roblox-video-game-app-metaverse-safe-children-ban.html)?

Do they know what’s trending? Do they know what’s cringe? What’s chopped? Do they know how tall LaMelo Ball is?

Anyway, earlier this week, Apple launched several new products, including the next generation iPhone, and [Ben Thompson thought something seemed missing](https://stratechery.com/2025/iphones-17-and-the-sugar-water-trap/):

> What was shocking to me, however, was actually watching the event in real time: my group chats and X feed acknowledged that the event was happening, but I had the distinct impression that almost no one was paying much attention, which was not at all the case a decade ago.

Thompson offered a commercial explanation: People care about AI now, not phones and hardware. Apple’s AI efforts have been haltingly inconsistent, and “why should anyone who cares about AI—which is to say basically everyone else in the industry—care about square camera sensors or vapor chambers?”

That may be true, but you have to wonder if it misses something larger: That Apple—and Thompson, and me, and probably many of you—have an outdated understanding of how the world works. It may be that nobody was talking about Apple’s big launch event because Apple isn’t doing interesting things with AI, but it also may be because *big launch events have no cultural traction*. They, like us, are part of a shrinking conversational artery. Apple’s playbook is stale; its vocabulary is stale; its entire economic model of demand generation is stale. [Apple’s launch events](https://www.youtube.com/watch?v=H3KnMyojEQU) are losing their grip over Silicon Valley because everything has to be a [meme](https://benn.substack.com/i/169857033/everyone-is-crazy-now) or a [controversy](https://benn.substack.com/p/it-is-the-internet) now, and polite launch events don’t produce [memes](https://www.youtube.com/watch?v=IwzF26o0AuU) or [controversy](https://www.nytimes.com/2025/08/05/style/american-eagle-stock-trump-sydney-sweeney.html).[^9]

It is easy to see when other people are the [unc](https://www.tiktok.com/@bleacherreport/video/7528192060785020191). They are from an earlier generation; a different time. For a while, when you’re living in the main channel, the world confirms your instincts: Their weird anachronisms are disappearing, and your vocabulary is ascendant.

But then we get stuck. And it is much harder to let go of our own sense of cosmology—because our beliefs don’t feel like fads, but fundamentals. Apple could make memes, sure, but tight messaging is fundamental. Polish and quality is fundamental. A well-executed launch is fundamental. *The innovator’s dilemma is fundamental.* The old generations believed in discredited science; our beliefs are settled science; the new generations are chasing pseudoscience.

[But you see the problem, right?](https://www.youtube.com/watch?v=a3VByFO2jKI)

# MSNBC becomes BI

You could have two theories about [this recent opinion piece](https://www.ft.com/content/de527ea7-04c1-4b82-af14-517d96ad1e36) in the *Financial Times*:[^10]

> President Donald Trump thinks the habit of forcing companies to report earnings at three-monthly intervals is “[Not good!!!](https://truthsocial.com/@realDonaldTrump/posts/115208219886830624)”. He is probably right. But since he [last complained](https://www.ft.com/content/c1d133aa-a211-11e8-85da-eeb7a9ce36e4) about quarterly reporting in 2018, the debate has moved on. The alternative will soon be not less disclosure, but much more.
> …
> Between businesses shifting their data to the cloud and artificial intelligence creating new ways to slice and dice it, it should one day be possible to see how companies are performing in close to real time. Tech groups such as Palantir, Databricks and Snowflake already help companies turn disparate records into crunchable digital data for executives to use and peruse. AI agents can summon information, package it and add gloss as well as any silver-tongued chief executive.
> Company bosses will blanch at the idea of radical financial transparency. After all, it amounts to handing over some control of how corporate facts are presented. Real-time reporting would also reduce the value of financial window-dressing — arranging cash flows to make the quarterly snapshot more attractive — to zero. Still, some nerves could be allayed by keeping a one-month lag, or by presenting data on a three-month average basis.
> Such innovations may be a while away, because AI still makes mistakes and thus requires human review. …
> Nonetheless, AI is advancing faster than most executives and investors thought possible a couple of years ago. And as the technology makes real-time data and analysis easier and faster to generate, it is naive to think that companies can get away with offering investors less information than they do now. Odds are that reporting financial performance at three-month intervals will indeed become a thing of the past, but not for the reasons Trump has proposed.

The first theory is: What?

Google doesn’t publish live dashboards of how many people are using Google because Wall Street analysts can’t write a SQL query, or because they *can’t compute a three-month average* in Excel without ChatGPT; they don’t publish it because they don’t want to! And when they do want to, they do publish it! [Famously so!](https://trends.google.com/trending?geo=US) What does AI have to do with any of this!

More generously, the second theory is: It’s not the game the company cares about; [it’s the broadcast](https://benn.substack.com/p/a-new-invisible-hand):

> Though [data] exists in an approximately raw form, most analysis comes with some sort of narrative. Corporate analysts caption their presentations to call out what’s most important. The *Wall Street Journal* delivers quantitative news in paragraphs of prose. Just as we’re given selective views of a basketball game [during a broadcast] , data consumers—executives, “business users,” the people who ask analysts questions—are typically given curated cuts of data, with its own sidebar of color commentary. …
> But those words—even seemingly innocuous ones, the sort that most people would still describe as objective—are inevitably manipulative. As I’m writing this, the top headline on the Wall Street Journal is about Google. [That article](https://www.wsj.com/business/earnings/google-earnings-alphabet-q1-2025-googl-stock-210b34b6?mod=hp_lead_pos1) opens with what appears to be basic reporting:—*Google’s earnings power is holding up well, even as the internet giant spends record sums on artificial intelligence in the midst of global economic turbulence.*
> *Parent company reported operating income of $30.6 billion for the first quarter on Thursday—solidly beating Wall Street’s forecast of $28.7 billion.—*Holding up? Holding up *well*? *Solidly* beating forecasts? Is a $2 billion beat solid? Expected? Record-setting? I don’t know. But I assume it must be solid, because that’s what it says. Had that line said “barely beating Wall Street’s forecast of $28.7 billion,” my perspective on Google would be entirely different, even if the numbers were the same.

That’s* *why AI could change how companies report data—not because it can write queries for Wall Street analysts, but because it can *influence* Wall Street analysts. If companies put public chatbots on top of their corporate databases, it won’t be for radical transparency, or because they haven’t had the technology to “crunch digital data” without it. Instead, they’ll do it because that chatbot will be told that it should use the right optimistic adjectives, that it should keep to the company line about the company’s recent performance, and that it should not look [quiet and downbeat](https://www.wsj.com/business/nestle-ceo-resigns-employee-tip-0e6e7c30) when it’s asked if the CEO is having an affair.

Everything becomes BI, but BI becomes the corporate spokesperson.


---


[^1]: Or Amazon, or Microsoft, or Facebook, or Salesforce, or any other huge tech company with global reach, a printing press in their basement, and the ability to will a [redundant](https://www.forbes.com/sites/siladityaray/2023/07/10/with-100-million-users-in-five-days-threads-is-the-fastest-growing-app-in-history/) and [unpopular](https://www.sec.gov/Archives/edgar/data/1288776/000119312512017008/d285258dex991.htm#:~:text=Google%2B%2C%20which%20now%20has%2090%C2%A0million%20users%20globally) product out to 100 million users by sending out a handful of push notifications.

[^2]: Over or under: Someone gets fired for threatening an AI by January 1, 2027. (And when it happens, how does *that* get politically coded? Who’s on which side in that case?)

[^3]: Google’s balance sheet says its figures are displayed “in millions,” and there are no decimals. Google makes $28 billion in profit every quarter. Google makes more than $300 million in profit *every day*. Google’s daily profit is bigger than the lifetime revenue of your startup; it is bigger than your startup’s paper valuation; it is bigger than your total addressable market.

[^4]: But [Macro](https://getmacro.com/)—built by several of Mode’s best!—is! The reviews from its users—relayed to me by a Macro employee, but still!—are that it “looks like the best thing for analysis I've ever seen!” Check it out! ([But also, you know.](https://benn-dot-files.s3.us-west-2.amazonaws.com/everything-becomes-bi.png))

[^5]: They have a [conversational chatbot](https://cloud.google.com/blog/products/business-intelligence/conversational-analytics-in-looker-is-now-in-preview) inside of Looker and a [Gemini integration inside of BigQuery](https://cloud.google.com/gemini/docs/bigquery/overview), but neither are a specialized service for data analysts [like Julius](https://julius.ai/) (or Macro!).

[^6]: If you click on the image above, it’ll pass you through the same interstitial that Google sends you through.

[^7]: It’s a little surprising to me that they don’t have some mechanic that updates the placeholder text in the chat box that says “How can I help you today?” with something like “What data can I help you analyze?”

[^8]: I did not know that I stole [this](https://benn.substack.com/p/the-context-layer).

[^9]: Of note: That Gap ad and the Apple launch event have almost exactly the same number of views on YouTube. But the Gap ad [blew up on TikTok](https://apnews.com/article/katseye-interview-gap-ad-9b42686b193b16150fdc6371bca1dee1)—and then, [in](https://www.cosmopolitan.com/entertainment/celebs/a65956866/katseye-gap-commercial-choreo/) the [zeitgeist](https://www.hollywoodreporter.com/music/music-news/milkshake-streams-double-after-katseyes-viral-gap-denim-ad-1236359237/).

[^10]: Shout to [Camille Fournier](https://www.camilletalk.com/) for this very excellent find.

================================================================================

# We were hired to do the grunt work

*If solving strategic problems is the more valuable thing to do, why aren't we doing it?*

---

![](https://substackcdn.com/image/fetch/$s_!2gG0!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bdfe8e9-0661-403b-ab2c-06de07938518_622x338.png)
*[salvation](https://the-leftovers.fandom.com/wiki/Sudden_Departure)*

If you regularly talk to people who work at technology companies, you will discover something surprising: Everyone is doing the wrong job. Most engineers are fixing bugs, migrating services between clouds, or upgrading some frontend framework from version 7.1.12 to 9.3.[^1] Most data analysts are answering the same dumb[^2] questions that they answered last month, living every week at the intersection of *Groundhog Day *and [LMGTFY](https://letmegooglethat.com/?q=LMGTFY). Most marketers are rewriting blog posts as LinkedIn posts and reconciling lists of leads. Most product managers are writing tedious specs and following up; most lawyers are converting everything to .docx and tracking tedious changes; most finance directors are conditionally formatting tedious Excel workbooks. Most managers are making decks; they are coordinating, aligning, reviewing; they are in back-to-back meetings that should’ve been emails.

Have a drink with a person who works in technology, and they will eventually tell you how they feel about their job: They are stuck in a white collar salt mine. The majority of their day is spent slogging through grunt work that is, if not beneath them, beneath their potential. They were hired to do higher impact work; more strategic work; more *valuable* work.

Product managers will say they should be dreaming up groundbreaking features, not sending status updates. Engineers will say they should be building those features, not bespoke integrations for a big customer. Analysts will say they want to be looking for strategic insights, not making yet another dashboard. Marketers will say they should be designing the next great brand; lawyers should be engineering the next [great](https://www.propublica.org/article/lord-of-the-roths-how-tech-mogul-peter-thiel-turned-a-retirement-account-for-the-middle-class-into-a-5-billion-dollar-tax-free-piggy-bank) tax [shenanigans](https://www.cooleygo.com/maximizing-qsbs-for-entrepreneurs/); finance directors should be engineering the [next great Bitcoin shenanigans](https://x.com/microstrategy).[^3] Managers will wonder if they should be managers at all.

But we are stuck doing these things—these inconsequential, minor tasks—because something is in the way. Our organization is too dysfunctional. Or we haven’t hired the right people yet. The tools we use are too brittle and need to be upgraded; the right infrastructure hasn’t been built; our tech debt hasn’t been repaid. Or our corporate overlords simply do not appreciate us for what we’re good at, and they keep asking us to do other stuff instead.

And so, if you talk to hopeful people in technology, they will say that they are waiting: Waiting for the reorg that will change their responsibilities. Waiting for the migration to be over. Waiting for the self-serve platform to be done; waiting for the open roles to be filled. Waiting to be saved.

You could have two theories about all of this:

The argument for the first point is that it sounds very nice, and that we want it to be true. The argument for the second point is that it is empirically true*. *[The rapture never comes](https://www.nytimes.com/2025/09/23/us/rapture-tiktok-sept-23.html). Reorgs come and go, and new problems land in our lap. The migration to 9.3 rolls into the migration to 11.2.1.[^4] People keep asking us questions instead of using the dashboards we built for them. The new hire needs to be onboarded; the new hire is starting to help; the new hire just quit to take a “more strategic” role somewhere else. Everything changes, and the indignities remain.

Anyway, things that sound nice are easier to sell, and this week, [Microsoft promised to be next savior](https://azure.microsoft.com/en-us/blog/accelerate-migration-and-modernization-with-agentic-ai/):

> Every organization has an innovation agenda. Whether it’s building AI-native applications, creating more engaging customer experiences, or unlocking new efficiencies—ambition is never the problem. But for many teams, it’s their technical debt that stands in the way. Legacy systems, outdated codebases, and fragmented infrastructure slow progress and drain resources. In fact, over 37% of application portfolios require modernization today—and that number will remain high over the next three years. Developers want the freedom to innovate, but migration and modernization is often slow, complex, and hard to start. These delays translate into lost opportunities and stalled transformation.
> Generative AI changes the game.

This is a common refrain these days: AI will finally be the thing to deliver us from evil.[^5] It will automatically [fix our bugs](https://cursor.com/bugbot), or [upgrade our databases](https://azure.microsoft.com/en-us/blog/accelerate-migration-and-modernization-with-agentic-ai/); it will create [tweets from blog posts](https://spiral.computer/old-home); it will [answer the dumb questions](https://www.databricks.com/product/business-intelligence); [it will follow up](https://www.usemotion.com/features/ai-project-manager). It will [track changes](https://www.harvey.ai/platform/word-add-in) and [format spreadsheets](https://sourcetable.com/). [It might be our manager](https://benn.substack.com/p/how-much-agency-do-we-actually-want), so that we don’t have to be. And that, of course, will give us the “freedom to innovate.”

But does having the former—robots to do rote work—necessarily imply the latter—that our jobs will be better? I mean. [From Dan Shipper at ](https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy)*[Every](https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy)*[:](https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy)

> You won’t be judged on how much you know, but instead on how well you can allocate and manage the resources to get work done. …
> Even junior employees will be expected to use AI, which will force them into the role of manager—model manager. Instead of managing humans, they’ll be allocating work to AI models and making sure the work gets done well. They’ll need many of the same skills as human managers of today do (though in slightly modified form).

And more recently, [from Julie Zhao](https://lg.substack.com/p/managing-ai-is-like-managing-humans):

> The old boundary lines are blurring. Just as we’ll see fewer “pure managers,” we’ll also see fewer “pure ICs.” Instead, more people will live in the messy middle: sometimes executing, sometimes designing processes, sometimes coordinating.

And just this week, [Deena Mousa](https://x.com/deenamousa/status/1971211420965781509) published [a new study](https://worksinprogress.co/issue/the-algorithm-will-see-you-now/) in *Works in Progress *investigating how AI was infiltrating radiology, where “there are over 700 FDA-cleared radiology models, which account for more than three-quarters of all medical AI devices:”

> A radiologist can’t just “hand off” a scan to AI. To cover a typical day, they’d need to pick from dozens of different models, run each one separately, and stitch the answers together.
> Even platforms that bundle multiple models still spit out a list of disconnected yes/no answers.

Do these things sound fun? Does coordinating robots and and comparing AI-generated diagnostic reports sound like strategic work? Or is this just the next generation of an email job?

If you talk to technologists about how AI might change how we work, [they](https://x.com/satyanadella/status/1883753899255046301?lang=en) will [eventually](https://www.npr.org/sections/planet-money/2025/02/04/g-s1-46018/ai-deepseek-economics-jevons-paradox) tell [you](https://www.nytimes.com/2025/02/14/business/deepseek-openai-jevons-paradox.html) about the [Jevons paradox](https://en.wikipedia.org/wiki/Jevons_paradox):[^6] As technology makes some resources more efficient, demand for those resources go up. More efficient coal-burning engines make us burn *more* coal, because we use engines for more things. As computers get smaller and cheaper, we first [put one in every home](https://quartr.com/insights/business-philosophy/bill-gates-the-man-who-put-a-computer-in-every-home) and then in every pocket. And, the extrapolation goes, if AI helps radiologists—or engineers, or [analysts](https://hex.tech/blog/jevons-paradox-demand-for-insight/), or any other job—work faster, [a lot more demand shows up](https://x.com/karpathy/status/1971220449515516391).

In any economic discussion about AI, this story is [our blunt instrument of choice](https://x.com/levie/status/1971226298786906490): Demand increases; life gets better; QED. But there’s also a bizarro, Waluigi version of the Jevons paradox that can also be true: No matter how many things technology makes convenient, the supply of inconvenient things seems to remain constant. If managers don’t have to write letters or send faxes, they become bogged down with more email. If accountants don’t have to do math by hand, they create dozens of mismatched spreadsheets. If engineers don’t have to program computers with punchcards, they create an avalanche of bugs that need to be fixed.

Likewise, when AI answers annoying analytical questions, [our jobs will be to review its work](https://benn.substack.com/p/can-analysis-ever-be-automated). When AI resolves engineering tickets, we will spend more time shuffling them around a kanban board. When AI cranks out 200,000,000 personalized Taco Bell ads, we have that many more email lists to reconcile. When AI diagnoses medical images, we spend our time stitching it all together. 

What will people who work at technology companies tell you, if you talk to them in ten years? I have no idea. But I suspect they will tell you that they are doing too much tedious grunt work, and they are hopeful that [they will soon be saved](https://www.telegraph.co.uk/news/uknews/1422794/Newton-set-2060-for-end-of-world.html).


---


[^1]: The latest release is 11.2.6.

[^2]: “Dumb” is a verbatim quote from the last conversation I had about this.

[^3]: The [replies](https://x.com/dariosats/status/1958575870076940501) to MicroStrategy’s tweets are [all](https://x.com/kasper_dolberg1/status/1965512582049226965) of [us](https://x.com/smelsopol/status/1965397919517020247).

[^4]: 11.2.6 requires Python 3.16, but we’re on 3.11, and that upgrade is blocked.

[^5]: Though really, it will probably [lead us to temptation](https://finance.yahoo.com/quote/YUM/earnings/YUM-Q2-2025-earnings_call-340323.html) (e.g., [Crispy Chicken Nuggets with Diablo Sauce](https://www.instagram.com/p/DJ9y-4bP1xC/) and a [Mountain Dew Baja Midnight](https://www.instagram.com/p/DOwLvNDjuQx/)):In Taco Bell US, 41 percent of our orders are digital, fueled by loyalty offers and unique digital activations like Mike’s Hot Honey Tuesday Drop and Feed the Beat Record Club box. Taco Bell’s unique activations helped grow active loyalty consumers nearly 45 percent year-over-year. Across the organization, AI is supercharging our marketing. Over 200 million AI-generated communications have been sent this year, delivering up to five times incrementality compared to traditional approaches.

[^6]: And Jevon’s paradox states that, as a concept becomes more widely known, we will all inevitably become more confused by it, because we will assume it was created someone named Jevon, and is therefore called Jevon’s paradox, or maybe even Jevons’ paradox, when it is, in fact, apparently, *the* Jevons paradox.